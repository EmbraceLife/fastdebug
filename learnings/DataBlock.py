
@docs=====================================================================================(0)       
@funcs_kwargs=============================================================================(1)       
class DataBlock():========================================================================(2)       
    "Generic container to quickly build `Datasets` and `DataLoaders`."====================(3)       
    get_x=get_items=splitter=get_y = None=================================================(4)       
    blocks,dl_type = (TransformBlock,TransformBlock),TfmdDL===============================(5)       
    _methods = 'get_items splitter get_y get_x'.split()===================================(6)       
    _msg = "If you wanted to compose several transforms in your getter don't forget to wrap them in a `Pipeline`."                                      (7)
    def __init__(self, ===================================================================(8)       
        blocks:list=None, # One or more `TransformBlock`s=================================(9)       
        dl_type:TfmdDL=None, # Task specific `TfmdDL`, defaults to `block`'s dl_type or`TfmdDL`                                                         (10)
        getters:list=None, # Getter functions applied to results of `get_items`===========(11)      
        n_inp:int=None, # Number of inputs================================================(12)      
        item_tfms:list=None, # `ItemTransform`s, applied on an item ======================(13)      
        batch_tfms:list=None, # `Transform`s or `RandTransform`s, applied by batch========(14)      
        **kwargs, ========================================================================(15)      
    ):====================================================================================(16)      
        blocks = L(self.blocks if blocks is None else blocks)=============================(17)      
        blocks = L(b() if callable(b) else b for b in blocks)=============================(18)      
        self.type_tfms = blocks.attrgot('type_tfms', L())=================================(19)      
        self.default_item_tfms  = _merge_tfms(*blocks.attrgot('item_tfms',  L()))=========(20)      
        self.default_batch_tfms = _merge_tfms(*blocks.attrgot('batch_tfms', L()))=========(21)      
        for b in blocks:==================================================================(22)      
            if getattr(b, 'dl_type', None) is not None: self.dl_type = b.dl_type==========(23)      
        if dl_type is not None: self.dl_type = dl_type====================================(24)      
        self.dataloaders = delegates(self.dl_type.__init__)(self.dataloaders)=============(25)      
        self.dls_kwargs = merge(*blocks.attrgot('dls_kwargs', {}))========================(26)      
                                                                                                                                                        (27)
        self.n_inp = ifnone(n_inp, max(1, len(blocks)-1))=================================(28)      
        self.getters = ifnone(getters, [noop]*len(self.type_tfms))========================(29)      
        if self.get_x:====================================================================(30)      
            if len(L(self.get_x)) != self.n_inp:==========================================(31)      
                raise ValueError(f'get_x contains {len(L(self.get_x))} functions, but must contain {self.n_inp} (one for each input)\n{self._msg}')     (32)
            self.getters[:self.n_inp] = L(self.get_x)=====================================(33)      
        if self.get_y:====================================================================(34)      
            n_targs = len(self.getters) - self.n_inp======================================(35)      
            if len(L(self.get_y)) != n_targs:=============================================(36)      
                raise ValueError(f'get_y contains {len(L(self.get_y))} functions, but must contain {n_targs} (one for each target)\n{self._msg}')       (37)
            self.getters[self.n_inp:] = L(self.get_y)=====================================(38)      
                                                                                                                                                        (39)
        if kwargs: raise TypeError(f'invalid keyword arguments: {", ".join(kwargs.keys())}')                                                            (40)
        self.new(item_tfms, batch_tfms)===================================================(41)      
                                                                                                                                                        (42)
    def _combine_type_tfms(self): return L([self.getters, self.type_tfms]).map_zip(=======(43)      
        lambda g,tt: (g.fs if isinstance(g, Pipeline) else L(g)) + tt)====================(44)      
                                                                                                                                                        (45)
    def new(self, ========================================================================(46)      
        item_tfms:list=None, # `ItemTransform`s, applied on an item=======================(47)      
        batch_tfms:list=None, # `Transform`s or `RandTransform`s, applied by batch =======(48)      
    ):====================================================================================(49)      
        self.item_tfms  = _merge_tfms(self.default_item_tfms,  item_tfms)=================(50)      
        self.batch_tfms = _merge_tfms(self.default_batch_tfms, batch_tfms)================(51)      
        return self=======================================================================(52)      
                                                                                                                                                        (53)
    @classmethod==========================================================================(54)      
    def from_columns(cls, ================================================================(55)      
        blocks:list =None, # One or more `TransformBlock`s================================(56)      
        getters:list =None, # Getter functions applied to results of `get_items`==========(57)      
        get_items:callable=None, # A function to get items================================(58)      
        **kwargs,=========================================================================(59)      
    ):====================================================================================(60)      
        if getters is None: getters = L(ItemGetter(i) for i in range(2 if blocks is None else len(L(blocks))))                                          (61)
        get_items = _zip if get_items is None else compose(get_items, _zip)===============(62)      
        return cls(blocks=blocks, getters=getters, get_items=get_items, **kwargs)=========(63)      
                                                                                                                                                        (64)
    def datasets(self, ===================================================================(65)      
        source, # The data source=========================================================(66)      
        verbose:bool=False, # Show verbose messages=======================================(67)      
    ) -> Datasets:========================================================================(68)      
        self.source = source                     ; pv(f"Collecting items from {source}", verbose)                                                       (69)
        items = (self.get_items or noop)(source) ; pv(f"Found {len(items)} items", verbose)                                                             (70)
        splits = (self.splitter or RandomSplitter())(items)===============================(71)      
        pv(f"{len(splits)} datasets of sizes {','.join([str(len(s)) for s in splits])}", verbose)                                                       (72)
        return Datasets(items, tfms=self._combine_type_tfms(), splits=splits, dl_type=self.dl_type, n_inp=self.n_inp, verbose=verbose)                  (73)
                                                                                                                                                        (74)
    def dataloaders(self, ================================================================(75)      
        source, # The data source=========================================================(76)      
        path:str='.', # Data source and default `Learner` path ===========================(77)      
        verbose:bool=False, # Show verbose messages=======================================(78)      
        **kwargs==========================================================================(79)      
    ) -> DataLoaders:=====================================================================(80)      
        dsets = self.datasets(source, verbose=verbose)====================================(81)      
        kwargs = {**self.dls_kwargs, **kwargs, 'verbose': verbose}========================(82)      
        return dsets.dataloaders(path=path, after_item=self.item_tfms, after_batch=self.batch_tfms, **kwargs)                                           (83)
                                                                                                                                                        (84)
    _docs = dict(new="Create a new `DataBlock` with other `item_tfms` and `batch_tfms`",==(85)      
                 datasets="Create a `Datasets` object from `source`",=====================(86)      
                 dataloaders="Create a `DataLoaders` object from `source`")===============(87)      
                                                                                                                                                        (88)
