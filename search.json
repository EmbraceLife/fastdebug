[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning fastai with joy",
    "section": "",
    "text": "The first step to learn fastai with joy is to make revision easier. I would like to be able to search learning points in fastai notebooks with ease.\nIf I want to read or run the notebook, I could click the second link to run the notebook on Kaggle.\n\nfastnbs(\"how gradient accumulation work\")\n\n\n\n\n\n\n\n\nFor instance, here’s a basic example of a single epoch of a training loop without gradient accumulation:\nfor x,y in dl:\n    calc_loss(coeffs, x, y).backward()\n    coeffs.data.sub_(coeffs.grad * lr)\n    coeffs.grad.zero_()\nHere’s the same thing, but with gradient accumulation added (assuming a target effective batch size of 64):\ncount = 0            # track count of items seen since last weight update\nfor x,y in dl:\n    count += len(x)  # update count based on this minibatch size\n    calc_loss(coeffs, x, y).backward()\n    if count>64:     # count is greater than accumulation target, so do weight update\n        coeffs.data.sub_(coeffs.grad * lr)\n        coeffs.grad.zero_()\n        count=0      # reset count\nThe full implementation in fastai is only a few lines of code – here’s the source code.\nTo see the impact of gradient accumulation, consider this small model: \ntrain('convnext_small_in22k', 128, epochs=1, accum=1, finetune=False)\n\n\nOpen 0010_fastai_scaling_up_road_to_top_part_3 in Jupyter Notebook locally\n\n\nOpen 0010_fastai_scaling_up_road_to_top_part_3 in Jupyter Notebook on Kaggle\n\n\nIf fastnbs doesn’t return anything to your query, it is because the search ability of fastnbs is minimum, I need to learn to improve it. But don’t worry the next function below fastlistnbs will assist you to continue searching.\n\n\n\nI would also like to view all the learning points (in the form of questions) of all the fastai notebooks I have studied. This is a long list, so press cmd + f and search keywords e.g., “ensemble” to find the relevant questions, and then use fastnbs to search and display the details like above.\npress cmd + o to view them all without scrolling inside a small window\n\nfastlistnbs()\n\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0007_fastai_how_random_forests_really_work.md\n## Introduction\n### why ensemble of decision trees, such as Random Forests and Gradient Boosting Machines\n### how to set print options for numpy and import `fastai.imports`\n## Data preprocessing\n### how to get Titanic dataset ready for creating a decision tree model\n## Binary splits\n### what is binary splits and who does it work\n### how to plot barplot and countplot with Seaborn\n### Create a simplest model based on binary split\n### how to do train and test split using `sklearn.model_selection.train_test_split`\n### how to access dependent and independent values for both training set and test set \n### calc the prediction (the simplest so far)\n### calc loss with mean absolute error using `sklearn.metrics.mean_absolute_error`\n### how to do binary split on a continuous column rather than category column\n### how to plot a boxenplot on survival and non-survival using `sns.logFare` column; how to a density plot with logFare using `sns.kdeplot` \n### how to find the binary split to calc predictions based on logFare using the boxenplot above\n### see how good is this model and prediction using loss (mean absolute error)\n### how does impurity measure the goodness of a split; how to create impurity as a measure for how good of a split\n### how to create a score function for a single side of the split\n### how to create the score function to measure the goodness of a binary split\n### calc the impurity score for sex split and then logFare split\n### how to make interactive on choose different split and calc score on continuous columns\n### how to make interactive on choose different split and calc score on categorical columns\n### how to make a list of all possible split points\n### how to get the score for all possible splits of a particular column like Age; how to get the index for the lowest core\n### how to write a function to return the best split value and its score on a particular column given the dataframe and the name of the column\n### how to run this function on all columns of the dataset\n### what is OneR classifier; why should it be a baseline to more sophisiticated models\n## Creating a decision tree\n### how is to do better than a OneR classifier which predict survival using sex? how about doing another OneR upon the first OneR classifier result (male group and female group)\n### how to get the dataset splitted by sex in pandas dataframe\n### how to find the best binary splits and score out of all columns in male dataset and then femal dataset\n### what does a decision tree mean when the second binary split is done here\n### how to do a decision tree automatically using sklearn\n### how to visualize the decision tree above\n## how is gini different from impurity \n### how to cacl gini\n### how to wrap the process of preparing submission csv file for kaggle\n### why no need to worry about dummy variables in decision trees\n## The random forest\n### what is random forest; what is bagging; what is the great insight behind it\n### how to create uncorrelated trees using random subset of data\n### how to make prediciton on each tree and take average on them, and then calc the loss\n### how is sklearn's RandomForestClassifier differ from the forest from scratch above; how to do random forest with sklearn\n## Conclusion\n### how should we think of simple models like OneR and decision tree and randomforest\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0004_fastai_how_neuralnet_work.md\n## Fitting a function with *gradient descent*\n### Is neuralnet just a math function? what does the function look like?\n### why neuralnet is random at first and how to make neuralnet useful\n### `plot_function`: how to plot a function with plt; how to create x input with torch.linspace; how to plot x, y, color and title with plt;\n### how to create a particular quadratic function\n### how to write a function `quad` to create any quadratic function\n### how does `partial` and `quad` work to modify `quad` to a slightly different func?\n### how to add noise to both mult and add of the neuralnet/function; how to create noise using `np.random.normal`\n### how to create a random seed to ensure x and y are the same each run\n## A numpy book recommended by Jeremy; what is a tensor\n### how to scatterplot with plt\n### how to plot a scatterplot and a line and slides for 3 params of the line func\n### why need a loss function? how to write a mean absolute error function with torch.abs and mean\n### how display and change loss by changing values of params with sliders of interactive plot\n### A 15-min calculus video series recommended by Jeremy to watch first\n## Automating gradient descent\n### how derivatives automatically guide params to change for a lower loss\n### how to create a mean absolute error function on any quadratic model\n### how to create an random tensor with 3 values as initialized params\n### how to calc gradients of params? 1. tell PyTorch to get ready for calculating gradients for these params; 2. calc loss; 3. calc the gradients with `loss.backward()`; 4. how to access params' gradients; \n### how to change params with gradients properly to lower loss¶\n### why `with torch.no_grad():` when updating params with gradients\n### how to do 10 iterations of updating params with gradients\n## How a neural network approximates any given function\n## how to combine a linear func with max(x, 0) into a rectified linear function; how to use torch.clip(y, 0.) to perform max(y, 0.)\n## how to use partial to wrap rectified_linear to create a specific rectified_linear func\n## how to use `F.relu` to replace `torch.clip` to create a rectified linear func; \n### create double and quaduple relu func/neuralnet\n## How to recognise an owl\n### deep learning basically is drawing squiggly lines infinitely given computation and time\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0001_fastai_is_it_a_bird.md\n## Useful Course sites\n## How to use autoreload\n## How to install and update libraries\n## Know a little about the libraries\n### what is fastai\n### what is duckduckgo\n## How to use fastdebug with fastai notebooks\n### how to use fastdebug\n### Did I document it in a notebook before?\n### Did I document it in a src before?\n## how to search and get a url of an image; how to download with an url; how to view an image;\n### how to create folders using path; how to search and download images in folders; how to resize images \n## Train my model\n### How to find and unlink images not properly downloaded\n### How to create a DataLoaders with DataBlock; how to view data with it\n### How to build my model with dataloaders and pretrained model; how to train my model\n### How to predict with my model; how to avoid running cells in nbdev_prepare\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0006_fastai_why_should_use_framework.md\n## Introduction and set up\n### what are the benefits of using fastai and PyTorch frameworks\n### which fastai module is for tabular data; how to set float format display for pandas; how to set random seed;\n## Prep the data\n### no worry of dummy variables, normalization, missing values and so on if using fastai; interesting feature ideas from a nice Titanic feature notebook;\n### how to create a tabular dataloaders with `TabularPandas` which handles all messing processing; how to set the parameters of `TabularPandas`\n## Train the model\n### how to create a tabular learner using tabular dataloader, metrics and layers\n### how to find the learning rate automatically in fastai\n### how to pick the best learning rate from the learning rate curve; how to train model 16 epochs using `learn.fit`\n## Submit to Kaggle\n### how to prepare test data including added new features\n### how to apply all the processing steps of training data to test data with `learn.dls.test_dl`\n### how to calc all predictions for test set using `learn.get_preds`\n### how to prepare the results of test set into a csv file for kaggle submission; how to save into csv file without idx number\n## Ensembling\n### what is ensembling and why it is more robust than any single model\n### how to create an ensemble function to create multiple models and generate predictions from each of them\n### how to get the average predictions from all ensembed models\n### how to create the csv file to Titanic competition\n## Final thoughts\n### Why you should use a framework like fastai\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0010_fastai_scaling_up_road_to_top_part_3.md\n## Memory and gradient accumulation\n### how to get the train_val dataset folder/path ready; how to get the test set images files ready\n### how to quickly train an ensemble of larger models with larger inputs on Kaggle\n### how to find out the num of files in each disease class using `pandas.value_counts`\n### how to choose a data folder which has the least num of image files for training\n### how `fine_tune` differ from `fit_one_cycle`\n### how to create a `train` function to do either fine_tune + tta or fit_one_cycle for all layers without freezing; how to add `gradient accumulation` to `train`\n### what does gradient accumulation do?\n### What benefits does gradient accumulation bring\n### how does gradient accumulation work under the hood\n### how to find out how much gpu memory is used; and how to free up the gpu memory\n## Checking memory use\n### how to check the gpu memory usage of large models with large image inputs\n## Running the models\n### how to use a dictionary to organize all models and their item and batch transformation setups\n### how to train all the selected models with transformation setups and save the tta results into a list\n## Ensembling\n### how to save all the tta results (a list) into a pickle file\n### how to get all the predictions from a list of results in which each result contains a prediction and a target for each row of test set\n### why and how to double the weights for vit models in the ensembles\n### what is the simplest way of doing ensembling\n### how to all the classes or vocab of the dataset using dataloaders; how to prepare the csv for kaggle submission\n### how to submit to kaggle using fastkaggle api\n## Conclusion\n### how fastai can superbly simply the codes and standardize processes\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0008_fastai_first_steps_road_to_top_part_1.md\n### how to install fastkaggle if not available\n### how to iterate like a grandmaster\n### what are the related walkthrus on paddy doctor competition\n## Getting set up\n### how to setup for fastkaggle; how to use fastkaggle to download dataset from kaggle; how to access the path\n### which fastai module to use for vision problem; how to check files inside the dataset path; why Jeremy recommend not to use seed in your own analysis;\n## Looking at the data\n### how to access a subfolder by name using path from `setup_comp`; how to extract all image files from a folder\n### how to create an image from an image file; how to access the size of an image; how to display it with specified size for viewing\n### how to use `fastcore.parallel` to quickly access size of all images; how to count the occurance of each unique value in a pandas \n### how to create an image dataloaders; how to setup `item_tfms` and `batch_tfms` on image sizes; why to start with the smallest sizes first; how to display images in batch\n## Our first model\n### how to pick the first pretrained model for our model; how to build our model based on the selected pretrained model\n### how to find the learning rate for our model\n## Submitting to Kaggle\n### how to check the kaggle submission sample csv file\n### how to sort the files in the test set in the alphabetical order; how to create dataloaders for the test set based on the dataloaders of the training set\n### how to make predictions for all test set; and what does `learn.get_preds` return\n### how to access all the classes of labels with dataloaders\n### how to map classes to each idx from the predictions\n### how to save result into csv file\n### how to submit to kaggle with fastkaggle api\n## Conclusion\n### what is the most important thing for your first model\n## Addendum\n### how to quickly push your local notebook to become kaggle notebook online\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0009_fastai_small_models_road_to_the_top_part_2.md\n## Going faster\n### why kaggle gpu is much slower for training and how does fastai to fix it with `resize_images`\n### how to create a new folder with `Path`\n### how to resize all images (including those in subfolders) of `train_images` folder and save them into a new destination folder; max_size = 256 does shrink the total size by 4+, but question: how Jeremy pick 256 not 250; \n### how to create an image dataloaders using the resized image folder and specify the resize for each image item; how to display just 3 images in a batch\n### how to wrap dataloaders creation, model creation, fine tuning together in a func `train` and return the trained model; how use model architecture, item transforms, and batch transforms, and num of epochs as the params of the `train` function;\n## A ConvNeXt model\n### How to tell whether a larger pretrained model would affect our training speed by reading GPU and CPU usage bar? why to pick convnext_small for our second model;\n### how to load and use a new pretrained model in fastai\n## Preprocessing experiments\n### question: why trying different ways of cutting images could possibly improve model performance; what are the proper options for cutting images or preparing images\n### how to try cutting image with `crop` instead of `squish` \n### what is transform image with padding and how does it differ from squish and crop\n### question: how `resize(256, 192)` and `size(171, 128)` are determined\n## Test time augmentation\n### how does test time augmentation TTA work; question: what is the rationale behind TTA\n### how to check the performance of our model on validation set\n### how to display the transformations which have been done to a single image in the training set\n### how to do TTA on validation set\n### how to calc the error rate of the tta_preds\n## Scaling up\n### how to scale up on the model using padding and the tta approach in terms of image size and epoch number\n### how to check the performance of the scaled up model using validation set\n## Submission\n### how to use TTA to predict instead of the usual `get_preds` to get predictions on the test set\n### how to get the index of the predictions\n### how to replace index with vocab or classes\n### how to submit prediction csv to kaggle with comment using fastkaggle api\n### how to push local notebook to Kaggle online\n## Conclusion\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0002_fastai_saving_a_basic_fastai_model.md\n## what to import to handle vision problems in fastai\n## how to download and decompress datasets prepared by fastai\n## how to tell it is a cat by reading filename\n## how to create dataloaders with `from_name_func`\n## how to create a pretrained model with resnet18 and error_rate; how to fine tune it 3 epochs\n## how to export model to a pickle file and download it from Kaggle\n## how to convert ipynb to md\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0005_fastai_linear_neuralnet_scratch.md\n## how to not execute the entire notebook\n## Introduction\n## How to download kaggle dataset to your local machine or colab? how to ues kaggle api and zipfile to download data into specified folder; how to use `pathlib.Path` to create a path;\n## how to set the print display option for numpy, torch and pandas\n## Cleaning the data\n### how to read csv file with pandas and `path/'subfolder_name'`\n### why missing value is a problem? how to find out the num of missing values of each column with pandas?\n### which value is most used to replace missing value? how to get mode for each column with pandas using `iloc[0]`\n### how to use pandas `iloc` function\n### how to fill missing values with mode without making a new copy with `pandas.fillna`\n### how to get a quick summary of all the numeric columns with pandas and numpy\n### what is long-tailed data in histogram and why it is a problem for neuralnet\n### how to plot histogram with pandas on a single column\n### how to fix long-tailed data with logarithm; why should logarithm work; how to handle zero values when applying logarithm\n### how to get a quick summary of all the non-numeric columns with pandas\n### when do we need dummy variables and how to create dummy variables with pandas\n### how to check the first few rows of selected columns with pandas\n### how to create dependent/target variable and independent/predictor variables in PyTorch tensors; how to create variables in tensor from pandas dataframe\n### how to check the size (rows and columns) of independent variables in tensor\n## Setting up a linear model\n### how to create coefficients for each (column) of our independent variables; how to get random seed in torch; how to get the num of columns; how to create random number between -0.5 and 0.5;\n### why no bias or a constant is needed for this Titanic dataset?\n### why a column `Age` having higher values than other columns can cause problem for our model; how to solve this problem by making them the same scale; how to get the max value of each column with pandas dataframe max func\n### what is maxtrix by vector operation (multiply or divide)\n### How to calculate the prediction of a linear model\n### how to look at the first 10 values of predictions\n### how to calc mean absolute error\n### how to calc predictions with a func `calc_preds`; how to calc loss with a func `calc_loss`\n## Doing a gradient descent step\n### How to cacl gradients for coefficients\n### why set gradients to zero after each gradient descent step; how to set gradient to zero; how to do one iteration of training\n### what does _ mean for `coeffs.sub_()` and `grad.zero_()`\n## Training the linear model\n### how to split the dataset by using train and valid idx produced by `fastai.data.transforms.RandomSplitter`\n### how to udpate coefficients in a function `update_coeffs`\n### how to do one epoch training in a function `one_epoch`\n### how to initializing coefficients in a function `init_coeffs`\n### how to integrate funcs above to form a function `train_model` on multiple epochs\n### how to display coefficients of the model with func `show_coeffs`\n## Measuring accuracy\n### There are many possible loss options such as accuracy other than mean absolute error\n### how to calc accuracy for the binary dependent variable\n### how to wrap the process of calc accuracy using coeffs into a func `acc(coeffs)`\n## Using sigmoid\n### when will we be needing something like sigmoid\n### how to write and plot a func like `sigmoid` using sympy\n### how to update `calc_preds` by wrapping `torch.sigmoid` around prediction\n## Submitting to Kaggle\n### read test data using `pandas.read_csv`\n### why and how to fill the missing value in Fare column with 0 instead of mode\n### how to handle missing values, long-tailed distribution and dummies together for test data\n### how to turn independent variable values into tensor\n### how to make sure independent variable in test data share the same value scare with those in training data\n### how to turn true or false into 1 or 0 and save them into a column\n### how to select two columns of a dataframe and save them into a csv file using `to_csv`\n### how to check the first few lines of the csv file using `!head`\n## Using matrix product\n### how to do matrix product `@` between a matrix and a vector with PyTorch; how to use `@` instead of doing multiplication and then addition together\n### update `calc_preds` func using matrix multiplication `@`\n### how to initialize coeffs and turn it into a matrix with a single column; question: but why make coeffs between 0 and 0.1 instead of -0.5 and 0.5\n### how to turn a single column of dependent variable into a single column matrix or a column vector\n### question: why set learning rate to be 100 for this Titanic model\n## A neural network\n### how to initialize coeffs for a neuralnet with two layers (including a hidden layer of n neurons) and the final output layer is a single neuron with a single coeff; question: how do `-0.5` and `-0.3` come from?\n### how to update `calc_preds` for this 2 layer neuralnet using `F.relu`, matrix product `@`, and `torch.sigmoid`\n### how to update coeffs layer by layer with `layer.sub_` and `layer.grad.zero_`\n### question: how the learning rate is chosen (1.4 or 20) when training\n## Deep learning\n### how to move from neuralnet with one hidden layer to a deep learning\n### why so many messy constants and how they block the progress of deep learning in the early days\n### how to use `enumerate` to loop both idx and item\n## Final thoughts\n### How much similar or different between practical models and the models from scratch above\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0003_fastai_which_image_model_best.md\n## timm\n## how to git clone TIMM analysis data; how to enter a directory with %cd\n## how to read a csv file with pandas\n## how to merge data with pandas; how to create new column with pandas; how to string extract with regex expression; how to select columns up to a particular column with pandas; how to do loc in pandas; how to select a group of columns using str.contains and regex\n## Inference results\n### how to scatterplot with plotly.express; how to set the plot's width, height, size, title, x, y, log_x, color, hover_name, hover_data; \n### how to scatterplot on a subgroup of data using regex and plotly\n## Training results\n### convert ipynb to md\n\n\n\n\n\nI would also like to search my own fastai notes with ease. The fastnotes can search but very rough at the moment, and the notes need a lot of rewrite.\n\n# fastnotes(\"how random forest work\")"
  },
  {
    "objectID": "demos/fastcore_meta_summary.html",
    "href": "demos/fastcore_meta_summary.html",
    "title": "0010_fastcore_meta_summary",
    "section": "",
    "text": "from fastdebug.utils import *\nfrom fastdebug.core import *"
  },
  {
    "objectID": "demos/fastcore_meta_summary.html#fastcore-and-fastcore.meta",
    "href": "demos/fastcore_meta_summary.html#fastcore-and-fastcore.meta",
    "title": "0010_fastcore_meta_summary",
    "section": "fastcore and fastcore.meta",
    "text": "fastcore and fastcore.meta\n\nimport fastcore\n\n\nwhichversion(\"fastcore\")\n\nfastcore: 1.5.27 \nPython supercharged for fastai development    \nJeremy Howard and Sylvain Gugger \nhttps://github.com/fastai/fastcore/     \npython_version: >=3.7     \n/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore\n\n\n\nwhatinside(fastcore, lib=True)\n\nThe library has 21 modules\n['_modidx',\n '_nbdev',\n 'all',\n 'basics',\n 'dispatch',\n 'docments',\n 'docscrape',\n 'foundation',\n 'imports',\n 'meta',\n 'nb_imports',\n 'net',\n 'parallel',\n 'script',\n 'shutil',\n 'style',\n 'test',\n 'transform',\n 'utils',\n 'xdg',\n 'xtras']\n\n\n\nfrom fastcore.meta import *\nimport fastcore.meta as fm\n\n\nWhat’s inside fastcore.meta\n\nwhatinside(fm, dun=True)\n\nfastcore.meta has: \n13 items in its __all__, and \n43 user defined functions, \n19 classes or class objects, \n2 builtin funcs and methods, and\n74 callables.\n\ntest_sig:            function    Test the signature of an object\nFixSigMeta:          metaclass, type    A metaclass that fixes the signature on classes that override `__new__`\nPrePostInitMeta:     metaclass, type    A metaclass that calls optional `__pre_init__` and `__post_init__` methods\nAutoInit:            class, PrePostInitMeta    Same as `object`, but no need for subclasses to call `super().__init__`\nNewChkMeta:          metaclass, type    Metaclass to avoid recreating object passed to constructor\nBypassNewMeta:       metaclass, type    Metaclass: casts `x` to this class if it's of type `cls._bypass_type`\nempty2none:          function    Replace `Parameter.empty` with `None`\nanno_dict:           function    `__annotation__ dictionary with `empty` cast to `None`, returning empty if doesn't exist\nuse_kwargs_dict:     decorator, function    Decorator: replace `**kwargs` in signature with `names` params\nuse_kwargs:          decorator, function    Decorator: replace `**kwargs` in signature with `names` params\ndelegates:           decorator, function    Decorator: replace `**kwargs` in signature with params from `to`\nmethod:              function    Mark `f` as a method\nfuncs_kwargs:        decorator, function    Replace methods in `cls._methods` with those from `kwargs`"
  },
  {
    "objectID": "demos/fastcore_meta_summary.html#review-individual-funcs-and-classes",
    "href": "demos/fastcore_meta_summary.html#review-individual-funcs-and-classes",
    "title": "0010_fastcore_meta_summary",
    "section": "Review individual funcs and classes",
    "text": "Review individual funcs and classes\n\nWhat is fastcore.meta all about?\nIt is a submodule contains 4 metaclasses, 1 class built by a metaclass, 4 decorators and a few functions.\nMetaclasses give us the power to create new breeds of classes with new features.\nDecorators give us the power to add new features to existing funcions.\nWe can find their basic info above\n\n\nWhat can these metaclasses do for me?\nWe design/create classes to breed objects as we like.\nWe design/create metaclasses to breed classes as we like.\nBefore metaclasses, all classes are created by type and are born the same.\nWith metaclasses, e.g., FixSigMeta first uses type to its instance classes exactly like above, but then FixSigMeta immediately adds new features to them right before they are born.\n\nFixSigMeta\ncan breed classes which are free of signature problems (or they can automatically fix signature problems).\n\n\nPrePostInitMeta\ninherited/evolved from FixSigMeta to breed classes which can initialize their objects using __pre_init__, __init__, __post_init__ whichever is available (allow me to abbreviate it as triple_init).\n\n\nAutoInit\nis an instance class created by PrePostInitMeta, and together with its own defined __pre_init__, subclasses of AutoInit has to worry about running super().__init__(...) no more.\n\nAs AutoInit is an instance class created by PrePostInitMeta, it can pass on both features (free of signature problem and triple_init) to its subclasses.\nAs it also defines its own __pre_init__ function which calls its superclass __init__ function, its subclasses will inherit this __pre_init__ function too.\nWhen subclasses of AutoInit create and initialize object intances through __call__ from PrePostInitMeta, AutoInit’s __pre_init__ runs super().__init__(...), so when we write __init__ function of subclasses which inherits from AutoInit, we don’t need to write super().__init__(...) any more.\n\n\n\nNewChkMeta\nis inherited from FixSigMeta, so any instance classes created by NewChkMeta can also pass on the no_signature_problem feature.\nIt defines its own __call__ to enable all the instance objects e.g., t created by all the instance classes e.g., T created by NewChkMeta to do the following:\n\nT(t) is t if isinstance(t, T) returns true\nwhen T(t) is t if not isinstance(t, T), or when T(t, 1) is t if isinstance(t, T) or when T(t, b=1) is t if isinstance(t, T), all return False\n\nIn other words, NewChkMeta creates a new breed of classes T as an example which won’t recreate the same instance object t twice. But if t is not T’s instance object, or we choose to add more flavor to t, then T(t) or T(t, 1) will create a new instance object of T.\n\n\nBypassNewMeta\nis inherited from FixSigMeta, so it has the feature of free from signature problems.\nIt defines its own __call__, so that when its instance classes _T create and initialize objects with a param t which is an instance object of another class _TestB, they can do the following:\n\nIf _T likes _TestB and prefers t as it is, then when we run t2 = _T(t), and t2 is t will be True, and both are instances of _T.\n\nIf _T is not please with t, it could be that _T does not like _TestB any more, then _T(t) is t will be False\nor maybe _T still likes _TestB, but want to add some flavors to t by _T(t, 1) or _T(t, b=1) for example, in this case _T(t) is t will also be False.\n\nIn other words, BypassNewMeta creates a new breed of instance classes _T which don’t need to create but make an object t of its own object instance, if t is an instance object of _TestB which is liked by _T and if _T likes t as it is.\n\n\n\nWhat can those decorators do for me?\nA decorator is a function that takes in a function and returns a modified function.\nA decorator allows us to modify the behavior of a function.\n\nuse_kwargs_dict\nallows us to replace an existing function’s param kwargs with a number of params with default values.\nThe params with their default values are provided in a dictionary.\n\n\nuse_kwargs\nallows us to replace an existing function’s param kwargs with a number of params with None as their default values.\nThe params are provided as names in a list.\n\n\ndelegates\nallows us to replace an existing function’s param kwargs with a number of params with their default values from another existing function.\nIn fact, delegates can work on function, classes, and methods.\n\n\nfuncs_kwargs\nis a decorator to classes. It can help classes to bring in existing functions as their methods.\nIt can set the methods to use or not use self in the class.\n\n\n\nThe remaining functions\ntest_sig and method are straightforward, their docs tell it all clearly.\nempty2none and anno_dict are no in use much at all. see the thread here.\n\nfastview(\"FixSigMeta\", nb=True)\n\n\nclass BaseMeta(FixSigMeta): \n    # using __new__ of  FixSigMeta instead of type\n    def __call__(cls, *args, **kwargs): pass\n\nclass Foo_call_fix(metaclass=BaseMeta): # Base\n    def __init__(self, d, e, f): pass\n\npprint(inspect._signature_from_callable(Foo_call_fix, sigcls=inspect.Signature))    \n\nclass FixSigMeta(type):===================================================================(0)       \n    \"A metaclass that fixes the signature on classes that override `__new__`\"=============(1) # Any class having FixSigMeta as metaclass will have its own __init__ func stored in its attr __signature__;FixSigMeta uses its __new__ to create a class instance; then check whether its class instance has its own __init__;if so, remove self from the sig of __init__; then assign this new sig to __signature__ for the class instance;; \n    def __new__(cls, name, bases, dict):==================================================(2) # how does a metaclass create a class instance; what does super().__new__() do here;; \n        res = super().__new__(cls, name, bases, dict)=====================================(3)       \n        if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__)) # how to remove self from a signature; how to check whether a class' __init__ is inherited from object or not;;  (4)\n        return res========================================================================(5)       \n                                                                                                                                                        (6)\n\n\nOpen 0003_Explore_document_FixSigMeta_PrePostInitMeta_AutoInit in Jupyter Notebook\n\n\n\n\n\nERROR:root:No traceback has been produced, nothing to debug.\n\n\n\nfastsrcs()\n\ntest_sig.py\nBypassNewMeta.py\nsnoop.py\nFixSigMeta.py\nfastnbs.py\nfuncs_kwargs.py\nNewChkMeta.py\nprinttitle.py\nAutoInit.py\nmethod.py\n_rm_self.py\ndelegates.py\ncreate_explore_str.py\nPrePostInitMeta.py\n_funcs_kwargs.py\nwhatinside.py\n\n\n\nfastview(FixSigMeta)\n\n\nclass BaseMeta(FixSigMeta): \n    # using __new__ of  FixSigMeta instead of type\n    def __call__(cls, *args, **kwargs): pass\n\nclass Foo_call_fix(metaclass=BaseMeta): # Base\n    def __init__(self, d, e, f): pass\n\npprint(inspect._signature_from_callable(Foo_call_fix, sigcls=inspect.Signature))    \n\nclass FixSigMeta(type):===================================================================(0)       \n    \"A metaclass that fixes the signature on classes that override `__new__`\"=============(1) # Any class having FixSigMeta as metaclass will have its own __init__ func stored in its attr __signature__;FixSigMeta uses its __new__ to create a class instance; then check whether its class instance has its own __init__;if so, remove self from the sig of __init__; then assign this new sig to __signature__ for the class instance;; \n    def __new__(cls, name, bases, dict):==================================================(2) # how does a metaclass create a class instance; what does super().__new__() do here;; \n        res = super().__new__(cls, name, bases, dict)=====================================(3)       \n        if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__)) # how to remove self from a signature; how to check whether a class' __init__ is inherited from object or not;;  (4)\n        return res========================================================================(5)       \n                                                                                                                                                        (6)\n\n\n\nfastcodes(\"how to get signature's parameters\", accu=0.8, nb=True, db=True)\n\nkeyword match is 0.8 , found a line: in delegates.py\n\n\n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items() # How to access a signature's parameters as a dict?; How to replace the kind of a parameter with a different kind?; how to check whether a parameter has a default value?; How to check whether a string is in a dict and a list?; how dict.items() and dict.values() differ;  (14)\n\n\n\nthe entire source code in delegates.py\n\n\n\ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n\ndef delegates(to:FunctionType=None, # Delegatee===========================================(0) # how to make delegates(to) to have to as FunctionType and default as None; \n              keep=False, # Keep `kwargs` in decorated function?==========================(1)       \n              but:list=None): # Exclude these parameters from signature===================(2) # how to make delegates(to, but) to have 'but' as list and default as None; \n    \"Decorator: replace `**kwargs` in signature with params from `to`\"====================(3)       \n    if but is None: but = []==============================================================(4)       \n    def _f(f):============================================================================(5)       \n        if to is None: to_f,from_f = f.__base__.__init__,f.__init__=======================(6) # how to write 2 ifs and elses in 2 lines; \n        else:          to_f,from_f = to.__init__ if isinstance(to,type) else to,f=========(7) # how to assign a,b together with if and else; \n        from_f = getattr(from_f,'__func__',from_f)========================================(8) # Is classmethod callable; does classmethod has __func__; can we do inspect.signature(clsmethod); how to use getattr(obj, attr, default); \n        to_f = getattr(to_f,'__func__',to_f)==============================================(9)       \n        if hasattr(from_f,'__delwrap__'): return f========================================(10) # if B has __delwrap__, can we do delegates(A)(B) again?; hasattr(obj, '__delwrap__'); \n        sig = inspect.signature(from_f)===================================================(11) # how to get signature obj of B; what does a signature look like; what is the type; \n        sigd = dict(sig.parameters)=======================================================(12) # How to access parameters of a signature?; How to turn parameters into a dict?; \n        k = sigd.pop('kwargs')============================================================(13) # How to remove an item from a dict?; How to get the removed item from a dict?; How to add the removed item back to the dict?; when writing expressions, as they share environment, so they may affect the following code; \n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items() # How to access a signature's parameters as a dict?; How to replace the kind of a parameter with a different kind?; how to check whether a parameter has a default value?; How to check whether a string is in a dict and a list?; how dict.items() and dict.values() differ;  (14)\n              if v.default != inspect.Parameter.empty and k not in sigd and k not in but}=(15)      \n        anno = {k:v for k,v in getattr(to_f, \"__annotations__\", {}).items() if k not in sigd and k not in but} # How to get A's __annotations__?; How to access it as a dict?; How to select annotations of the right params with names?; How to put them into a dict?; How to do it all in a single line;  (16)\n        sigd.update(s2)===================================================================(17) # How to add the selected params from A's signature to B's signature; How to add items into a dict;; \n        if keep: sigd['kwargs'] = k=======================================================(18) # How to add a new item into a dict;; \n        else: from_f.__delwrap__ = to_f===================================================(19) # How to create a new attr for a function or obj;; \n        from_f.__signature__ = sig.replace(parameters=sigd.values())======================(20) # How to update a signature with a new set of parameters;; \n        if hasattr(from_f, '__annotations__'): from_f.__annotations__.update(anno)========(21) # How to check whether a func has __annotations__; How add selected params' annotations from A to B's annotations;; \n        return f==========================================================================(22)      \n    return _f=============================================================================(23)      \n                                                                                                                                                        (24)\n\n\n\nOpen 0001_fastcore_meta_delegates in Jupyter Notebook\n\n\n\nfastnotes(\"how make the most\", folder=\"all\")\n\n\n\n\nkeyword match is 1.0 , found a line: in 2022_part1/fastai-lecture-1.md\n\n\ndo you want to know how to make the most out of fastai? - do you know lesson 0 and the book meta learning by an alumni?\n\n\n\n\n\nshow 2 lines above and after in  2 0 2 2 _part1/fastai-lecture-1.md :\n\n\nDo Jeremy and fastai community take it very seriously in help beginners along the way?\n\n\n16:33 Make the most out of fast.ai\n\n\ndo you want to know how to make the most out of fastai? - do you know lesson 0 and the book meta learning by an alumni?\n\n\n17:41 Learn in context\n\n\nDo you know people learn naturally (better) with context rather than by theoretical curriculum? - Do you want this course to make you a competent deep learning practitioner by context and practical knowledge? - If you want theory from ground up, should you go to part 2 fastai 2019?\n\n\n\n\n\nkeyword match is 1.0 , found a line: in 2022_part1/fastai-lecture-2.md\n\n\n\nhow to make the most out of fastai forum?\n\n\n\n\n\n\nshow 2 lines above and after in  2 0 2 2 _part1/fastai-lecture- 2 .md :\n\n\n\nWhere can you get more quizzes of fastai and memorize them forever?\n\n\n\n02:38 Introducing the forum\n\n\n\nhow to make the most out of fastai forum?\n\n\n\n04:12 Students’ works after week 1\n\n\n06:08 A Wow moment\n\n\n\n\n\nkeyword match is 1.0 , found a line: in 2022_livecoding/live-coding-1.md\n\n\n\n\nhow to make the most out of .bash_history file?\n\n\n\n\n\n\n\nshow 2 lines above and after in  2 0 2 2 _livecoding/live-coding-1.md :\n\n\n\n\nHow to run jupyter lab without browser? jupyter lab --no-browser\n\n\n\n\n\n\nHow to find and check the content of .bash_history? cat .bash_history 1:12:53\n\n\n\n\n\n\nhow to make the most out of .bash_history file?\n\n\n\n\n\n\nHow to search the .bash_history commands? ctrl + r and use delete tab to clear the search, use esc tab to exit search\n\n\n\n\n\n\nHow to run a command starting with ju? !ju"
  },
  {
    "objectID": "demos/fastcore_meta_summary.html#what-is-fastcore.meta-all-about-1",
    "href": "demos/fastcore_meta_summary.html#what-is-fastcore.meta-all-about-1",
    "title": "0010_fastcore_meta_summary",
    "section": "What is fastcore.meta all about",
    "text": "What is fastcore.meta all about"
  },
  {
    "objectID": "demos/funcs_kwargs.html",
    "href": "demos/funcs_kwargs.html",
    "title": "09_method_funcs_kwargs",
    "section": "",
    "text": "#|export\ndef method(f):\n    \"Mark `f` as a method\"\n    # `1` is a dummy instance since Py3 doesn't allow `None` any more\n    return MethodType(f, 1)\nThe method function is used to change a function’s type to a method. In the below example we change the type of a from a function to a method:\ndef a(x=2): return x + 1\nassert type(a).__name__ == 'function'\n\na = method(a)\nassert type(a).__name__ == 'method'\n\n\n\n\nfrom fastcore.meta import method\n\n\ndef a(x=2): return x + 1\nassert type(a).__name__ == 'function' # how to test on the type of function or method\n\na = method(a)\nassert type(a).__name__ == 'method'\n\n\n\n\n\nfrom fastdebug.utils import *\nfrom fastdebug.core import *\nfrom fastcore.meta import *\n\n\n\n\n\nfdb = Fastdb(method)\nfdb.eg = \"\"\"\ndef a(x=2): return x + 1\nassert type(a).__name__ == 'function' # how to test on the type of function or method\n\na = method(a)\nassert type(a).__name__ == 'method'\n\"\"\"\nfdb.print()\n\n==========================================================     Investigating method     ==========================================================\n==============================================================     on line None     ==============================================================\n     with example \ndef a(x=2): return x + 1\nassert type(a).__name__ == 'function' # how to test on the type of function or method\n\na = method(a)\nassert type(a).__name__ == 'method'\n     \n\ndef method(f):============================================================================(0)       \n    \"Mark `f` as a method\"================================================================(1)       \n    # `1` is a dummy instance since Py3 doesn't allow `None` any more=====================(2)       \n    return MethodType(f, 1)===============================================================(3)       \n                                                                                                                                                        (4)\n\n\n\nfdb.docsrc(2, \"How to use fastcore.meta.method; method(function, instance); f needs to be a function; \\\n1 is a dummy instance to which the newly created method belongs; no need to worry about instance here\")\n\n==========================================================     Investigating method     ==========================================================\n===============================================================     on line 2     ================================================================\n     with example \ndef a(x=2): return x + 1\nassert type(a).__name__ == 'function' # how to test on the type of function or method\n\na = method(a)\nassert type(a).__name__ == 'method'\n     \n\nprint selected srcline with expands below--------\ndef method(f):                                                                                                                                          (0)\n    \"Mark `f` as a method\"                                                                                                                              (1)\n    # `1` is a dummy instance since Py3 doesn't allow `None` any more===================================================================================(2)\nHow to use fastcore.meta.method; method(function, instance); f needs to be a function; 1 is a dummy instance to which the newly created method belongs; no need to worry about instance here\n    return MethodType(f, 1)                                                                                                                             (3)\n                                                                                                                                                        (4)\n\n\n\nfdb.debug()\n\nmethod's dbsrc code: ==============\nimport snoop\n@snoop\ndef method(f):\n    \"Mark `f` as a method\"\n    # `1` is a dummy instance since Py3 doesn't allow `None` any more\n    return MethodType(f, 1)\n\n\n\nmethod's example processed with dbsrc: ===============\n\ndef a(x=2): return x + 1\nassert type(a).__name__ == 'function' # how to test on the type of function or method\n\na = method(a)\nassert type(a).__name__ == 'method'\n\n\n\n\n\n\n\nfdb.snoop()\n\n22:28:59.92 >>> Call to method in File \"/tmp/method.py\", line 3\n22:28:59.92 ...... f = <function a>\n22:28:59.92    3 | def method(f):\n22:28:59.92    6 |     return MethodType(f, 1)\n22:28:59.92 <<< Return value from method: <bound method int.a of 1>\n\n\n==========================================================     Investigating method     ==========================================================\n==============================================================     on line None     ==============================================================\n     with example \ndef a(x=2): return x + 1\nassert type(a).__name__ == 'function' # how to test on the type of function or method\n\na = method(a)\nassert type(a).__name__ == 'method'\n     \n\n\n\n\nfdb.debug()\n\nmethod's dbsrc code: ==============\nimport snoop\n@snoop\ndef method(f):\n    \"Mark `f` as a method\"\n    # `1` is a dummy instance since Py3 doesn't allow `None` any more\n    return MethodType(f, 1)\n\n\n\nmethod's example processed with dbsrc: ===============\n\ndef a(x=2): return x + 1\nassert type(a).__name__ == 'function' # how to test on the type of function or method\n\na = self.dbsrc(a)\nassert type(a).__name__ == 'method'"
  },
  {
    "objectID": "demos/funcs_kwargs.html#funcs_kwargs",
    "href": "demos/funcs_kwargs.html#funcs_kwargs",
    "title": "09_method_funcs_kwargs",
    "section": "funcs_kwargs",
    "text": "funcs_kwargs\n\nOfficial docs\nThe func_kwargs decorator allows you to add a list of functions or methods to an existing class. You must set this list as a class attribute named _methods when defining your class. Additionally, you must incldue the **kwargs argument in the ___init__ method of your class.\nAfter defining your class this way, you can add functions to your class upon instantation as illusrated below.\nFor example, we define class T to allow adding the function b to class T as follows (note that this function is stored as an attribute of T and doesn’t have access to cls or self):\n\n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\n\n\nsnoop: from _funcs_kwargs to funcs_kwargs\nhow to snoop on two functions one wrap around another: funcs_kwargs is a wrapper around _funcs_kwargs, so I can first snoop on _funcs_kwargs and assign its snoop dbsrc to\nfm._funcs_kwargs so that when I snoop on funcs_kwargs, it can use the snoop dbsrc of _funcs_kwargs and no example codes need to change.\n\nfrom fastcore.meta import _funcs_kwargs\n\n\nfdb_ = Fastdb(_funcs_kwargs)\nfdb_.eg = \"\"\"\n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\"\"\"\n\n\n# no snoop result, it is expected, because the example is not calling _funcs_kwargs, but funcs_kwargs\nfdb_.snoop(deco=True) # how to snoop decorator: _funcs_kwargs is a decorator, so set deco=True to see running codes in inner f\n\n======================================================     Investigating _funcs_kwargs     =======================================================\n==============================================================     on line None     ==============================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n     \n\n\n\n\nimport fastcore.meta as fm\n\n\nfm._funcs_kwargs = fdb_.dbsrc # how to snoop on two functions one wrap around another\n\n\nfdb = Fastdb(funcs_kwargs)\nfdb.eg = \"\"\"\n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\ndef _f(self,a=1): return self.num + a # access the num attribute from the instance\n\n@funcs_kwargs(as_method=True)\nclass T: \n    _methods=['b']\n    num = 5\n    \nt = T(b = _f) # adds method b\ntest_eq(t.b(5), 10) # self.num + 5 = 10\n\ndef _f(self,a=1): return self.num * a #multiply instead of add \n\nclass T2(T):\n    def __init__(self,num):\n        super().__init__(b = _f) # add method b from the super class\n        self.num=num\n        \nt = T2(num=3)\ntest_eq(t.b(a=5), 15) # 3 * 5 = 15\ntest_sig(T2, '(num)')\n\"\"\"\n\n\nfdb.print()\n\n=======================================================     Investigating funcs_kwargs     =======================================================\n==============================================================     on line None     ==============================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\ndef _f(self,a=1): return self.num + a # access the num attribute from the instance\n\n@funcs_kwargs(as_method=True)\nclass T: \n    _methods=['b']\n    num = 5\n    \nt = T(b = _f) # adds method b\ntest_eq(t.b(5), 10) # self.num + 5 = 10\n\ndef _f(self,a=1): return self.num * a #multiply instead of add \n\nclass T2(T):\n    def __init__(self,num):\n        super().__init__(b = _f) # add method b from the super class\n        self.num=num\n        \nt = T2(num=3)\ntest_eq(t.b(a=5), 15) # 3 * 5 = 15\ntest_sig(T2, '(num)')\n     \n\ndef funcs_kwargs(as_method=False):========================================================(0)       \n    \"Replace methods in `cls._methods` with those from `kwargs`\"==========================(1)       \n    if callable(as_method): return _funcs_kwargs(as_method, False)========================(2)       \n    return partial(_funcs_kwargs, as_method=as_method)====================================(3)       \n                                                                                                                                                        (4)\n\n\n\nfdb_.print()\n\n======================================================     Investigating _funcs_kwargs     =======================================================\n==============================================================     on line None     ==============================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\n     \n\ndef _funcs_kwargs(cls, as_method):========================================================(0)       \n    old_init = cls.__init__===============================================================(1)       \n    def _init(self, *args, **kwargs):=====================================================(2)       \n        for k in cls._methods:============================================================(3)       \n            arg = kwargs.pop(k,None)======================================================(4)       \n            if arg is not None:===========================================================(5)       \n                if as_method: arg = method(arg)===========================================(6)       \n                if isinstance(arg,MethodType): arg = MethodType(arg.__func__, self)=======(7)       \n                setattr(self, k, arg)=====================================================(8)       \n        old_init(self, *args, **kwargs)===================================================(9)       \n    functools.update_wrapper(_init, old_init)=============================================(10)      \n    cls.__init__ = use_kwargs(cls._methods)(_init)========================================(11)      \n    if hasattr(cls, '__signature__'): cls.__signature__ = _rm_self(inspect.signature(cls.__init__))                                                     (12)\n    return cls============================================================================(13)      \n                                                                                                                                                        (14)\n\n\n\nfdb.docsrc(1, \"how funcs_kwargs works; it is a wrapper around _funcs_kwargs; it offers two ways of running _funcs_kwargs; \\\nthe first, default way, is to add a func to a class without using self; second way is to add func to class enabling self use;\")\nfdb.docsrc(2, \"how to check whether an object is callable; how to return a result of running a func; \")\nfdb.docsrc(3, \"how to custom the params of `_funcs_kwargs` for a particular use with partial\")\n\n=======================================================     Investigating funcs_kwargs     =======================================================\n===============================================================     on line 1     ================================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\ndef _f(self,a=1): return self.num + a # access the num attribute from the instance\n\n@funcs_kwargs(as_method=True)\nclass T: \n    _methods=['b']\n    num = 5\n    \nt = T(b = _f) # adds method b\ntest_eq(t.b(5), 10) # self.num + 5 = 10\n\ndef _f(self,a=1): return self.num * a #multiply instead of add \n\nclass T2(T):\n    def __init__(self,num):\n        super().__init__(b = _f) # add method b from the super class\n        self.num=num\n        \nt = T2(num=3)\ntest_eq(t.b(a=5), 15) # 3 * 5 = 15\ntest_sig(T2, '(num)')\n     \n\nprint selected srcline with expands below--------\ndef funcs_kwargs(as_method=False):                                                                                                                      (0)\n    \"Replace methods in `cls._methods` with those from `kwargs`\"========================================================================================(1)\nhow funcs_kwargs works; it is a wrapper around _funcs_kwargs; it offers two ways of running _funcs_kwargs; the first, default way, is to add a func to a class without using self; second way is to add func to class enabling self use;\n    if callable(as_method): return _funcs_kwargs(as_method, False)                                                                                      (2)\n    return partial(_funcs_kwargs, as_method=as_method)                                                                                                  (3)\n=======================================================     Investigating funcs_kwargs     =======================================================\n===============================================================     on line 2     ================================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\ndef _f(self,a=1): return self.num + a # access the num attribute from the instance\n\n@funcs_kwargs(as_method=True)\nclass T: \n    _methods=['b']\n    num = 5\n    \nt = T(b = _f) # adds method b\ntest_eq(t.b(5), 10) # self.num + 5 = 10\n\ndef _f(self,a=1): return self.num * a #multiply instead of add \n\nclass T2(T):\n    def __init__(self,num):\n        super().__init__(b = _f) # add method b from the super class\n        self.num=num\n        \nt = T2(num=3)\ntest_eq(t.b(a=5), 15) # 3 * 5 = 15\ntest_sig(T2, '(num)')\n     \n\nprint selected srcline with expands below--------\ndef funcs_kwargs(as_method=False):                                                                                                                      (0)\n    \"Replace methods in `cls._methods` with those from `kwargs`\"                                                                                        (1)\n    if callable(as_method): return _funcs_kwargs(as_method, False)======================================================================================(2)\n                                                                       how to check whether an object is callable; how to return a result of running a func; \n    return partial(_funcs_kwargs, as_method=as_method)                                                                                                  (3)\n                                                                                                                                                        (4)\n=======================================================     Investigating funcs_kwargs     =======================================================\n===============================================================     on line 3     ================================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\ndef _f(self,a=1): return self.num + a # access the num attribute from the instance\n\n@funcs_kwargs(as_method=True)\nclass T: \n    _methods=['b']\n    num = 5\n    \nt = T(b = _f) # adds method b\ntest_eq(t.b(5), 10) # self.num + 5 = 10\n\ndef _f(self,a=1): return self.num * a #multiply instead of add \n\nclass T2(T):\n    def __init__(self,num):\n        super().__init__(b = _f) # add method b from the super class\n        self.num=num\n        \nt = T2(num=3)\ntest_eq(t.b(a=5), 15) # 3 * 5 = 15\ntest_sig(T2, '(num)')\n     \n\nprint selected srcline with expands below--------\n    \"Replace methods in `cls._methods` with those from `kwargs`\"                                                                                        (1)\n    if callable(as_method): return _funcs_kwargs(as_method, False)                                                                                      (2)\n    return partial(_funcs_kwargs, as_method=as_method)==================================================================================================(3)\n                                                                                how to custom the params of `_funcs_kwargs` for a particular use with partial\n                                                                                                                                                        (4)\n\n\n\nfdb_.print()\n\n======================================================     Investigating _funcs_kwargs     =======================================================\n==============================================================     on line None     ==============================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\n     \n\ndef _funcs_kwargs(cls, as_method):========================================================(0)       \n    old_init = cls.__init__===============================================================(1)       \n    def _init(self, *args, **kwargs):=====================================================(2)       \n        for k in cls._methods:============================================================(3)       \n            arg = kwargs.pop(k,None)======================================================(4)       \n            if arg is not None:===========================================================(5)       \n                if as_method: arg = method(arg)===========================================(6)       \n                if isinstance(arg,MethodType): arg = MethodType(arg.__func__, self)=======(7)       \n                setattr(self, k, arg)=====================================================(8)       \n        old_init(self, *args, **kwargs)===================================================(9)       \n    functools.update_wrapper(_init, old_init)=============================================(10)      \n    cls.__init__ = use_kwargs(cls._methods)(_init)========================================(11)      \n    if hasattr(cls, '__signature__'): cls.__signature__ = _rm_self(inspect.signature(cls.__init__))                                                     (12)\n    return cls============================================================================(13)      \n                                                                                                                                                        (14)\n\n\n\nfdb_.docsrc(0, \"how does _funcs_kwargs work: _funcs_kwargs is a decorator; it helps class e.g., T to add more methods; \\\nI need to give the method a name, \\\nand put the name e.g., 'b' inside a list called _methods=['b'] inside class T; \\\nthen after writing a func e.g., _new_func, I can add it by T(b = _new_func); if I want the func added to class to use self, \\\nI shall write @funcs_kwargs(as_method=True)\")\nfdb_.docsrc(2, \"how to define a method which can use self and accept any parameters\")\nfdb_.docsrc(3, \"how to pop out the value of an item in a dict (with None as default), and if the item name is not found, pop out None instead; \")\nfdb_.docsrc(6, \"how to turn a func into a method\")\nfdb_.docsrc(7, \"how to give a method a different instance, like self\")\nfdb_.docsrc(8, \"how to add a method to a class as an attribute\")\nfdb_.docsrc(10, \"how to wrap `_init` around `old_init`, so that `_init` can use `old_init` inside itself\")\nfdb_.docsrc(11, \"how to add a list of names with None as default value to function `_init` to repalce its kwargs param\")\nfdb_.docsrc(12, \"how to make a class.`__init__` signature to be the signature of the class using `__signature__` and `_rm_self`\")\n\n======================================================     Investigating _funcs_kwargs     =======================================================\n===============================================================     on line 0     ================================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\n     \n\nprint selected srcline with expands below--------\ndef _funcs_kwargs(cls, as_method):======================================================================================================================(0)\nhow does _funcs_kwargs work: _funcs_kwargs is a decorator; it helps class e.g., T to add more methods; I need to give the method a name, and put the name e.g., 'b' inside a list called _methods=['b'] inside class T; then after writing a func e.g., _new_func, I can add it by T(b = _new_func); if I want the func added to class to use self, I shall write @funcs_kwargs(as_method=True)\n    old_init = cls.__init__                                                                                                                             (1)\n    def _init(self, *args, **kwargs):                                                                                                                   (2)\n======================================================     Investigating _funcs_kwargs     =======================================================\n===============================================================     on line 2     ================================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\n     \n\nprint selected srcline with expands below--------\ndef _funcs_kwargs(cls, as_method):                                                                                                                      (0)\n    old_init = cls.__init__                                                                                                                             (1)\n    def _init(self, *args, **kwargs):===================================================================================================================(2)\n                                                                                          how to define a method which can use self and accept any parameters\n        for k in cls._methods:                                                                                                                          (3)\n            arg = kwargs.pop(k,None)                                                                                                                    (4)\n======================================================     Investigating _funcs_kwargs     =======================================================\n===============================================================     on line 3     ================================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\n     \n\nprint selected srcline with expands below--------\n    old_init = cls.__init__                                                                                                                             (1)\n    def _init(self, *args, **kwargs):                                                                                                                   (2)\n        for k in cls._methods:==========================================================================================================================(3)\n                              how to pop out the value of an item in a dict (with None as default), and if the item name is not found, pop out None instead; \n            arg = kwargs.pop(k,None)                                                                                                                    (4)\n            if arg is not None:                                                                                                                         (5)\n======================================================     Investigating _funcs_kwargs     =======================================================\n===============================================================     on line 6     ================================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\n     \n\nprint selected srcline with expands below--------\n            arg = kwargs.pop(k,None)                                                                                                                    (4)\n            if arg is not None:                                                                                                                         (5)\n                if as_method: arg = method(arg)=========================================================================================================(6)\n                                                                                                                             how to turn a func into a method\n                if isinstance(arg,MethodType): arg = MethodType(arg.__func__, self)                                                                     (7)\n                setattr(self, k, arg)                                                                                                                   (8)\n======================================================     Investigating _funcs_kwargs     =======================================================\n===============================================================     on line 7     ================================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\n     \n\nprint selected srcline with expands below--------\n            if arg is not None:                                                                                                                         (5)\n                if as_method: arg = method(arg)                                                                                                         (6)\n                if isinstance(arg,MethodType): arg = MethodType(arg.__func__, self)=====================================================================(7)\n                                                                                                         how to give a method a different instance, like self\n                setattr(self, k, arg)                                                                                                                   (8)\n        old_init(self, *args, **kwargs)                                                                                                                 (9)\n======================================================     Investigating _funcs_kwargs     =======================================================\n===============================================================     on line 8     ================================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\n     \n\nprint selected srcline with expands below--------\n                if as_method: arg = method(arg)                                                                                                         (6)\n                if isinstance(arg,MethodType): arg = MethodType(arg.__func__, self)                                                                     (7)\n                setattr(self, k, arg)===================================================================================================================(8)\n                                                                                                               how to add a method to a class as an attribute\n        old_init(self, *args, **kwargs)                                                                                                                 (9)\n    functools.update_wrapper(_init, old_init)                                                                                                           (10)\n======================================================     Investigating _funcs_kwargs     =======================================================\n===============================================================     on line 10     ===============================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\n     \n\nprint selected srcline with expands below--------\n                setattr(self, k, arg)                                                                                                                   (8)\n        old_init(self, *args, **kwargs)                                                                                                                 (9)\n    functools.update_wrapper(_init, old_init)===========================================================================================================(10)\n                                                                      how to wrap `_init` around `old_init`, so that `_init` can use `old_init` inside itself\n    cls.__init__ = use_kwargs(cls._methods)(_init)                                                                                                      (11)\n    if hasattr(cls, '__signature__'): cls.__signature__ = _rm_self(inspect.signature(cls.__init__))                                                     (12)\n======================================================     Investigating _funcs_kwargs     =======================================================\n===============================================================     on line 11     ===============================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\n     \n\nprint selected srcline with expands below--------\n        old_init(self, *args, **kwargs)                                                                                                                 (9)\n    functools.update_wrapper(_init, old_init)                                                                                                           (10)\n    cls.__init__ = use_kwargs(cls._methods)(_init)======================================================================================================(11)\n                                                        how to add a list of names with None as default value to function `_init` to repalce its kwargs param\n    if hasattr(cls, '__signature__'): cls.__signature__ = _rm_self(inspect.signature(cls.__init__))                                                     (12)\n    return cls                                                                                                                                          (13)\n======================================================     Investigating _funcs_kwargs     =======================================================\n===============================================================     on line 12     ===============================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\n     \n\nprint selected srcline with expands below--------\n    functools.update_wrapper(_init, old_init)                                                                                                           (10)\n    cls.__init__ = use_kwargs(cls._methods)(_init)                                                                                                      (11)\n    if hasattr(cls, '__signature__'): cls.__signature__ = _rm_self(inspect.signature(cls.__init__))=====================================================(12)\n                                               how to make a class.`__init__` signature to be the signature of the class using `__signature__` and `_rm_self`\n    return cls                                                                                                                                          (13)\n                                                                                                                                                        (14)\n\n\n\nfdb.snoop() # how to snoop together with docsrc: snoop first and docsrc above it\n\n22:28:59.99 >>> Call to funcs_kwargs in File \"/tmp/funcs_kwargs.py\", line 3\n22:28:59.99 ...... as_method = <class 'fastcore.meta.T'>\n22:28:59.99    3 | def funcs_kwargs(as_method=False):\n22:28:59.99    5 |     if callable(as_method): return _funcs_kwargs(as_method, False)\n    22:28:59.99 >>> Call to _funcs_kwargs in File \"/tmp/_funcs_kwargs.py\", line 3\n    22:28:59.99 ...... cls = <class 'fastcore.meta.T'>\n    22:28:59.99 ...... as_method = False\n    22:28:59.99    3 | def _funcs_kwargs(cls, as_method):\n    22:28:59.99    4 |     old_init = cls.__init__\n    22:28:59.99 .......... old_init = <function T.__init__>\n    22:28:59.99    5 |     import snoop\n    22:28:59.99 .......... snoop = <class 'snoop.configuration.Config.__init__.<locals>.ConfiguredTracer'>\n    22:28:59.99    6 |     @snoop\n    22:28:59.99    7 |     def _init(self, *args, **kwargs):\n    22:28:59.99 .......... _init = <function _funcs_kwargs.<locals>._init>\n    22:28:59.99   15 |     functools.update_wrapper(_init, old_init)\n    22:28:59.99 .......... _init = <function T.__init__>\n    22:28:59.99   16 |     cls.__init__ = use_kwargs(cls._methods)(_init)\n    22:28:59.99   17 |     if hasattr(cls, '__signature__'): cls.__signature__ = _rm_self(inspect.signature(cls.__init__))\n    22:28:59.99   18 |     return cls\n    22:28:59.99 <<< Return value from _funcs_kwargs: <class 'fastcore.meta.T'>\n22:28:59.99    5 |     if callable(as_method): return _funcs_kwargs(as_method, False)\n22:28:59.99 <<< Return value from funcs_kwargs: <class 'fastcore.meta.T'>\n22:28:59.99 >>> Call to _funcs_kwargs.<locals>._init in File \"/tmp/_funcs_kwargs.py\", line 7\n22:28:59.99 .......... self = <fastcore.meta.T object>\n22:28:59.99 .......... args = ()\n22:28:59.99 .......... kwargs = {}\n22:28:59.99 .......... as_method = False\n22:28:59.99 .......... cls = <class 'fastcore.meta.T'>\n22:28:59.99 .......... old_init = <function T.__init__>\n22:28:59.99    7 |     def _init(self, *args, **kwargs):\n22:29:00.00    8 |         for k in cls._methods:\n22:29:00.00 .............. k = 'b'\n22:29:00.00    9 |             arg = kwargs.pop(k,None)\n22:29:00.00 .................. arg = None\n22:29:00.00   10 |             if arg is not None:\n22:29:00.00    8 |         for k in cls._methods:\n22:29:00.00   14 |         old_init(self, *args, **kwargs)\n22:29:00.00 <<< Return value from _funcs_kwargs.<locals>._init: None\n22:29:00.00 >>> Call to _funcs_kwargs.<locals>._init in File \"/tmp/_funcs_kwargs.py\", line 7\n22:29:00.00 .......... self = <fastcore.meta.T object>\n22:29:00.00 .......... args = ()\n22:29:00.00 .......... kwargs = {'b': <function _new_func>}\n22:29:00.00 .......... len(kwargs) = 1\n22:29:00.00 .......... as_method = False\n22:29:00.00 .......... cls = <class 'fastcore.meta.T'>\n22:29:00.00 .......... old_init = <function T.__init__>\n22:29:00.00    7 |     def _init(self, *args, **kwargs):\n22:29:00.00    8 |         for k in cls._methods:\n22:29:00.00 .............. k = 'b'\n22:29:00.00    9 |             arg = kwargs.pop(k,None)\n22:29:00.00 .................. kwargs = {}\n22:29:00.00 .................. arg = <function _new_func>\n22:29:00.00   10 |             if arg is not None:\n22:29:00.00   11 |                 if as_method: arg = method(arg)\n22:29:00.00   12 |                 if isinstance(arg,MethodType): arg = MethodType(arg.__func__, self)\n22:29:00.00   13 |                 setattr(self, k, arg)\n22:29:00.00    8 |         for k in cls._methods:\n22:29:00.00   14 |         old_init(self, *args, **kwargs)\n22:29:00.00 <<< Return value from _funcs_kwargs.<locals>._init: None\n22:29:00.00 >>> Call to _funcs_kwargs.<locals>._init in File \"/tmp/_funcs_kwargs.py\", line 7\n22:29:00.00 .......... self = <fastcore.meta.T object>\n22:29:00.00 .......... args = ()\n22:29:00.00 .......... kwargs = {'a': <function <lambda>>}\n22:29:00.00 .......... len(kwargs) = 1\n22:29:00.00 .......... as_method = False\n22:29:00.00 .......... cls = <class 'fastcore.meta.T'>\n22:29:00.00 .......... old_init = <function T.__init__>\n22:29:00.00    7 |     def _init(self, *args, **kwargs):\n22:29:00.00    8 |         for k in cls._methods:\n22:29:00.00 .............. k = 'b'\n22:29:00.00    9 |             arg = kwargs.pop(k,None)\n22:29:00.00 .................. arg = None\n22:29:00.00   10 |             if arg is not None:\n22:29:00.00    8 |         for k in cls._methods:\n22:29:00.00   14 |         old_init(self, *args, **kwargs)\n22:29:00.00 <<< Return value from _funcs_kwargs.<locals>._init: None\n22:29:00.00 >>> Call to funcs_kwargs in File \"/tmp/funcs_kwargs.py\", line 3\n22:29:00.00 ...... as_method = True\n22:29:00.00    3 | def funcs_kwargs(as_method=False):\n22:29:00.00    5 |     if callable(as_method): return _funcs_kwargs(as_method, False)\n22:29:00.00    6 |     return partial(_funcs_kwargs, as_method=as_method)\n22:29:00.00 <<< Return value from funcs_kwargs: functools.partial(<function _funcs_kwargs>, as_method=True)\n22:29:00.00 >>> Call to _funcs_kwargs in File \"/tmp/_funcs_kwargs.py\", line 3\n22:29:00.00 ...... cls = <class 'fastcore.meta.T'>\n22:29:00.00 ...... as_method = True\n22:29:00.00    3 | def _funcs_kwargs(cls, as_method):\n22:29:00.00    4 |     old_init = cls.__init__\n22:29:00.00 .......... old_init = <slot wrapper '__init__' of 'object' objects>\n22:29:00.00    5 |     import snoop\n22:29:00.00 .......... snoop = <class 'snoop.configuration.Config.__init__.<locals>.ConfiguredTracer'>\n22:29:00.00    6 |     @snoop\n22:29:00.00    7 |     def _init(self, *args, **kwargs):\n22:29:00.00 .......... _init = <function _funcs_kwargs.<locals>._init>\n22:29:00.00   15 |     functools.update_wrapper(_init, old_init)\n22:29:00.00 .......... _init = <function object.__init__>\n22:29:00.00   16 |     cls.__init__ = use_kwargs(cls._methods)(_init)\n22:29:00.01   17 |     if hasattr(cls, '__signature__'): cls.__signature__ = _rm_self(inspect.signature(cls.__init__))\n22:29:00.01   18 |     return cls\n22:29:00.01 <<< Return value from _funcs_kwargs: <class 'fastcore.meta.T'>\n22:29:00.01 >>> Call to _funcs_kwargs.<locals>._init in File \"/tmp/_funcs_kwargs.py\", line 7\n22:29:00.01 .......... self = <fastcore.meta.T object>\n22:29:00.01 .......... args = ()\n22:29:00.01 .......... kwargs = {'b': <function _f>}\n22:29:00.01 .......... len(kwargs) = 1\n22:29:00.01 .......... as_method = True\n22:29:00.01 .......... cls = <class 'fastcore.meta.T'>\n22:29:00.01 .......... old_init = <slot wrapper '__init__' of 'object' objects>\n22:29:00.01    7 |     def _init(self, *args, **kwargs):\n22:29:00.01    8 |         for k in cls._methods:\n22:29:00.01 .............. k = 'b'\n22:29:00.01    9 |             arg = kwargs.pop(k,None)\n22:29:00.01 .................. kwargs = {}\n22:29:00.01 .................. arg = <function _f>\n22:29:00.01   10 |             if arg is not None:\n22:29:00.01   11 |                 if as_method: arg = method(arg)\n22:29:00.01 ...... arg = <bound method int._f of 1>\n22:29:00.01   12 |                 if isinstance(arg,MethodType): arg = MethodType(arg.__func__, self)\n22:29:00.01 ...... arg = <bound method T._f of <fastcore.meta.T object>>\n22:29:00.01   13 |                 setattr(self, k, arg)\n22:29:00.01    8 |         for k in cls._methods:\n22:29:00.01   14 |         old_init(self, *args, **kwargs)\n22:29:00.01 <<< Return value from _funcs_kwargs.<locals>._init: None\n22:29:00.01 >>> Call to _funcs_kwargs.<locals>._init in File \"/tmp/_funcs_kwargs.py\", line 7\n22:29:00.01 .......... self = <fastcore.meta.T2 object>\n22:29:00.01 .......... args = ()\n22:29:00.01 .......... kwargs = {'b': <function _f>}\n22:29:00.01 .......... len(kwargs) = 1\n22:29:00.01 .......... as_method = True\n22:29:00.01 .......... cls = <class 'fastcore.meta.T'>\n22:29:00.01 .......... old_init = <slot wrapper '__init__' of 'object' objects>\n22:29:00.01    7 |     def _init(self, *args, **kwargs):\n22:29:00.01    8 |         for k in cls._methods:\n22:29:00.01 .............. k = 'b'\n22:29:00.01    9 |             arg = kwargs.pop(k,None)\n22:29:00.01 .................. kwargs = {}\n22:29:00.01 .................. arg = <function _f>\n22:29:00.01   10 |             if arg is not None:\n22:29:00.01   11 |                 if as_method: arg = method(arg)\n22:29:00.01 ...... arg = <bound method int._f of 1>\n22:29:00.01   12 |                 if isinstance(arg,MethodType): arg = MethodType(arg.__func__, self)\n22:29:00.01 ...... arg = <bound method T2._f of <fastcore.meta.T2 object>>\n22:29:00.01   13 |                 setattr(self, k, arg)\n22:29:00.01    8 |         for k in cls._methods:\n22:29:00.01   14 |         old_init(self, *args, **kwargs)\n22:29:00.01 <<< Return value from _funcs_kwargs.<locals>._init: None\n\n\n=======================================================     Investigating funcs_kwargs     =======================================================\n==============================================================     on line None     ==============================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\ndef _f(self,a=1): return self.num + a # access the num attribute from the instance\n\n@funcs_kwargs(as_method=True)\nclass T: \n    _methods=['b']\n    num = 5\n    \nt = T(b = _f) # adds method b\ntest_eq(t.b(5), 10) # self.num + 5 = 10\n\ndef _f(self,a=1): return self.num * a #multiply instead of add \n\nclass T2(T):\n    def __init__(self,num):\n        super().__init__(b = _f) # add method b from the super class\n        self.num=num\n        \nt = T2(num=3)\ntest_eq(t.b(a=5), 15) # 3 * 5 = 15\ntest_sig(T2, '(num)')\n     \n\n\n\n\nfdb_.debug()\n\n_funcs_kwargs's dbsrc code: ==============\nimport snoop\n@snoop\ndef _funcs_kwargs(cls, as_method):\n    old_init = cls.__init__\n    import snoop\n    @snoop\n    def _init(self, *args, **kwargs):\n        for k in cls._methods:\n            arg = kwargs.pop(k,None)\n            if arg is not None:\n                if as_method: arg = method(arg)\n                if isinstance(arg,MethodType): arg = MethodType(arg.__func__, self)\n                setattr(self, k, arg)\n        old_init(self, *args, **kwargs)\n    functools.update_wrapper(_init, old_init)\n    cls.__init__ = use_kwargs(cls._methods)(_init)\n    if hasattr(cls, '__signature__'): cls.__signature__ = _rm_self(inspect.signature(cls.__init__))\n    return cls\n\n\n\n_funcs_kwargs's example processed with dbsrc: ===============\n\n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\n\n\n\n\nfdb.print()\n\n=======================================================     Investigating funcs_kwargs     =======================================================\n==============================================================     on line None     ==============================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\ndef _f(self,a=1): return self.num + a # access the num attribute from the instance\n\n@funcs_kwargs(as_method=True)\nclass T: \n    _methods=['b']\n    num = 5\n    \nt = T(b = _f) # adds method b\ntest_eq(t.b(5), 10) # self.num + 5 = 10\n\ndef _f(self,a=1): return self.num * a #multiply instead of add \n\nclass T2(T):\n    def __init__(self,num):\n        super().__init__(b = _f) # add method b from the super class\n        self.num=num\n        \nt = T2(num=3)\ntest_eq(t.b(a=5), 15) # 3 * 5 = 15\ntest_sig(T2, '(num)')\n     \n\ndef funcs_kwargs(as_method=False):========================================================(0)       \n    \"Replace methods in `cls._methods` with those from `kwargs`\"==========================(1) # how funcs_kwargs works; it is a wrapper around _funcs_kwargs; it offers two ways of running _funcs_kwargs; the first, default way, is to add a func to a class without using self; second way is to add func to class enabling self use;; \n    if callable(as_method): return _funcs_kwargs(as_method, False)========================(2) # how to check whether an object is callable; how to return a result of running a func; ; \n    return partial(_funcs_kwargs, as_method=as_method)====================================(3) # how to custom the params of `_funcs_kwargs` for a particular use with partial; \n                                                                                                                                                        (4)\n\n\n\nfdb_.print()\n\n======================================================     Investigating _funcs_kwargs     =======================================================\n===============================================================     on line 12     ===============================================================\n     with example \n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\n     \n\ndef _funcs_kwargs(cls, as_method):========================================================(0) # how does _funcs_kwargs work: _funcs_kwargs is a decorator; it helps class e.g., T to add more methods; I need to give the method a name, and put the name e.g., 'b' inside a list called _methods=['b'] inside class T; then after writing a func e.g., _new_func, I can add it by T(b = _new_func); if I want the func added to class to use self, I shall write @funcs_kwargs(as_method=True); \n    old_init = cls.__init__===============================================================(1)       \n    def _init(self, *args, **kwargs):=====================================================(2) # how to define a method which can use self and accept any parameters; \n        for k in cls._methods:============================================================(3) # how to pop out the value of an item in a dict (with None as default), and if the item name is not found, pop out None instead; ; \n            arg = kwargs.pop(k,None)======================================================(4)       \n            if arg is not None:===========================================================(5)       \n                if as_method: arg = method(arg)===========================================(6) # how to turn a func into a method; \n                if isinstance(arg,MethodType): arg = MethodType(arg.__func__, self)=======(7) # how to give a method a different instance, like self; \n                setattr(self, k, arg)=====================================================(8) # how to add a method to a class as an attribute; \n        old_init(self, *args, **kwargs)===================================================(9)       \n    functools.update_wrapper(_init, old_init)=============================================(10) # how to wrap `_init` around `old_init`, so that `_init` can use `old_init` inside itself; \n    cls.__init__ = use_kwargs(cls._methods)(_init)========================================(11) # how to add a list of names with None as default value to function `_init` to repalce its kwargs param; \n    if hasattr(cls, '__signature__'): cls.__signature__ = _rm_self(inspect.signature(cls.__init__)) # how to make a class.`__init__` signature to be the signature of the class using `__signature__` and `_rm_self`;  (12)\n    return cls============================================================================(13)      \n                                                                                                                                                        (14)\n\n\n\n\nsnoop only ’_funcs_kwargs’ by breaking up ‘funcs_kwargs’\nI could do it this way, but I have to change more codes which leads to more efforts and potential errors. So not recommended.\n\nfdb = Fastdb(funcs_kwargs)\nfdb_ = Fastdb(_funcs_kwargs)\n\n\nfdb_.eg = \"\"\"\n\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = _funcs_kwargs(T, False)()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\"\"\"\nfdb_.eg = \"\"\"\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \ndef _new_func(): return 5\n\nt = _funcs_kwargs(T, False)(b = _new_func)\ntest_eq(t.b(), 5)\n\"\"\"\n# fdb_.eg = \"\"\"\n# class T:\n#     _methods=['b'] # allows you to add method b upon instantiation\n#     def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n#     def a(self): return 1\n#     def b(self): return 2\n    \n# t = _funcs_kwargs(T, False)(a = lambda:3)\n# test_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n# \"\"\"\n\n\nfdb_.snoop(watch=[\"cls.__init__\"], deco=True) # can't do this expression\n\n22:29:00.04 >>> Call to _funcs_kwargs in File \"/tmp/_funcs_kwargs.py\", line 3\n22:29:00.04 ...... cls = <class 'fastcore.meta.T'>\n22:29:00.04 ...... as_method = False\n22:29:00.04    3 | def _funcs_kwargs(cls, as_method):\n22:29:00.04    4 |     old_init = cls.__init__\n22:29:00.05 .......... old_init = <function T.__init__>\n22:29:00.05    5 |     import snoop\n22:29:00.05 .......... snoop = <class 'snoop.configuration.Config.__init__.<locals>.ConfiguredTracer'>\n22:29:00.05    6 |     @snoop\n22:29:00.05    7 |     def _init(self, *args, **kwargs):\n22:29:00.05 .......... _init = <function _funcs_kwargs.<locals>._init>\n22:29:00.05   15 |     functools.update_wrapper(_init, old_init)\n22:29:00.05 .......... _init = <function T.__init__>\n22:29:00.05   16 |     cls.__init__ = use_kwargs(cls._methods)(_init)\n22:29:00.05   17 |     if hasattr(cls, '__signature__'): cls.__signature__ = _rm_self(inspect.signature(cls.__init__))\n22:29:00.05   18 |     return cls\n22:29:00.05 <<< Return value from _funcs_kwargs: <class 'fastcore.meta.T'>\n22:29:00.05 >>> Call to _funcs_kwargs.<locals>._init in File \"/tmp/_funcs_kwargs.py\", line 7\n22:29:00.05 .......... self = <fastcore.meta.T object>\n22:29:00.05 .......... args = ()\n22:29:00.05 .......... kwargs = {'b': <function _new_func>}\n22:29:00.05 .......... len(kwargs) = 1\n22:29:00.05 .......... as_method = False\n22:29:00.05 .......... cls = <class 'fastcore.meta.T'>\n22:29:00.05 .......... old_init = <function T.__init__>\n22:29:00.05    7 |     def _init(self, *args, **kwargs):\n22:29:00.05    8 |         for k in cls._methods:\n22:29:00.05 .............. k = 'b'\n22:29:00.05    9 |             arg = kwargs.pop(k,None)\n22:29:00.05 .................. kwargs = {}\n22:29:00.05 .................. arg = <function _new_func>\n22:29:00.05   10 |             if arg is not None:\n22:29:00.05   11 |                 if as_method: arg = method(arg)\n22:29:00.05   12 |                 if isinstance(arg,MethodType): arg = MethodType(arg.__func__, self)\n22:29:00.05   13 |                 setattr(self, k, arg)\n22:29:00.05    8 |         for k in cls._methods:\n22:29:00.05   14 |         old_init(self, *args, **kwargs)\n22:29:00.05 <<< Return value from _funcs_kwargs.<locals>._init: None\n\n\n======================================================     Investigating _funcs_kwargs     =======================================================\n==============================================================     on line None     ==============================================================\n     with example \nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \ndef _new_func(): return 5\n\nt = _funcs_kwargs(T, False)(b = _new_func)\ntest_eq(t.b(), 5)"
  },
  {
    "objectID": "demos/fastcore.meta._rm_self.html",
    "href": "demos/fastcore.meta._rm_self.html",
    "title": "04_rm_self",
    "section": "",
    "text": "from fastdebug.utils import *\nfrom fastdebug.core import *\nfrom fastcore.meta import *\n\n\n\n\n\nfrom fastcore.meta import _rm_self"
  },
  {
    "objectID": "demos/fastcore.meta._rm_self.html#set-up",
    "href": "demos/fastcore.meta._rm_self.html#set-up",
    "title": "04_rm_self",
    "section": "set up",
    "text": "set up\n\ng = locals()\nfdb = Fastdb(_rm_self, outloc = g)\n\n\nfdb.print()\n\n=========================================================     Investigating _rm_self     =========================================================\n==============================================================     on line None     ==============================================================\n=============================================================     with example      ==============================================================\n\ndef _rm_self(sig):========================================================================(0)       \n    sigd = dict(sig.parameters)===========================================================(1)       \n    sigd.pop('self')======================================================================(2)       \n    return sig.replace(parameters=sigd.values())==========================================(3)       \n                                                                                                                                                        (4)\n\n\n\nclass Foo:\n    def __init__(self, a, b:int=1): pass\npprint(inspect.signature(Foo.__init__))\npprint(_rm_self(inspect.signature(Foo.__init__)))\n\n<Signature (self, a, b: int = 1)>\n<Signature (a, b: int = 1)>\n\n\n\nfdb.eg = \"\"\"\nclass Foo:\n    def __init__(self, a, b:int=1): pass\npprint(inspect.signature(Foo.__init__))\npprint(_rm_self(inspect.signature(Foo.__init__)))\n\"\"\""
  },
  {
    "objectID": "demos/fastcore.meta._rm_self.html#document",
    "href": "demos/fastcore.meta._rm_self.html#document",
    "title": "04_rm_self",
    "section": "document",
    "text": "document\n\nfdb.docsrc(0, \"remove parameter self from a signature which has self;\")\nfdb.docsrc(1, \"how to access parameters from a signature; how is parameters stored in sig; how to turn parameters into a dict;\", \\\n           \"sig\", \"sig.parameters\", \"dict(sig.parameters)\")\nfdb.docsrc(2, \"how to remove the self parameter from the dict of sig;\")\nfdb.docsrc(3, \"how to update a sig using a updated dict of sig's parameters\", \"sigd\", \"sigd.values()\")\n\n=========================================================     Investigating _rm_self     =========================================================\n===============================================================     on line 0     ================================================================\n     with example \nclass Foo:\n    def __init__(self, a, b:int=1): pass\npprint(inspect.signature(Foo.__init__))\npprint(_rm_self(inspect.signature(Foo.__init__)))\n     \n\nprint selected srcline with expands below--------\ndef _rm_self(sig):======================================================================================================================================(0)\n                                                                                                       remove parameter self from a signature which has self;\n    sigd = dict(sig.parameters)                                                                                                                         (1)\n    sigd.pop('self')                                                                                                                                    (2)\n<Signature (self, a, b: int = 1)>\n<Signature (a, b: int = 1)>\n=========================================================     Investigating _rm_self     =========================================================\n===============================================================     on line 1     ================================================================\n     with example \nclass Foo:\n    def __init__(self, a, b:int=1): pass\npprint(inspect.signature(Foo.__init__))\npprint(_rm_self(inspect.signature(Foo.__init__)))\n     \n\nprint selected srcline with expands below--------\ndef _rm_self(sig):                                                                                                                                      (0)\n    sigd = dict(sig.parameters)=========================================================================================================================(1)\n                                              how to access parameters from a signature; how is parameters stored in sig; how to turn parameters into a dict;\n    sigd.pop('self')                                                                                                                                    (2)\n    return sig.replace(parameters=sigd.values())                                                                                                        (3)\n<Signature (self, a, b: int = 1)>\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                                                                                           sig => sig : (self, a, b: int = 1)\n\n\n                      sig.parameters => sig.parameters : OrderedDict([('self', <Parameter \"self\">), ('a', <Parameter \"a\">), ('b', <Parameter \"b: int = 1\">)])\n\n\n                             dict(sig.parameters) => dict(sig.parameters) : {'self': <Parameter \"self\">, 'a': <Parameter \"a\">, 'b': <Parameter \"b: int = 1\">}\n====================================================================================================================End of my srcline exploration:\n\n<Signature (a, b: int = 1)>\n\nReview srcode with all comments added so far======================================================================================================\ndef _rm_self(sig):========================================================================(0) # remove parameter self from a signature which has self;; \n    sigd = dict(sig.parameters)===========================================================(1) # how to access parameters from a signature; how is parameters stored in sig; how to turn parameters into a dict;; \n    sigd.pop('self')======================================================================(2)       \n    return sig.replace(parameters=sigd.values())==========================================(3)       \n                                                                                                                                                        (4)\n                                                                                                                                     part No.1 out of 1 parts\n\n=========================================================     Investigating _rm_self     =========================================================\n===============================================================     on line 2     ================================================================\n     with example \nclass Foo:\n    def __init__(self, a, b:int=1): pass\npprint(inspect.signature(Foo.__init__))\npprint(_rm_self(inspect.signature(Foo.__init__)))\n     \n\nprint selected srcline with expands below--------\ndef _rm_self(sig):                                                                                                                                      (0)\n    sigd = dict(sig.parameters)                                                                                                                         (1)\n    sigd.pop('self')====================================================================================================================================(2)\n                                                                                                       how to remove the self parameter from the dict of sig;\n    return sig.replace(parameters=sigd.values())                                                                                                        (3)\n                                                                                                                                                        (4)\n<Signature (self, a, b: int = 1)>\n<Signature (a, b: int = 1)>\n\nReview srcode with all comments added so far======================================================================================================\ndef _rm_self(sig):========================================================================(0) # remove parameter self from a signature which has self;; \n    sigd = dict(sig.parameters)===========================================================(1) # how to access parameters from a signature; how is parameters stored in sig; how to turn parameters into a dict;; \n    sigd.pop('self')======================================================================(2) # how to remove the self parameter from the dict of sig;; \n    return sig.replace(parameters=sigd.values())==========================================(3)       \n                                                                                                                                                        (4)\n                                                                                                                                     part No.1 out of 1 parts\n\n=========================================================     Investigating _rm_self     =========================================================\n===============================================================     on line 3     ================================================================\n     with example \nclass Foo:\n    def __init__(self, a, b:int=1): pass\npprint(inspect.signature(Foo.__init__))\npprint(_rm_self(inspect.signature(Foo.__init__)))\n     \n\nprint selected srcline with expands below--------\n    sigd = dict(sig.parameters)                                                                                                                         (1)\n    sigd.pop('self')                                                                                                                                    (2)\n    return sig.replace(parameters=sigd.values())========================================================================================================(3)\n                                                                                                 how to update a sig using a updated dict of sig's parameters\n                                                                                                                                                        (4)\n<Signature (self, a, b: int = 1)>\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                                                         sigd => sigd : {'a': <Parameter \"a\">, 'b': <Parameter \"b: int = 1\">}\n\n\n                                                                    sigd.values() => sigd.values() : dict_values([<Parameter \"a\">, <Parameter \"b: int = 1\">])\n====================================================================================================================End of my srcline exploration:\n\n<Signature (a, b: int = 1)>\n\nReview srcode with all comments added so far======================================================================================================\ndef _rm_self(sig):========================================================================(0) # remove parameter self from a signature which has self;; \n    sigd = dict(sig.parameters)===========================================================(1) # how to access parameters from a signature; how is parameters stored in sig; how to turn parameters into a dict;; \n    sigd.pop('self')======================================================================(2) # how to remove the self parameter from the dict of sig;; \n    return sig.replace(parameters=sigd.values())==========================================(3) # how to update a sig using a updated dict of sig's parameters; \n                                                                                                                                                        (4)\n                                                                                                                                     part No.1 out of 1 parts"
  },
  {
    "objectID": "demos/fastcore.meta._rm_self.html#snoop",
    "href": "demos/fastcore.meta._rm_self.html#snoop",
    "title": "04_rm_self",
    "section": "snoop",
    "text": "snoop\n\nfdb.snoop()\n\n06:38:56.81 >>> Call to _rm_self in File \"/tmp/_rm_self.py\", line 3\n06:38:56.81 ...... sig = <Signature (self, a, b: int = 1)>\n06:38:56.81    3 | def _rm_self(sig):\n06:38:56.81    4 |     sigd = dict(sig.parameters)\n06:38:56.81 .......... sigd = {'self': <Parameter \"self\">, 'a': <Parameter \"a\">, 'b': <Parameter \"b: int = 1\">}\n06:38:56.81 .......... len(sigd) = 3\n06:38:56.81    5 |     sigd.pop('self')\n06:38:56.81 .......... sigd = {'a': <Parameter \"a\">, 'b': <Parameter \"b: int = 1\">}\n06:38:56.81 .......... len(sigd) = 2\n06:38:56.81    6 |     return sig.replace(parameters=sigd.values())\n06:38:56.81 <<< Return value from _rm_self: <Signature (a, b: int = 1)>\n\n\n=========================================================     Investigating _rm_self     =========================================================\n==============================================================     on line None     ==============================================================\n     with example \nclass Foo:\n    def __init__(self, a, b:int=1): pass\npprint(inspect.signature(Foo.__init__))\npprint(_rm_self(inspect.signature(Foo.__init__)))\n     \n\n<Signature (self, a, b: int = 1)>\n<Signature (a, b: int = 1)>\n\n\n\nfdb.print()\n\n=========================================================     Investigating _rm_self     =========================================================\n==============================================================     on line None     ==============================================================\n     with example \nclass Foo:\n    def __init__(self, a, b:int=1): pass\npprint(inspect.signature(Foo.__init__))\npprint(_rm_self(inspect.signature(Foo.__init__)))\n     \n\ndef _rm_self(sig):========================================================================(0) # remove parameter self from a signature which has self;; \n    sigd = dict(sig.parameters)===========================================================(1) # how to access parameters from a signature; how is parameters stored in sig; how to turn parameters into a dict;; \n    sigd.pop('self')======================================================================(2) # how to remove the self parameter from the dict of sig;; \n    return sig.replace(parameters=sigd.values())==========================================(3) # how to update a sig using a updated dict of sig's parameters; \n                                                                                                                                                        (4)"
  },
  {
    "objectID": "demos/fastcore_foundation_l.html",
    "href": "demos/fastcore_foundation_l.html",
    "title": "0012_fastcore_foundation_L",
    "section": "",
    "text": "fastnbs(\"how to download images\")\n\nkeyword match is 1.0 , found a section: in 0001_is_it_a_bird.md\n\n\n\n\n\n\n\n\n\nfrom duckduckgo_search import ddg_images\nfrom fastcore.all import *\ndef search_images(term, max_images=30):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')\n#NB: `search_images` depends on duckduckgo.com, which doesn't always return correct responses.\n#    If you get a JSON error, just try running it again (it may take a couple of tries).\nurls = search_images('bird photos', max_images=1)\nurls[0]\nfrom fastdownload import download_url\ndest = 'bird.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nfrom fastai.vision.all import *\nim = Image.open(dest)\nim.to_thumb(256,256)\ndownload_url(search_images('forest photos', max_images=1)[0], 'forest.jpg', show_progress=False)\nImage.open('forest.jpg').to_thumb(256,256)\n\n\n\nOpen 0001_is_it_a_bird in Jupyter Notebook\n\n\nI want to know what is L and how does L.itemgot do?\n\nfrom nbdev.showdoc import * # how to get doc(func) ready\n\n\ndoc(L)\n\n\n\nL(items=None, *rest, use_list=False, match=None)Behaves like a list of `items` but can also index with list of indices or masks\nShow in docs\n\n\n\ndoc(L.itemgot)\n\n\n\nL.itemgot(*idxs)Create new `L` with item `idx` of all `items`\nShow in docs\n\n\n\ninspect_class(L)\n\n\nis L a metaclass: False\nis L created by a metaclass: True\nL is created by metaclass <class 'fastcore.foundation._L_Meta'>\nL.__new__ is object.__new__: True\nL.__new__ is type.__new__: False\nL.__new__: <built-in method __new__ of type object>\nL.__init__ is object.__init__: False\nL.__init__ is type.__init__: False\nL.__init__: <function L.__init__>\nL.__call__ is object.__call__: False\nL.__call__ is type.__call__: False\nL.__call__: <bound method _L_Meta.__call__ of <class 'fastcore.foundation.L'>>\nL.__class__: <class 'fastcore.foundation._L_Meta'>\nL.__bases__: (<class 'fastcore.basics.GetAttr'>, <class 'fastcore.foundation.CollBase'>)\nL.__mro__: (<class 'fastcore.foundation.L'>, <class 'fastcore.basics.GetAttr'>, <class 'fastcore.foundation.CollBase'>, <class 'object'>)\n\nL's metaclass <class 'fastcore.foundation._L_Meta'>'s function members are:\n{'__call__': <function _L_Meta.__call__>}\n\nL's function members are:\n__add__: None\n__addi__: None\n__contains__: None\n__delitem__: None\n__dir__: Default dir() implementation.\n__eq__: Return self==value.\n__getattr__: None\n__getitem__: Retrieve `idx` (can be list of indices, or mask, or int) items\n__init__: Initialize self.  See help(type(self)) for accurate signature.\n__invert__: None\n__iter__: None\n__len__: None\n__mul__: None\n__radd__: None\n__repr__: Return repr(self).\n__reversed__: None\n__setitem__: Set `idx` (can be list of indices, or mask, or int) items to `o` (which is broadcast if not iterable)\n__setstate__: None\n_component_attr_filter: None\n_dir: None\n_get: None\n_new: None\n_repr_pretty_: None\nargfirst: Return index of first matching item\nargwhere: Like `filter`, but return indices for matching items\nattrgot: Create new `L` with attr `k` (or value `k` for dicts) of all `items`.\nconcat: Concatenate all elements of list\ncopy: Same as `list.copy`, but returns an `L`\ncycle: Same as `itertools.cycle`\nenumerate: Same as `enumerate`\nfilter: Create new `L` filtered by predicate `f`, passing `args` and `kwargs` to `f`\nitemgot: Create new `L` with item `idx` of all `items`\nmap: Create new `L` with `f` applied to all `items`, passing `args` and `kwargs` to `f`\nmap_dict: Like `map`, but creates a dict from `items` to function results\nmap_first: First element of `map_filter`\nmap_zip: Combine `zip` and `starmap`\nmap_zipwith: Combine `zipwith` and `starmap`\nproduct: Product of the items\nreduce: Wrapper for `functools.reduce`\nrenumerate: Same as `renumerate`\nsetattrs: Call `setattr` on all items\nshuffle: Same as `random.shuffle`, but not inplace\nsorted: New `L` sorted by `key`. If key is str use `attrgetter`; if int use `itemgetter`\nstarmap: Like `map`, but use `itertools.starmap`\nsum: Sum of the items\nunique: Unique items, in stable order\nval2idx: Dict from value to index\nzip: Create new `L` with `zip(*items)`\nzipwith: Create new `L` with `self` zip with each of `*rest`\n\nL's method members are:\n{'range': <bound method L.range of <class 'fastcore.foundation.L'>>,\n 'split': <bound method L.split of <class 'fastcore.foundation.L'>>}\n\nL's class members are:\n{'__class__': <class 'fastcore.foundation._L_Meta'>}\n\nL's namespace are:\nmappingproxy({'__add__': <function L.__add__>,\n              '__addi__': <function L.__addi__>,\n              '__contains__': <function L.__contains__>,\n              '__doc__': 'Behaves like a list of `items` but can also index '\n                         'with list of indices or masks',\n              '__eq__': <function L.__eq__>,\n              '__getitem__': <function L.__getitem__>,\n              '__hash__': None,\n              '__init__': <function L.__init__>,\n              '__invert__': <function L.__invert__>,\n              '__iter__': <function L.__iter__>,\n              '__module__': 'fastcore.foundation',\n              '__mul__': <function L.__mul__>,\n              '__radd__': <function L.__radd__>,\n              '__repr__': <function L.__repr__>,\n              '__reversed__': <function L.__reversed__>,\n              '__setitem__': <function L.__setitem__>,\n              '__signature__': <Signature (items=None, *rest, use_list=False, match=None)>,\n              '_default': 'items',\n              '_get': <function L._get>,\n              '_new': <function L._new>,\n              '_repr_pretty_': <function L._repr_pretty_>,\n              '_xtra': <property object>,\n              'argfirst': <function L.argfirst>,\n              'argwhere': <function L.argwhere>,\n              'attrgot': <function L.attrgot>,\n              'concat': <function L.concat>,\n              'copy': <function L.copy>,\n              'cycle': <function L.cycle>,\n              'enumerate': <function L.enumerate>,\n              'filter': <function L.filter>,\n              'itemgot': <function L.itemgot>,\n              'map': <function L.map>,\n              'map_dict': <function L.map_dict>,\n              'map_first': <function L.map_first>,\n              'map_zip': <function L.map_zip>,\n              'map_zipwith': <function L.map_zipwith>,\n              'product': <function L.product>,\n              'range': <classmethod object>,\n              'reduce': <function L.reduce>,\n              'renumerate': <function L.renumerate>,\n              'setattrs': <function L.setattrs>,\n              'shuffle': <function L.shuffle>,\n              'sorted': <function L.sorted>,\n              'split': <classmethod object>,\n              'starmap': <function L.starmap>,\n              'sum': <function L.sum>,\n              'unique': <function L.unique>,\n              'val2idx': <function L.val2idx>,\n              'zip': <function L.zip>,\n              'zipwith': <function L.zipwith>})"
  },
  {
    "objectID": "demos/fastcore.meta.test_sig.html",
    "href": "demos/fastcore.meta.test_sig.html",
    "title": "05_test_sig",
    "section": "",
    "text": "from fastdebug.utils import *\nfrom fastdebug.core import *\n\n\n\n\n\nfrom fastcore.meta import *\nimport fastcore.meta as fm"
  },
  {
    "objectID": "demos/fastcore.meta.test_sig.html#setups",
    "href": "demos/fastcore.meta.test_sig.html#setups",
    "title": "05_test_sig",
    "section": "setups",
    "text": "setups\n\nwhatinside(fm, dun=True)\n\nfastcore.meta has: \n13 items in its __all__, and \n43 user defined functions, \n19 classes or class objects, \n2 builtin funcs and methods, and\n74 callables.\n\ntest_sig:            function    Test the signature of an object\nFixSigMeta:          metaclass, type    A metaclass that fixes the signature on classes that override `__new__`\nPrePostInitMeta:     metaclass, type    A metaclass that calls optional `__pre_init__` and `__post_init__` methods\nAutoInit:            class, PrePostInitMeta    Same as `object`, but no need for subclasses to call `super().__init__`\nNewChkMeta:          metaclass, type    Metaclass to avoid recreating object passed to constructor\nBypassNewMeta:       metaclass, type    Metaclass: casts `x` to this class if it's of type `cls._bypass_type`\nempty2none:          function    Replace `Parameter.empty` with `None`\nanno_dict:           function    `__annotation__ dictionary with `empty` cast to `None`, returning empty if doesn't exist\nuse_kwargs_dict:     decorator, function    Decorator: replace `**kwargs` in signature with `names` params\nuse_kwargs:          decorator, function    Decorator: replace `**kwargs` in signature with `names` params\ndelegates:           decorator, function    Decorator: replace `**kwargs` in signature with params from `to`\nmethod:              function    Mark `f` as a method\nfuncs_kwargs:        decorator, function    Replace methods in `cls._methods` with those from `kwargs`\n\n\n\ng = locals()\nfdb = Fastdb(test_sig, outloc=g)\n\n\nfdb.print()\n\n=========================================================     Investigating test_sig     =========================================================\n==============================================================     on line None     ==============================================================\n=============================================================     with example      ==============================================================\n\ndef test_sig(f, b):=======================================================================(0)       \n    \"Test the signature of an object\"=====================================================(1)       \n    test_eq(str(inspect.signature(f)), b)=================================================(2)       \n                                                                                                                                                        (3)\n\n\n\nfdb.eg = \"\"\"\ndef func_1(h,i,j): pass\ntest_sig(func_1, '(h, i, j)')\n\"\"\"\n\nfdb.eg = \"\"\"\nclass T:\n    def __init__(self, a, b): pass\ntest_sig(T, '(a, b)')\n\"\"\"\nfdb.eg = \"\"\"\ndef func_2(h,i=3, j=[5,6]): pass\ntest_sig(func_2, '(h, i=3, j=[5, 6])')\n\"\"\""
  },
  {
    "objectID": "demos/fastcore.meta.test_sig.html#documents",
    "href": "demos/fastcore.meta.test_sig.html#documents",
    "title": "05_test_sig",
    "section": "documents",
    "text": "documents\n\nfdb.docsrc(2, \"test_sig is to test two strings with test_eq; how to turn a signature into a string;\", \"pprint(inspect.signature(f))\", \\\n\"inspect.signature(f)\", \"str(inspect.signature(f))\")\n\n=========================================================     Investigating test_sig     =========================================================\n===============================================================     on line 2     ================================================================\n=========================     with example \ndef func_2(h,i=3, j=[5,6]): pass\ntest_sig(func_2, '(h, i=3, j=[5, 6])')\n     =========================\n\nprint selected srcline with expands below--------\ndef test_sig(f, b):                                                                                                                                     (0)\n    \"Test the signature of an object\"                                                                                                                   (1)\n    test_eq(str(inspect.signature(f)), b)===============================================================================================================(2)\n                                                                         test_sig is to test two strings with test_eq; how to turn a signature into a string;\n                                                                                                                                                        (3)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n<Signature (h, i=3, j=[5, 6])>\n                                                                                          pprint(inspect.signature(f)) => pprint(inspect.signature(f)) : None\n\n\n                                                                                            inspect.signature(f) => inspect.signature(f) : (h, i=3, j=[5, 6])\n\n\n                                                                                  str(inspect.signature(f)) => str(inspect.signature(f)) : (h, i=3, j=[5, 6])\n====================================================================================================================End of my srcline exploration:\n\n\nReview srcode with all comments added so far======================================================================================================\ndef test_sig(f, b):=======================================================================(0)       \n    \"Test the signature of an object\"=====================================================(1)       \n    test_eq(str(inspect.signature(f)), b)=================================================(2) # test_sig is to test two strings with test_eq; how to turn a signature into a string;; \n                                                                                                                                                        (3)\n                                                                                                                                     part No.1 out of 1 parts"
  },
  {
    "objectID": "demos/fastcore.meta.test_sig.html#snoop",
    "href": "demos/fastcore.meta.test_sig.html#snoop",
    "title": "05_test_sig",
    "section": "snoop",
    "text": "snoop\n\nfdb.snoop()\n\n21:28:55.21 >>> Call to test_sig in File \"/tmp/test_sig.py\", line 3\n21:28:55.21 ...... f = <function func_2>\n21:28:55.21 ...... b = '(h, i=3, j=[5, 6])'\n21:28:55.21    3 | def test_sig(f, b):\n21:28:55.21    5 |     test_eq(str(inspect.signature(f)), b)\n21:28:55.21 <<< Return value from test_sig: None\n\n\n=========================================================     Investigating test_sig     =========================================================\n==============================================================     on line None     ==============================================================\n=========================     with example \ndef func_2(h,i=3, j=[5,6]): pass\ntest_sig(func_2, '(h, i=3, j=[5, 6])')\n     =========================\n\n\n\n\nfdb.docsrc(1, \"test_sig(f:FunctionType or ClassType, b:str); test_sig will get f's signature as a string; \\\nb is a signature in string provided by the user; in fact, test_sig is to compare two strings\")\n\n=========================================================     Investigating test_sig     =========================================================\n===============================================================     on line 1     ================================================================\n=========================     with example \ndef func_2(h,i=3, j=[5,6]): pass\ntest_sig(func_2, '(h, i=3, j=[5, 6])')\n     =========================\n\nprint selected srcline with expands below--------\ndef test_sig(f, b):                                                                                                                                     (0)\n    \"Test the signature of an object\"===================================================================================================================(1)\ntest_sig(f:FunctionType or ClassType, b:str); test_sig will get f's signature as a string; b is a signature in string provided by the user; in fact, test_sig is to compare two strings\n    test_eq(str(inspect.signature(f)), b)                                                                                                               (2)\n                                                                                                                                                        (3)\n\n\n\nfdb.print()\n\n=========================================================     Investigating test_sig     =========================================================\n===============================================================     on line 1     ================================================================\n=========================     with example \ndef func_2(h,i=3, j=[5,6]): pass\ntest_sig(func_2, '(h, i=3, j=[5, 6])')\n     =========================\n\ndef test_sig(f, b):=======================================================================(0)       \n    \"Test the signature of an object\"=====================================================(1) # test_sig(f:FunctionType or ClassType, b:str); test_sig will get f's signature as a string; b is a signature in string provided by the user; in fact, test_sig is to compare two strings; \n    test_eq(str(inspect.signature(f)), b)=================================================(2) # test_sig is to test two strings with test_eq; how to turn a signature into a string;; \n                                                                                                                                                        (3)"
  },
  {
    "objectID": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html",
    "href": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html",
    "title": "03_FixSigMeta_PrePostInitMeta_AutoInit",
    "section": "",
    "text": "from fastdebug.utils import *\nfrom fastdebug.core import *\nimport inspect"
  },
  {
    "objectID": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#initialize-fastdebug-objects",
    "href": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#initialize-fastdebug-objects",
    "title": "03_FixSigMeta_PrePostInitMeta_AutoInit",
    "section": "Initialize fastdebug objects",
    "text": "Initialize fastdebug objects\n\ng = locals() # g can update itself as more cells get run, like globals() in the __main__\nfdbF = Fastdb(FixSigMeta, outloc=g)\nfdbP = Fastdb(PrePostInitMeta, outloc=g)\nfdbA = Fastdb(AutoInit, outloc=g)"
  },
  {
    "objectID": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#class-fixsigmetatype-vs-class-footype",
    "href": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#class-fixsigmetatype-vs-class-footype",
    "title": "03_FixSigMeta_PrePostInitMeta_AutoInit",
    "section": "class FixSigMeta(type) vs class Foo(type)",
    "text": "class FixSigMeta(type) vs class Foo(type)\nFixSigMeta inherits __init__, and __call__ from type, but writes its own __new__\nFoo inherits all three from type\nFixSigMeta is used to create class instance not object instance\n\nfdbF.docsrc(1, \"FixSigMeta inherits __init__, and __call__ from type; but writes its own __new__; Foo inherits all three from type; \\\nFixSigMeta is used to create class instance not object instance.\")\n# fdbF.print()\n\n========================================================     Investigating FixSigMeta     ========================================================\n===============================================================     on line 1     ================================================================\n=============================================================     with example      ==============================================================\n\nprint selected srcline with expands below--------\nclass FixSigMeta(type):                                                                                                                                 (0)\n    \"A metaclass that fixes the signature on classes that override `__new__`\"===========================================================================(1)\nFixSigMeta inherits __init__, and __call__ from type; but writes its own __new__; Foo inherits all three from type; FixSigMeta is used to create class instance not object instance.\n    def __new__(cls, name, bases, dict):                                                                                                                (2)\n        res = super().__new__(cls, name, bases, dict)                                                                                                   (3)\n\n\n\nprint(inspect.getsource(FixSigMeta))\n\nclass FixSigMeta(type):\n    \"A metaclass that fixes the signature on classes that override `__new__`\"\n    def __new__(cls, name, bases, dict):\n        res = super().__new__(cls, name, bases, dict)\n        if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__))\n        return res\n\n\n\n\ninspect_class(FixSigMeta)\n\nclass FixSigMeta(type):\n    \"A metaclass that fixes the signature on classes that override `__new__`\"\n    def __new__(cls, name, bases, dict):\n        res = super().__new__(cls, name, bases, dict)\n        if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__))\n        return res\n\n\nis FixSigMeta a metaclass: True\nis FixSigMeta created by a metaclass: False\nFixSigMeta is created by <class 'type'>\nFixSigMeta.__new__ is object.__new__: False\nFixSigMeta.__new__ is type.__new__: False\nFixSigMeta.__new__: <function FixSigMeta.__new__>\nFixSigMeta.__init__ is object.__init__: False\nFixSigMeta.__init__ is type.__init__: True\nFixSigMeta.__init__: <slot wrapper '__init__' of 'type' objects>\nFixSigMeta.__call__ is object.__call__: False\nFixSigMeta.__call__ is type.__call__: True\nFixSigMeta.__call__: <slot wrapper '__call__' of 'type' objects>\nFixSigMeta.__class__: <class 'type'>\nFixSigMeta.__bases__: (<class 'type'>,)\nFixSigMeta.__mro__: (<class 'fastcore.meta.FixSigMeta'>, <class 'type'>, <class 'object'>)\n\nFixSigMeta's function members are:\n{'__new__': <function FixSigMeta.__new__>}\n\nFixSigMeta's method members are:\n{}\n\nFixSigMeta's class members are:\n{'__base__': <class 'type'>, '__class__': <class 'type'>}\n\nFixSigMeta's namespace are:\nmappingproxy({'__doc__': 'A metaclass that fixes the signature on classes that '\n                         'override `__new__`',\n              '__module__': 'fastcore.meta',\n              '__new__': <staticmethod object>})\n\n\n\nclass Foo(type): pass\ninspect_class(Foo)\n\n\nis Foo a metaclass: True\nis Foo created by a metaclass: False\nFoo is created by <class 'type'>\nFoo.__new__ is object.__new__: False\nFoo.__new__ is type.__new__: True\nFoo.__new__: <built-in method __new__ of type object>\nFoo.__init__ is object.__init__: False\nFoo.__init__ is type.__init__: True\nFoo.__init__: <slot wrapper '__init__' of 'type' objects>\nFoo.__call__ is object.__call__: False\nFoo.__call__ is type.__call__: True\nFoo.__call__: <slot wrapper '__call__' of 'type' objects>\nFoo.__class__: <class 'type'>\nFoo.__bases__: (<class 'type'>,)\nFoo.__mro__: (<class '__main__.Foo'>, <class 'type'>, <class 'object'>)\n\nFoo's function members are:\n{}\n\nFoo's method members are:\n{}\n\nFoo's class members are:\n{'__base__': <class 'type'>, '__class__': <class 'type'>}\n\nFoo's namespace are:\nmappingproxy({'__module__': '__main__', '__doc__': None})"
  },
  {
    "objectID": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#class-foo",
    "href": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#class-foo",
    "title": "03_FixSigMeta_PrePostInitMeta_AutoInit",
    "section": "class Foo()",
    "text": "class Foo()\nWhen Foo inherit __new__ and __new__ from object\nbut __call__ of Foo and __call__ of object maybe the same but different objects\nFoo is to create object instance not class instance\n\nclass Foo(): pass\ninspect_class(Foo)\n\n\nis Foo a metaclass: False\nis Foo created by a metaclass: False\nFoo is created by <class 'type'>\nFoo.__new__ is object.__new__: True\nFoo.__new__ is type.__new__: False\nFoo.__new__: <built-in method __new__ of type object>\nFoo.__init__ is object.__init__: True\nFoo.__init__ is type.__init__: False\nFoo.__init__: <slot wrapper '__init__' of 'object' objects>\nFoo.__call__ is object.__call__: False\nFoo.__call__ is type.__call__: False\nFoo.__call__: <method-wrapper '__call__' of type object>\nFoo.__class__: <class 'type'>\nFoo.__bases__: (<class 'object'>,)\nFoo.__mro__: (<class '__main__.Foo'>, <class 'object'>)\n\nFoo's function members are:\n{}\n\nFoo's method members are:\n{}\n\nFoo's class members are:\n{'__class__': <class 'type'>}\n\nFoo's namespace are:\nmappingproxy({'__dict__': <attribute '__dict__' of 'Foo' objects>,\n              '__doc__': None,\n              '__module__': '__main__',\n              '__weakref__': <attribute '__weakref__' of 'Foo' objects>})"
  },
  {
    "objectID": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#class-prepostinitmetafixsigmeta",
    "href": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#class-prepostinitmetafixsigmeta",
    "title": "03_FixSigMeta_PrePostInitMeta_AutoInit",
    "section": "class PrePostInitMeta(FixSigMeta)",
    "text": "class PrePostInitMeta(FixSigMeta)\nPrePostInitMeta inherit __new__ and __init__ from FixSigMeta as a metaclass (a different type), not from type, nor from object\nPrePostInitMeta is itself a metaclass, which is used to create class instance not object instance\nPrePostInitMeta writes its own __call__ which regulates how its class instance create and initialize object instance\n\nfdbP.docsrc(1, \"PrePostInitMeta inherit __new__ and __init__ from FixSigMeta as a metaclass (a different type); \\\nnot from type, nor from object; PrePostInitMeta is itself a metaclass, which is used to create class instance not object instance; \\\nPrePostInitMeta writes its own __call__ which regulates how its class instance create and initialize object instance\")\n\n=====================================================     Investigating PrePostInitMeta     ======================================================\n===============================================================     on line 1     ================================================================\n=============================================================     with example      ==============================================================\n\nprint selected srcline with expands below--------\nclass PrePostInitMeta(FixSigMeta):                                                                                                                      (0)\n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"========================================================================(1)\nPrePostInitMeta inherit __new__ and __init__ from FixSigMeta as a metaclass (a different type); not from type, nor from object; PrePostInitMeta is itself a metaclass, which is used to create class instance not object instance; PrePostInitMeta writes its own __call__ which regulates how its class instance create and initialize object instance\n    def __call__(cls, *args, **kwargs):                                                                                                                 (2)\n        res = cls.__new__(cls)                                                                                                                          (3)\n\n\n\ninspect_class(PrePostInitMeta)\n\nclass PrePostInitMeta(FixSigMeta):\n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"\n    def __call__(cls, *args, **kwargs):\n        res = cls.__new__(cls)\n        if type(res)==cls:\n            if hasattr(res,'__pre_init__'): res.__pre_init__(*args,**kwargs)\n            res.__init__(*args,**kwargs)\n            if hasattr(res,'__post_init__'): res.__post_init__(*args,**kwargs)\n        return res\n\n\nis PrePostInitMeta a metaclass: True\nis PrePostInitMeta created by a metaclass: False\nPrePostInitMeta is created by <class 'type'>\nPrePostInitMeta.__new__ is object.__new__: False\nPrePostInitMeta.__new__ is type.__new__: False\nPrePostInitMeta.__new__: <function FixSigMeta.__new__>\nPrePostInitMeta.__init__ is object.__init__: False\nPrePostInitMeta.__init__ is type.__init__: True\nPrePostInitMeta.__init__: <slot wrapper '__init__' of 'type' objects>\nPrePostInitMeta.__call__ is object.__call__: False\nPrePostInitMeta.__call__ is type.__call__: False\nPrePostInitMeta.__call__: <function PrePostInitMeta.__call__>\nPrePostInitMeta.__class__: <class 'type'>\nPrePostInitMeta.__bases__: (<class 'fastcore.meta.FixSigMeta'>,)\nPrePostInitMeta.__mro__: (<class 'fastcore.meta.PrePostInitMeta'>, <class 'fastcore.meta.FixSigMeta'>, <class 'type'>, <class 'object'>)\n\nPrePostInitMeta's function members are:\n{'__call__': <function PrePostInitMeta.__call__>,\n '__new__': <function FixSigMeta.__new__>}\n\nPrePostInitMeta's method members are:\n{}\n\nPrePostInitMeta's class members are:\n{'__base__': <class 'fastcore.meta.FixSigMeta'>, '__class__': <class 'type'>}\n\nPrePostInitMeta's namespace are:\nmappingproxy({'__call__': <function PrePostInitMeta.__call__>,\n              '__doc__': 'A metaclass that calls optional `__pre_init__` and '\n                         '`__post_init__` methods',\n              '__module__': 'fastcore.meta'})\n\n\n\nclass Foo(FixSigMeta): pass\ninspect_class(Foo)\n\n\nis Foo a metaclass: True\nis Foo created by a metaclass: False\nFoo is created by <class 'type'>\nFoo.__new__ is object.__new__: False\nFoo.__new__ is type.__new__: False\nFoo.__new__: <function FixSigMeta.__new__>\nFoo.__init__ is object.__init__: False\nFoo.__init__ is type.__init__: True\nFoo.__init__: <slot wrapper '__init__' of 'type' objects>\nFoo.__call__ is object.__call__: False\nFoo.__call__ is type.__call__: True\nFoo.__call__: <slot wrapper '__call__' of 'type' objects>\nFoo.__class__: <class 'type'>\nFoo.__bases__: (<class 'fastcore.meta.FixSigMeta'>,)\nFoo.__mro__: (<class '__main__.Foo'>, <class 'fastcore.meta.FixSigMeta'>, <class 'type'>, <class 'object'>)\n\nFoo's function members are:\n{'__new__': <function FixSigMeta.__new__>}\n\nFoo's method members are:\n{}\n\nFoo's class members are:\n{'__base__': <class 'fastcore.meta.FixSigMeta'>, '__class__': <class 'type'>}\n\nFoo's namespace are:\nmappingproxy({'__module__': '__main__', '__doc__': None})"
  },
  {
    "objectID": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#class-foometaclassfixsigmeta",
    "href": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#class-foometaclassfixsigmeta",
    "title": "03_FixSigMeta_PrePostInitMeta_AutoInit",
    "section": "class Foo(metaclass=FixSigMeta)",
    "text": "class Foo(metaclass=FixSigMeta)\nFoo inherit __new__, __init__ from object to create object instance\nFoo uses FixSigMeta not type to create class instance FixSigMeta.__new__ determine what kind of a class is Foo\nIn this case, FixSigMeta.__new__ create Foo class and an attr __signature__ if Foo has its own __init__\nFixSigMeta.__new__ create Foo the class, has nothing to do with the instance method Foo.__init__\n\nclass Foo(metaclass=FixSigMeta): pass\ninspect_class(Foo)\n\n\nis Foo a metaclass: False\nis Foo created by a metaclass: True\nFoo is created by metaclass <class 'fastcore.meta.FixSigMeta'>\nFoo.__new__ is object.__new__: True\nFoo.__new__ is type.__new__: False\nFoo.__new__: <built-in method __new__ of type object>\nFoo.__init__ is object.__init__: True\nFoo.__init__ is type.__init__: False\nFoo.__init__: <slot wrapper '__init__' of 'object' objects>\nFoo.__call__ is object.__call__: False\nFoo.__call__ is type.__call__: False\nFoo.__call__: <method-wrapper '__call__' of FixSigMeta object>\nFoo.__class__: <class 'fastcore.meta.FixSigMeta'>\nFoo.__bases__: (<class 'object'>,)\nFoo.__mro__: (<class '__main__.Foo'>, <class 'object'>)\n\nFoo's metaclass <class 'fastcore.meta.FixSigMeta'>'s function members are:\n{'__new__': <function FixSigMeta.__new__>}\n\nFoo's function members are:\n{}\n\nFoo's method members are:\n{}\n\nFoo's class members are:\n{'__class__': <class 'fastcore.meta.FixSigMeta'>}\n\nFoo's namespace are:\nmappingproxy({'__dict__': <attribute '__dict__' of 'Foo' objects>,\n              '__doc__': None,\n              '__module__': '__main__',\n              '__weakref__': <attribute '__weakref__' of 'Foo' objects>})\n\n\n\nclass Foo(metaclass=FixSigMeta): \n    def __init__(self, a, b): pass\ninspect_class(Foo)\n\n\nis Foo a metaclass: False\nis Foo created by a metaclass: True\nFoo is created by metaclass <class 'fastcore.meta.FixSigMeta'>\nFoo.__new__ is object.__new__: True\nFoo.__new__ is type.__new__: False\nFoo.__new__: <built-in method __new__ of type object>\nFoo.__init__ is object.__init__: False\nFoo.__init__ is type.__init__: False\nFoo.__init__: <function Foo.__init__>\nFoo.__call__ is object.__call__: False\nFoo.__call__ is type.__call__: False\nFoo.__call__: <method-wrapper '__call__' of FixSigMeta object>\nFoo.__class__: <class 'fastcore.meta.FixSigMeta'>\nFoo.__bases__: (<class 'object'>,)\nFoo.__mro__: (<class '__main__.Foo'>, <class 'object'>)\n\nFoo's metaclass <class 'fastcore.meta.FixSigMeta'>'s function members are:\n{'__new__': <function FixSigMeta.__new__>}\n\nFoo's function members are:\n{'__init__': <function Foo.__init__>}\n\nFoo's method members are:\n{}\n\nFoo's class members are:\n{'__class__': <class 'fastcore.meta.FixSigMeta'>}\n\nFoo's namespace are:\nmappingproxy({'__dict__': <attribute '__dict__' of 'Foo' objects>,\n              '__doc__': None,\n              '__init__': <function Foo.__init__>,\n              '__module__': '__main__',\n              '__signature__': <Signature (a, b)>,\n              '__weakref__': <attribute '__weakref__' of 'Foo' objects>})"
  },
  {
    "objectID": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#class-autoinitmetaclassprepostinitmeta",
    "href": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#class-autoinitmetaclassprepostinitmeta",
    "title": "03_FixSigMeta_PrePostInitMeta_AutoInit",
    "section": "class AutoInit(metaclass=PrePostInitMeta)",
    "text": "class AutoInit(metaclass=PrePostInitMeta)\nAutoInit inherit __new__ and __init__ from object to create and initialize object instances\nAutoInit uses PrePostInitMeta.__new__ or in fact FixSigMeta.__new__ to create its own class instance, which can have __signature__\nAutoInit uses PrePostInitMeta.__call__ to specify how its object instance to be created and initialized (with pre_init, init, post_init)\nAutoInit as a normal or non-metaclass, it writes its own __pre_init__ instance method\n\nfdbA.docsrc(1, \"AutoInit inherit __new__ and __init__ from object to create and initialize object instances; \\\nAutoInit uses PrePostInitMeta.__new__ or in fact FixSigMeta.__new__ to create its own class instance, which can have __signature__; \\\nAutoInit uses PrePostInitMeta.__call__ to specify how its object instance to be created and initialized (with pre_init, init, post_init)); \\\nAutoInit as a normal or non-metaclass, it writes its own __pre_init__ method\")\n\n=========================================================     Investigating AutoInit     =========================================================\n===============================================================     on line 1     ================================================================\n=============================================================     with example      ==============================================================\n\nprint selected srcline with expands below--------\nclass AutoInit(metaclass=PrePostInitMeta):                                                                                                              (0)\n    \"Same as `object`, but no need for subclasses to call `super().__init__`\"===========================================================================(1)\nAutoInit inherit __new__ and __init__ from object to create and initialize object instances; AutoInit uses PrePostInitMeta.__new__ or in fact FixSigMeta.__new__ to create its own class instance, which can have __signature__; AutoInit uses PrePostInitMeta.__call__ to specify how its object instance to be created and initialized (with pre_init, init, post_init)); AutoInit as a normal or non-metaclass, it writes its own __pre_init__ method\n    def __pre_init__(self, *args, **kwargs): super().__init__(*args, **kwargs)                                                                          (2)\n                                                                                                                                                        (3)\n\n\n\ninspect_class(AutoInit)\n\nclass AutoInit(metaclass=PrePostInitMeta):\n    \"Same as `object`, but no need for subclasses to call `super().__init__`\"\n    def __pre_init__(self, *args, **kwargs): super().__init__(*args, **kwargs)\n\n\nis AutoInit a metaclass: False\nis AutoInit created by a metaclass: True\nAutoInit is created by metaclass <class 'fastcore.meta.PrePostInitMeta'>\nAutoInit.__new__ is object.__new__: True\nAutoInit.__new__ is type.__new__: False\nAutoInit.__new__: <built-in method __new__ of type object>\nAutoInit.__init__ is object.__init__: True\nAutoInit.__init__ is type.__init__: False\nAutoInit.__init__: <slot wrapper '__init__' of 'object' objects>\nAutoInit.__call__ is object.__call__: False\nAutoInit.__call__ is type.__call__: False\nAutoInit.__call__: <bound method PrePostInitMeta.__call__ of <class 'fastcore.meta.AutoInit'>>\nAutoInit.__class__: <class 'fastcore.meta.PrePostInitMeta'>\nAutoInit.__bases__: (<class 'object'>,)\nAutoInit.__mro__: (<class 'fastcore.meta.AutoInit'>, <class 'object'>)\n\nAutoInit's metaclass <class 'fastcore.meta.PrePostInitMeta'>'s function members are:\n{'__call__': <function PrePostInitMeta.__call__>,\n '__new__': <function FixSigMeta.__new__>}\n\nAutoInit's function members are:\n{'__pre_init__': <function AutoInit.__pre_init__>}\n\nAutoInit's method members are:\n{}\n\nAutoInit's class members are:\n{'__class__': <class 'fastcore.meta.PrePostInitMeta'>}\n\nAutoInit's namespace are:\nmappingproxy({'__dict__': <attribute '__dict__' of 'AutoInit' objects>,\n              '__doc__': 'Same as `object`, but no need for subclasses to call '\n                         '`super().__init__`',\n              '__module__': 'fastcore.meta',\n              '__pre_init__': <function AutoInit.__pre_init__>,\n              '__weakref__': <attribute '__weakref__' of 'AutoInit' objects>})\n\n\n\nclass Foo(AutoInit): pass\ninspect_class(Foo)\n\n\nis Foo a metaclass: False\nis Foo created by a metaclass: True\nFoo is created by metaclass <class 'fastcore.meta.PrePostInitMeta'>\nFoo.__new__ is object.__new__: True\nFoo.__new__ is type.__new__: False\nFoo.__new__: <built-in method __new__ of type object>\nFoo.__init__ is object.__init__: True\nFoo.__init__ is type.__init__: False\nFoo.__init__: <slot wrapper '__init__' of 'object' objects>\nFoo.__call__ is object.__call__: False\nFoo.__call__ is type.__call__: False\nFoo.__call__: <bound method PrePostInitMeta.__call__ of <class '__main__.Foo'>>\nFoo.__class__: <class 'fastcore.meta.PrePostInitMeta'>\nFoo.__bases__: (<class 'fastcore.meta.AutoInit'>,)\nFoo.__mro__: (<class '__main__.Foo'>, <class 'fastcore.meta.AutoInit'>, <class 'object'>)\n\nFoo's metaclass <class 'fastcore.meta.PrePostInitMeta'>'s function members are:\n{'__call__': <function PrePostInitMeta.__call__>,\n '__new__': <function FixSigMeta.__new__>}\n\nFoo's function members are:\n{'__pre_init__': <function AutoInit.__pre_init__>}\n\nFoo's method members are:\n{}\n\nFoo's class members are:\n{'__class__': <class 'fastcore.meta.PrePostInitMeta'>}\n\nFoo's namespace are:\nmappingproxy({'__module__': '__main__', '__doc__': None})\n\n\n\nclass Foo(AutoInit): \n    def __init__(self): pass # to enable __signature__ by FixSigMeta.__new__\ninspect_class(Foo)\n\n\nis Foo a metaclass: False\nis Foo created by a metaclass: True\nFoo is created by metaclass <class 'fastcore.meta.PrePostInitMeta'>\nFoo.__new__ is object.__new__: True\nFoo.__new__ is type.__new__: False\nFoo.__new__: <built-in method __new__ of type object>\nFoo.__init__ is object.__init__: False\nFoo.__init__ is type.__init__: False\nFoo.__init__: <function Foo.__init__>\nFoo.__call__ is object.__call__: False\nFoo.__call__ is type.__call__: False\nFoo.__call__: <bound method PrePostInitMeta.__call__ of <class '__main__.Foo'>>\nFoo.__class__: <class 'fastcore.meta.PrePostInitMeta'>\nFoo.__bases__: (<class 'fastcore.meta.AutoInit'>,)\nFoo.__mro__: (<class '__main__.Foo'>, <class 'fastcore.meta.AutoInit'>, <class 'object'>)\n\nFoo's metaclass <class 'fastcore.meta.PrePostInitMeta'>'s function members are:\n{'__call__': <function PrePostInitMeta.__call__>,\n '__new__': <function FixSigMeta.__new__>}\n\nFoo's function members are:\n{'__init__': <function Foo.__init__>,\n '__pre_init__': <function AutoInit.__pre_init__>}\n\nFoo's method members are:\n{}\n\nFoo's class members are:\n{'__class__': <class 'fastcore.meta.PrePostInitMeta'>}\n\nFoo's namespace are:\nmappingproxy({'__doc__': None,\n              '__init__': <function Foo.__init__>,\n              '__module__': '__main__',\n              '__signature__': <Signature ()>})\n\n\n\nclass TestParent():\n    def __init__(self): self.h = 10\n        \nclass TestChild(AutoInit, TestParent):\n    def __init__(self): self.k = self.h + 2\ninspect_class(TestChild)\n\n\nis TestChild a metaclass: False\nis TestChild created by a metaclass: True\nTestChild is created by metaclass <class 'fastcore.meta.PrePostInitMeta'>\nTestChild.__new__ is object.__new__: True\nTestChild.__new__ is type.__new__: False\nTestChild.__new__: <built-in method __new__ of type object>\nTestChild.__init__ is object.__init__: False\nTestChild.__init__ is type.__init__: False\nTestChild.__init__: <function TestChild.__init__>\nTestChild.__call__ is object.__call__: False\nTestChild.__call__ is type.__call__: False\nTestChild.__call__: <bound method PrePostInitMeta.__call__ of <class '__main__.TestChild'>>\nTestChild.__class__: <class 'fastcore.meta.PrePostInitMeta'>\nTestChild.__bases__: (<class 'fastcore.meta.AutoInit'>, <class '__main__.TestParent'>)\nTestChild.__mro__: (<class '__main__.TestChild'>, <class 'fastcore.meta.AutoInit'>, <class '__main__.TestParent'>, <class 'object'>)\n\nTestChild's metaclass <class 'fastcore.meta.PrePostInitMeta'>'s function members are:\n{'__call__': <function PrePostInitMeta.__call__>,\n '__new__': <function FixSigMeta.__new__>}\n\nTestChild's function members are:\n{'__init__': <function TestChild.__init__>,\n '__pre_init__': <function AutoInit.__pre_init__>}\n\nTestChild's method members are:\n{}\n\nTestChild's class members are:\n{'__class__': <class 'fastcore.meta.PrePostInitMeta'>}\n\nTestChild's namespace are:\nmappingproxy({'__doc__': None,\n              '__init__': <function TestChild.__init__>,\n              '__module__': '__main__',\n              '__signature__': <Signature ()>})\n\n\n\nclass _T(metaclass=PrePostInitMeta):\n    def __pre_init__(self):  self.a  = 0; \n    def __init__(self,b=0):  self.b = self.a + 1; assert self.b==1\n    def __post_init__(self): self.c = self.b + 2; assert self.c==3\ninspect_class(_T)\n\n\nis _T a metaclass: False\nis _T created by a metaclass: True\n_T is created by metaclass <class 'fastcore.meta.PrePostInitMeta'>\n_T.__new__ is object.__new__: True\n_T.__new__ is type.__new__: False\n_T.__new__: <built-in method __new__ of type object>\n_T.__init__ is object.__init__: False\n_T.__init__ is type.__init__: False\n_T.__init__: <function _T.__init__>\n_T.__call__ is object.__call__: False\n_T.__call__ is type.__call__: False\n_T.__call__: <bound method PrePostInitMeta.__call__ of <class '__main__._T'>>\n_T.__class__: <class 'fastcore.meta.PrePostInitMeta'>\n_T.__bases__: (<class 'object'>,)\n_T.__mro__: (<class '__main__._T'>, <class 'object'>)\n\n_T's metaclass <class 'fastcore.meta.PrePostInitMeta'>'s function members are:\n{'__call__': <function PrePostInitMeta.__call__>,\n '__new__': <function FixSigMeta.__new__>}\n\n_T's function members are:\n{'__init__': <function _T.__init__>,\n '__post_init__': <function _T.__post_init__>,\n '__pre_init__': <function _T.__pre_init__>}\n\n_T's method members are:\n{}\n\n_T's class members are:\n{'__class__': <class 'fastcore.meta.PrePostInitMeta'>}\n\n_T's namespace are:\nmappingproxy({'__dict__': <attribute '__dict__' of '_T' objects>,\n              '__doc__': None,\n              '__init__': <function _T.__init__>,\n              '__module__': '__main__',\n              '__post_init__': <function _T.__post_init__>,\n              '__pre_init__': <function _T.__pre_init__>,\n              '__signature__': <Signature (b=0)>,\n              '__weakref__': <attribute '__weakref__' of '_T' objects>})"
  },
  {
    "objectID": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#prepare-examples-for-fixsigmeta-prepostinitmeta-autoinit",
    "href": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#prepare-examples-for-fixsigmeta-prepostinitmeta-autoinit",
    "title": "03_FixSigMeta_PrePostInitMeta_AutoInit",
    "section": "Prepare examples for FixSigMeta, PrePostInitMeta, AutoInit",
    "text": "Prepare examples for FixSigMeta, PrePostInitMeta, AutoInit\n\n# g = locals() \n# fdbF = Fastdb(FixSigMeta, outloc=g)\nfdbF.eg = \"\"\"\nclass Foo(metaclass=FixSigMeta):\n    def __init__(self): pass\n\"\"\"\n\n# fdbP = Fastdb(PrePostInitMeta, outloc=g)\nfdbP.eg = \"\"\"\nclass _T(metaclass=PrePostInitMeta):\n    def __pre_init__(self):  self.a  = 0; \n    def __init__(self,b=0):  self.b = self.a + 1; assert self.b==1\n    def __post_init__(self): self.c = self.b + 2; assert self.c==3\n\nt = _T()\ntest_eq(t.a, 0) # set with __pre_init__\ntest_eq(t.b, 1) # set with __init__\ntest_eq(t.c, 3) # set with __post_init__\ninspect.signature(_T)\n\"\"\"\n\n# fdbA = Fastdb(AutoInit, outloc=g)\nfdbA.eg = \"\"\"\nclass TestParent():\n    def __init__(self): self.h = 10\n        \nclass TestChild(AutoInit, TestParent):\n    def __init__(self): self.k = self.h + 2\n    \nt = TestChild()\ntest_eq(t.h, 10) # h=10 is initialized in the parent class\ntest_eq(t.k, 12)\n\"\"\""
  },
  {
    "objectID": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#snoop-them-together-in-one-go",
    "href": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#snoop-them-together-in-one-go",
    "title": "03_FixSigMeta_PrePostInitMeta_AutoInit",
    "section": "Snoop them together in one go",
    "text": "Snoop them together in one go\n\nfdbF.snoop(watch=['res', 'type(res)', 'res.__class__', 'res.__dict__'])\n\n23:04:33.14 >>> Call to FixSigMeta.__new__ in File \"/tmp/FixSigMeta.py\", line 5\n23:04:33.14 .......... cls = <class 'fastcore.meta.FixSigMeta'>\n23:04:33.14 .......... name = 'Foo'\n23:04:33.14 .......... bases = ()\n23:04:33.14 .......... dict = {'__module__': '__main__', '__qualname__': 'Foo', '__init__': <function Foo.__init__>}\n23:04:33.14 .......... len(dict) = 3\n23:04:33.14 .......... __class__ = <class 'fastcore.meta.FixSigMeta'>\n23:04:33.14    5 |     def __new__(cls, name, bases, dict):\n23:04:33.14    6 |         res = super().__new__(cls, name, bases, dict)\n23:04:33.14 .............. res = <class '__main__.Foo'>\n23:04:33.14 .............. type(res) = <class 'fastcore.meta.FixSigMeta'>\n23:04:33.14 .............. res.__class__ = <class 'fastcore.meta.FixSigMeta'>\n23:04:33.14 .............. res.__dict__ = mappingproxy({'__module__': '__main__', '__init_...__weakref__' of 'Foo' objects>, '__doc__': None})\n23:04:33.14 .............. len(res.__dict__) = 5\n23:04:33.14    7 |         if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__))\n23:04:33.14 ...... res.__dict__ = mappingproxy({'__module__': '__main__', '__init_...__doc__': None, '__signature__': <Signature ()>})\n23:04:33.14 ...... len(res.__dict__) = 6\n23:04:33.14    8 |         return res\n23:04:33.14 <<< Return value from FixSigMeta.__new__: <class '__main__.Foo'>\n\n\n========================================================     Investigating FixSigMeta     ========================================================\n==============================================================     on line None     ==============================================================\n==============================     with example \nclass Foo(metaclass=FixSigMeta):\n    def __init__(self): pass\n     ==============================\n\n\n\n\nembed the dbsrc of FixSigMeta into PrePostInitMeta\nImportant!\nFixSigMeta is untouched, fdbF.dbsrc.__new__ is the actual dbsrc\nTo use fdbF.dbsrc in other functions or classes which uses FixSigMeta, we need to assign fdbF.dbsrc to fm.FixSigMeta\n\nimport fastcore.meta as fm\n\n\nfm.FixSigMeta = fdbF.dbsrc\n\n\nfdbP.snoop(['res.__dict__'])\n\n23:04:33.18 >>> Call to FixSigMeta.__new__ in File \"/tmp/FixSigMeta.py\", line 5\n23:04:33.18 .......... cls = <class 'fastcore.meta.PrePostInitMeta'>\n23:04:33.18 .......... name = '_T'\n23:04:33.18 .......... bases = ()\n23:04:33.18 .......... dict = {'__module__': '__main__', '__qualname__': '_T', '__pre_init__': <function _T.__pre_init__>, '__init__': <function _T.__init__>, ...}\n23:04:33.18 .......... len(dict) = 5\n23:04:33.18 .......... __class__ = <class 'fastcore.meta.FixSigMeta'>\n23:04:33.18    5 |     def __new__(cls, name, bases, dict):\n23:04:33.18    6 |         res = super().__new__(cls, name, bases, dict)\n23:04:33.18 .............. res = <class '__main__._T'>\n23:04:33.18 .............. type(res) = <class 'fastcore.meta.PrePostInitMeta'>\n23:04:33.18 .............. res.__class__ = <class 'fastcore.meta.PrePostInitMeta'>\n23:04:33.18 .............. res.__dict__ = mappingproxy({'__module__': '__main__', '__pre_i...'__weakref__' of '_T' objects>, '__doc__': None})\n23:04:33.18 .............. len(res.__dict__) = 7\n23:04:33.18    7 |         if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__))\n23:04:33.18 ...... res.__dict__ = mappingproxy({'__module__': '__main__', '__pre_i...oc__': None, '__signature__': <Signature (b=0)>})\n23:04:33.18 ...... len(res.__dict__) = 8\n23:04:33.18    8 |         return res\n23:04:33.18 <<< Return value from FixSigMeta.__new__: <class '__main__._T'>\n23:04:33.19 >>> Call to PrePostInitMeta.__call__ in File \"/tmp/PrePostInitMeta.py\", line 5\n23:04:33.19 .......... cls = <class '__main__._T'>\n23:04:33.19 .......... args = ()\n23:04:33.19 .......... kwargs = {}\n23:04:33.19    5 |     def __call__(cls, *args, **kwargs):\n23:04:33.19    6 |         res = cls.__new__(cls)\n23:04:33.19 .............. res = <__main__._T object>\n23:04:33.19 .............. res.__dict__ = {}\n23:04:33.19    7 |         if type(res)==cls:\n23:04:33.19    8 |             if hasattr(res,'__pre_init__'): res.__pre_init__(*args,**kwargs)\n23:04:33.19 ...... res.__dict__ = {'a': 0}\n23:04:33.19 ...... len(res.__dict__) = 1\n23:04:33.19    9 |             res.__init__(*args,**kwargs)\n23:04:33.19 .................. res.__dict__ = {'a': 0, 'b': 1}\n23:04:33.19 .................. len(res.__dict__) = 2\n23:04:33.19   10 |             if hasattr(res,'__post_init__'): res.__post_init__(*args,**kwargs)\n23:04:33.19 ...... res.__dict__ = {'a': 0, 'b': 1, 'c': 3}\n23:04:33.19 ...... len(res.__dict__) = 3\n23:04:33.19   11 |         return res\n23:04:33.19 <<< Return value from PrePostInitMeta.__call__: <__main__._T object>\n\n\n=====================================================     Investigating PrePostInitMeta     ======================================================\n==============================================================     on line None     ==============================================================\n     with example \nclass _T(metaclass=PrePostInitMeta):\n    def __pre_init__(self):  self.a  = 0; \n    def __init__(self,b=0):  self.b = self.a + 1; assert self.b==1\n    def __post_init__(self): self.c = self.b + 2; assert self.c==3\n\nt = _T()\ntest_eq(t.a, 0) # set with __pre_init__\ntest_eq(t.b, 1) # set with __init__\ntest_eq(t.c, 3) # set with __post_init__\ninspect.signature(_T)\n     \n\n\n\n\n\nembed dbsrc of PrePostInitMeta into AutoInit\n\nfm.PrePostInitMeta = fdbP.dbsrc\n\n\nfdbA.snoop()\n\n23:04:33.20 >>> Call to FixSigMeta.__new__ in File \"/tmp/FixSigMeta.py\", line 5\n23:04:33.20 .......... cls = <class 'fastcore.meta.PrePostInitMeta'>\n23:04:33.20 .......... name = 'AutoInit'\n23:04:33.20 .......... bases = ()\n23:04:33.20 .......... dict = {'__module__': 'fastcore.meta', '__qualname__': 'AutoInit', '__doc__': 'Same as `object`, but no need for subclasses to call `super().__init__`', 'snoop': <class 'snoop.configuration.Config.__init__.<locals>.ConfiguredTracer'>, ...}\n23:04:33.20 .......... len(dict) = 6\n23:04:33.20 .......... __class__ = <class 'fastcore.meta.FixSigMeta'>\n23:04:33.20    5 |     def __new__(cls, name, bases, dict):\n23:04:33.20    6 |         res = super().__new__(cls, name, bases, dict)\n23:04:33.20 .............. res = <class 'fastcore.meta.AutoInit'>\n23:04:33.20 .............. type(res) = <class 'fastcore.meta.PrePostInitMeta'>\n23:04:33.20 .............. res.__class__ = <class 'fastcore.meta.PrePostInitMeta'>\n23:04:33.20 .............. res.__dict__ = mappingproxy({'__module__': 'fastcore.meta', '__...<attribute '__weakref__' of 'AutoInit' objects>})\n23:04:33.20 .............. len(res.__dict__) = 6\n23:04:33.20    7 |         if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__))\n23:04:33.20    8 |         return res\n23:04:33.20 <<< Return value from FixSigMeta.__new__: <class 'fastcore.meta.AutoInit'>\n23:04:33.20 >>> Call to FixSigMeta.__new__ in File \"/tmp/FixSigMeta.py\", line 5\n23:04:33.20 .......... cls = <class 'fastcore.meta.PrePostInitMeta'>\n23:04:33.20 .......... name = 'TestChild'\n23:04:33.20 .......... bases = (<class 'fastcore.meta.AutoInit'>, <class '__main__.TestParent'>)\n23:04:33.20 .......... len(bases) = 2\n23:04:33.20 .......... dict = {'__module__': '__main__', '__qualname__': 'TestChild', '__init__': <function TestChild.__init__>}\n23:04:33.20 .......... len(dict) = 3\n23:04:33.20 .......... __class__ = <class 'fastcore.meta.FixSigMeta'>\n23:04:33.20    5 |     def __new__(cls, name, bases, dict):\n23:04:33.20    6 |         res = super().__new__(cls, name, bases, dict)\n23:04:33.20 .............. res = <class '__main__.TestChild'>\n23:04:33.20 .............. type(res) = <class 'fastcore.meta.PrePostInitMeta'>\n23:04:33.20 .............. res.__class__ = <class 'fastcore.meta.PrePostInitMeta'>\n23:04:33.20 .............. res.__dict__ = mappingproxy({'__module__': '__main__', '__init_...Child.__init__ at 0x11fbf51f0>, '__doc__': None})\n23:04:33.20 .............. len(res.__dict__) = 3\n23:04:33.20    7 |         if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__))\n23:04:33.20 ...... res.__dict__ = mappingproxy({'__module__': '__main__', '__init_...__doc__': None, '__signature__': <Signature ()>})\n23:04:33.20 ...... len(res.__dict__) = 4\n23:04:33.20    8 |         return res\n23:04:33.20 <<< Return value from FixSigMeta.__new__: <class '__main__.TestChild'>\n23:04:33.20 >>> Call to PrePostInitMeta.__call__ in File \"/tmp/PrePostInitMeta.py\", line 5\n23:04:33.20 .......... cls = <class '__main__.TestChild'>\n23:04:33.20 .......... args = ()\n23:04:33.20 .......... kwargs = {}\n23:04:33.20    5 |     def __call__(cls, *args, **kwargs):\n23:04:33.20    6 |         res = cls.__new__(cls)\n23:04:33.20 .............. res = <__main__.TestChild object>\n23:04:33.20 .............. res.__dict__ = {}\n23:04:33.20    7 |         if type(res)==cls:\n23:04:33.20    8 |             if hasattr(res,'__pre_init__'): res.__pre_init__(*args,**kwargs)\n    23:04:33.20 >>> Call to AutoInit.__pre_init__ in File \"/tmp/AutoInit.py\", line 5\n    23:04:33.20 .......... self = <__main__.TestChild object>\n    23:04:33.20 .......... args = ()\n    23:04:33.20 .......... kwargs = {}\n    23:04:33.20 .......... __class__ = <class 'fastcore.meta.AutoInit'>\n    23:04:33.20    5 |     def __pre_init__(self, *args, **kwargs): super().__init__(*args, **kwargs)\n    23:04:33.20    5 |     def __pre_init__(self, *args, **kwargs): super().__init__(*args, **kwargs)\n    23:04:33.20 <<< Return value from AutoInit.__pre_init__: None\n23:04:33.20    8 |             if hasattr(res,'__pre_init__'): res.__pre_init__(*args,**kwargs)\n23:04:33.20 ...... res.__dict__ = {'h': 10}\n23:04:33.20 ...... len(res.__dict__) = 1\n23:04:33.20    9 |             res.__init__(*args,**kwargs)\n23:04:33.20 .................. res.__dict__ = {'h': 10, 'k': 12}\n23:04:33.20 .................. len(res.__dict__) = 2\n23:04:33.20   10 |             if hasattr(res,'__post_init__'): res.__post_init__(*args,**kwargs)\n23:04:33.20   11 |         return res\n23:04:33.20 <<< Return value from PrePostInitMeta.__call__: <__main__.TestChild object>\n\n\n=========================================================     Investigating AutoInit     =========================================================\n==============================================================     on line None     ==============================================================\n     with example \nclass TestParent():\n    def __init__(self): self.h = 10\n        \nclass TestChild(AutoInit, TestParent):\n    def __init__(self): self.k = self.h + 2\n    \nt = TestChild()\ntest_eq(t.h, 10) # h=10 is initialized in the parent class\ntest_eq(t.k, 12)"
  },
  {
    "objectID": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#explore-and-document-on-them-together",
    "href": "demos/explore_document_fixsigmeta_prepostinitmeta_autoinit.html#explore-and-document-on-them-together",
    "title": "03_FixSigMeta_PrePostInitMeta_AutoInit",
    "section": "Explore and Document on them together",
    "text": "Explore and Document on them together\n\nfdbF.docsrc(4, \"FixSigMeta: what is res\", \"'inside FixSigMeta, line 4'\", \"res.__name__\")\nfm.FixSigMeta = fdbF.dbsrc\n\n========================================================     Investigating FixSigMeta     ========================================================\n===============================================================     on line 4     ================================================================\n==============================     with example \nclass Foo(metaclass=FixSigMeta):\n    def __init__(self): pass\n     ==============================\n\nprint selected srcline with expands below--------\n    def __new__(cls, name, bases, dict):                                                                                                                (2)\n        res = super().__new__(cls, name, bases, dict)                                                                                                   (3)\n        if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__))===========================================(4)\n                                                                                                                                      FixSigMeta: what is res\n        return res                                                                                                                                      (5)\n                                                                                                                                                        (6)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                                       'inside FixSigMeta, line 4' => 'inside FixSigMeta, line 4' : inside FixSigMeta, line 4\n\n\n                                                                                                                           res.__name__ => res.__name__ : Foo\n====================================================================================================================End of my srcline exploration:\n\n\nReview srcode with all comments added so far======================================================================================================\nclass FixSigMeta(type):===================================================================(0)       \n    \"A metaclass that fixes the signature on classes that override `__new__`\"=============(1) # FixSigMeta inherits __init__, and __call__ from type; but writes its own __new__; Foo inherits all three from type; FixSigMeta is used to create class instance not object instance.; \n    def __new__(cls, name, bases, dict):==================================================(2)       \n        res = super().__new__(cls, name, bases, dict)=====================================(3)       \n        if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__)) # FixSigMeta: what is res;                   (4)\n        return res========================================================================(5)       \n                                                                                                                                                        (6)\n                                                                                                                                     part No.1 out of 1 parts\n\n\n\n\nfdbP.docsrc(6, \"what inside res.__dict__\", \"'inside PrePostInitMeta: '\", \"res.__dict__\")\nfm.PrePostInitMeta = fdbP.dbsrc\n\n=====================================================     Investigating PrePostInitMeta     ======================================================\n===============================================================     on line 6     ================================================================\n     with example \nclass _T(metaclass=PrePostInitMeta):\n    def __pre_init__(self):  self.a  = 0; \n    def __init__(self,b=0):  self.b = self.a + 1; assert self.b==1\n    def __post_init__(self): self.c = self.b + 2; assert self.c==3\n\nt = _T()\ntest_eq(t.a, 0) # set with __pre_init__\ntest_eq(t.b, 1) # set with __init__\ntest_eq(t.c, 3) # set with __post_init__\ninspect.signature(_T)\n     \n\nprint selected srcline with expands below--------\n        if type(res)==cls:                                                                                                                              (4)\n            if hasattr(res,'__pre_init__'): res.__pre_init__(*args,**kwargs)                                                                            (5)\n            res.__init__(*args,**kwargs)================================================================================================================(6)\n                                                                                                                                     what inside res.__dict__\n            if hasattr(res,'__post_init__'): res.__post_init__(*args,**kwargs)                                                                          (7)\n        return res                                                                                                                                      (8)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                                       'inside FixSigMeta, line 4' => 'inside FixSigMeta, line 4' : inside FixSigMeta, line 4\n\n\n                                                                                                                            res.__name__ => res.__name__ : _T\n====================================================================================================================End of my srcline exploration:\n\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                                          'inside PrePostInitMeta: ' => 'inside PrePostInitMeta: ' : inside PrePostInitMeta: \n\n\n                                                                                                                      res.__dict__ => res.__dict__ : {'a': 0}\n====================================================================================================================End of my srcline exploration:\n\n\nReview srcode with all comments added so far======================================================================================================\nclass PrePostInitMeta(FixSigMeta):========================================================(0)       \n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"==========(1) # PrePostInitMeta inherit __new__ and __init__ from FixSigMeta as a metaclass (a different type); not from type, nor from object; PrePostInitMeta is itself a metaclass, which is used to create class instance not object instance; PrePostInitMeta writes its own __call__ which regulates how its class instance create and initialize object instance; \n    def __call__(cls, *args, **kwargs):===================================================(2)       \n        res = cls.__new__(cls)============================================================(3)       \n        if type(res)==cls:================================================================(4)       \n            if hasattr(res,'__pre_init__'): res.__pre_init__(*args,**kwargs)==============(5)       \n            res.__init__(*args,**kwargs)==================================================(6) # what inside res.__dict__; \n            if hasattr(res,'__post_init__'): res.__post_init__(*args,**kwargs)============(7)       \n        return res========================================================================(8)       \n                                                                                                                                                        (9)\n                                                                                                                                     part No.1 out of 1 parts\n\n\n\n\nfdbA.docsrc(2, \"what is cls\", \"'Inside AutoInit'\", \"cls\") # need to run it twice (a little bug here)\n\n=========================================================     Investigating AutoInit     =========================================================\n===============================================================     on line 2     ================================================================\n     with example \nclass TestParent():\n    def __init__(self): self.h = 10\n        \nclass TestChild(AutoInit, TestParent):\n    def __init__(self): self.k = self.h + 2\n    \nt = TestChild()\ntest_eq(t.h, 10) # h=10 is initialized in the parent class\ntest_eq(t.k, 12)\n     \n\nprint selected srcline with expands below--------\nclass AutoInit(metaclass=PrePostInitMeta):                                                                                                              (0)\n    \"Same as `object`, but no need for subclasses to call `super().__init__`\"                                                                           (1)\n    def __pre_init__(self, *args, **kwargs): super().__init__(*args, **kwargs)==========================================================================(2)\n                                                                                                                                                  what is cls\n                                                                                                                                                        (3)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                                                                     'Inside AutoInit' => 'Inside AutoInit' : Inside AutoInit\n\n\n                                                                                                                           cls => cls : <class '__main__._T'>\n====================================================================================================================End of my srcline exploration:\n\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                                       'inside FixSigMeta, line 4' => 'inside FixSigMeta, line 4' : inside FixSigMeta, line 4\n\n\n                                                                                                                      res.__name__ => res.__name__ : AutoInit\n====================================================================================================================End of my srcline exploration:\n\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                                       'inside FixSigMeta, line 4' => 'inside FixSigMeta, line 4' : inside FixSigMeta, line 4\n\n\n                                                                                                                     res.__name__ => res.__name__ : TestChild\n====================================================================================================================End of my srcline exploration:\n\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                                          'inside PrePostInitMeta: ' => 'inside PrePostInitMeta: ' : inside PrePostInitMeta: \n\n\n                                                                                                                     res.__dict__ => res.__dict__ : {'h': 10}\n====================================================================================================================End of my srcline exploration:\n\n\nReview srcode with all comments added so far======================================================================================================\nclass AutoInit(metaclass=PrePostInitMeta):================================================(0)       \n    \"Same as `object`, but no need for subclasses to call `super().__init__`\"=============(1) # AutoInit inherit __new__ and __init__ from object to create and initialize object instances; AutoInit uses PrePostInitMeta.__new__ or in fact FixSigMeta.__new__ to create its own class instance, which can have __signature__; AutoInit uses PrePostInitMeta.__call__ to specify how its object instance to be created and initialized (with pre_init, init, post_init)); AutoInit as a normal or non-metaclass, it writes its own __pre_init__ method; \n    def __pre_init__(self, *args, **kwargs): super().__init__(*args, **kwargs)============(2) # what is cls; \n                                                                                                                                                        (3)\n                                                                                                                                     part No.1 out of 1 parts\n\n\n\n\nfdbF.docsrc(3, \"how to create a new class instance with type dynamically; \\\nthe rest below is how FixSigMeta as a metaclass create its own instance classes\")\nfdbF.docsrc(4, \"how to check whether a class has its own __init__ function; how to remove self param from a signature\")\n\n========================================================     Investigating FixSigMeta     ========================================================\n===============================================================     on line 3     ================================================================\n==============================     with example \nclass Foo(metaclass=FixSigMeta):\n    def __init__(self): pass\n     ==============================\n\nprint selected srcline with expands below--------\n    \"A metaclass that fixes the signature on classes that override `__new__`\"                                                                           (1)\n    def __new__(cls, name, bases, dict):                                                                                                                (2)\n        res = super().__new__(cls, name, bases, dict)===================================================================================================(3)\n                    how to create a new class instance with type dynamically; the rest below is how FixSigMeta as a metaclass create its own instance classes\n        if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__))                                           (4)\n        return res                                                                                                                                      (5)\n========================================================     Investigating FixSigMeta     ========================================================\n===============================================================     on line 4     ================================================================\n==============================     with example \nclass Foo(metaclass=FixSigMeta):\n    def __init__(self): pass\n     ==============================\n\nprint selected srcline with expands below--------\n    def __new__(cls, name, bases, dict):                                                                                                                (2)\n        res = super().__new__(cls, name, bases, dict)                                                                                                   (3)\n        if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__))===========================================(4)\n                                                        how to check whether a class has its own __init__ function; how to remove self param from a signature\n        return res                                                                                                                                      (5)\n                                                                                                                                                        (6)\n\n\n\nfdbF.print()\n\n========================================================     Investigating FixSigMeta     ========================================================\n===============================================================     on line 4     ================================================================\n==============================     with example \nclass Foo(metaclass=FixSigMeta):\n    def __init__(self): pass\n     ==============================\n\nclass FixSigMeta(type):===================================================================(0)       \n    \"A metaclass that fixes the signature on classes that override `__new__`\"=============(1) # FixSigMeta inherits __init__, and __call__ from type; but writes its own __new__; Foo inherits all three from type; FixSigMeta is used to create class instance not object instance.; \n    def __new__(cls, name, bases, dict):==================================================(2)       \n        res = super().__new__(cls, name, bases, dict)=====================================(3) # how to create a new class instance with type dynamically; the rest below is how FixSigMeta as a metaclass create its own instance classes; \n        if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__)) # how to check whether a class has its own __init__ function; how to remove self param from a signature;  (4)\n        return res========================================================================(5)       \n                                                                                                                                                        (6)\n\n\n\nfdbP.docsrc(3, \"how to create an object instance with a cls; how to check the type of an object is cls; \\\nhow to run a function without knowing its params;\")\nfdbP.print()\n\n=====================================================     Investigating PrePostInitMeta     ======================================================\n===============================================================     on line 3     ================================================================\n     with example \nclass _T(metaclass=PrePostInitMeta):\n    def __pre_init__(self):  self.a  = 0; \n    def __init__(self,b=0):  self.b = self.a + 1; assert self.b==1\n    def __post_init__(self): self.c = self.b + 2; assert self.c==3\n\nt = _T()\ntest_eq(t.a, 0) # set with __pre_init__\ntest_eq(t.b, 1) # set with __init__\ntest_eq(t.c, 3) # set with __post_init__\ninspect.signature(_T)\n     \n\nprint selected srcline with expands below--------\n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"                                                                        (1)\n    def __call__(cls, *args, **kwargs):                                                                                                                 (2)\n        res = cls.__new__(cls)==========================================================================================================================(3)\n                    how to create an object instance with a cls; how to check the type of an object is cls; how to run a function without knowing its params;\n        if type(res)==cls:                                                                                                                              (4)\n            if hasattr(res,'__pre_init__'): res.__pre_init__(*args,**kwargs)                                                                            (5)\n=====================================================     Investigating PrePostInitMeta     ======================================================\n===============================================================     on line 3     ================================================================\n     with example \nclass _T(metaclass=PrePostInitMeta):\n    def __pre_init__(self):  self.a  = 0; \n    def __init__(self,b=0):  self.b = self.a + 1; assert self.b==1\n    def __post_init__(self): self.c = self.b + 2; assert self.c==3\n\nt = _T()\ntest_eq(t.a, 0) # set with __pre_init__\ntest_eq(t.b, 1) # set with __init__\ntest_eq(t.c, 3) # set with __post_init__\ninspect.signature(_T)\n     \n\nclass PrePostInitMeta(FixSigMeta):========================================================(0)       \n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"==========(1) # PrePostInitMeta inherit __new__ and __init__ from FixSigMeta as a metaclass (a different type); not from type, nor from object; PrePostInitMeta is itself a metaclass, which is used to create class instance not object instance; PrePostInitMeta writes its own __call__ which regulates how its class instance create and initialize object instance; \n    def __call__(cls, *args, **kwargs):===================================================(2)       \n        res = cls.__new__(cls)============================================================(3) # how to create an object instance with a cls; how to check the type of an object is cls; how to run a function without knowing its params;; \n        if type(res)==cls:================================================================(4)       \n            if hasattr(res,'__pre_init__'): res.__pre_init__(*args,**kwargs)==============(5)       \n            res.__init__(*args,**kwargs)==================================================(6) # what inside res.__dict__; \n            if hasattr(res,'__post_init__'): res.__post_init__(*args,**kwargs)============(7)       \n        return res========================================================================(8)       \n                                                                                                                                                        (9)\n\n\n\nfdbA.docsrc(2, \"how to run superclass' __init__ function\")\n\n=========================================================     Investigating AutoInit     =========================================================\n===============================================================     on line 2     ================================================================\n     with example \nclass TestParent():\n    def __init__(self): self.h = 10\n        \nclass TestChild(AutoInit, TestParent):\n    def __init__(self): self.k = self.h + 2\n    \nt = TestChild()\ntest_eq(t.h, 10) # h=10 is initialized in the parent class\ntest_eq(t.k, 12)\n     \n\nprint selected srcline with expands below--------\nclass AutoInit(metaclass=PrePostInitMeta):                                                                                                              (0)\n    \"Same as `object`, but no need for subclasses to call `super().__init__`\"                                                                           (1)\n    def __pre_init__(self, *args, **kwargs): super().__init__(*args, **kwargs)==========================================================================(2)\n                                                                                                                     how to run superclass' __init__ function\n                                                                                                                                                        (3)\n\n\n\nfdbA.print()\n\n=========================================================     Investigating AutoInit     =========================================================\n===============================================================     on line 2     ================================================================\n     with example \nclass TestParent():\n    def __init__(self): self.h = 10\n        \nclass TestChild(AutoInit, TestParent):\n    def __init__(self): self.k = self.h + 2\n    \nt = TestChild()\ntest_eq(t.h, 10) # h=10 is initialized in the parent class\ntest_eq(t.k, 12)\n     \n\nclass AutoInit(metaclass=PrePostInitMeta):================================================(0)       \n    \"Same as `object`, but no need for subclasses to call `super().__init__`\"=============(1) # AutoInit inherit __new__ and __init__ from object to create and initialize object instances; AutoInit uses PrePostInitMeta.__new__ or in fact FixSigMeta.__new__ to create its own class instance, which can have __signature__; AutoInit uses PrePostInitMeta.__call__ to specify how its object instance to be created and initialized (with pre_init, init, post_init)); AutoInit as a normal or non-metaclass, it writes its own __pre_init__ method; \n    def __pre_init__(self, *args, **kwargs): super().__init__(*args, **kwargs)============(2) # how to run superclass' __init__ function; \n                                                                                                                                                        (3)\n\n\n\nfdbP.docsrc(6, \"how to run __init__ without knowing its params\")\n\n=====================================================     Investigating PrePostInitMeta     ======================================================\n===============================================================     on line 6     ================================================================\n     with example \nclass _T(metaclass=PrePostInitMeta):\n    def __pre_init__(self):  self.a  = 0; \n    def __init__(self,b=0):  self.b = self.a + 1; assert self.b==1\n    def __post_init__(self): self.c = self.b + 2; assert self.c==3\n\nt = _T()\ntest_eq(t.a, 0) # set with __pre_init__\ntest_eq(t.b, 1) # set with __init__\ntest_eq(t.c, 3) # set with __post_init__\ninspect.signature(_T)\n     \n\nprint selected srcline with expands below--------\n        if type(res)==cls:                                                                                                                              (4)\n            if hasattr(res,'__pre_init__'): res.__pre_init__(*args,**kwargs)                                                                            (5)\n            res.__init__(*args,**kwargs)================================================================================================================(6)\n                                                                                                               how to run __init__ without knowing its params\n            if hasattr(res,'__post_init__'): res.__post_init__(*args,**kwargs)                                                                          (7)\n        return res                                                                                                                                      (8)\n\n\n\nfdbP.print()\n\n=====================================================     Investigating PrePostInitMeta     ======================================================\n===============================================================     on line 6     ================================================================\n     with example \nclass _T(metaclass=PrePostInitMeta):\n    def __pre_init__(self):  self.a  = 0; \n    def __init__(self,b=0):  self.b = self.a + 1; assert self.b==1\n    def __post_init__(self): self.c = self.b + 2; assert self.c==3\n\nt = _T()\ntest_eq(t.a, 0) # set with __pre_init__\ntest_eq(t.b, 1) # set with __init__\ntest_eq(t.c, 3) # set with __post_init__\ninspect.signature(_T)\n     \n\nclass PrePostInitMeta(FixSigMeta):========================================================(0)       \n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"==========(1) # PrePostInitMeta inherit __new__ and __init__ from FixSigMeta as a metaclass (a different type); not from type, nor from object; PrePostInitMeta is itself a metaclass, which is used to create class instance not object instance; PrePostInitMeta writes its own __call__ which regulates how its class instance create and initialize object instance; \n    def __call__(cls, *args, **kwargs):===================================================(2)       \n        res = cls.__new__(cls)============================================================(3) # how to create an object instance with a cls; how to check the type of an object is cls; how to run a function without knowing its params;; \n        if type(res)==cls:================================================================(4)       \n            if hasattr(res,'__pre_init__'): res.__pre_init__(*args,**kwargs)==============(5)       \n            res.__init__(*args,**kwargs)==================================================(6) # how to run __init__ without knowing its params; \n            if hasattr(res,'__post_init__'): res.__post_init__(*args,**kwargs)============(7)       \n        return res========================================================================(8)       \n                                                                                                                                                        (9)\n\n\n\nfdbF.print()\n\n========================================================     Investigating FixSigMeta     ========================================================\n===============================================================     on line 4     ================================================================\n==============================     with example \nclass Foo(metaclass=FixSigMeta):\n    def __init__(self): pass\n     ==============================\n\nclass FixSigMeta(type):===================================================================(0)       \n    \"A metaclass that fixes the signature on classes that override `__new__`\"=============(1) # FixSigMeta inherits __init__, and __call__ from type; but writes its own __new__; Foo inherits all three from type; FixSigMeta is used to create class instance not object instance.; \n    def __new__(cls, name, bases, dict):==================================================(2)       \n        res = super().__new__(cls, name, bases, dict)=====================================(3) # how to create a new class instance with type dynamically; the rest below is how FixSigMeta as a metaclass create its own instance classes; \n        if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__)) # how to check whether a class has its own __init__ function; how to remove self param from a signature;  (4)\n        return res========================================================================(5)       \n                                                                                                                                                        (6)"
  },
  {
    "objectID": "demos/fastcore_meta_delegates.html",
    "href": "demos/fastcore_meta_delegates.html",
    "title": "0001_Fastcore.meta.delegates",
    "section": "",
    "text": "# from IPython.core.display import display, HTML # a depreciated import\nfrom IPython.display import display, HTML \n\ndisplay(HTML(\"<style>.container { width:100% !important; }</style>\"))"
  },
  {
    "objectID": "demos/fastcore_meta_delegates.html#import",
    "href": "demos/fastcore_meta_delegates.html#import",
    "title": "0001_Fastcore.meta.delegates",
    "section": "Import",
    "text": "Import\n\nfrom fastdebug.core import *\n\n\nfrom fastcore.meta import delegates"
  },
  {
    "objectID": "demos/fastcore_meta_delegates.html#initiate-fastdb-and-example-in-str",
    "href": "demos/fastcore_meta_delegates.html#initiate-fastdb-and-example-in-str",
    "title": "0001_Fastcore.meta.delegates",
    "section": "Initiate Fastdb and example in str",
    "text": "Initiate Fastdb and example in str\n\ng = locals() # this is a must\nfdb = Fastdb(delegates, outloc=g)"
  },
  {
    "objectID": "demos/fastcore_meta_delegates.html#example",
    "href": "demos/fastcore_meta_delegates.html#example",
    "title": "0001_Fastcore.meta.delegates",
    "section": "Example",
    "text": "Example\n\ndef low(a, b=1): pass\n@delegates(low) # this format is fine too\ndef mid(c, d=1, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n\n<Signature (c, d=1, *, b=1)>\n\n\n\ndef low(a, b=1): pass\ndef mid(c, d=1, **kwargs): pass\npprint(inspect.signature(delegates(low)(mid)))\n\n<Signature (c, d=1, *, b=1)>\n\n\n\nfdb.eg = \"\"\"\ndef low(a, b=1): pass\ndef mid(c, d=1, **kwargs): pass\npprint(inspect.signature(delegates(low)(mid)))\n\"\"\"\n\n\nfdb.eg = \"\"\"\ndef low(a, b=1): pass\n@delegates(low)\ndef mid(c, d=1, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n\"\"\"\n\n\nfdb.eg = \"\"\"\nclass Foo:\n    @classmethod\n    def clsm(a, b=1): pass\n    \n    @delegates(clsm)\n    def instm(c, d=1, **kwargs): pass\nf = Foo()\npprint(inspect.signature(f.instm)) # pprint and inspect is loaded from fastdebug\n\"\"\"\n\n\nfdb.eg = \"\"\"\ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n\"\"\""
  },
  {
    "objectID": "demos/fastcore_meta_delegates.html#docsrc",
    "href": "demos/fastcore_meta_delegates.html#docsrc",
    "title": "0001_Fastcore.meta.delegates",
    "section": "docsrc",
    "text": "docsrc\n\nfdb.eg\n\n'\\ndef low(a, b:int=1): pass\\n@delegates(low)\\ndef mid(c, d:list=None, **kwargs): pass\\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\\n'\n\n\n\nfdb.print()\n\n========================================================     Investigating delegates     =========================================================\n==============================================================     on line None     ==============================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\ndef delegates(to:FunctionType=None, # Delegatee===========================================(0)       \n              keep=False, # Keep `kwargs` in decorated function?==========================(1)       \n              but:list=None): # Exclude these parameters from signature===================(2)       \n    \"Decorator: replace `**kwargs` in signature with params from `to`\"====================(3)       \n    if but is None: but = []==============================================================(4)       \n    def _f(f):============================================================================(5)       \n        if to is None: to_f,from_f = f.__base__.__init__,f.__init__=======================(6)       \n        else:          to_f,from_f = to.__init__ if isinstance(to,type) else to,f=========(7)       \n        from_f = getattr(from_f,'__func__',from_f)========================================(8)       \n        to_f = getattr(to_f,'__func__',to_f)==============================================(9)       \n        if hasattr(from_f,'__delwrap__'): return f========================================(10)      \n        sig = inspect.signature(from_f)===================================================(11)      \n        sigd = dict(sig.parameters)=======================================================(12)      \n        k = sigd.pop('kwargs')============================================================(13)      \n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items()                                    (14)\n              if v.default != inspect.Parameter.empty and k not in sigd and k not in but}=(15)      \n        anno = {k:v for k,v in getattr(to_f, \"__annotations__\", {}).items() if k not in sigd and k not in but}                                          (16)\n        sigd.update(s2)===================================================================(17)      \n        if keep: sigd['kwargs'] = k=======================================================(18)      \n        else: from_f.__delwrap__ = to_f===================================================(19)      \n        from_f.__signature__ = sig.replace(parameters=sigd.values())======================(20)      \n        if hasattr(from_f, '__annotations__'): from_f.__annotations__.update(anno)========(21)      \n        return f==========================================================================(22)      \n    return _f=============================================================================(23)      \n                                                                                                                                                        (24)\n\n\n\nfdb.docsrc(21, \"How to check whether a func has __annotations__; How add selected params' annotations from A to B's annotations;\")\n\nfdb.docsrc(14, \"How to access a signature's parameters as a dict?; How to replace the kind of a parameter with a different kind?; \\\nhow to check whether a parameter has a default value?; How to check whether a string is in a dict and a list?; \\\nhow dict.items() and dict.values() differ\", \\\n\"inspect.signature(to_f).parameters.items()\", \"inspect.signature(to_f).parameters.values()\", \"inspect.Parameter.empty\", \\\n\"for k,v in inspect.signature(to_f).parameters.items():\\\\n\\\n    printright(f'v.kind: {v.kind}')\\\\n\\\n    printright(f'v.default: {v.default}')\\\\n\\\n    v1 = v.replace(kind=inspect.Parameter.KEYWORD_ONLY)\\\\n\\\n    printright(f'v1.kind: {v1.kind}')\")\n\nfdb.docsrc(16, \"How to get A's __annotations__?; How to access it as a dict?; \\\nHow to select annotations of the right params with names?; How to put them into a dict?; How to do it all in a single line\", \\\n          \"getattr(to_f, '__annotations__', {})\", \"getattr(from_f, '__annotations__', {})\")\nfdb.docsrc(17, \"How to add the selected params from A's signature to B's signature; How to add items into a dict;\")\nfdb.docsrc(18, \"How to add a new item into a dict;\")\nfdb.docsrc(19, \"How to create a new attr for a function or obj;\")\nfdb.docsrc(20, \"How to update a signature with a new set of parameters;\", \"sigd\", \"sigd.values()\", \"sig\", \\\n           \"sig.replace(parameters=sigd.values())\")\n\n\nfdb.docsrc(2, \"how to make delegates(to, but) to have 'but' as list and default as None\")\nfdb.docsrc(0, \"how to make delegates(to) to have to as FunctionType and default as None\")\nfdb.docsrc(6, \"how to write 2 ifs and elses in 2 lines\")\nfdb.docsrc(7, \"how to assign a,b together with if and else\")\nfdb.docsrc(8, \"Is classmethod callable; does classmethod has __func__; can we do inspect.signature(clsmethod); \\\nhow to use getattr(obj, attr, default)\", \\\n           \"from_f\", \"to_f\", \\\n           \"hasattr(from_f, '__func__')\", \"from_f = getattr(from_f,'__func__',from_f)\", \\\n           \"hasattr(to_f, '__func__')\", \"from_f = getattr(to_f,'__func__',to_f)\", \"callable(to_f)\")\n\nfdb.docsrc(10, \"if B has __delwrap__, can we do delegates(A)(B) again?; hasattr(obj, '__delwrap__')\")\nfdb.docsrc(11, \"how to get signature obj of B; what does a signature look like; what is the type\", \"inspect.signature(from_f)\", \"type(inspect.signature(from_f))\")\nfdb.docsrc(12, \"How to access parameters of a signature?; How to turn parameters into a dict?\", \"sig.parameters\", \"dict(sig.parameters)\")\nfdb.docsrc(13, \"How to remove an item from a dict?; How to get the removed item from a dict?; How to add the removed item back to the dict?; \\\nwhen writing expressions, as they share environment, so they may affect the following code\", \"sigd\", \"k = sigd.pop('kwargs')\", \"sigd\", \"sigd['kwargs'] = k\")\n\n\n# fdb.docsrc(3,\"Personal Docs: delegates(A)(B), given B has kwargs in sig; delegating params of A to B; A and B can be funcs, methods, classes; \\\n# when A or B are classmethod or if they have __func__, then __func__ shall be used to get sig/params; \\\n# when A and B are classes, A.__init__ is actually used to get sig/params, B offers sig/params as a class; \\\n# B only take wanted and missing params with default values; B can keep its kwargs, if not, B will store A in __delwrap__ to prevent delegates(A)(B) again;\\\n# B will get __signature__ and store its new sig; if B has __annotations__, then add what B want from A's __annotations__\")\n\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 21     ===============================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\n        else: from_f.__delwrap__ = to_f                                                                                                                 (19)\n        from_f.__signature__ = sig.replace(parameters=sigd.values())                                                                                    (20)\n        if hasattr(from_f, '__annotations__'): from_f.__annotations__.update(anno)======================================================================(21)\n                                             How to check whether a func has __annotations__; How add selected params' annotations from A to B's annotations;\n        return f                                                                                                                                        (22)\n    return _f                                                                                                                                           (23)\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 14     ===============================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\n        sigd = dict(sig.parameters)                                                                                                                     (12)\n        k = sigd.pop('kwargs')                                                                                                                          (13)\n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items()====================================(14)\nHow to access a signature's parameters as a dict?; How to replace the kind of a parameter with a different kind?; how to check whether a parameter has a default value?; How to check whether a string is in a dict and a list?; how dict.items() and dict.values() differ\n              if v.default != inspect.Parameter.empty and k not in sigd and k not in but}                                                               (15)\n        anno = {k:v for k,v in getattr(to_f, \"__annotations__\", {}).items() if k not in sigd and k not in but}                                          (16)\n\n==================================================================================================================Start of my srcline exploration:\n\n\ninspect.signature(to_f).parameters.items() => inspect.signature(to_f).parameters.items() : odict_items([('a', <Parameter \"a\">), ('b', <Parameter \"b: int = 1\">)])\n\n\n       inspect.signature(to_f).parameters.values() => inspect.signature(to_f).parameters.values() : odict_values([<Parameter \"a\">, <Parameter \"b: int = 1\">])\n\n\n                                                                                inspect.Parameter.empty => inspect.Parameter.empty : <class 'inspect._empty'>\n\n\nfor k,v in inspect.signature(to_f).parameters.items():\n    printright(f'v.kind: {v.kind}')\n    printright(f'v.default: {v.default}')\n    v1 = v.replace(kind=inspect.Parameter.KEYWORD_ONLY)\n    printright(f'v1.kind: {v1.kind}')\n\nRunning the code block above => ====================================================================\n\n                                                                                                                                v.kind: POSITIONAL_OR_KEYWORD\n                                                                                                                          v.default: <class 'inspect._empty'>\n                                                                                                                                        v1.kind: KEYWORD_ONLY\n                                                                                                                                v.kind: POSITIONAL_OR_KEYWORD\n                                                                                                                                                 v.default: 1\n                                                                                                                                        v1.kind: KEYWORD_ONLY\n====================================================================================================================End of my srcline exploration:\n\n<Signature (c, d: list = None, *, b: int = 1)>\n\nReview srcode with all comments added so far======================================================================================================\ndef delegates(to:FunctionType=None, # Delegatee===========================================(0)       \n              keep=False, # Keep `kwargs` in decorated function?==========================(1)       \n              but:list=None): # Exclude these parameters from signature===================(2)       \n    \"Decorator: replace `**kwargs` in signature with params from `to`\"====================(3)       \n    if but is None: but = []==============================================================(4)       \n    def _f(f):============================================================================(5)       \n        if to is None: to_f,from_f = f.__base__.__init__,f.__init__=======================(6)       \n        else:          to_f,from_f = to.__init__ if isinstance(to,type) else to,f=========(7)       \n        from_f = getattr(from_f,'__func__',from_f)========================================(8)       \n        to_f = getattr(to_f,'__func__',to_f)==============================================(9)       \n        if hasattr(from_f,'__delwrap__'): return f========================================(10)      \n        sig = inspect.signature(from_f)===================================================(11)      \n        sigd = dict(sig.parameters)=======================================================(12)      \n        k = sigd.pop('kwargs')============================================================(13)      \n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items() # How to access a signature's parameters as a dict?; How to replace the kind of a parameter with a different kind?; how to check whether a parameter has a default value?; How to check whether a string is in a dict and a list?; how dict.items() and dict.values() differ;  (14)\n              if v.default != inspect.Parameter.empty and k not in sigd and k not in but}=(15)      \n        anno = {k:v for k,v in getattr(to_f, \"__annotations__\", {}).items() if k not in sigd and k not in but}                                          (16)\n        sigd.update(s2)===================================================================(17)      \n        if keep: sigd['kwargs'] = k=======================================================(18)      \n        else: from_f.__delwrap__ = to_f===================================================(19)      \n                                                                                                                                     part No.1 out of 2 parts\n\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 16     ===============================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items()                                    (14)\n              if v.default != inspect.Parameter.empty and k not in sigd and k not in but}                                                               (15)\n        anno = {k:v for k,v in getattr(to_f, \"__annotations__\", {}).items() if k not in sigd and k not in but}==========================================(16)\nHow to get A's __annotations__?; How to access it as a dict?; How to select annotations of the right params with names?; How to put them into a dict?; How to do it all in a single line\n        sigd.update(s2)                                                                                                                                 (17)\n        if keep: sigd['kwargs'] = k                                                                                                                     (18)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                          getattr(to_f, '__annotations__', {}) => getattr(to_f, '__annotations__', {}) : {'b': <class 'int'>}\n\n\n                                                     getattr(from_f, '__annotations__', {}) => getattr(from_f, '__annotations__', {}) : {'d': <class 'list'>}\n====================================================================================================================End of my srcline exploration:\n\n<Signature (c, d: list = None, *, b: int = 1)>\n\nReview srcode with all comments added so far======================================================================================================\ndef delegates(to:FunctionType=None, # Delegatee===========================================(0)       \n              keep=False, # Keep `kwargs` in decorated function?==========================(1)       \n              but:list=None): # Exclude these parameters from signature===================(2)       \n    \"Decorator: replace `**kwargs` in signature with params from `to`\"====================(3)       \n    if but is None: but = []==============================================================(4)       \n    def _f(f):============================================================================(5)       \n        if to is None: to_f,from_f = f.__base__.__init__,f.__init__=======================(6)       \n        else:          to_f,from_f = to.__init__ if isinstance(to,type) else to,f=========(7)       \n        from_f = getattr(from_f,'__func__',from_f)========================================(8)       \n        to_f = getattr(to_f,'__func__',to_f)==============================================(9)       \n        if hasattr(from_f,'__delwrap__'): return f========================================(10)      \n        sig = inspect.signature(from_f)===================================================(11)      \n        sigd = dict(sig.parameters)=======================================================(12)      \n        k = sigd.pop('kwargs')============================================================(13)      \n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items() # How to access a signature's parameters as a dict?; How to replace the kind of a parameter with a different kind?; how to check whether a parameter has a default value?; How to check whether a string is in a dict and a list?; how dict.items() and dict.values() differ;  (14)\n              if v.default != inspect.Parameter.empty and k not in sigd and k not in but}=(15)      \n        anno = {k:v for k,v in getattr(to_f, \"__annotations__\", {}).items() if k not in sigd and k not in but} # How to get A's __annotations__?; How to access it as a dict?; How to select annotations of the right params with names?; How to put them into a dict?; How to do it all in a single line;  (16)\n        sigd.update(s2)===================================================================(17)      \n        if keep: sigd['kwargs'] = k=======================================================(18)      \n        else: from_f.__delwrap__ = to_f===================================================(19)      \n                                                                                                                                     part No.1 out of 2 parts\n\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 17     ===============================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\n              if v.default != inspect.Parameter.empty and k not in sigd and k not in but}                                                               (15)\n        anno = {k:v for k,v in getattr(to_f, \"__annotations__\", {}).items() if k not in sigd and k not in but}                                          (16)\n        sigd.update(s2)=================================================================================================================================(17)\n                                                            How to add the selected params from A's signature to B's signature; How to add items into a dict;\n        if keep: sigd['kwargs'] = k                                                                                                                     (18)\n        else: from_f.__delwrap__ = to_f                                                                                                                 (19)\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 18     ===============================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\n        anno = {k:v for k,v in getattr(to_f, \"__annotations__\", {}).items() if k not in sigd and k not in but}                                          (16)\n        sigd.update(s2)                                                                                                                                 (17)\n        if keep: sigd['kwargs'] = k=====================================================================================================================(18)\n                                                                                                                           How to add a new item into a dict;\n        else: from_f.__delwrap__ = to_f                                                                                                                 (19)\n        from_f.__signature__ = sig.replace(parameters=sigd.values())                                                                                    (20)\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 19     ===============================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\n        sigd.update(s2)                                                                                                                                 (17)\n        if keep: sigd['kwargs'] = k                                                                                                                     (18)\n        else: from_f.__delwrap__ = to_f=================================================================================================================(19)\n                                                                                                              How to create a new attr for a function or obj;\n        from_f.__signature__ = sig.replace(parameters=sigd.values())                                                                                    (20)\n        if hasattr(from_f, '__annotations__'): from_f.__annotations__.update(anno)                                                                      (21)\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 20     ===============================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\n        if keep: sigd['kwargs'] = k                                                                                                                     (18)\n        else: from_f.__delwrap__ = to_f                                                                                                                 (19)\n        from_f.__signature__ = sig.replace(parameters=sigd.values())====================================================================================(20)\n                                                                                                      How to update a signature with a new set of parameters;\n        if hasattr(from_f, '__annotations__'): from_f.__annotations__.update(anno)                                                                      (21)\n        return f                                                                                                                                        (22)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                      sigd => sigd : {'c': <Parameter \"c\">, 'd': <Parameter \"d: list = None\">, 'b': <Parameter \"b: int = 1\">}\n\n\n                                      sigd.values() => sigd.values() : dict_values([<Parameter \"c\">, <Parameter \"d: list = None\">, <Parameter \"b: int = 1\">])\n\n\n                                                                                                                   sig => sig : (c, d: list = None, **kwargs)\n\n\n                                           sig.replace(parameters=sigd.values()) => sig.replace(parameters=sigd.values()): (c, d: list = None, *, b: int = 1)\n====================================================================================================================End of my srcline exploration:\n\n<Signature (c, d: list = None, *, b: int = 1)>\n\nReview srcode with all comments added so far======================================================================================================\n        from_f.__signature__ = sig.replace(parameters=sigd.values())======================(20) # How to update a signature with a new set of parameters;; \n        if hasattr(from_f, '__annotations__'): from_f.__annotations__.update(anno)========(21) # How to check whether a func has __annotations__; How add selected params' annotations from A to B's annotations;; \n        return f==========================================================================(22)      \n    return _f=============================================================================(23)      \n                                                                                                                                                        (24)\n                                                                                                                                     part No.2 out of 2 parts\n\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 2     ================================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\ndef delegates(to:FunctionType=None, # Delegatee                                                                                                         (0)\n              keep=False, # Keep `kwargs` in decorated function?                                                                                        (1)\n              but:list=None): # Exclude these parameters from signature=================================================================================(2)\n                                                                                     how to make delegates(to, but) to have 'but' as list and default as None\n    \"Decorator: replace `**kwargs` in signature with params from `to`\"                                                                                  (3)\n    if but is None: but = []                                                                                                                            (4)\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 0     ================================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\ndef delegates(to:FunctionType=None, # Delegatee=========================================================================================================(0)\n                                                                                     how to make delegates(to) to have to as FunctionType and default as None\n              keep=False, # Keep `kwargs` in decorated function?                                                                                        (1)\n              but:list=None): # Exclude these parameters from signature                                                                                 (2)\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 6     ================================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\n    if but is None: but = []                                                                                                                            (4)\n    def _f(f):                                                                                                                                          (5)\n        if to is None: to_f,from_f = f.__base__.__init__,f.__init__=====================================================================================(6)\n                                                                                                                      how to write 2 ifs and elses in 2 lines\n        else:          to_f,from_f = to.__init__ if isinstance(to,type) else to,f                                                                       (7)\n        from_f = getattr(from_f,'__func__',from_f)                                                                                                      (8)\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 7     ================================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\n    def _f(f):                                                                                                                                          (5)\n        if to is None: to_f,from_f = f.__base__.__init__,f.__init__                                                                                     (6)\n        else:          to_f,from_f = to.__init__ if isinstance(to,type) else to,f=======================================================================(7)\n                                                                                                                  how to assign a,b together with if and else\n        from_f = getattr(from_f,'__func__',from_f)                                                                                                      (8)\n        to_f = getattr(to_f,'__func__',to_f)                                                                                                            (9)\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 8     ================================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\n        if to is None: to_f,from_f = f.__base__.__init__,f.__init__                                                                                     (6)\n        else:          to_f,from_f = to.__init__ if isinstance(to,type) else to,f                                                                       (7)\n        from_f = getattr(from_f,'__func__',from_f)======================================================================================================(8)\n                       Is classmethod callable; does classmethod has __func__; can we do inspect.signature(clsmethod); how to use getattr(obj, attr, default)\n        to_f = getattr(to_f,'__func__',to_f)                                                                                                            (9)\n        if hasattr(from_f,'__delwrap__'): return f                                                                                                      (10)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                                                                             from_f => from_f : <function mid>\n\n\n                                                                                                                 to_f => to_f : <function low>\n\n\n                                                                                           hasattr(from_f, '__func__') => hasattr(from_f, '__func__') : False\n\n\n                                                                          from_f = getattr(from_f,'__func__',from_f) => from_f: <function mid>\n\n\n                                                                                               hasattr(to_f, '__func__') => hasattr(to_f, '__func__') : False\n\n\n                                                                              from_f = getattr(to_f,'__func__',to_f) => from_f: <function low>\n\n\n                                                                                                                      callable(to_f) => callable(to_f) : True\n====================================================================================================================End of my srcline exploration:\n\n<Signature (c, d: list = None, *, b: int = 1)>\n\nReview srcode with all comments added so far======================================================================================================\ndef delegates(to:FunctionType=None, # Delegatee===========================================(0) # how to make delegates(to) to have to as FunctionType and default as None; \n              keep=False, # Keep `kwargs` in decorated function?==========================(1)       \n              but:list=None): # Exclude these parameters from signature===================(2) # how to make delegates(to, but) to have 'but' as list and default as None; \n    \"Decorator: replace `**kwargs` in signature with params from `to`\"====================(3)       \n    if but is None: but = []==============================================================(4)       \n    def _f(f):============================================================================(5)       \n        if to is None: to_f,from_f = f.__base__.__init__,f.__init__=======================(6) # how to write 2 ifs and elses in 2 lines; \n        else:          to_f,from_f = to.__init__ if isinstance(to,type) else to,f=========(7) # how to assign a,b together with if and else; \n        from_f = getattr(from_f,'__func__',from_f)========================================(8) # Is classmethod callable; does classmethod has __func__; can we do inspect.signature(clsmethod); how to use getattr(obj, attr, default); \n        to_f = getattr(to_f,'__func__',to_f)==============================================(9)       \n        if hasattr(from_f,'__delwrap__'): return f========================================(10)      \n        sig = inspect.signature(from_f)===================================================(11)      \n        sigd = dict(sig.parameters)=======================================================(12)      \n        k = sigd.pop('kwargs')============================================================(13)      \n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items() # How to access a signature's parameters as a dict?; How to replace the kind of a parameter with a different kind?; how to check whether a parameter has a default value?; How to check whether a string is in a dict and a list?; how dict.items() and dict.values() differ;  (14)\n              if v.default != inspect.Parameter.empty and k not in sigd and k not in but}=(15)      \n        anno = {k:v for k,v in getattr(to_f, \"__annotations__\", {}).items() if k not in sigd and k not in but} # How to get A's __annotations__?; How to access it as a dict?; How to select annotations of the right params with names?; How to put them into a dict?; How to do it all in a single line;  (16)\n        sigd.update(s2)===================================================================(17) # How to add the selected params from A's signature to B's signature; How to add items into a dict;; \n        if keep: sigd['kwargs'] = k=======================================================(18) # How to add a new item into a dict;; \n        else: from_f.__delwrap__ = to_f===================================================(19) # How to create a new attr for a function or obj;; \n                                                                                                                                     part No.1 out of 2 parts\n\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 10     ===============================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\n        from_f = getattr(from_f,'__func__',from_f)                                                                                                      (8)\n        to_f = getattr(to_f,'__func__',to_f)                                                                                                            (9)\n        if hasattr(from_f,'__delwrap__'): return f======================================================================================================(10)\n                                                                          if B has __delwrap__, can we do delegates(A)(B) again?; hasattr(obj, '__delwrap__')\n        sig = inspect.signature(from_f)                                                                                                                 (11)\n        sigd = dict(sig.parameters)                                                                                                                     (12)\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 11     ===============================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\n        to_f = getattr(to_f,'__func__',to_f)                                                                                                            (9)\n        if hasattr(from_f,'__delwrap__'): return f                                                                                                      (10)\n        sig = inspect.signature(from_f)=================================================================================================================(11)\n                                                                             how to get signature obj of B; what does a signature look like; what is the type\n        sigd = dict(sig.parameters)                                                                                                                     (12)\n        k = sigd.pop('kwargs')                                                                                                                          (13)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                                       inspect.signature(from_f) => inspect.signature(from_f) : (c, d: list = None, **kwargs)\n\n\n                                                             type(inspect.signature(from_f)) => type(inspect.signature(from_f)) : <class 'inspect.Signature'>\n====================================================================================================================End of my srcline exploration:\n\n<Signature (c, d: list = None, *, b: int = 1)>\n\nReview srcode with all comments added so far======================================================================================================\ndef delegates(to:FunctionType=None, # Delegatee===========================================(0) # how to make delegates(to) to have to as FunctionType and default as None; \n              keep=False, # Keep `kwargs` in decorated function?==========================(1)       \n              but:list=None): # Exclude these parameters from signature===================(2) # how to make delegates(to, but) to have 'but' as list and default as None; \n    \"Decorator: replace `**kwargs` in signature with params from `to`\"====================(3)       \n    if but is None: but = []==============================================================(4)       \n    def _f(f):============================================================================(5)       \n        if to is None: to_f,from_f = f.__base__.__init__,f.__init__=======================(6) # how to write 2 ifs and elses in 2 lines; \n        else:          to_f,from_f = to.__init__ if isinstance(to,type) else to,f=========(7) # how to assign a,b together with if and else; \n        from_f = getattr(from_f,'__func__',from_f)========================================(8) # Is classmethod callable; does classmethod has __func__; can we do inspect.signature(clsmethod); how to use getattr(obj, attr, default); \n        to_f = getattr(to_f,'__func__',to_f)==============================================(9)       \n        if hasattr(from_f,'__delwrap__'): return f========================================(10) # if B has __delwrap__, can we do delegates(A)(B) again?; hasattr(obj, '__delwrap__'); \n        sig = inspect.signature(from_f)===================================================(11) # how to get signature obj of B; what does a signature look like; what is the type; \n        sigd = dict(sig.parameters)=======================================================(12)      \n        k = sigd.pop('kwargs')============================================================(13)      \n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items() # How to access a signature's parameters as a dict?; How to replace the kind of a parameter with a different kind?; how to check whether a parameter has a default value?; How to check whether a string is in a dict and a list?; how dict.items() and dict.values() differ;  (14)\n              if v.default != inspect.Parameter.empty and k not in sigd and k not in but}=(15)      \n        anno = {k:v for k,v in getattr(to_f, \"__annotations__\", {}).items() if k not in sigd and k not in but} # How to get A's __annotations__?; How to access it as a dict?; How to select annotations of the right params with names?; How to put them into a dict?; How to do it all in a single line;  (16)\n        sigd.update(s2)===================================================================(17) # How to add the selected params from A's signature to B's signature; How to add items into a dict;; \n        if keep: sigd['kwargs'] = k=======================================================(18) # How to add a new item into a dict;; \n        else: from_f.__delwrap__ = to_f===================================================(19) # How to create a new attr for a function or obj;; \n                                                                                                                                     part No.1 out of 2 parts\n\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 12     ===============================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\n        if hasattr(from_f,'__delwrap__'): return f                                                                                                      (10)\n        sig = inspect.signature(from_f)                                                                                                                 (11)\n        sigd = dict(sig.parameters)=====================================================================================================================(12)\n                                                                                How to access parameters of a signature?; How to turn parameters into a dict?\n        k = sigd.pop('kwargs')                                                                                                                          (13)\n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items()                                    (14)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n            sig.parameters => sig.parameters : OrderedDict([('c', <Parameter \"c\">), ('d', <Parameter \"d: list = None\">), ('kwargs', <Parameter \"**kwargs\">)])\n\n\n                   dict(sig.parameters) => dict(sig.parameters) : {'c': <Parameter \"c\">, 'd': <Parameter \"d: list = None\">, 'kwargs': <Parameter \"**kwargs\">}\n====================================================================================================================End of my srcline exploration:\n\n<Signature (c, d: list = None, *, b: int = 1)>\n\nReview srcode with all comments added so far======================================================================================================\ndef delegates(to:FunctionType=None, # Delegatee===========================================(0) # how to make delegates(to) to have to as FunctionType and default as None; \n              keep=False, # Keep `kwargs` in decorated function?==========================(1)       \n              but:list=None): # Exclude these parameters from signature===================(2) # how to make delegates(to, but) to have 'but' as list and default as None; \n    \"Decorator: replace `**kwargs` in signature with params from `to`\"====================(3)       \n    if but is None: but = []==============================================================(4)       \n    def _f(f):============================================================================(5)       \n        if to is None: to_f,from_f = f.__base__.__init__,f.__init__=======================(6) # how to write 2 ifs and elses in 2 lines; \n        else:          to_f,from_f = to.__init__ if isinstance(to,type) else to,f=========(7) # how to assign a,b together with if and else; \n        from_f = getattr(from_f,'__func__',from_f)========================================(8) # Is classmethod callable; does classmethod has __func__; can we do inspect.signature(clsmethod); how to use getattr(obj, attr, default); \n        to_f = getattr(to_f,'__func__',to_f)==============================================(9)       \n        if hasattr(from_f,'__delwrap__'): return f========================================(10) # if B has __delwrap__, can we do delegates(A)(B) again?; hasattr(obj, '__delwrap__'); \n        sig = inspect.signature(from_f)===================================================(11) # how to get signature obj of B; what does a signature look like; what is the type; \n        sigd = dict(sig.parameters)=======================================================(12) # How to access parameters of a signature?; How to turn parameters into a dict?; \n        k = sigd.pop('kwargs')============================================================(13)      \n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items() # How to access a signature's parameters as a dict?; How to replace the kind of a parameter with a different kind?; how to check whether a parameter has a default value?; How to check whether a string is in a dict and a list?; how dict.items() and dict.values() differ;  (14)\n              if v.default != inspect.Parameter.empty and k not in sigd and k not in but}=(15)      \n        anno = {k:v for k,v in getattr(to_f, \"__annotations__\", {}).items() if k not in sigd and k not in but} # How to get A's __annotations__?; How to access it as a dict?; How to select annotations of the right params with names?; How to put them into a dict?; How to do it all in a single line;  (16)\n        sigd.update(s2)===================================================================(17) # How to add the selected params from A's signature to B's signature; How to add items into a dict;; \n        if keep: sigd['kwargs'] = k=======================================================(18) # How to add a new item into a dict;; \n        else: from_f.__delwrap__ = to_f===================================================(19) # How to create a new attr for a function or obj;; \n                                                                                                                                     part No.1 out of 2 parts\n\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 13     ===============================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\nprint selected srcline with expands below--------\n        sig = inspect.signature(from_f)                                                                                                                 (11)\n        sigd = dict(sig.parameters)                                                                                                                     (12)\n        k = sigd.pop('kwargs')==========================================================================================================================(13)\nHow to remove an item from a dict?; How to get the removed item from a dict?; How to add the removed item back to the dict?; when writing expressions, as they share environment, so they may affect the following code\n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items()                                    (14)\n              if v.default != inspect.Parameter.empty and k not in sigd and k not in but}                                                               (15)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                   sigd => sigd : {'c': <Parameter \"c\">, 'd': <Parameter \"d: list = None\">, 'kwargs': <Parameter \"**kwargs\">}\n\n\n                                                                                                                        k = sigd.pop('kwargs') => k: **kwargs\n\n\n                                                                                     sigd => sigd : {'c': <Parameter \"c\">, 'd': <Parameter \"d: list = None\">}\n\n\n                                                                                                               sigd['kwargs'] = k => sigd['kwargs']: **kwargs\n====================================================================================================================End of my srcline exploration:\n\n<Signature (c, d: list = None, *, b: int = 1)>\n\nReview srcode with all comments added so far======================================================================================================\ndef delegates(to:FunctionType=None, # Delegatee===========================================(0) # how to make delegates(to) to have to as FunctionType and default as None; \n              keep=False, # Keep `kwargs` in decorated function?==========================(1)       \n              but:list=None): # Exclude these parameters from signature===================(2) # how to make delegates(to, but) to have 'but' as list and default as None; \n    \"Decorator: replace `**kwargs` in signature with params from `to`\"====================(3)       \n    if but is None: but = []==============================================================(4)       \n    def _f(f):============================================================================(5)       \n        if to is None: to_f,from_f = f.__base__.__init__,f.__init__=======================(6) # how to write 2 ifs and elses in 2 lines; \n        else:          to_f,from_f = to.__init__ if isinstance(to,type) else to,f=========(7) # how to assign a,b together with if and else; \n        from_f = getattr(from_f,'__func__',from_f)========================================(8) # Is classmethod callable; does classmethod has __func__; can we do inspect.signature(clsmethod); how to use getattr(obj, attr, default); \n        to_f = getattr(to_f,'__func__',to_f)==============================================(9)       \n        if hasattr(from_f,'__delwrap__'): return f========================================(10) # if B has __delwrap__, can we do delegates(A)(B) again?; hasattr(obj, '__delwrap__'); \n        sig = inspect.signature(from_f)===================================================(11) # how to get signature obj of B; what does a signature look like; what is the type; \n        sigd = dict(sig.parameters)=======================================================(12) # How to access parameters of a signature?; How to turn parameters into a dict?; \n        k = sigd.pop('kwargs')============================================================(13) # How to remove an item from a dict?; How to get the removed item from a dict?; How to add the removed item back to the dict?; when writing expressions, as they share environment, so they may affect the following code; \n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items() # How to access a signature's parameters as a dict?; How to replace the kind of a parameter with a different kind?; how to check whether a parameter has a default value?; How to check whether a string is in a dict and a list?; how dict.items() and dict.values() differ;  (14)\n              if v.default != inspect.Parameter.empty and k not in sigd and k not in but}=(15)      \n        anno = {k:v for k,v in getattr(to_f, \"__annotations__\", {}).items() if k not in sigd and k not in but} # How to get A's __annotations__?; How to access it as a dict?; How to select annotations of the right params with names?; How to put them into a dict?; How to do it all in a single line;  (16)\n        sigd.update(s2)===================================================================(17) # How to add the selected params from A's signature to B's signature; How to add items into a dict;; \n        if keep: sigd['kwargs'] = k=======================================================(18) # How to add a new item into a dict;; \n        else: from_f.__delwrap__ = to_f===================================================(19) # How to create a new attr for a function or obj;; \n                                                                                                                                     part No.1 out of 2 parts\n\n\n\n\nfdb.print()\n\n========================================================     Investigating delegates     =========================================================\n===============================================================     on line 13     ===============================================================\n     with example \ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n     \n\ndef delegates(to:FunctionType=None, # Delegatee===========================================(0) # how to make delegates(to) to have to as FunctionType and default as None; \n              keep=False, # Keep `kwargs` in decorated function?==========================(1)       \n              but:list=None): # Exclude these parameters from signature===================(2) # how to make delegates(to, but) to have 'but' as list and default as None; \n    \"Decorator: replace `**kwargs` in signature with params from `to`\"====================(3)       \n    if but is None: but = []==============================================================(4)       \n    def _f(f):============================================================================(5)       \n        if to is None: to_f,from_f = f.__base__.__init__,f.__init__=======================(6) # how to write 2 ifs and elses in 2 lines; \n        else:          to_f,from_f = to.__init__ if isinstance(to,type) else to,f=========(7) # how to assign a,b together with if and else; \n        from_f = getattr(from_f,'__func__',from_f)========================================(8) # Is classmethod callable; does classmethod has __func__; can we do inspect.signature(clsmethod); how to use getattr(obj, attr, default); \n        to_f = getattr(to_f,'__func__',to_f)==============================================(9)       \n        if hasattr(from_f,'__delwrap__'): return f========================================(10) # if B has __delwrap__, can we do delegates(A)(B) again?; hasattr(obj, '__delwrap__'); \n        sig = inspect.signature(from_f)===================================================(11) # how to get signature obj of B; what does a signature look like; what is the type; \n        sigd = dict(sig.parameters)=======================================================(12) # How to access parameters of a signature?; How to turn parameters into a dict?; \n        k = sigd.pop('kwargs')============================================================(13) # How to remove an item from a dict?; How to get the removed item from a dict?; How to add the removed item back to the dict?; when writing expressions, as they share environment, so they may affect the following code; \n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items() # How to access a signature's parameters as a dict?; How to replace the kind of a parameter with a different kind?; how to check whether a parameter has a default value?; How to check whether a string is in a dict and a list?; how dict.items() and dict.values() differ;  (14)\n              if v.default != inspect.Parameter.empty and k not in sigd and k not in but}=(15)      \n        anno = {k:v for k,v in getattr(to_f, \"__annotations__\", {}).items() if k not in sigd and k not in but} # How to get A's __annotations__?; How to access it as a dict?; How to select annotations of the right params with names?; How to put them into a dict?; How to do it all in a single line;  (16)\n        sigd.update(s2)===================================================================(17) # How to add the selected params from A's signature to B's signature; How to add items into a dict;; \n        if keep: sigd['kwargs'] = k=======================================================(18) # How to add a new item into a dict;; \n        else: from_f.__delwrap__ = to_f===================================================(19) # How to create a new attr for a function or obj;; \n        from_f.__signature__ = sig.replace(parameters=sigd.values())======================(20) # How to update a signature with a new set of parameters;; \n        if hasattr(from_f, '__annotations__'): from_f.__annotations__.update(anno)========(21) # How to check whether a func has __annotations__; How add selected params' annotations from A to B's annotations;; \n        return f==========================================================================(22)      \n    return _f=============================================================================(23)      \n                                                                                                                                                        (24)"
  },
  {
    "objectID": "demos/fastcore_meta_delegates.html#snoop",
    "href": "demos/fastcore_meta_delegates.html#snoop",
    "title": "0001_Fastcore.meta.delegates",
    "section": "Snoop",
    "text": "Snoop\n\n# fdb.snoop(deco=True) # both examples above works for Fastdb"
  },
  {
    "objectID": "demos/fastcore.meta.bypassnewmeta.html",
    "href": "demos/fastcore.meta.bypassnewmeta.html",
    "title": "07_BypassNewMeta",
    "section": "",
    "text": "from fastdebug.utils import *\nfrom fastdebug.core import *\nfrom fastcore.meta import *"
  },
  {
    "objectID": "demos/fastcore.meta.bypassnewmeta.html#reading-official-docs",
    "href": "demos/fastcore.meta.bypassnewmeta.html#reading-official-docs",
    "title": "07_BypassNewMeta",
    "section": "Reading official docs",
    "text": "Reading official docs\nBypassNewMeta > BypassNewMeta (name, bases, dict)\nMetaclass: casts x to this class if it’s of type cls._bypass_type\nBypassNewMeta is identical to NewChkMeta, except for checking for a class as the same type, we instead check for a class of type specified in attribute _bypass_type.\nIn NewChkMeta, objects of the same type passed to the constructor (without arguments) would result into a new variable referencing the same object.\nHowever, with BypassNewMeta this only occurs if the type matches the _bypass_type of the class you are defining:\n\n# class _TestA: pass\n# class _TestB: pass\n\n# class _T(_TestA, metaclass=BypassNewMeta):\n#     _bypass_type=_TestB\n#     def __init__(self,x): self.x=x\n\nIn the below example, t does not refer to t2 because t is of type _TestA while _T._bypass_type is of type TestB:\n\n# t = _TestA()\n# t2 = _T(t)\n# assert t is not t2\n\nHowever, if t is set to _TestB to match _T._bypass_type, then both t and t2 will refer to the same object.\n\n# t = _TestB()\n# t2 = _T(t)\n# t2.new_attr = 15\n\n# test_is(t, t2)\n# # since t2 just references t these will be the same\n# test_eq(t.new_attr, t2.new_attr)\n\n# # likewise, chaning an attribute on t will also affect t2 because they both point to the same object.\n# t.new_attr = 9\n# test_eq(t2.new_attr, 9)\n\n\n# t = _TestB(); t\n# isinstance(t, _TestB)\n# id(_TestB)\n# # t2 = _T(t)\n# # t, t2"
  },
  {
    "objectID": "demos/fastcore.meta.bypassnewmeta.html#inspecting-class",
    "href": "demos/fastcore.meta.bypassnewmeta.html#inspecting-class",
    "title": "07_BypassNewMeta",
    "section": "Inspecting class",
    "text": "Inspecting class\n\ninspect_class(BypassNewMeta)\n\nclass BypassNewMeta(FixSigMeta):\n    \"Metaclass: casts `x` to this class if it's of type `cls._bypass_type`\"\n    def __call__(cls, x=None, *args, **kwargs):\n        if hasattr(cls, '_new_meta'): x = cls._new_meta(x, *args, **kwargs)\n        elif not isinstance(x,getattr(cls,'_bypass_type',object)) or len(args) or len(kwargs):\n            x = super().__call__(*((x,)+args), **kwargs)\n        if cls!=x.__class__: x.__class__ = cls\n        return x\n\n\nis BypassNewMeta a metaclass: True\nis BypassNewMeta created by a metaclass: False\nBypassNewMeta is created by <class 'type'>\nBypassNewMeta.__new__ is object.__new__: False\nBypassNewMeta.__new__ is type.__new__: False\nBypassNewMeta.__new__: <function FixSigMeta.__new__>\nBypassNewMeta.__init__ is object.__init__: False\nBypassNewMeta.__init__ is type.__init__: True\nBypassNewMeta.__init__: <slot wrapper '__init__' of 'type' objects>\nBypassNewMeta.__call__ is object.__call__: False\nBypassNewMeta.__call__ is type.__call__: False\nBypassNewMeta.__call__: <function BypassNewMeta.__call__>\nBypassNewMeta.__class__: <class 'type'>\nBypassNewMeta.__bases__: (<class 'fastcore.meta.FixSigMeta'>,)\nBypassNewMeta.__mro__: (<class 'fastcore.meta.BypassNewMeta'>, <class 'fastcore.meta.FixSigMeta'>, <class 'type'>, <class 'object'>)\n\nBypassNewMeta's function members are:\n{'__call__': <function BypassNewMeta.__call__>,\n '__new__': <function FixSigMeta.__new__>}\n\nBypassNewMeta's method members are:\n{}\n\nBypassNewMeta's class members are:\n{'__base__': <class 'fastcore.meta.FixSigMeta'>, '__class__': <class 'type'>}\n\nBypassNewMeta's namespace are:\nmappingproxy({'__call__': <function BypassNewMeta.__call__>,\n              '__doc__': \"Metaclass: casts `x` to this class if it's of type \"\n                         '`cls._bypass_type`',\n              '__module__': 'fastcore.meta'})"
  },
  {
    "objectID": "demos/fastcore.meta.bypassnewmeta.html#initiating-with-examples",
    "href": "demos/fastcore.meta.bypassnewmeta.html#initiating-with-examples",
    "title": "07_BypassNewMeta",
    "section": "Initiating with examples",
    "text": "Initiating with examples\n\ng = locals()\nfdb = Fastdb(BypassNewMeta, outloc=g)\nfdb.eg = \"\"\"\nclass _TestA: pass\nclass _TestB: pass\n\nclass _T(_TestA, metaclass=BypassNewMeta):\n    _bypass_type=_TestB\n    def __init__(self,x): self.x=x\n\nt = _TestA()\nprint(t)\nt2 = _T(t)\nprint(t2)\nassert t is not t2\n\"\"\"\n\nfdb.eg = \"\"\"\nclass _TestA: pass\nclass _TestB: pass\n\nclass _T(_TestA, metaclass=BypassNewMeta):\n    _bypass_type=_TestB\n    def __init__(self,x): self.x=x\n\nt = _TestB()\nt2 = _T(t)\nt2.new_attr = 15\n\ntest_is(t, t2)\n# since t2 just references t these will be the same\ntest_eq(t.new_attr, t2.new_attr)\n\n# likewise, chaning an attribute on t will also affect t2 because they both point to the same object.\nt.new_attr = 9\ntest_eq(t2.new_attr, 9)\n\n# both t and t2's __class__ is _T\ntest_eq(t.__class__, t2.__class__)\ntest_eq(t.__class__, _T)\n\"\"\""
  },
  {
    "objectID": "demos/fastcore.meta.bypassnewmeta.html#snoop",
    "href": "demos/fastcore.meta.bypassnewmeta.html#snoop",
    "title": "07_BypassNewMeta",
    "section": "Snoop",
    "text": "Snoop\n\nfdb.snoop()\n\n23:28:43.69 >>> Call to BypassNewMeta.__call__ in File \"/tmp/BypassNewMeta.py\", line 5\n23:28:43.69 .......... cls = <class '__main__._T'>\n23:28:43.69 .......... x = <__main__._TestB object>\n23:28:43.69 .......... args = ()\n23:28:43.69 .......... kwargs = {}\n23:28:43.69 .......... __class__ = <class 'fastcore.meta.BypassNewMeta'>\n23:28:43.69    5 |     def __call__(cls, x=None, *args, **kwargs):\n23:28:43.69    6 |         if hasattr(cls, '_new_meta'): x = cls._new_meta(x, *args, **kwargs)\n23:28:43.69    7 |         elif not isinstance(x,getattr(cls,'_bypass_type',object)) or len(args) or len(kwargs):\n23:28:43.69    9 |         if cls!=x.__class__: x.__class__ = cls\n23:28:43.69 ...... x = <__main__._T object>\n23:28:43.69   10 |         return x\n23:28:43.69 <<< Return value from BypassNewMeta.__call__: <__main__._T object>\n\n\n======================================================     Investigating BypassNewMeta     =======================================================\n==============================================================     on line None     ==============================================================\n     with example \nclass _TestA: pass\nclass _TestB: pass\n\nclass _T(_TestA, metaclass=BypassNewMeta):\n    _bypass_type=_TestB\n    def __init__(self,x): self.x=x\n\nt = _TestB()\nt2 = _T(t)\nt2.new_attr = 15\n\ntest_is(t, t2)\n# since t2 just references t these will be the same\ntest_eq(t.new_attr, t2.new_attr)\n\n# likewise, chaning an attribute on t will also affect t2 because they both point to the same object.\nt.new_attr = 9\ntest_eq(t2.new_attr, 9)\n\n# both t and t2's __class__ is _T\ntest_eq(t.__class__, t2.__class__)\ntest_eq(t.__class__, _T)\n     \n\n\n\n\nfdb.debug()\n\nBypassNewMeta's dbsrc code: ==============\nclass BypassNewMeta(FixSigMeta):\n    \"Metaclass: casts `x` to this class if it's of type `cls._bypass_type`\"\n    import snoop\n    @snoop\n    def __call__(cls, x=None, *args, **kwargs):\n        if hasattr(cls, '_new_meta'): x = cls._new_meta(x, *args, **kwargs)\n        elif not isinstance(x,getattr(cls,'_bypass_type',object)) or len(args) or len(kwargs):\n            x = super().__call__(*((x,)+args), **kwargs)\n        if cls!=x.__class__: x.__class__ = cls\n        return x\n\n\n\nBypassNewMeta's example processed with dbsrc: ===============\n\nclass _TestA: pass\nclass _TestB: pass\n\nclass _T(_TestA, metaclass=self.dbsrc):\n    _bypass_type=_TestB\n    def __init__(self,x): self.x=x\n\nt = _TestB()\nt2 = _T(t)\nt2.new_attr = 15\n\ntest_is(t, t2)\n# since t2 just references t these will be the same\ntest_eq(t.new_attr, t2.new_attr)\n\n# likewise, chaning an attribute on t will also affect t2 because they both point to the same object.\nt.new_attr = 9\ntest_eq(t2.new_attr, 9)\n\n# both t and t2's __class__ is _T\ntest_eq(t.__class__, t2.__class__)\ntest_eq(t.__class__, _T)"
  },
  {
    "objectID": "demos/fastcore.meta.bypassnewmeta.html#document",
    "href": "demos/fastcore.meta.bypassnewmeta.html#document",
    "title": "07_BypassNewMeta",
    "section": "Document",
    "text": "Document\n\nfdb.docsrc(3, \"If the instance class like _T has attr '_new_meta', then run it with param x;\", \"x\", \\\n           \"cls\", \"getattr(cls,'_bypass_type',object)\", \"isinstance(x, _TestB)\", \"isinstance(x,getattr(cls,'_bypass_type',object))\")\nfdb.docsrc(4, \"when x is not an instance of _T's _bypass_type; or when a positional param is given; or when a keyword arg is given; \\\nlet's run _T's super's __call__ function with x as param; and assign the result to x\")\nfdb.docsrc(6, \"If x.__class__ is not cls or _T, then make it so\")\nfdb.docsrc(1, \"BypassNewMeta allows its instance class e.g., _T to choose a specific class e.g., _TestB and \\\nchange `__class__` of an object e.g., t of _TestB to _T without creating a new object\")\n\n======================================================     Investigating BypassNewMeta     =======================================================\n===============================================================     on line 3     ================================================================\n     with example \nclass _TestA: pass\nclass _TestB: pass\n\nclass _T(_TestA, metaclass=BypassNewMeta):\n    _bypass_type=_TestB\n    def __init__(self,x): self.x=x\n\nt = _TestB()\nt2 = _T(t)\nt2.new_attr = 15\n\ntest_is(t, t2)\n# since t2 just references t these will be the same\ntest_eq(t.new_attr, t2.new_attr)\n\n# likewise, chaning an attribute on t will also affect t2 because they both point to the same object.\nt.new_attr = 9\ntest_eq(t2.new_attr, 9)\n\n# both t and t2's __class__ is _T\ntest_eq(t.__class__, t2.__class__)\ntest_eq(t.__class__, _T)\n     \n\nprint selected srcline with expands below--------\n    \"Metaclass: casts `x` to this class if it's of type `cls._bypass_type`\"                                                                             (1)\n    def __call__(cls, x=None, *args, **kwargs):                                                                                                         (2)\n        if hasattr(cls, '_new_meta'): x = cls._new_meta(x, *args, **kwargs)=============================================================================(3)\n                                                                                If the instance class like _T has attr '_new_meta', then run it with param x;\n        elif not isinstance(x,getattr(cls,'_bypass_type',object)) or len(args) or len(kwargs):                                                          (4)\n            x = super().__call__(*((x,)+args), **kwargs)                                                                                                (5)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                                                                             x => x : <__main__._TestB object>\n\n\n                                                                                                                           cls => cls : <class '__main__._T'>\n\n\n                                                         getattr(cls,'_bypass_type',object) => getattr(cls,'_bypass_type',object) : <class '__main__._TestB'>\n\n\n                                                                                                        isinstance(x, _TestB) => isinstance(x, _TestB) : True\n\n\n                                                  isinstance(x,getattr(cls,'_bypass_type',object)) => isinstance(x,getattr(cls,'_bypass_type',object)) : True\n====================================================================================================================End of my srcline exploration:\n\n\nReview srcode with all comments added so far======================================================================================================\nclass BypassNewMeta(FixSigMeta):==========================================================(0)       \n    \"Metaclass: casts `x` to this class if it's of type `cls._bypass_type`\"===============(1)       \n    def __call__(cls, x=None, *args, **kwargs):===========================================(2)       \n        if hasattr(cls, '_new_meta'): x = cls._new_meta(x, *args, **kwargs)===============(3) # If the instance class like _T has attr '_new_meta', then run it with param x;; \n        elif not isinstance(x,getattr(cls,'_bypass_type',object)) or len(args) or len(kwargs):                                                          (4)\n            x = super().__call__(*((x,)+args), **kwargs)==================================(5)       \n        if cls!=x.__class__: x.__class__ = cls============================================(6)       \n        return x==========================================================================(7)       \n                                                                                                                                                        (8)\n                                                                                                                                     part No.1 out of 1 parts\n\n======================================================     Investigating BypassNewMeta     =======================================================\n===============================================================     on line 4     ================================================================\n     with example \nclass _TestA: pass\nclass _TestB: pass\n\nclass _T(_TestA, metaclass=BypassNewMeta):\n    _bypass_type=_TestB\n    def __init__(self,x): self.x=x\n\nt = _TestB()\nt2 = _T(t)\nt2.new_attr = 15\n\ntest_is(t, t2)\n# since t2 just references t these will be the same\ntest_eq(t.new_attr, t2.new_attr)\n\n# likewise, chaning an attribute on t will also affect t2 because they both point to the same object.\nt.new_attr = 9\ntest_eq(t2.new_attr, 9)\n\n# both t and t2's __class__ is _T\ntest_eq(t.__class__, t2.__class__)\ntest_eq(t.__class__, _T)\n     \n\nprint selected srcline with expands below--------\n    def __call__(cls, x=None, *args, **kwargs):                                                                                                         (2)\n        if hasattr(cls, '_new_meta'): x = cls._new_meta(x, *args, **kwargs)                                                                             (3)\n        elif not isinstance(x,getattr(cls,'_bypass_type',object)) or len(args) or len(kwargs):==========================================================(4)\nwhen x is not an instance of _T's _bypass_type; or when a positional param is given; or when a keyword arg is given; let's run _T's super's __call__ function with x as param; and assign the result to x\n            x = super().__call__(*((x,)+args), **kwargs)                                                                                                (5)\n        if cls!=x.__class__: x.__class__ = cls                                                                                                          (6)\n\nReview srcode with all comments added so far======================================================================================================\nclass BypassNewMeta(FixSigMeta):==========================================================(0)       \n    \"Metaclass: casts `x` to this class if it's of type `cls._bypass_type`\"===============(1)       \n    def __call__(cls, x=None, *args, **kwargs):===========================================(2)       \n        if hasattr(cls, '_new_meta'): x = cls._new_meta(x, *args, **kwargs)===============(3) # If the instance class like _T has attr '_new_meta', then run it with param x;; \n        elif not isinstance(x,getattr(cls,'_bypass_type',object)) or len(args) or len(kwargs): # when x is not an instance of _T's _bypass_type; or when a positional param is given; or when a keyword arg is given; let's run _T's super's __call__ function with x as param; and assign the result to x;  (4)\n            x = super().__call__(*((x,)+args), **kwargs)==================================(5)       \n        if cls!=x.__class__: x.__class__ = cls============================================(6)       \n        return x==========================================================================(7)       \n                                                                                                                                                        (8)\n                                                                                                                                     part No.1 out of 1 parts\n\n======================================================     Investigating BypassNewMeta     =======================================================\n===============================================================     on line 6     ================================================================\n     with example \nclass _TestA: pass\nclass _TestB: pass\n\nclass _T(_TestA, metaclass=BypassNewMeta):\n    _bypass_type=_TestB\n    def __init__(self,x): self.x=x\n\nt = _TestB()\nt2 = _T(t)\nt2.new_attr = 15\n\ntest_is(t, t2)\n# since t2 just references t these will be the same\ntest_eq(t.new_attr, t2.new_attr)\n\n# likewise, chaning an attribute on t will also affect t2 because they both point to the same object.\nt.new_attr = 9\ntest_eq(t2.new_attr, 9)\n\n# both t and t2's __class__ is _T\ntest_eq(t.__class__, t2.__class__)\ntest_eq(t.__class__, _T)\n     \n\nprint selected srcline with expands below--------\n        elif not isinstance(x,getattr(cls,'_bypass_type',object)) or len(args) or len(kwargs):                                                          (4)\n            x = super().__call__(*((x,)+args), **kwargs)                                                                                                (5)\n        if cls!=x.__class__: x.__class__ = cls==========================================================================================================(6)\n                                                                                                             If x.__class__ is not cls or _T, then make it so\n        return x                                                                                                                                        (7)\n                                                                                                                                                        (8)\n\nReview srcode with all comments added so far======================================================================================================\nclass BypassNewMeta(FixSigMeta):==========================================================(0)       \n    \"Metaclass: casts `x` to this class if it's of type `cls._bypass_type`\"===============(1)       \n    def __call__(cls, x=None, *args, **kwargs):===========================================(2)       \n        if hasattr(cls, '_new_meta'): x = cls._new_meta(x, *args, **kwargs)===============(3) # If the instance class like _T has attr '_new_meta', then run it with param x;; \n        elif not isinstance(x,getattr(cls,'_bypass_type',object)) or len(args) or len(kwargs): # when x is not an instance of _T's _bypass_type; or when a positional param is given; or when a keyword arg is given; let's run _T's super's __call__ function with x as param; and assign the result to x;  (4)\n            x = super().__call__(*((x,)+args), **kwargs)==================================(5)       \n        if cls!=x.__class__: x.__class__ = cls============================================(6) # If x.__class__ is not cls or _T, then make it so; \n        return x==========================================================================(7)       \n                                                                                                                                                        (8)\n                                                                                                                                     part No.1 out of 1 parts\n\n======================================================     Investigating BypassNewMeta     =======================================================\n===============================================================     on line 1     ================================================================\n     with example \nclass _TestA: pass\nclass _TestB: pass\n\nclass _T(_TestA, metaclass=BypassNewMeta):\n    _bypass_type=_TestB\n    def __init__(self,x): self.x=x\n\nt = _TestB()\nt2 = _T(t)\nt2.new_attr = 15\n\ntest_is(t, t2)\n# since t2 just references t these will be the same\ntest_eq(t.new_attr, t2.new_attr)\n\n# likewise, chaning an attribute on t will also affect t2 because they both point to the same object.\nt.new_attr = 9\ntest_eq(t2.new_attr, 9)\n\n# both t and t2's __class__ is _T\ntest_eq(t.__class__, t2.__class__)\ntest_eq(t.__class__, _T)\n     \n\nprint selected srcline with expands below--------\nclass BypassNewMeta(FixSigMeta):                                                                                                                        (0)\n    \"Metaclass: casts `x` to this class if it's of type `cls._bypass_type`\"=============================================================================(1)\nBypassNewMeta allows its instance class e.g., _T to choose a specific class e.g., _TestB and change `__class__` of an object e.g., t of _TestB to _T without creating a new object\n    def __call__(cls, x=None, *args, **kwargs):                                                                                                         (2)\n        if hasattr(cls, '_new_meta'): x = cls._new_meta(x, *args, **kwargs)                                                                             (3)\n\nReview srcode with all comments added so far======================================================================================================\nclass BypassNewMeta(FixSigMeta):==========================================================(0)       \n    \"Metaclass: casts `x` to this class if it's of type `cls._bypass_type`\"===============(1) # BypassNewMeta allows its instance class e.g., _T to choose a specific class e.g., _TestB and change `__class__` of an object e.g., t of _TestB to _T without creating a new object; \n    def __call__(cls, x=None, *args, **kwargs):===========================================(2)       \n        if hasattr(cls, '_new_meta'): x = cls._new_meta(x, *args, **kwargs)===============(3) # If the instance class like _T has attr '_new_meta', then run it with param x;; \n        elif not isinstance(x,getattr(cls,'_bypass_type',object)) or len(args) or len(kwargs): # when x is not an instance of _T's _bypass_type; or when a positional param is given; or when a keyword arg is given; let's run _T's super's __call__ function with x as param; and assign the result to x;  (4)\n            x = super().__call__(*((x,)+args), **kwargs)==================================(5)       \n        if cls!=x.__class__: x.__class__ = cls============================================(6) # If x.__class__ is not cls or _T, then make it so; \n        return x==========================================================================(7)       \n                                                                                                                                                        (8)\n                                                                                                                                     part No.1 out of 1 parts\n\n\n\n\nfdb.snoop(['cls._bypass_type', \"isinstance(x,getattr(cls,'_bypass_type',object))\"])\n\n23:28:43.75 >>> Call to BypassNewMeta.__call__ in File \"/tmp/BypassNewMeta.py\", line 5\n23:28:43.75 .......... cls = <class '__main__._T'>\n23:28:43.75 .......... x = <__main__._TestB object>\n23:28:43.75 .......... args = ()\n23:28:43.75 .......... kwargs = {}\n23:28:43.75 .......... __class__ = <class 'fastcore.meta.BypassNewMeta'>\n23:28:43.75 .......... cls._bypass_type = <class '__main__._TestB'>\n23:28:43.75 .......... isinstance(x,getattr(cls,'_bypass_type',object)) = True\n23:28:43.75    5 |     def __call__(cls, x=None, *args, **kwargs):\n23:28:43.76    6 |         if hasattr(cls, '_new_meta'): x = cls._new_meta(x, *args, **kwargs)\n23:28:43.76    7 |         elif not isinstance(x,getattr(cls,'_bypass_type',object)) or len(args) or len(kwargs):\n23:28:43.76    9 |         if cls!=x.__class__: x.__class__ = cls\n23:28:43.76 ...... x = <__main__._T object>\n23:28:43.76 ...... isinstance(x,getattr(cls,'_bypass_type',object)) = False\n23:28:43.76   10 |         return x\n23:28:43.76 <<< Return value from BypassNewMeta.__call__: <__main__._T object>\n\n\n======================================================     Investigating BypassNewMeta     =======================================================\n==============================================================     on line None     ==============================================================\n     with example \nclass _TestA: pass\nclass _TestB: pass\n\nclass _T(_TestA, metaclass=BypassNewMeta):\n    _bypass_type=_TestB\n    def __init__(self,x): self.x=x\n\nt = _TestB()\nt2 = _T(t)\nt2.new_attr = 15\n\ntest_is(t, t2)\n# since t2 just references t these will be the same\ntest_eq(t.new_attr, t2.new_attr)\n\n# likewise, chaning an attribute on t will also affect t2 because they both point to the same object.\nt.new_attr = 9\ntest_eq(t2.new_attr, 9)\n\n# both t and t2's __class__ is _T\ntest_eq(t.__class__, t2.__class__)\ntest_eq(t.__class__, _T)\n     \n\n\n\n\nfdb.debug()\n\nBypassNewMeta's dbsrc code: ==============\nclass BypassNewMeta(FixSigMeta):\n    \"Metaclass: casts `x` to this class if it's of type `cls._bypass_type`\"\n    import snoop\n    @snoop(watch=(\"cls._bypass_type\",\"isinstance(x,getattr(cls,'_bypass_type',object))\"))\n    def __call__(cls, x=None, *args, **kwargs):\n        if hasattr(cls, '_new_meta'): x = cls._new_meta(x, *args, **kwargs)\n        elif not isinstance(x,getattr(cls,'_bypass_type',object)) or len(args) or len(kwargs):\n            x = super().__call__(*((x,)+args), **kwargs)\n        if cls!=x.__class__: x.__class__ = cls\n        return x\n\n\n\nBypassNewMeta's example processed with dbsrc: ===============\n\nclass _TestA: pass\nclass _TestB: pass\n\nclass _T(_TestA, metaclass=self.dbsrc):\n    _bypass_type=_TestB\n    def __init__(self,x): self.x=x\n\nt = _TestB()\nt2 = _T(t)\nt2.new_attr = 15\n\ntest_is(t, t2)\n# since t2 just references t these will be the same\ntest_eq(t.new_attr, t2.new_attr)\n\n# likewise, chaning an attribute on t will also affect t2 because they both point to the same object.\nt.new_attr = 9\ntest_eq(t2.new_attr, 9)\n\n# both t and t2's __class__ is _T\ntest_eq(t.__class__, t2.__class__)\ntest_eq(t.__class__, _T)\n\n\n\n\n\n\n\n\n\n\nfdb.print()\n\n======================================================     Investigating BypassNewMeta     =======================================================\n==============================================================     on line None     ==============================================================\n     with example \nclass _TestA: pass\nclass _TestB: pass\n\nclass _T(_TestA, metaclass=BypassNewMeta):\n    _bypass_type=_TestB\n    def __init__(self,x): self.x=x\n\nt = _TestB()\nt2 = _T(t)\nt2.new_attr = 15\n\ntest_is(t, t2)\n# since t2 just references t these will be the same\ntest_eq(t.new_attr, t2.new_attr)\n\n# likewise, chaning an attribute on t will also affect t2 because they both point to the same object.\nt.new_attr = 9\ntest_eq(t2.new_attr, 9)\n\n# both t and t2's __class__ is _T\ntest_eq(t.__class__, t2.__class__)\ntest_eq(t.__class__, _T)\n     \n\nclass BypassNewMeta(FixSigMeta):==========================================================(0)       \n    \"Metaclass: casts `x` to this class if it's of type `cls._bypass_type`\"===============(1) # BypassNewMeta allows its instance class e.g., _T to choose a specific class e.g., _TestB and change `__class__` of an object e.g., t of _TestB to _T without creating a new object; \n    def __call__(cls, x=None, *args, **kwargs):===========================================(2)       \n        if hasattr(cls, '_new_meta'): x = cls._new_meta(x, *args, **kwargs)===============(3) # If the instance class like _T has attr '_new_meta', then run it with param x;; \n        elif not isinstance(x,getattr(cls,'_bypass_type',object)) or len(args) or len(kwargs): # when x is not an instance of _T's _bypass_type; or when a positional param is given; or when a keyword arg is given; let's run _T's super's __call__ function with x as param; and assign the result to x;  (4)\n            x = super().__call__(*((x,)+args), **kwargs)==================================(5)       \n        if cls!=x.__class__: x.__class__ = cls============================================(6) # If x.__class__ is not cls or _T, then make it so; \n        return x==========================================================================(7)       \n                                                                                                                                                        (8)"
  },
  {
    "objectID": "demos/intro_fastdebug.html",
    "href": "demos/intro_fastdebug.html",
    "title": "Introducing fastdebug",
    "section": "",
    "text": "What is the fastai coding style\nHow to do abbreviation the fastai way\nA great example of how fastai libraries can make life more comfortable"
  },
  {
    "objectID": "demos/intro_fastdebug.html#what-is-the-motivation-behind-fastdebug-library",
    "href": "demos/intro_fastdebug.html#what-is-the-motivation-behind-fastdebug-library",
    "title": "Introducing fastdebug",
    "section": "What is the motivation behind fastdebug library?",
    "text": "What is the motivation behind fastdebug library?\nI have always wanted to explore and learn the fastai libraries thoroughly. However, reading source code is intimidating for beginners even for well-designed and written libraries like fastcore, fastai. So, I have relied on pdbpp to explore source code previously. To do fastai is to do exploratory coding with jupyter, but pdbpp is not working for jupyter at the moment and none of debugging tools I know exactly suit my needs. So, with the help of the amazing nbdev, I created this little library with 4 little tools to assist me explore source code and document my learning along the way.\nHere are the four tools: > Fastdb.snoop(): print out all the executed lines and local vars of the source code I am exploring\n\nFastdb.explore(9): start pdb at source line 9 or any srcline at my choose\n\n\nFastdb.print(10, 2): print out the 2nd part of source code, given the source code is divded into multi parts (each part has 10 lines)\n\n\nFastdb.docsrc(10, “comments”, “code expression1”, “code expression2”, “multi-line expressions”): to document the leanring of the srcline 10\n\nAs you should know now, this lib does two things: explore and document source code. Let’s start with Fastdb.explore first on a simple example. If you would like to see it working on a more complex real world example, I have fastcore.meta.FixSigMeta ready for you.\nIf you find anything confusing or bug-like, please inform me in this forum post."
  },
  {
    "objectID": "demos/intro_fastdebug.html#fastdb.explore",
    "href": "demos/intro_fastdebug.html#fastdb.explore",
    "title": "Introducing fastdebug",
    "section": "Fastdb.explore",
    "text": "Fastdb.explore\n\nWhy not explore with pure ipdb.set_trace?\nFastdb.explore is a wrapper around ipdb.set_trace and make my life easier when I am exploring because:\n\nI don’t need to write from ipdb import set_trace for every notebook\n\n\nI don’t need to manually open the source code file and scroll down the source code\n\n\nI don’t need to insert set_trace() above every line of source code (srcline) I want to start exploring\n\n\nI don’t need to remove set_trace() from the source code every time after exploration\n\n\n\nHow to use Fastdb.explore?\nLet’s explore the source code of whatinside from fastdebug.utils using this tool.\n\nfrom fastdebug.utils import * # for making an example \nfrom fastcore.test import * \nimport inspect\n\n\n\n\n\nimport fastdebug.utils as fu\n\n\nwhatinside(fu) # this is the example we are going to explore whatinside with\n\nfastdebug.utils has: \n8 items in its __all__, and \n23 user defined functions, \n1 classes or class objects, \n0 builtin funcs and methods, and\n24 callables.\n\n\n\n\nfrom fastdebug.core import * # Let's import Fastdb and its dependencies\n\n\n# g = locals()\n# fdb = Fastdb(whatinside, outloc=g) # first, create an object of Fastdb class, using `whatinside` as param\nfdb = Fastdb(whatinside)\n\n\n# 1. you can view source code in whole or in parts with the length you set, \n# and it gives you srcline idx so that you can set breakpoint with ease.\n#| column: screen\nfdb.print(20,1)\n\ndef whatinside(mo, # module, e.g., `import fastcore.all as fa`, use `fa` here=============(0)       \n               dun:bool=False, # print all items in __all__===============================(1)       \n               func:bool=False, # print all user defined functions========================(2)       \n               clas:bool=False, # print all class objects=================================(3)       \n               bltin:bool=False, # print all builtin funcs or methods=====================(4)       \n               lib:bool=False, # print all the modules of the library it belongs to=======(5)       \n               cal:bool=False # print all callables=======================================(6)       \n             ): ==========================================================================(7)       \n    'Check what inside a module: `__all__`, functions, classes, builtins, and callables'==(8)       \n    dun_all = len(mo.__all__) if hasattr(mo, \"__all__\") else 0============================(9)       \n    funcs = inspect.getmembers(mo, inspect.isfunction)====================================(10)      \n    classes = inspect.getmembers(mo, inspect.isclass)=====================================(11)      \n    builtins = inspect.getmembers(mo, inspect.isbuiltin)==================================(12)      \n    callables = inspect.getmembers(mo, callable)==========================================(13)      \n    pkgpath = os.path.dirname(mo.__file__)================================================(14)      \n    if not lib:===========================================================================(15)      \n        print(f\"{mo.__name__} has: \\n{dun_all} items in its __all__, and \\n{len(funcs)} user defined functions, \\n{len(classes)} classes or class objects, \\n{len(builtins)} builtin funcs and methods, and\\n{len(callables)} callables.\\n\")  (16)\n    if hasattr(mo, \"__all__\") and dun: pprint(mo.__all__)=================================(17)      \n    if func: =============================================================================(18)      \n        print(f'The user defined functions are:')=========================================(19)      \n                                                                                                                                     part No.1 out of 2 parts\n\n\n\n# 2. after viewing source code, choose a srcline idx to set breakpoint and write down why I want to explore this line\nfdb.eg = \"\"\"\nimport fastdebug.utils as fu\nwhatinside(fu)\n\"\"\"\n\n\n# fdb.explore(11)\n\n\n# 2. you can set multiple breakpoints from the start if you like (but not necessary)\n# fdb.explore([11, 16, 13])"
  },
  {
    "objectID": "demos/intro_fastdebug.html#fastdb.snoop",
    "href": "demos/intro_fastdebug.html#fastdb.snoop",
    "title": "Introducing fastdebug",
    "section": "Fastdb.snoop",
    "text": "Fastdb.snoop\nBut more often I just want to have an overview of what srclines get run so that I know which lines to dive into and start documenting.\nNote: I borrowed snoop from snoop library and automated it.\n\nfdb.snoop()\n\n06:33:11.07 >>> Call to whatinside in File \"/tmp/whatinside.py\", line 3\n06:33:11.07 ...... mo = <module 'fastdebug.utils' from '/Users/Natsume/Documents/fastdebug/fastdebug/utils.py'>\n06:33:11.07 ...... dun = False\n06:33:11.07 ...... func = False\n06:33:11.07 ...... clas = False\n06:33:11.07 ...... bltin = False\n06:33:11.07 ...... lib = False\n06:33:11.07 ...... cal = False\n06:33:11.07    3 | def whatinside(mo, # module, e.g., `import fastcore.all as fa`, use `fa` here\n06:33:11.07   12 |     dun_all = len(mo.__all__) if hasattr(mo, \"__all__\") else 0\n06:33:11.07 .......... dun_all = 8\n06:33:11.07   13 |     funcs = inspect.getmembers(mo, inspect.isfunction)\n06:33:11.07 .......... funcs = [('distribution', <function distribution>), ('expandcell', <function expandcell>), ('inspect_class', <function inspect_class>), ..., ('version', <function version>), ('whatinside', <function whatinside>), ('whichversion', <function whichversion>)]\n06:33:11.07 .......... len(funcs) = 23\n06:33:11.07   14 |     classes = inspect.getmembers(mo, inspect.isclass)\n06:33:11.07 .......... classes = [('ExceptionExpected', <class 'fastcore.test.ExceptionExpected'>)]\n06:33:11.07 .......... len(classes) = 1\n06:33:11.07   15 |     builtins = inspect.getmembers(mo, inspect.isbuiltin)\n06:33:11.07 .......... builtins = []\n06:33:11.07   16 |     callables = inspect.getmembers(mo, callable)\n06:33:11.07 .......... callables = [('ExceptionExpected', <class 'fastcore.test.ExceptionExpected'>), ('distribution', <function distribution>), ('expandcell', <function expandcell>), ..., ('version', <function version>), ('whatinside', <function whatinside>), ('whichversion', <function whichversion>)]\n06:33:11.07 .......... len(callables) = 24\n06:33:11.07   17 |     pkgpath = os.path.dirname(mo.__file__)\n06:33:11.07 .......... pkgpath = '/Users/Natsume/Documents/fastdebug/fastdebug'\n06:33:11.07   18 |     if not lib:\n06:33:11.07   19 |         print(f\"{mo.__name__} has: \\n{dun_all} items in its __all__, and \\n{len(funcs)} user defined functions, \\n{len(classes)} classes or class objects, \\n{len(builtins)} builtin funcs and methods, and\\n{len(callables)} callables.\\n\")  \n06:33:11.07   20 |     if hasattr(mo, \"__all__\") and dun: pprint(mo.__all__)\n06:33:11.08   21 |     if func: \n06:33:11.08   24 |     if clas: \n06:33:11.08   27 |     if bltin: \n06:33:11.08   30 |     if cal: \n06:33:11.08   33 |     if lib: \n06:33:11.08 <<< Return value from whatinside: None\n\n\n========================================================     Investigating whatinside     ========================================================\n==============================================================     on line None     ==============================================================\n=======================================     with example \nimport fastdebug.utils as fu\nwhatinside(fu)\n     =======================================\n\nfastdebug.utils has: \n8 items in its __all__, and \n23 user defined functions, \n1 classes or class objects, \n0 builtin funcs and methods, and\n24 callables."
  },
  {
    "objectID": "demos/intro_fastdebug.html#fastdb.docsrc",
    "href": "demos/intro_fastdebug.html#fastdb.docsrc",
    "title": "Introducing fastdebug",
    "section": "Fastdb.docsrc",
    "text": "Fastdb.docsrc\nAfter exploring and snooping, if I realize there is something new to learn and maybe want to come back for a second look, I find ipdb and the alike are not designed to document my learning. So, I created docsrc to make my life easier in the following ways:\n\nI won’t need to scroll through a long cell output of pdb commands, src prints and results to find what I learnt during exploration\n\n\nI won’t need to type all the expressions during last exploration to regenerate the findings for me\n\n\nI can choose any srclines to explore and write any sinlge or multi-line expressions to evaluate the srcline\n\n\nI can write down what I learn or what is new on any srcline as comment, and all comments are attached to the src code for review\n\n\nAll expressions with results and comments for each srcline under exploration are documented for easy reviews\n\n\nOf course, no worry about your original source code, as it is untouched.\n\n\nImport\n\nfrom fastdebug.core import * # to make Fastdb available\nfrom fastdebug.utils import whatinside # for making an example\n\n\n\nInitiating\n\ng = locals()\nfdb = Fastdb(whatinside, outloc=g) # use either fu.whatinside or whatinside is fine\n\n\nfdb.print(maxlines=20, part=1) # view the source code with idx\n\ndef whatinside(mo, # module, e.g., `import fastcore.all as fa`, use `fa` here=============(0)       \n               dun:bool=False, # print all items in __all__===============================(1)       \n               func:bool=False, # print all user defined functions========================(2)       \n               clas:bool=False, # print all class objects=================================(3)       \n               bltin:bool=False, # print all builtin funcs or methods=====================(4)       \n               lib:bool=False, # print all the modules of the library it belongs to=======(5)       \n               cal:bool=False # print all callables=======================================(6)       \n             ): ==========================================================================(7)       \n    'Check what inside a module: `__all__`, functions, classes, builtins, and callables'==(8)       \n    dun_all = len(mo.__all__) if hasattr(mo, \"__all__\") else 0============================(9)       \n    funcs = inspect.getmembers(mo, inspect.isfunction)====================================(10)      \n    classes = inspect.getmembers(mo, inspect.isclass)=====================================(11)      \n    builtins = inspect.getmembers(mo, inspect.isbuiltin)==================================(12)      \n    callables = inspect.getmembers(mo, callable)==========================================(13)      \n    pkgpath = os.path.dirname(mo.__file__)================================================(14)      \n    if not lib:===========================================================================(15)      \n        print(f\"{mo.__name__} has: \\n{dun_all} items in its __all__, and \\n{len(funcs)} user defined functions, \\n{len(classes)} classes or class objects, \\n{len(builtins)} builtin funcs and methods, and\\n{len(callables)} callables.\\n\")  (16)\n    if hasattr(mo, \"__all__\") and dun: pprint(mo.__all__)=================================(17)      \n    if func: =============================================================================(18)      \n        print(f'The user defined functions are:')=========================================(19)      \n                                                                                                                                     part No.1 out of 2 parts\n\n\n\n\nWhat does the first line do?\n\nfdb.eg = \"whatinside(fu)\"\n\n\nfdb.docsrc(9, \"how many items inside mo.__all__?\", \"mo\", \\\n\"if hasattr(mo, '__all__'):\\\\n\\\n    printright(f'mo: {mo}')\\\\n\\\n    printright(f'mo.__all__: {mo.__all__}')\\\\n\\\n    printright(f'len(mo.__all__): {len(mo.__all__)}')\")\n\n========================================================     Investigating whatinside     ========================================================\n===============================================================     on line 9     ================================================================\n======================================================     with example whatinside(fu)     =======================================================\n\nprint selected srcline with expands below--------\n             ):                                                                                                                                         (7)\n    'Check what inside a module: `__all__`, functions, classes, builtins, and callables'                                                                (8)\n    dun_all = len(mo.__all__) if hasattr(mo, \"__all__\") else 0==========================================================================================(9)\n                                                                                                                            how many items inside mo.__all__?\n    funcs = inspect.getmembers(mo, inspect.isfunction)                                                                                                  (10)\n    classes = inspect.getmembers(mo, inspect.isclass)                                                                                                   (11)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                           mo => mo : <module 'fastdebug.utils' from '/Users/Natsume/Documents/fastdebug/fastdebug/utils.py'>\n\n\nif hasattr(mo, '__all__'):\n    printright(f'mo: {mo}')\n    printright(f'mo.__all__: {mo.__all__}')\n    printright(f'len(mo.__all__): {len(mo.__all__)}')     \n\nRunning the code block above => ====================================================================\n\n                                                                  mo: <module 'fastdebug.utils' from '/Users/Natsume/Documents/fastdebug/fastdebug/utils.py'>\n                                     mo.__all__: ['expand', 'test_eq', 'test_is', 'expandcell', 'inspect_class', 'ismetaclass', 'whatinside', 'whichversion']\n                                                                                                                                           len(mo.__all__): 8\n====================================================================================================================End of my srcline exploration:\n\nfastdebug.utils has: \n8 items in its __all__, and \n23 user defined functions, \n1 classes or class objects, \n0 builtin funcs and methods, and\n24 callables.\n\n\nReview srcode with all comments added so far======================================================================================================\ndef whatinside(mo, # module, e.g., `import fastcore.all as fa`, use `fa` here=============(0)       \n               dun:bool=False, # print all items in __all__===============================(1)       \n               func:bool=False, # print all user defined functions========================(2)       \n               clas:bool=False, # print all class objects=================================(3)       \n               bltin:bool=False, # print all builtin funcs or methods=====================(4)       \n               lib:bool=False, # print all the modules of the library it belongs to=======(5)       \n               cal:bool=False # print all callables=======================================(6)       \n             ): ==========================================================================(7)       \n    'Check what inside a module: `__all__`, functions, classes, builtins, and callables'==(8)       \n    dun_all = len(mo.__all__) if hasattr(mo, \"__all__\") else 0============================(9) # how many items inside mo.__all__?; \n    funcs = inspect.getmembers(mo, inspect.isfunction)====================================(10)      \n    classes = inspect.getmembers(mo, inspect.isclass)=====================================(11)      \n    builtins = inspect.getmembers(mo, inspect.isbuiltin)==================================(12)      \n    callables = inspect.getmembers(mo, callable)==========================================(13)      \n    pkgpath = os.path.dirname(mo.__file__)================================================(14)      \n    if not lib:===========================================================================(15)      \n        print(f\"{mo.__name__} has: \\n{dun_all} items in its __all__, and \\n{len(funcs)} user defined functions, \\n{len(classes)} classes or class objects, \\n{len(builtins)} builtin funcs and methods, and\\n{len(callables)} callables.\\n\")  (16)\n    if hasattr(mo, \"__all__\") and dun: pprint(mo.__all__)=================================(17)      \n    if func: =============================================================================(18)      \n        print(f'The user defined functions are:')=========================================(19)      \n                                                                                                                                     part No.1 out of 2 parts\n\n\n\n\ndbsrc = fdb.docsrc(10, \"get all funcs of a module\", \"mo\", \"inspect.getdoc(inspect.isfunction)\", \\\n            \"inspect.getdoc(inspect.getmembers)\", \"funcs = inspect.getmembers(mo, inspect.isfunction)\")\n\n========================================================     Investigating whatinside     ========================================================\n===============================================================     on line 10     ===============================================================\n======================================================     with example whatinside(fu)     =======================================================\n\nprint selected srcline with expands below--------\n    'Check what inside a module: `__all__`, functions, classes, builtins, and callables'                                                                (8)\n    dun_all = len(mo.__all__) if hasattr(mo, \"__all__\") else 0                                                                                          (9)\n    funcs = inspect.getmembers(mo, inspect.isfunction)==================================================================================================(10)\n                                                                                                                                    get all funcs of a module\n    classes = inspect.getmembers(mo, inspect.isclass)                                                                                                   (11)\n    builtins = inspect.getmembers(mo, inspect.isbuiltin)                                                                                                (12)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                           mo => mo : <module 'fastdebug.utils' from '/Users/Natsume/Documents/fastdebug/fastdebug/utils.py'>\n\n\ninspect.getdoc(inspect.isfunction) => inspect.getdoc(inspect.isfunction) : Return true if the object is a user-defined function.\n\nFunction objects provide these attributes:\n    __doc__         documentation string\n    __name__        name with which this function was defined\n    __code__        code object containing compiled function bytecode\n    __defaults__    tuple of any default values for arguments\n    __globals__     global namespace in which this function was defined\n    __annotations__ dict of parameter annotations\n    __kwdefaults__  dict of keyword only parameters with defaults\n\n\ninspect.getdoc(inspect.getmembers) => inspect.getdoc(inspect.getmembers) : Return all members of an object as (name, value) pairs sorted by name.\nOptionally, only return members that satisfy a given predicate.\n\n\nfuncs = inspect.getmembers(mo, inspect.isfunction) => funcs: [('distribution', <function distribution>), ('expandcell', <function expandcell>), ('inspect_class', <function inspect_class>), ('is_close', <function is_close>), ('ismetaclass', <function ismetaclass>), ('metadata', <function metadata>), ('nequals', <function nequals>), ('pprint', <function pprint>), ('python_version', <function python_version>), ('test', <function test>), ('test_close', <function test_close>), ('test_eq', <function test_eq>), ('test_eq_type', <function test_eq_type>), ('test_fail', <function test_fail>), ('test_fig_exists', <function test_fig_exists>), ('test_is', <function test_is>), ('test_ne', <function test_ne>), ('test_shuffled', <function test_shuffled>), ('test_stdout', <function test_stdout>), ('test_warns', <function test_warns>), ('version', <function version>), ('whatinside', <function whatinside>), ('whichversion', <function whichversion>)]\n====================================================================================================================End of my srcline exploration:\n\nfastdebug.utils has: \n8 items in its __all__, and \n23 user defined functions, \n1 classes or class objects, \n0 builtin funcs and methods, and\n24 callables.\n\n\nReview srcode with all comments added so far======================================================================================================\ndef whatinside(mo, # module, e.g., `import fastcore.all as fa`, use `fa` here=============(0)       \n               dun:bool=False, # print all items in __all__===============================(1)       \n               func:bool=False, # print all user defined functions========================(2)       \n               clas:bool=False, # print all class objects=================================(3)       \n               bltin:bool=False, # print all builtin funcs or methods=====================(4)       \n               lib:bool=False, # print all the modules of the library it belongs to=======(5)       \n               cal:bool=False # print all callables=======================================(6)       \n             ): ==========================================================================(7)       \n    'Check what inside a module: `__all__`, functions, classes, builtins, and callables'==(8)       \n    dun_all = len(mo.__all__) if hasattr(mo, \"__all__\") else 0============================(9) # how many items inside mo.__all__?; \n    funcs = inspect.getmembers(mo, inspect.isfunction)====================================(10) # get all funcs of a module; \n    classes = inspect.getmembers(mo, inspect.isclass)=====================================(11)      \n    builtins = inspect.getmembers(mo, inspect.isbuiltin)==================================(12)      \n    callables = inspect.getmembers(mo, callable)==========================================(13)      \n    pkgpath = os.path.dirname(mo.__file__)================================================(14)      \n    if not lib:===========================================================================(15)      \n        print(f\"{mo.__name__} has: \\n{dun_all} items in its __all__, and \\n{len(funcs)} user defined functions, \\n{len(classes)} classes or class objects, \\n{len(builtins)} builtin funcs and methods, and\\n{len(callables)} callables.\\n\")  (16)\n    if hasattr(mo, \"__all__\") and dun: pprint(mo.__all__)=================================(17)      \n    if func: =============================================================================(18)      \n        print(f'The user defined functions are:')=========================================(19)      \n                                                                                                                                     part No.1 out of 2 parts\n\n\n\n\n\nIf I find the src is too long, and I customize the print out of src the way I like\n\nfdb.print(maxlines=15, part=1)\n\ndef whatinside(mo, # module, e.g., `import fastcore.all as fa`, use `fa` here=============(0)       \n               dun:bool=False, # print all items in __all__===============================(1)       \n               func:bool=False, # print all user defined functions========================(2)       \n               clas:bool=False, # print all class objects=================================(3)       \n               bltin:bool=False, # print all builtin funcs or methods=====================(4)       \n               lib:bool=False, # print all the modules of the library it belongs to=======(5)       \n               cal:bool=False # print all callables=======================================(6)       \n             ): ==========================================================================(7)       \n    'Check what inside a module: `__all__`, functions, classes, builtins, and callables'==(8)       \n    dun_all = len(mo.__all__) if hasattr(mo, \"__all__\") else 0============================(9) # how many items inside mo.__all__?; \n    funcs = inspect.getmembers(mo, inspect.isfunction)====================================(10) # get all funcs of a module; \n    classes = inspect.getmembers(mo, inspect.isclass)=====================================(11)      \n    builtins = inspect.getmembers(mo, inspect.isbuiltin)==================================(12)      \n    callables = inspect.getmembers(mo, callable)==========================================(13)      \n    pkgpath = os.path.dirname(mo.__file__)================================================(14)      \n                                                                                                                                     part No.1 out of 3 parts\n\n\n\n\nI can write a block of codes to evaluate\n\nimport fastcore.meta as core\n\n\n# fdb.takExample(\"whatinside(core)\", whatinside=whatinside, core=core)\nfdb.eg = \"whatinside(core)\"\ndbsrc = fdb.docsrc(11, \"get all classes from the module\", \\\n\"clas = inspect.getmembers(mo, inspect.isclass)\\\\n\\\nfor c in clas:\\\\n\\\n    print(c)\")\n\n========================================================     Investigating whatinside     ========================================================\n===============================================================     on line 11     ===============================================================\n=====================================================     with example whatinside(core)     ======================================================\n\nprint selected srcline with expands below--------\n    dun_all = len(mo.__all__) if hasattr(mo, \"__all__\") else 0                                                                                          (9)\n    funcs = inspect.getmembers(mo, inspect.isfunction)                                                                                                  (10)\n    classes = inspect.getmembers(mo, inspect.isclass)===================================================================================================(11)\n                                                                                                                              get all classes from the module\n    builtins = inspect.getmembers(mo, inspect.isbuiltin)                                                                                                (12)\n    callables = inspect.getmembers(mo, callable)                                                                                                        (13)\n\n==================================================================================================================Start of my srcline exploration:\n\n\nclas = inspect.getmembers(mo, inspect.isclass)\nfor c in clas:\n    print(c)                                                                                   \n\nRunning the code block above => ====================================================================\n\n('AutoInit', <class 'fastcore.meta.AutoInit'>)\n('BuiltinFunctionType', <class 'builtin_function_or_method'>)\n('BuiltinMethodType', <class 'builtin_function_or_method'>)\n('BypassNewMeta', <class 'fastcore.meta.BypassNewMeta'>)\n('ExceptionExpected', <class 'fastcore.test.ExceptionExpected'>)\n('FixSigMeta', <class 'fastcore.meta.FixSigMeta'>)\n('FunctionType', <class 'function'>)\n('MethodDescriptorType', <class 'method_descriptor'>)\n('MethodType', <class 'method'>)\n('MethodWrapperType', <class 'method-wrapper'>)\n('NewChkMeta', <class 'fastcore.meta.NewChkMeta'>)\n('NoneType', <class 'NoneType'>)\n('Path', <class 'pathlib.Path'>)\n('PrePostInitMeta', <class 'fastcore.meta.PrePostInitMeta'>)\n('SimpleNamespace', <class 'types.SimpleNamespace'>)\n('WrapperDescriptorType', <class 'wrapper_descriptor'>)\n('attrgetter', <class 'operator.attrgetter'>)\n('itemgetter', <class 'operator.itemgetter'>)\n('partial', <class 'functools.partial'>)\n====================================================================================================================End of my srcline exploration:\n\nfastcore.meta has: \n13 items in its __all__, and \n43 user defined functions, \n19 classes or class objects, \n2 builtin funcs and methods, and\n74 callables.\n\n\nReview srcode with all comments added so far======================================================================================================\ndef whatinside(mo, # module, e.g., `import fastcore.all as fa`, use `fa` here=============(0)       \n               dun:bool=False, # print all items in __all__===============================(1)       \n               func:bool=False, # print all user defined functions========================(2)       \n               clas:bool=False, # print all class objects=================================(3)       \n               bltin:bool=False, # print all builtin funcs or methods=====================(4)       \n               lib:bool=False, # print all the modules of the library it belongs to=======(5)       \n               cal:bool=False # print all callables=======================================(6)       \n             ): ==========================================================================(7)       \n    'Check what inside a module: `__all__`, functions, classes, builtins, and callables'==(8)       \n    dun_all = len(mo.__all__) if hasattr(mo, \"__all__\") else 0============================(9) # how many items inside mo.__all__?; \n    funcs = inspect.getmembers(mo, inspect.isfunction)====================================(10) # get all funcs of a module; \n    classes = inspect.getmembers(mo, inspect.isclass)=====================================(11) # get all classes from the module; \n    builtins = inspect.getmembers(mo, inspect.isbuiltin)==================================(12)      \n    callables = inspect.getmembers(mo, callable)==========================================(13)      \n    pkgpath = os.path.dirname(mo.__file__)================================================(14)      \n    if not lib:===========================================================================(15)      \n        print(f\"{mo.__name__} has: \\n{dun_all} items in its __all__, and \\n{len(funcs)} user defined functions, \\n{len(classes)} classes or class objects, \\n{len(builtins)} builtin funcs and methods, and\\n{len(callables)} callables.\\n\")  (16)\n    if hasattr(mo, \"__all__\") and dun: pprint(mo.__all__)=================================(17)      \n    if func: =============================================================================(18)      \n        print(f'The user defined functions are:')=========================================(19)      \n                                                                                                                                     part No.1 out of 2 parts\n\n\n\n\ndbsrc = fdb.docsrc(14, \"get the file path of the module\", \"mo.__file__\", \"inspect.getdoc(os.path.dirname)\", \"pkgpath = os.path.dirname(mo.__file__)\")\n\n========================================================     Investigating whatinside     ========================================================\n===============================================================     on line 14     ===============================================================\n=====================================================     with example whatinside(core)     ======================================================\n\nprint selected srcline with expands below--------\n    builtins = inspect.getmembers(mo, inspect.isbuiltin)                                                                                                (12)\n    callables = inspect.getmembers(mo, callable)                                                                                                        (13)\n    pkgpath = os.path.dirname(mo.__file__)==============================================================================================================(14)\n                                                                                                                              get the file path of the module\n    if not lib:                                                                                                                                         (15)\n        print(f\"{mo.__name__} has: \\n{dun_all} items in its __all__, and \\n{len(funcs)} user defined functions, \\n{len(classes)} classes or class objects, \\n{len(builtins)} builtin funcs and methods, and\\n{len(callables)} callables.\\n\")  (16)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                          mo.__file__ => mo.__file__ : /Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore/meta.py\n\n\n                                           inspect.getdoc(os.path.dirname) => inspect.getdoc(os.path.dirname) : Returns the directory component of a pathname\n\n\n                                            pkgpath = os.path.dirname(mo.__file__) => pkgpath: /Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore\n====================================================================================================================End of my srcline exploration:\n\nfastcore.meta has: \n13 items in its __all__, and \n43 user defined functions, \n19 classes or class objects, \n2 builtin funcs and methods, and\n74 callables.\n\n\nReview srcode with all comments added so far======================================================================================================\ndef whatinside(mo, # module, e.g., `import fastcore.all as fa`, use `fa` here=============(0)       \n               dun:bool=False, # print all items in __all__===============================(1)       \n               func:bool=False, # print all user defined functions========================(2)       \n               clas:bool=False, # print all class objects=================================(3)       \n               bltin:bool=False, # print all builtin funcs or methods=====================(4)       \n               lib:bool=False, # print all the modules of the library it belongs to=======(5)       \n               cal:bool=False # print all callables=======================================(6)       \n             ): ==========================================================================(7)       \n    'Check what inside a module: `__all__`, functions, classes, builtins, and callables'==(8)       \n    dun_all = len(mo.__all__) if hasattr(mo, \"__all__\") else 0============================(9) # how many items inside mo.__all__?; \n    funcs = inspect.getmembers(mo, inspect.isfunction)====================================(10) # get all funcs of a module; \n    classes = inspect.getmembers(mo, inspect.isclass)=====================================(11) # get all classes from the module; \n    builtins = inspect.getmembers(mo, inspect.isbuiltin)==================================(12)      \n    callables = inspect.getmembers(mo, callable)==========================================(13)      \n    pkgpath = os.path.dirname(mo.__file__)================================================(14) # get the file path of the module; \n    if not lib:===========================================================================(15)      \n        print(f\"{mo.__name__} has: \\n{dun_all} items in its __all__, and \\n{len(funcs)} user defined functions, \\n{len(classes)} classes or class objects, \\n{len(builtins)} builtin funcs and methods, and\\n{len(callables)} callables.\\n\")  (16)\n    if hasattr(mo, \"__all__\") and dun: pprint(mo.__all__)=================================(17)      \n    if func: =============================================================================(18)      \n        print(f'The user defined functions are:')=========================================(19)      \n                                                                                                                                     part No.1 out of 2 parts\n\n\n\n\n# fdb.takExample(\"whatinside(core, lib=True)\", whatinside=whatinside, core=core)\nfdb.eg = \"whatinside(core, lib=True)\"\ndbsrc = fdb.docsrc(30, \"get names of all modules of a lib\", \"pkgpath\", \"inspect.getdoc(pkgutil.iter_modules)\", \\\n\"for a, b, c in pkgutil.iter_modules([pkgpath]):\\\\n\\\n    printright(f'{a} ; {b}; {c}')\", db=True)\n\n========================================================     Investigating whatinside     ========================================================\n===============================================================     on line 30     ===============================================================\n================================================     with example whatinside(core, lib=True)     =================================================\n\nprint selected srcline with expands below--------\n        print(f'The callables are: ')                                                                                                                   (28)\n        pprint([i[0] for i in callables])                                                                                                               (29)\n    if lib: ============================================================================================================================================(30)\n                                                                                                                            get names of all modules of a lib\n        modules = [name for _, name, _ in pkgutil.iter_modules([pkgpath])]                                                                              (31)\n        print(f'The library has {len(modules)} modules')                                                                                                (32)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                                          pkgpath => pkgpath : /Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore\n\n\ninspect.getdoc(pkgutil.iter_modules) => inspect.getdoc(pkgutil.iter_modules) : Yields ModuleInfo for all submodules on path,\nor, if path is None, all top-level modules on sys.path.\n\n'path' should be either None or a list of paths to look for\nmodules in.\n\n'prefix' is a string to output on the front of every module name\non output.\n\n\nfor a, b, c in pkgutil.iter_modules([pkgpath]):\n    printright(f'{a} ; {b}; {c}')                                                                            \n\nRunning the code block above => ====================================================================\n\n                                                                FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; _modidx; False\n                                                                 FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; _nbdev; False\n                                                                    FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; all; False\n                                                                 FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; basics; False\n                                                               FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; dispatch; False\n                                                               FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; docments; False\n                                                              FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; docscrape; False\n                                                             FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; foundation; False\n                                                                FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; imports; False\n                                                                   FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; meta; False\n                                                             FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; nb_imports; False\n                                                                    FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; net; False\n                                                               FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; parallel; False\n                                                                 FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; script; False\n                                                                 FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; shutil; False\n                                                                  FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; style; False\n                                                                   FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; test; False\n                                                              FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; transform; False\n                                                                  FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; utils; False\n                                                                    FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; xdg; False\n                                                                  FileFinder('/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastcore') ; xtras; False\n====================================================================================================================End of my srcline exploration:\n\nThe library has 21 modules\n['_modidx',\n '_nbdev',\n 'all',\n 'basics',\n 'dispatch',\n 'docments',\n 'docscrape',\n 'foundation',\n 'imports',\n 'meta',\n 'nb_imports',\n 'net',\n 'parallel',\n 'script',\n 'shutil',\n 'style',\n 'test',\n 'transform',\n 'utils',\n 'xdg',\n 'xtras']\n\nReview srcode with all comments added so far======================================================================================================\n        pprint([i[0] for i in funcs])=====================================================(20)      \n    if clas: =============================================================================(21)      \n        print(f'The class objects are:')==================================================(22)      \n        pprint([i[0] for i in classes])===================================================(23)      \n    if bltin: ============================================================================(24)      \n        print(f'The builtin functions or methods are:')===================================(25)      \n        pprint([i[0] for i in builtins])==================================================(26)      \n    if cal: ==============================================================================(27)      \n        print(f'The callables are: ')=====================================================(28)      \n        pprint([i[0] for i in callables])=================================================(29)      \n    if lib: ==============================================================================(30) # get names of all modules of a lib; \n        modules = [name for _, name, _ in pkgutil.iter_modules([pkgpath])]================(31)      \n        print(f'The library has {len(modules)} modules')==================================(32)      \n        pprint(modules)===================================================================(33)      \n                                                                                                                                                        (34)\n                                                                                                                                     part No.2 out of 2 parts\n\n\n\n\n\nPrint out the entire src with idx and comments, when I finish documenting\n\nfdb.print()\n\n========================================================     Investigating whatinside     ========================================================\n===============================================================     on line 30     ===============================================================\n================================================     with example whatinside(core, lib=True)     =================================================\n\ndef whatinside(mo, # module, e.g., `import fastcore.all as fa`, use `fa` here=============(0)       \n               dun:bool=False, # print all items in __all__===============================(1)       \n               func:bool=False, # print all user defined functions========================(2)       \n               clas:bool=False, # print all class objects=================================(3)       \n               bltin:bool=False, # print all builtin funcs or methods=====================(4)       \n               lib:bool=False, # print all the modules of the library it belongs to=======(5)       \n               cal:bool=False # print all callables=======================================(6)       \n             ): ==========================================================================(7)       \n    'Check what inside a module: `__all__`, functions, classes, builtins, and callables'==(8)       \n    dun_all = len(mo.__all__) if hasattr(mo, \"__all__\") else 0============================(9) # how many items inside mo.__all__?; \n    funcs = inspect.getmembers(mo, inspect.isfunction)====================================(10) # get all funcs of a module; \n    classes = inspect.getmembers(mo, inspect.isclass)=====================================(11) # get all classes from the module; \n    builtins = inspect.getmembers(mo, inspect.isbuiltin)==================================(12)      \n    callables = inspect.getmembers(mo, callable)==========================================(13)      \n    pkgpath = os.path.dirname(mo.__file__)================================================(14) # get the file path of the module; \n    if not lib:===========================================================================(15)      \n        print(f\"{mo.__name__} has: \\n{dun_all} items in its __all__, and \\n{len(funcs)} user defined functions, \\n{len(classes)} classes or class objects, \\n{len(builtins)} builtin funcs and methods, and\\n{len(callables)} callables.\\n\")  (16)\n    if hasattr(mo, \"__all__\") and dun: pprint(mo.__all__)=================================(17)      \n    if func: =============================================================================(18)      \n        print(f'The user defined functions are:')=========================================(19)      \n        pprint([i[0] for i in funcs])=====================================================(20)      \n    if clas: =============================================================================(21)      \n        print(f'The class objects are:')==================================================(22)      \n        pprint([i[0] for i in classes])===================================================(23)      \n    if bltin: ============================================================================(24)      \n        print(f'The builtin functions or methods are:')===================================(25)      \n        pprint([i[0] for i in builtins])==================================================(26)      \n    if cal: ==============================================================================(27)      \n        print(f'The callables are: ')=====================================================(28)      \n        pprint([i[0] for i in callables])=================================================(29)      \n    if lib: ==============================================================================(30) # get names of all modules of a lib; \n        modules = [name for _, name, _ in pkgutil.iter_modules([pkgpath])]================(31)      \n        print(f'The library has {len(modules)} modules')==================================(32)      \n        pprint(modules)===================================================================(33)      \n                                                                                                                                                        (34)\n\n\n\n\nAfter running .dbprint, everything is back to normal automatically\n\ninspect.getsourcefile(fu.whatinside)\n\n'/Users/Natsume/Documents/fastdebug/fastdebug/utils.py'\n\n\n\ninspect.getsourcefile(whatinside)\n\n'/Users/Natsume/Documents/fastdebug/fastdebug/utils.py'\n\n\nTo check, when run whatinside?? we should see the actually source code whereas the db version of whatinside does not have."
  },
  {
    "objectID": "demos/intro_fastdebug.html#install",
    "href": "demos/intro_fastdebug.html#install",
    "title": "Introducing fastdebug",
    "section": "Install",
    "text": "Install\npip install fastdebug"
  },
  {
    "objectID": "demos/intro_fastdebug.html#how-to-use",
    "href": "demos/intro_fastdebug.html#how-to-use",
    "title": "Introducing fastdebug",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2"
  },
  {
    "objectID": "demos/fastcore.meta.newchkmeta.html",
    "href": "demos/fastcore.meta.newchkmeta.html",
    "title": "06_NewChkMeta",
    "section": "",
    "text": "from fastdebug.utils import *\nfrom fastdebug.core import *\nfrom fastcore.meta import *\n\n\n\n\n\ng = locals()\nfdb = Fastdb(NewChkMeta, outloc = g)\n\n\nfdb.print()\n\n========================================================     Investigating NewChkMeta     ========================================================\n==============================================================     on line None     ==============================================================\n=============================================================     with example      ==============================================================\n\nclass NewChkMeta(FixSigMeta):=============================================================(0)       \n    \"Metaclass to avoid recreating object passed to constructor\"==========================(1)       \n    def __call__(cls, x=None, *args, **kwargs):===========================================(2)       \n        if not args and not kwargs and x is not None and isinstance(x,cls): return x======(3)       \n        res = super().__call__(*((x,) + args), **kwargs)==================================(4)       \n        return res========================================================================(5)       \n                                                                                                                                                        (6)"
  },
  {
    "objectID": "demos/fastcore.meta.newchkmeta.html#official-docs",
    "href": "demos/fastcore.meta.newchkmeta.html#official-docs",
    "title": "06_NewChkMeta",
    "section": "Official docs",
    "text": "Official docs\nThe official docs (at first, it does not make sense to me)\nNewChkMeta is used when an object of the same type is the first argument to your class’s constructor (i.e. the init function), and you would rather it not create a new object but point to the same exact object.\nThis is used in L, for example, to avoid creating a new object when the object is already of type L. This allows the users to defenisvely instantiate an L object and just return a reference to the same object if it already happens to be of type L.\nFor example, the below class _T optionally accepts an object o as its first argument. A new object is returned upon instantiation per usual:\n\nclass _T():\n    \"Testing\"\n    def __init__(self, o): \n        # if `o` is not an object without an attribute `foo`, set foo = 1\n        self.foo = getattr(o,'foo',1)\n        \nt = _T(3)\ntest_eq(t.foo,1) # 1 was not of type _T, so foo = 1\n\nt2 = _T(t) #t1 is of type _T\nassert t is not t2 # t1 and t2 are different objects\n\nHowever, if we want _T to return a reference to the same object when passed an an object of type _T we can inherit from the NewChkMeta class as illustrated below:\n\nclass _T(metaclass=NewChkMeta):\n    \"Testing with metaclass NewChkMeta\"\n    def __init__(self, o=None, b=1):\n        # if `o` is not an object without an attribute `foo`, set foo = 1\n        self.foo = getattr(o,'foo',1)\n        self.b = b\n\nt = _T(3)\ntest_eq(t.foo,1) # 1 was not of type _T, so foo = 1\n\nt2 = _T(t) # t2 will now reference t\n\ntest_is(t, t2) # t and t2 are the same object\nt2.foo = 5 # this will also change t.foo to 5 because it is the same object\ntest_eq(t.foo, 5)\ntest_eq(t2.foo, 5)\n\nt3 = _T(t, b=1)\nassert t3 is not t\n\nt4 = _T(t) # without any arguments the constructor will return a reference to the same object\nassert t4 is t"
  },
  {
    "objectID": "demos/fastcore.meta.newchkmeta.html#prepare-example",
    "href": "demos/fastcore.meta.newchkmeta.html#prepare-example",
    "title": "06_NewChkMeta",
    "section": "Prepare Example",
    "text": "Prepare Example\n\nfdb.eg = \"\"\"\nclass _T(metaclass=NewChkMeta):\n    \"Testing with metaclass NewChkMeta\"\n    def __init__(self, o=None, b=1):\n        # if `o` is not an object without an attribute `foo`, set foo = 1\n        self.foo = getattr(o,'foo',1)\n        self.b = b\n\nt = _T(3)\ntest_eq(t.foo,1) # 1 was not of type _T, so foo = 1\n\nt2 = _T(t) # t2 will now reference t\n\ntest_is(t, t2) # t and t2 are the same object\nt2.foo = 5 # this will also change t.foo to 5 because it is the same object\ntest_eq(t.foo, 5)\ntest_eq(t2.foo, 5)\n\nt3 = _T(t, b=1)\nassert t3 is not t\n\nt4 = _T(t) # without any arguments the constructor will return a reference to the same object\nassert t4 is t\n\"\"\""
  },
  {
    "objectID": "demos/fastcore.meta.newchkmeta.html#inspect-classes",
    "href": "demos/fastcore.meta.newchkmeta.html#inspect-classes",
    "title": "06_NewChkMeta",
    "section": "Inspect classes",
    "text": "Inspect classes\n\ninspect_class(NewChkMeta)\n\nclass NewChkMeta(FixSigMeta):\n    \"Metaclass to avoid recreating object passed to constructor\"\n    def __call__(cls, x=None, *args, **kwargs):\n        if not args and not kwargs and x is not None and isinstance(x,cls): return x\n        res = super().__call__(*((x,) + args), **kwargs)\n        return res\n\n\nis NewChkMeta a metaclass: True\nis NewChkMeta created by a metaclass: False\nNewChkMeta is created by <class 'type'>\nNewChkMeta.__new__ is object.__new__: False\nNewChkMeta.__new__ is type.__new__: False\nNewChkMeta.__new__: <function FixSigMeta.__new__>\nNewChkMeta.__init__ is object.__init__: False\nNewChkMeta.__init__ is type.__init__: True\nNewChkMeta.__init__: <slot wrapper '__init__' of 'type' objects>\nNewChkMeta.__call__ is object.__call__: False\nNewChkMeta.__call__ is type.__call__: False\nNewChkMeta.__call__: <function NewChkMeta.__call__>\nNewChkMeta.__class__: <class 'type'>\nNewChkMeta.__bases__: (<class 'fastcore.meta.FixSigMeta'>,)\nNewChkMeta.__mro__: (<class 'fastcore.meta.NewChkMeta'>, <class 'fastcore.meta.FixSigMeta'>, <class 'type'>, <class 'object'>)\n\nNewChkMeta's function members are:\n{'__call__': <function NewChkMeta.__call__>,\n '__new__': <function FixSigMeta.__new__>}\n\nNewChkMeta's method members are:\n{}\n\nNewChkMeta's class members are:\n{'__base__': <class 'fastcore.meta.FixSigMeta'>, '__class__': <class 'type'>}\n\nNewChkMeta's namespace are:\nmappingproxy({'__call__': <function NewChkMeta.__call__>,\n              '__doc__': 'Metaclass to avoid recreating object passed to '\n                         'constructor',\n              '__module__': 'fastcore.meta'})\n\n\n\ninspect_class(_T)\n\n\nis _T a metaclass: False\nis _T created by a metaclass: True\n_T is created by metaclass <class 'fastcore.meta.NewChkMeta'>\n_T.__new__ is object.__new__: True\n_T.__new__ is type.__new__: False\n_T.__new__: <built-in method __new__ of type object>\n_T.__init__ is object.__init__: False\n_T.__init__ is type.__init__: False\n_T.__init__: <function _T.__init__>\n_T.__call__ is object.__call__: False\n_T.__call__ is type.__call__: False\n_T.__call__: <bound method NewChkMeta.__call__ of <class '__main__._T'>>\n_T.__class__: <class 'fastcore.meta.NewChkMeta'>\n_T.__bases__: (<class 'object'>,)\n_T.__mro__: (<class '__main__._T'>, <class 'object'>)\n\n_T's metaclass <class 'fastcore.meta.NewChkMeta'>'s function members are:\n{'__call__': <function NewChkMeta.__call__>,\n '__new__': <function FixSigMeta.__new__>}\n\n_T's function members are:\n{'__init__': <function _T.__init__>}\n\n_T's method members are:\n{}\n\n_T's class members are:\n{'__class__': <class 'fastcore.meta.NewChkMeta'>}\n\n_T's namespace are:\nmappingproxy({'__dict__': <attribute '__dict__' of '_T' objects>,\n              '__doc__': 'Testing with metaclass NewChkMeta',\n              '__init__': <function _T.__init__>,\n              '__module__': '__main__',\n              '__signature__': <Signature (o=None, b=1)>,\n              '__weakref__': <attribute '__weakref__' of '_T' objects>})"
  },
  {
    "objectID": "demos/fastcore.meta.newchkmeta.html#snoop",
    "href": "demos/fastcore.meta.newchkmeta.html#snoop",
    "title": "06_NewChkMeta",
    "section": "Snoop",
    "text": "Snoop\n\nfdb.snoop()\n\n21:38:05.32 >>> Call to NewChkMeta.__call__ in File \"/tmp/NewChkMeta.py\", line 5\n21:38:05.32 .......... cls = <class 'fastcore.meta._T'>\n21:38:05.32 .......... x = 3\n21:38:05.32 .......... args = ()\n21:38:05.32 .......... kwargs = {}\n21:38:05.32 .......... __class__ = <class 'fastcore.meta.NewChkMeta'>\n21:38:05.32    5 |     def __call__(cls, x=None, *args, **kwargs):\n21:38:05.32    6 |         if not args and not kwargs and x is not None and isinstance(x,cls): return x\n21:38:05.32    7 |         res = super().__call__(*((x,) + args), **kwargs)\n21:38:05.32 .............. res = <fastcore.meta._T object>\n21:38:05.32    8 |         return res\n21:38:05.32 <<< Return value from NewChkMeta.__call__: <fastcore.meta._T object>\n21:38:05.32 >>> Call to NewChkMeta.__call__ in File \"/tmp/NewChkMeta.py\", line 5\n21:38:05.32 .......... cls = <class 'fastcore.meta._T'>\n21:38:05.32 .......... x = <fastcore.meta._T object>\n21:38:05.32 .......... args = ()\n21:38:05.32 .......... kwargs = {}\n21:38:05.32 .......... __class__ = <class 'fastcore.meta.NewChkMeta'>\n21:38:05.32    5 |     def __call__(cls, x=None, *args, **kwargs):\n21:38:05.32    6 |         if not args and not kwargs and x is not None and isinstance(x,cls): return x\n21:38:05.32 <<< Return value from NewChkMeta.__call__: <fastcore.meta._T object>\n21:38:05.32 >>> Call to NewChkMeta.__call__ in File \"/tmp/NewChkMeta.py\", line 5\n21:38:05.32 .......... cls = <class 'fastcore.meta._T'>\n21:38:05.32 .......... x = <fastcore.meta._T object>\n21:38:05.32 .......... args = ()\n21:38:05.32 .......... kwargs = {'b': 1}\n21:38:05.32 .......... len(kwargs) = 1\n21:38:05.32 .......... __class__ = <class 'fastcore.meta.NewChkMeta'>\n21:38:05.32    5 |     def __call__(cls, x=None, *args, **kwargs):\n21:38:05.32    6 |         if not args and not kwargs and x is not None and isinstance(x,cls): return x\n21:38:05.32    7 |         res = super().__call__(*((x,) + args), **kwargs)\n21:38:05.32 .............. res = <fastcore.meta._T object>\n21:38:05.32    8 |         return res\n21:38:05.32 <<< Return value from NewChkMeta.__call__: <fastcore.meta._T object>\n21:38:05.32 >>> Call to NewChkMeta.__call__ in File \"/tmp/NewChkMeta.py\", line 5\n21:38:05.32 .......... cls = <class 'fastcore.meta._T'>\n21:38:05.32 .......... x = <fastcore.meta._T object>\n21:38:05.32 .......... args = ()\n21:38:05.32 .......... kwargs = {}\n21:38:05.32 .......... __class__ = <class 'fastcore.meta.NewChkMeta'>\n21:38:05.32    5 |     def __call__(cls, x=None, *args, **kwargs):\n21:38:05.32    6 |         if not args and not kwargs and x is not None and isinstance(x,cls): return x\n21:38:05.32 <<< Return value from NewChkMeta.__call__: <fastcore.meta._T object>\n\n\n========================================================     Investigating NewChkMeta     ========================================================\n==============================================================     on line None     ==============================================================\n     with example \nclass _T(metaclass=NewChkMeta):\n    \"Testing with metaclass NewChkMeta\"\n    def __init__(self, o=None, b=1):\n        # if `o` is not an object without an attribute `foo`, set foo = 1\n        self.foo = getattr(o,'foo',1)\n        self.b = b\n\nt = _T(3)\ntest_eq(t.foo,1) # 1 was not of type _T, so foo = 1\n\nt2 = _T(t) # t2 will now reference t\n\ntest_is(t, t2) # t and t2 are the same object\nt2.foo = 5 # this will also change t.foo to 5 because it is the same object\ntest_eq(t.foo, 5)\ntest_eq(t2.foo, 5)\n\nt3 = _T(t, b=1)\nassert t3 is not t\n\nt4 = _T(t) # without any arguments the constructor will return a reference to the same object\nassert t4 is t"
  },
  {
    "objectID": "demos/fastcore.meta.newchkmeta.html#document",
    "href": "demos/fastcore.meta.newchkmeta.html#document",
    "title": "06_NewChkMeta",
    "section": "Document",
    "text": "Document\n\nfdb.docsrc(1, \"NewChkMeta is a metaclass inherited from FixSigMea; it makes its own __call__; \\\nwhen its class instance, e.g., _T, create object instances (e.g, t) without args nor kwargs but only x, \\\nand x is an object of the instance class, then return x; otherwise, create and return a new object created by \\\nthe instance class's super class' __call__ method with x as param; In other words, t = _T(3) will create a new obj; \\\n_T(t) will return t; _T(t, 1) or _T(t, b=1) will also return a new obj\")\nfdb.docsrc(2, \"how to create a __call__ method with param cls, x, *args, **kwargs;\")\nfdb.docsrc(3, \"how to express no args and no kwargs and x is an instance of cls?\")\nfdb.docsrc(4, \"how to call __call__ of super class with x and consider all possible situations of args and kwargs\")\n\n========================================================     Investigating NewChkMeta     ========================================================\n===============================================================     on line 1     ================================================================\n     with example \nclass _T(metaclass=NewChkMeta):\n    \"Testing with metaclass NewChkMeta\"\n    def __init__(self, o=None, b=1):\n        # if `o` is not an object without an attribute `foo`, set foo = 1\n        self.foo = getattr(o,'foo',1)\n        self.b = b\n\nt = _T(3)\ntest_eq(t.foo,1) # 1 was not of type _T, so foo = 1\n\nt2 = _T(t) # t2 will now reference t\n\ntest_is(t, t2) # t and t2 are the same object\nt2.foo = 5 # this will also change t.foo to 5 because it is the same object\ntest_eq(t.foo, 5)\ntest_eq(t2.foo, 5)\n\nt3 = _T(t, b=1)\nassert t3 is not t\n\nt4 = _T(t) # without any arguments the constructor will return a reference to the same object\nassert t4 is t\n     \n\nprint selected srcline with expands below--------\nclass NewChkMeta(FixSigMeta):                                                                                                                           (0)\n    \"Metaclass to avoid recreating object passed to constructor\"========================================================================================(1)\nNewChkMeta is a metaclass inherited from FixSigMea; it makes its own __call__; when its class instance, e.g., _T, create object instances (e.g, t) without args nor kwargs but only x, and x is an object of the instance class, then return x; otherwise, create and return a new object created by the instance class's super class' __call__ method with x as param; In other words, t = _T(3) will create a new obj; _T(t) will return t; _T(t, 1) or _T(t, b=1) will also return a new obj\n    def __call__(cls, x=None, *args, **kwargs):                                                                                                         (2)\n        if not args and not kwargs and x is not None and isinstance(x,cls): return x                                                                    (3)\n\nReview srcode with all comments added so far======================================================================================================\nclass NewChkMeta(FixSigMeta):=============================================================(0)       \n    \"Metaclass to avoid recreating object passed to constructor\"==========================(1) # NewChkMeta is a metaclass inherited from FixSigMea; it makes its own __call__; when its class instance, e.g., _T, create object instances (e.g, t) without args nor kwargs but only x, and x is an object of the instance class, then return x; otherwise, create and return a new object created by the instance class's super class' __call__ method with x as param; In other words, t = _T(3) will create a new obj; _T(t) will return t; _T(t, 1) or _T(t, b=1) will also return a new obj; \n    def __call__(cls, x=None, *args, **kwargs):===========================================(2)       \n        if not args and not kwargs and x is not None and isinstance(x,cls): return x======(3)       \n        res = super().__call__(*((x,) + args), **kwargs)==================================(4)       \n        return res========================================================================(5)       \n                                                                                                                                                        (6)\n                                                                                                                                     part No.1 out of 1 parts\n\n========================================================     Investigating NewChkMeta     ========================================================\n===============================================================     on line 2     ================================================================\n     with example \nclass _T(metaclass=NewChkMeta):\n    \"Testing with metaclass NewChkMeta\"\n    def __init__(self, o=None, b=1):\n        # if `o` is not an object without an attribute `foo`, set foo = 1\n        self.foo = getattr(o,'foo',1)\n        self.b = b\n\nt = _T(3)\ntest_eq(t.foo,1) # 1 was not of type _T, so foo = 1\n\nt2 = _T(t) # t2 will now reference t\n\ntest_is(t, t2) # t and t2 are the same object\nt2.foo = 5 # this will also change t.foo to 5 because it is the same object\ntest_eq(t.foo, 5)\ntest_eq(t2.foo, 5)\n\nt3 = _T(t, b=1)\nassert t3 is not t\n\nt4 = _T(t) # without any arguments the constructor will return a reference to the same object\nassert t4 is t\n     \n\nprint selected srcline with expands below--------\nclass NewChkMeta(FixSigMeta):                                                                                                                           (0)\n    \"Metaclass to avoid recreating object passed to constructor\"                                                                                        (1)\n    def __call__(cls, x=None, *args, **kwargs):=========================================================================================================(2)\n                                                                                          how to create a __call__ method with param cls, x, *args, **kwargs;\n        if not args and not kwargs and x is not None and isinstance(x,cls): return x                                                                    (3)\n        res = super().__call__(*((x,) + args), **kwargs)                                                                                                (4)\n\nReview srcode with all comments added so far======================================================================================================\nclass NewChkMeta(FixSigMeta):=============================================================(0)       \n    \"Metaclass to avoid recreating object passed to constructor\"==========================(1) # NewChkMeta is a metaclass inherited from FixSigMea; it makes its own __call__; when its class instance, e.g., _T, create object instances (e.g, t) without args nor kwargs but only x, and x is an object of the instance class, then return x; otherwise, create and return a new object created by the instance class's super class' __call__ method with x as param; In other words, t = _T(3) will create a new obj; _T(t) will return t; _T(t, 1) or _T(t, b=1) will also return a new obj; \n    def __call__(cls, x=None, *args, **kwargs):===========================================(2) # how to create a __call__ method with param cls, x, *args, **kwargs;; \n        if not args and not kwargs and x is not None and isinstance(x,cls): return x======(3)       \n        res = super().__call__(*((x,) + args), **kwargs)==================================(4)       \n        return res========================================================================(5)       \n                                                                                                                                                        (6)\n                                                                                                                                     part No.1 out of 1 parts\n\n========================================================     Investigating NewChkMeta     ========================================================\n===============================================================     on line 3     ================================================================\n     with example \nclass _T(metaclass=NewChkMeta):\n    \"Testing with metaclass NewChkMeta\"\n    def __init__(self, o=None, b=1):\n        # if `o` is not an object without an attribute `foo`, set foo = 1\n        self.foo = getattr(o,'foo',1)\n        self.b = b\n\nt = _T(3)\ntest_eq(t.foo,1) # 1 was not of type _T, so foo = 1\n\nt2 = _T(t) # t2 will now reference t\n\ntest_is(t, t2) # t and t2 are the same object\nt2.foo = 5 # this will also change t.foo to 5 because it is the same object\ntest_eq(t.foo, 5)\ntest_eq(t2.foo, 5)\n\nt3 = _T(t, b=1)\nassert t3 is not t\n\nt4 = _T(t) # without any arguments the constructor will return a reference to the same object\nassert t4 is t\n     \n\nprint selected srcline with expands below--------\n    \"Metaclass to avoid recreating object passed to constructor\"                                                                                        (1)\n    def __call__(cls, x=None, *args, **kwargs):                                                                                                         (2)\n        if not args and not kwargs and x is not None and isinstance(x,cls): return x====================================================================(3)\n                                                                                            how to express no args and no kwargs and x is an instance of cls?\n        res = super().__call__(*((x,) + args), **kwargs)                                                                                                (4)\n        return res                                                                                                                                      (5)\n\nReview srcode with all comments added so far======================================================================================================\nclass NewChkMeta(FixSigMeta):=============================================================(0)       \n    \"Metaclass to avoid recreating object passed to constructor\"==========================(1) # NewChkMeta is a metaclass inherited from FixSigMea; it makes its own __call__; when its class instance, e.g., _T, create object instances (e.g, t) without args nor kwargs but only x, and x is an object of the instance class, then return x; otherwise, create and return a new object created by the instance class's super class' __call__ method with x as param; In other words, t = _T(3) will create a new obj; _T(t) will return t; _T(t, 1) or _T(t, b=1) will also return a new obj; \n    def __call__(cls, x=None, *args, **kwargs):===========================================(2) # how to create a __call__ method with param cls, x, *args, **kwargs;; \n        if not args and not kwargs and x is not None and isinstance(x,cls): return x======(3) # how to express no args and no kwargs and x is an instance of cls?; \n        res = super().__call__(*((x,) + args), **kwargs)==================================(4)       \n        return res========================================================================(5)       \n                                                                                                                                                        (6)\n                                                                                                                                     part No.1 out of 1 parts\n\n========================================================     Investigating NewChkMeta     ========================================================\n===============================================================     on line 4     ================================================================\n     with example \nclass _T(metaclass=NewChkMeta):\n    \"Testing with metaclass NewChkMeta\"\n    def __init__(self, o=None, b=1):\n        # if `o` is not an object without an attribute `foo`, set foo = 1\n        self.foo = getattr(o,'foo',1)\n        self.b = b\n\nt = _T(3)\ntest_eq(t.foo,1) # 1 was not of type _T, so foo = 1\n\nt2 = _T(t) # t2 will now reference t\n\ntest_is(t, t2) # t and t2 are the same object\nt2.foo = 5 # this will also change t.foo to 5 because it is the same object\ntest_eq(t.foo, 5)\ntest_eq(t2.foo, 5)\n\nt3 = _T(t, b=1)\nassert t3 is not t\n\nt4 = _T(t) # without any arguments the constructor will return a reference to the same object\nassert t4 is t\n     \n\nprint selected srcline with expands below--------\n    def __call__(cls, x=None, *args, **kwargs):                                                                                                         (2)\n        if not args and not kwargs and x is not None and isinstance(x,cls): return x                                                                    (3)\n        res = super().__call__(*((x,) + args), **kwargs)================================================================================================(4)\n                                                           how to call __call__ of super class with x and consider all possible situations of args and kwargs\n        return res                                                                                                                                      (5)\n                                                                                                                                                        (6)\n\nReview srcode with all comments added so far======================================================================================================\nclass NewChkMeta(FixSigMeta):=============================================================(0)       \n    \"Metaclass to avoid recreating object passed to constructor\"==========================(1) # NewChkMeta is a metaclass inherited from FixSigMea; it makes its own __call__; when its class instance, e.g., _T, create object instances (e.g, t) without args nor kwargs but only x, and x is an object of the instance class, then return x; otherwise, create and return a new object created by the instance class's super class' __call__ method with x as param; In other words, t = _T(3) will create a new obj; _T(t) will return t; _T(t, 1) or _T(t, b=1) will also return a new obj; \n    def __call__(cls, x=None, *args, **kwargs):===========================================(2) # how to create a __call__ method with param cls, x, *args, **kwargs;; \n        if not args and not kwargs and x is not None and isinstance(x,cls): return x======(3) # how to express no args and no kwargs and x is an instance of cls?; \n        res = super().__call__(*((x,) + args), **kwargs)==================================(4) # how to call __call__ of super class with x and consider all possible situations of args and kwargs; \n        return res========================================================================(5)       \n                                                                                                                                                        (6)\n                                                                                                                                     part No.1 out of 1 parts\n\n\n\n\nfdb.print()\n\n========================================================     Investigating NewChkMeta     ========================================================\n===============================================================     on line 4     ================================================================\n     with example \nclass _T(metaclass=NewChkMeta):\n    \"Testing with metaclass NewChkMeta\"\n    def __init__(self, o=None, b=1):\n        # if `o` is not an object without an attribute `foo`, set foo = 1\n        self.foo = getattr(o,'foo',1)\n        self.b = b\n\nt = _T(3)\ntest_eq(t.foo,1) # 1 was not of type _T, so foo = 1\n\nt2 = _T(t) # t2 will now reference t\n\ntest_is(t, t2) # t and t2 are the same object\nt2.foo = 5 # this will also change t.foo to 5 because it is the same object\ntest_eq(t.foo, 5)\ntest_eq(t2.foo, 5)\n\nt3 = _T(t, b=1)\nassert t3 is not t\n\nt4 = _T(t) # without any arguments the constructor will return a reference to the same object\nassert t4 is t\n     \n\nclass NewChkMeta(FixSigMeta):=============================================================(0)       \n    \"Metaclass to avoid recreating object passed to constructor\"==========================(1) # NewChkMeta is a metaclass inherited from FixSigMea; it makes its own __call__; when its class instance, e.g., _T, create object instances (e.g, t) without args nor kwargs but only x, and x is an object of the instance class, then return x; otherwise, create and return a new object created by the instance class's super class' __call__ method with x as param; In other words, t = _T(3) will create a new obj; _T(t) will return t; _T(t, 1) or _T(t, b=1) will also return a new obj; \n    def __call__(cls, x=None, *args, **kwargs):===========================================(2) # how to create a __call__ method with param cls, x, *args, **kwargs;; \n        if not args and not kwargs and x is not None and isinstance(x,cls): return x======(3) # how to express no args and no kwargs and x is an instance of cls?; \n        res = super().__call__(*((x,) + args), **kwargs)==================================(4) # how to call __call__ of super class with x and consider all possible situations of args and kwargs; \n        return res========================================================================(5)       \n                                                                                                                                                        (6)"
  },
  {
    "objectID": "demos/signature_from_callable.html",
    "href": "demos/signature_from_callable.html",
    "title": "0002_signature_from_callable",
    "section": "",
    "text": "# from IPython.core.display import display, HTML # a depreciated import\nfrom IPython.display import display, HTML\n\n\ndisplay(HTML(\"<style>.container { width:100% !important; }</style>\"))"
  },
  {
    "objectID": "demos/signature_from_callable.html#imports-and-initiate",
    "href": "demos/signature_from_callable.html#imports-and-initiate",
    "title": "0002_signature_from_callable",
    "section": "Imports and initiate",
    "text": "Imports and initiate\n\nfrom fastdebug.core import *\nfrom fastcore.meta import *\n\n\ng = locals()\nfdb = Fastdb(inspect._signature_from_callable, outloc=g)\nfdbF = Fastdb(FixSigMeta, outloc=g)"
  },
  {
    "objectID": "demos/signature_from_callable.html#examples",
    "href": "demos/signature_from_callable.html#examples",
    "title": "0002_signature_from_callable",
    "section": "Examples",
    "text": "Examples\n\nfrom fastdebug.utils import whatinside\n\n\n\n\n\ninspect._signature_from_callable(whatinside, sigcls=inspect.Signature)\n\n<Signature (mo, dun: bool = False, func: bool = False, clas: bool = False, bltin: bool = False, lib: bool = False, cal: bool = False)>\n\n\n\nfdb.eg = \"inspect._signature_from_callable(whatinside, sigcls=inspect.Signature)\"\n\nfdb.eg = \"\"\"\nclass Base: # pass\n    def __new__(self, **args): pass  # defines a __new__ \n\nclass Foo_new(Base):\n    def __init__(self, d, e, f): pass\n    \npprint(inspect._signature_from_callable(Foo_new, sigcls=inspect.Signature))\n\"\"\"\nfdb.eg = \"\"\"\nclass Base: # pass\n    def __new__(self, **args): pass  # defines a __new__ \n\nclass Foo_new_fix(Base, metaclass=FixSigMeta):\n    def __init__(self, d, e, f): pass\n    \npprint(inspect._signature_from_callable(Foo_new_fix, sigcls=inspect.Signature))\n\"\"\"\n\nfdb.eg = \"\"\"\nclass BaseMeta(type): \n    # using __new__ from type\n    def __call__(cls, *args, **kwargs): pass\nclass Foo_call(metaclass=BaseMeta): \n    def __init__(self, d, e, f): pass\n\npprint(inspect._signature_from_callable(Foo_call, sigcls=inspect.Signature))\n\"\"\"\n\nfdbF.eg = \"\"\"\nclass BaseMeta(FixSigMeta): \n    # using __new__ of  FixSigMeta instead of type\n    def __call__(cls, *args, **kwargs): pass\n\nclass Foo_call_fix(metaclass=BaseMeta): # Base\n    def __init__(self, d, e, f): pass\n\npprint(inspect._signature_from_callable(Foo_call_fix, sigcls=inspect.Signature))    \n\"\"\"\n\nfdb.eg = \"\"\"\nclass Foo_init:\n    def __init__(self, a, b, c): pass\n\npprint(inspect._signature_from_callable(Foo_init, sigcls=inspect.Signature))\n\"\"\"\n\n\nfdbF.docsrc(2, \"how does a metaclass create a class instance; what does super().__new__() do here;\", \"inspect.getdoc(super)\")\nfdbF.docsrc(4, \"how to remove self from a signature; how to check whether a class' __init__ is inherited from object or not;\",\\\n            \"res\", \"res.__init__ is not object.__init__\")\nfdbF.docsrc(1, \"Any class having FixSigMeta as metaclass will have its own __init__ func stored in its attr __signature__;\\\nFixSigMeta uses its __new__ to create a class instance; then check whether its class instance has its own __init__;\\\nif so, remove self from the sig of __init__; then assign this new sig to __signature__ for the class instance;\")\n\n========================================================     Investigating FixSigMeta     ========================================================\n===============================================================     on line 2     ================================================================\n     with example \nclass BaseMeta(FixSigMeta): \n    # using __new__ of  FixSigMeta instead of type\n    def __call__(cls, *args, **kwargs): pass\n\nclass Foo_call_fix(metaclass=BaseMeta): # Base\n    def __init__(self, d, e, f): pass\n\npprint(inspect._signature_from_callable(Foo_call_fix, sigcls=inspect.Signature))    \n     \n\nprint selected srcline with expands below--------\nclass FixSigMeta(type):                                                                                                                                 (0)\n    \"A metaclass that fixes the signature on classes that override `__new__`\"                                                                           (1)\n    def __new__(cls, name, bases, dict):================================================================================================================(2)\n                                                                           how does a metaclass create a class instance; what does super().__new__() do here;\n        res = super().__new__(cls, name, bases, dict)                                                                                                   (3)\n        if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__))                                           (4)\n\n==================================================================================================================Start of my srcline exploration:\n\n\ninspect.getdoc(super) => inspect.getdoc(super) : super() -> same as super(__class__, <first argument>)\nsuper(type) -> unbound super object\nsuper(type, obj) -> bound super object; requires isinstance(obj, type)\nsuper(type, type2) -> bound super object; requires issubclass(type2, type)\nTypical use to call a cooperative superclass method:\nclass C(B):\n    def meth(self, arg):\n        super().meth(arg)\nThis works for class methods too:\nclass C(B):\n    @classmethod\n    def cmeth(cls, arg):\n        super().cmeth(arg)\n====================================================================================================================End of my srcline exploration:\n\n<Signature (d, e, f)>\n\nReview srcode with all comments added so far======================================================================================================\nclass FixSigMeta(type):===================================================================(0)       \n    \"A metaclass that fixes the signature on classes that override `__new__`\"=============(1)       \n    def __new__(cls, name, bases, dict):==================================================(2) # how does a metaclass create a class instance; what does super().__new__() do here;; \n        res = super().__new__(cls, name, bases, dict)=====================================(3)       \n        if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__))                                           (4)\n        return res========================================================================(5)       \n                                                                                                                                                        (6)\n                                                                                                                                     part No.1 out of 1 parts\n\n========================================================     Investigating FixSigMeta     ========================================================\n===============================================================     on line 4     ================================================================\n     with example \nclass BaseMeta(FixSigMeta): \n    # using __new__ of  FixSigMeta instead of type\n    def __call__(cls, *args, **kwargs): pass\n\nclass Foo_call_fix(metaclass=BaseMeta): # Base\n    def __init__(self, d, e, f): pass\n\npprint(inspect._signature_from_callable(Foo_call_fix, sigcls=inspect.Signature))    \n     \n\nprint selected srcline with expands below--------\n    def __new__(cls, name, bases, dict):                                                                                                                (2)\n        res = super().__new__(cls, name, bases, dict)                                                                                                   (3)\n        if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__))===========================================(4)\n                                                 how to remove self from a signature; how to check whether a class' __init__ is inherited from object or not;\n        return res                                                                                                                                      (5)\n                                                                                                                                                        (6)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                                                                                 res => res : <class '__main__.Foo_call_fix'>\n\n\n                                                                            res.__init__ is not object.__init__ => res.__init__ is not object.__init__ : True\n====================================================================================================================End of my srcline exploration:\n\n<Signature (d, e, f)>\n\nReview srcode with all comments added so far======================================================================================================\nclass FixSigMeta(type):===================================================================(0)       \n    \"A metaclass that fixes the signature on classes that override `__new__`\"=============(1)       \n    def __new__(cls, name, bases, dict):==================================================(2) # how does a metaclass create a class instance; what does super().__new__() do here;; \n        res = super().__new__(cls, name, bases, dict)=====================================(3)       \n        if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__)) # how to remove self from a signature; how to check whether a class' __init__ is inherited from object or not;;  (4)\n        return res========================================================================(5)       \n                                                                                                                                                        (6)\n                                                                                                                                     part No.1 out of 1 parts\n\n========================================================     Investigating FixSigMeta     ========================================================\n===============================================================     on line 1     ================================================================\n     with example \nclass BaseMeta(FixSigMeta): \n    # using __new__ of  FixSigMeta instead of type\n    def __call__(cls, *args, **kwargs): pass\n\nclass Foo_call_fix(metaclass=BaseMeta): # Base\n    def __init__(self, d, e, f): pass\n\npprint(inspect._signature_from_callable(Foo_call_fix, sigcls=inspect.Signature))    \n     \n\nprint selected srcline with expands below--------\nclass FixSigMeta(type):                                                                                                                                 (0)\n    \"A metaclass that fixes the signature on classes that override `__new__`\"===========================================================================(1)\nAny class having FixSigMeta as metaclass will have its own __init__ func stored in its attr __signature__;FixSigMeta uses its __new__ to create a class instance; then check whether its class instance has its own __init__;if so, remove self from the sig of __init__; then assign this new sig to __signature__ for the class instance;\n    def __new__(cls, name, bases, dict):                                                                                                                (2)\n        res = super().__new__(cls, name, bases, dict)                                                                                                   (3)\n\n\n\nfdbF.snoop()\n\n23:01:29.15 >>> Call to FixSigMeta.__new__ in File \"/tmp/FixSigMeta.py\", line 5\n23:01:29.15 .......... cls = <class '__main__.BaseMeta'>\n23:01:29.15 .......... name = 'Foo_call_fix'\n23:01:29.15 .......... bases = ()\n23:01:29.15 .......... dict = {'__module__': '__main__', '__qualname__': 'Foo_call_fix', '__init__': <function Foo_call_fix.__init__>}\n23:01:29.15 .......... len(dict) = 3\n23:01:29.15 .......... __class__ = <class 'fastcore.meta.FixSigMeta'>\n23:01:29.15    5 |     def __new__(cls, name, bases, dict):\n23:01:29.15    6 |         res = super().__new__(cls, name, bases, dict)\n23:01:29.15 .............. res = <class '__main__.Foo_call_fix'>\n23:01:29.15    7 |         if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__))\n23:01:29.15    8 |         return res\n23:01:29.15 <<< Return value from FixSigMeta.__new__: <class '__main__.Foo_call_fix'>\n\n\n========================================================     Investigating FixSigMeta     ========================================================\n==============================================================     on line None     ==============================================================\n     with example \nclass BaseMeta(FixSigMeta): \n    # using __new__ of  FixSigMeta instead of type\n    def __call__(cls, *args, **kwargs): pass\n\nclass Foo_call_fix(metaclass=BaseMeta): # Base\n    def __init__(self, d, e, f): pass\n\npprint(inspect._signature_from_callable(Foo_call_fix, sigcls=inspect.Signature))    \n     \n\n<Signature (d, e, f)>\n\n\n\nfdb.docsrc(29, \"How to check whether a class has __signature__?\", \"hasattr(obj, '__signature__')\")\nfdb.docsrc(82, \"how to check whether obj whose signature is builtins;\", \"inspect.getdoc(_signature_is_builtin)\")\nfdb.docsrc(7, \"inspect.signature is calling inspect._signature_from_callable; \\\ncreate _get_signature_of using functools.partial to call on _signature_from_callable itself;\\\nobj is first tested for callable; then test obj for classmethod; then unwrap to the end unless obj has __signature__;\\\nif obj has __signature__, assign __signature__ to sig; then test obj for function, is true calling _signature_from_function; \\\nthen test obj whose signature is builtins or not; test whether obj created by functools.partial; test obj is a class or not; \\\nif obj is a class, then check obj has its own __call__ first; then its own __new__; then its own __init__; then inherited __new__; \\\nfinally inherited __init__; and then get sig from either of them by calling _get_signature_of on them; \\\nFixSigMeta assigns __init__ function to __signature__ attr for the instance class it creates; \\\nso that class with FixSigMeta as metaclass can have sig from __init__ through __signature__; \\\nno more worry about interference of sig from __call__ or __new__.\")\n\n=================================================     Investigating _signature_from_callable     =================================================\n===============================================================     on line 29     ===============================================================\n     with example \nclass Foo_init:\n    def __init__(self, a, b, c): pass\n\npprint(inspect._signature_from_callable(Foo_init, sigcls=inspect.Signature))\n     \n\nprint selected srcline with expands below--------\n    # Was this function wrapped by a decorator?                                                                                                         (27)\n    if follow_wrapper_chains:                                                                                                                           (28)\n        obj = unwrap(obj, stop=(lambda f: hasattr(f, \"__signature__\")))=================================================================================(29)\n                                                                                                              How to check whether a class has __signature__?\n        if isinstance(obj, types.MethodType):                                                                                                           (30)\n            # If the unwrapped object is a *method*, we might want to                                                                                   (31)\n\n==================================================================================================================Start of my srcline exploration:\n\n\n                                                                                       hasattr(obj, '__signature__') => hasattr(obj, '__signature__') : False\n====================================================================================================================End of my srcline exploration:\n\n<Signature (a, b, c)>\n\nReview srcode with all comments added so far======================================================================================================\n        sig = _get_signature_of(obj.__func__)=============================================(20)      \n                                                                                                                                                        (21)\n        if skip_bound_arg:================================================================(22)      \n            return _signature_bound_method(sig)===========================================(23)      \n        else:=============================================================================(24)      \n            return sig====================================================================(25)      \n                                                                                                                                                        (26)\n    # Was this function wrapped by a decorator?===========================================(27)      \n    if follow_wrapper_chains:=============================================================(28)      \n        obj = unwrap(obj, stop=(lambda f: hasattr(f, \"__signature__\")))===================(29) # How to check whether a class has __signature__?; \n        if isinstance(obj, types.MethodType):=============================================(30)      \n            # If the unwrapped object is a *method*, we might want to=====================(31)      \n            # skip its first parameter (self).============================================(32)      \n            # See test_signature_wrapped_bound_method for details.========================(33)      \n            return _get_signature_of(obj)=================================================(34)      \n                                                                                                                                                        (35)\n    try:==================================================================================(36)      \n        sig = obj.__signature__===========================================================(37)      \n    except AttributeError:================================================================(38)      \n        pass==============================================================================(39)      \n                                                                                                                                    part No.2 out of 10 parts\n\n=================================================     Investigating _signature_from_callable     =================================================\n===============================================================     on line 82     ===============================================================\n     with example \nclass Foo_init:\n    def __init__(self, a, b, c): pass\n\npprint(inspect._signature_from_callable(Foo_init, sigcls=inspect.Signature))\n     \n\nprint selected srcline with expands below--------\n                                        skip_bound_arg=skip_bound_arg)                                                                                  (80)\n                                                                                                                                                        (81)\n    if _signature_is_builtin(obj):======================================================================================================================(82)\n                                                                                                        how to check whether obj whose signature is builtins;\n        return _signature_from_builtin(sigcls, obj,                                                                                                     (83)\n                                       skip_bound_arg=skip_bound_arg)                                                                                   (84)\n\n==================================================================================================================Start of my srcline exploration:\n\n\ninspect.getdoc(_signature_is_builtin) => inspect.getdoc(_signature_is_builtin) : Private helper to test if `obj` is a callable that might\nsupport Argument Clinic's __text_signature__ protocol.\n====================================================================================================================End of my srcline exploration:\n\n<Signature (a, b, c)>\n\nReview srcode with all comments added so far======================================================================================================\n                                        skip_bound_arg=skip_bound_arg)====================(80)      \n                                                                                                                                                        (81)\n    if _signature_is_builtin(obj):========================================================(82) # how to check whether obj whose signature is builtins;; \n        return _signature_from_builtin(sigcls, obj,=======================================(83)      \n                                       skip_bound_arg=skip_bound_arg)=====================(84)      \n                                                                                                                                                        (85)\n    if isinstance(obj, functools.partial):================================================(86)      \n        wrapped_sig = _get_signature_of(obj.func)=========================================(87)      \n        return _signature_get_partial(wrapped_sig, obj)===================================(88)      \n                                                                                                                                                        (89)\n    sig = None============================================================================(90)      \n    if isinstance(obj, type):=============================================================(91)      \n        # obj is a class or a metaclass===================================================(92)      \n                                                                                                                                                        (93)\n        # First, let's see if it has an overloaded __call__ defined=======================(94)      \n        # in its metaclass================================================================(95)      \n        call = _signature_get_user_defined_method(type(obj), '__call__')==================(96)      \n        if call is not None:==============================================================(97)      \n            sig = _get_signature_of(call)=================================================(98)      \n        else:=============================================================================(99)      \n                                                                                                                                    part No.5 out of 10 parts\n\n=================================================     Investigating _signature_from_callable     =================================================\n===============================================================     on line 7     ================================================================\n     with example \nclass Foo_init:\n    def __init__(self, a, b, c): pass\n\npprint(inspect._signature_from_callable(Foo_init, sigcls=inspect.Signature))\n     \n\nprint selected srcline with expands below--------\n    \"\"\"Private helper function to get signature for arbitrary                                                                                           (5)\n    callable objects.                                                                                                                                   (6)\n    \"\"\"=================================================================================================================================================(7)\ninspect.signature is calling inspect._signature_from_callable; create _get_signature_of using functools.partial to call on _signature_from_callable itself;obj is first tested for callable; then test obj for classmethod; then unwrap to the end unless obj has __signature__;if obj has __signature__, assign __signature__ to sig; then test obj for function, is true calling _signature_from_function; then test obj whose signature is builtins or not; test whether obj created by functools.partial; test obj is a class or not; if obj is a class, then check obj has its own __call__ first; then its own __new__; then its own __init__; then inherited __new__; finally inherited __init__; and then get sig from either of them by calling _get_signature_of on them; FixSigMeta assigns __init__ function to __signature__ attr for the instance class it creates; so that class with FixSigMeta as metaclass can have sig from __init__ through __signature__; no more worry about interference of sig from __call__ or __new__.\n                                                                                                                                                        (8)\n    _get_signature_of = functools.partial(_signature_from_callable,                                                                                     (9)\n\n\n\nfdb.snoop()\n\n23:01:29.21 >>> Call to _signature_from_callable in File \"/tmp/_signature_from_callable.py\", line 3\n23:01:29.21 ...... obj = <class '__main__.Foo_init'>\n23:01:29.21 ...... follow_wrapper_chains = True\n23:01:29.21 ...... skip_bound_arg = True\n23:01:29.21 ...... sigcls = <class 'inspect.Signature'>\n23:01:29.21    3 | def _signature_from_callable(obj, *,\n23:01:29.21   12 |     _get_signature_of = functools.partial(_signature_from_callable,\n23:01:29.21   13 |                                 follow_wrapper_chains=follow_wrapper_chains,\n23:01:29.21   14 |                                 skip_bound_arg=skip_bound_arg,\n23:01:29.21   15 |                                 sigcls=sigcls)\n23:01:29.21   12 |     _get_signature_of = functools.partial(_signature_from_callable,\n23:01:29.21 .......... _get_signature_of = functools.partial(<function _signature_from_call...und_arg=True, sigcls=<class 'inspect.Signature'>)\n23:01:29.21   17 |     if not callable(obj):\n23:01:29.22   20 |     if isinstance(obj, types.MethodType):\n23:01:29.22   31 |     if follow_wrapper_chains:\n23:01:29.22   32 |         obj = unwrap(obj, stop=(lambda f: hasattr(f, \"__signature__\")))\n23:01:29.22   33 |         if isinstance(obj, types.MethodType):\n23:01:29.22   39 |     try:\n23:01:29.22   40 |         sig = obj.__signature__\n\n\n=================================================     Investigating _signature_from_callable     =================================================\n==============================================================     on line None     ==============================================================\n     with example \nclass Foo_init:\n    def __init__(self, a, b, c): pass\n\npprint(inspect._signature_from_callable(Foo_init, sigcls=inspect.Signature))\n     \n\n\n\n23:01:29.35 !!! AttributeError: type object 'Foo_init' has no attribute '__signature__'\n23:01:29.35 !!! When getting attribute: obj.__signature__\n23:01:29.35   41 |     except AttributeError:\n23:01:29.35   42 |         pass\n23:01:29.35   51 |     try:\n23:01:29.35   52 |         partialmethod = obj._partialmethod\n23:01:29.36 !!! AttributeError: type object 'Foo_init' has no attribute '_partialmethod'\n23:01:29.36 !!! When getting attribute: obj._partialmethod\n23:01:29.36   53 |     except AttributeError:\n23:01:29.36   54 |         pass\n23:01:29.36   79 |     if isfunction(obj) or _signature_is_functionlike(obj):\n23:01:29.36   85 |     if _signature_is_builtin(obj):\n23:01:29.36   89 |     if isinstance(obj, functools.partial):\n23:01:29.36   93 |     sig = None\n23:01:29.36   94 |     if isinstance(obj, type):\n23:01:29.36   99 |         call = _signature_get_user_defined_method(type(obj), '__call__')\n23:01:29.36 .............. call = None\n23:01:29.36  100 |         if call is not None:\n23:01:29.36  103 |             factory_method = None\n23:01:29.36  104 |             new = _signature_get_user_defined_method(obj, '__new__')\n23:01:29.36 .................. new = None\n23:01:29.36  105 |             init = _signature_get_user_defined_method(obj, '__init__')\n23:01:29.36 .................. init = <function Foo_init.__init__>\n23:01:29.36  107 |             if '__new__' in obj.__dict__:\n23:01:29.36  110 |             elif '__init__' in obj.__dict__:\n23:01:29.36  111 |                 factory_method = init\n23:01:29.36 ...................... factory_method = <function Foo_init.__init__>\n23:01:29.36  118 |             if factory_method is not None:\n23:01:29.36  119 |                 sig = _get_signature_of(factory_method)\n23:01:29.36 ...................... sig = <Signature (self, a, b, c)>\n23:01:29.36  121 |         if sig is None:\n23:01:29.36  170 |     if sig is not None:\n23:01:29.36  173 |         if skip_bound_arg:\n23:01:29.36  174 |             return _signature_bound_method(sig)\n23:01:29.36 <<< Return value from _signature_from_callable: <Signature (a, b, c)>\n\n\n<Signature (a, b, c)>\n\n\n\nfdbF.print()\n\n========================================================     Investigating FixSigMeta     ========================================================\n==============================================================     on line None     ==============================================================\n     with example \nclass BaseMeta(FixSigMeta): \n    # using __new__ of  FixSigMeta instead of type\n    def __call__(cls, *args, **kwargs): pass\n\nclass Foo_call_fix(metaclass=BaseMeta): # Base\n    def __init__(self, d, e, f): pass\n\npprint(inspect._signature_from_callable(Foo_call_fix, sigcls=inspect.Signature))    \n     \n\nclass FixSigMeta(type):===================================================================(0)       \n    \"A metaclass that fixes the signature on classes that override `__new__`\"=============(1) # Any class having FixSigMeta as metaclass will have its own __init__ func stored in its attr __signature__;FixSigMeta uses its __new__ to create a class instance; then check whether its class instance has its own __init__;if so, remove self from the sig of __init__; then assign this new sig to __signature__ for the class instance;; \n    def __new__(cls, name, bases, dict):==================================================(2) # how does a metaclass create a class instance; what does super().__new__() do here;; \n        res = super().__new__(cls, name, bases, dict)=====================================(3)       \n        if res.__init__ is not object.__init__: res.__signature__ = _rm_self(inspect.signature(res.__init__)) # how to remove self from a signature; how to check whether a class' __init__ is inherited from object or not;;  (4)\n        return res========================================================================(5)       \n                                                                                                                                                        (6)\n\n\n\nfdb.print(30, 1)\n\ndef _signature_from_callable(obj, *,======================================================(0)       \n                             follow_wrapper_chains=True,==================================(1)       \n                             skip_bound_arg=True,=========================================(2)       \n                             sigcls):=====================================================(3)       \n                                                                                                                                                        (4)\n    \"\"\"Private helper function to get signature for arbitrary=============================(5)       \n    callable objects.=====================================================================(6)       \n    \"\"\"===================================================================================(7) # inspect.signature is calling inspect._signature_from_callable; create _get_signature_of using functools.partial to call on _signature_from_callable itself;obj is first tested for callable; then test obj for classmethod; then unwrap to the end unless obj has __signature__;if obj has __signature__, assign __signature__ to sig; then test obj for function, is true calling _signature_from_function; then test obj whose signature is builtins or not; test whether obj created by functools.partial; test obj is a class or not; if obj is a class, then check obj has its own __call__ first; then its own __new__; then its own __init__; then inherited __new__; finally inherited __init__; and then get sig from either of them by calling _get_signature_of on them; FixSigMeta assigns __init__ function to __signature__ attr for the instance class it creates; so that class with FixSigMeta as metaclass can have sig from __init__ through __signature__; no more worry about interference of sig from __call__ or __new__.; \n                                                                                                                                                        (8)\n    _get_signature_of = functools.partial(_signature_from_callable,=======================(9)       \n                                follow_wrapper_chains=follow_wrapper_chains,==============(10)      \n                                skip_bound_arg=skip_bound_arg,============================(11)      \n                                sigcls=sigcls)============================================(12)      \n                                                                                                                                                        (13)\n    if not callable(obj):=================================================================(14)      \n        raise TypeError('{!r} is not a callable object'.format(obj))======================(15)      \n                                                                                                                                                        (16)\n    if isinstance(obj, types.MethodType):=================================================(17)      \n        # In this case we skip the first parameter of the underlying======================(18)      \n        # function (usually `self` or `cls`).=============================================(19)      \n        sig = _get_signature_of(obj.__func__)=============================================(20)      \n                                                                                                                                                        (21)\n        if skip_bound_arg:================================================================(22)      \n            return _signature_bound_method(sig)===========================================(23)      \n        else:=============================================================================(24)      \n            return sig====================================================================(25)      \n                                                                                                                                                        (26)\n    # Was this function wrapped by a decorator?===========================================(27)      \n    if follow_wrapper_chains:=============================================================(28)      \n        obj = unwrap(obj, stop=(lambda f: hasattr(f, \"__signature__\")))===================(29) # How to check whether a class has __signature__?; \n                                                                                                                                     part No.1 out of 7 parts"
  },
  {
    "objectID": "demos/use_kwargs_dict.html",
    "href": "demos/use_kwargs_dict.html",
    "title": "08_use_kwargs_dict",
    "section": "",
    "text": "from fastdebug.utils import *\nfrom fastdebug.core import *\nfrom fastcore.meta import *"
  },
  {
    "objectID": "demos/use_kwargs_dict.html#reading-official-docs",
    "href": "demos/use_kwargs_dict.html#reading-official-docs",
    "title": "08_use_kwargs_dict",
    "section": "Reading official docs",
    "text": "Reading official docs\n\nfrom fastcore.meta import _mk_param # not included in __all__"
  },
  {
    "objectID": "demos/use_kwargs_dict.html#empty2none",
    "href": "demos/use_kwargs_dict.html#empty2none",
    "title": "08_use_kwargs_dict",
    "section": "empty2none",
    "text": "empty2none\n\nfdbe = Fastdb(empty2none)\nfdbe.docsrc(0, \"p is the Parameter.default value\")\nfdbe.docsrc(1, \"to use empty2none, I need to make sure p is not a parameter, but parameter.default\")\nfdbe.docsrc(2, \"how to check whether a parameter default value is empty\")\n\n========================================================     Investigating empty2none     ========================================================\n===============================================================     on line 0     ================================================================\n=============================================================     with example      ==============================================================\n\nprint selected srcline with expands below--------\ndef empty2none(p):======================================================================================================================================(0)\n                                                                                                                             p is the Parameter.default value\n    \"Replace `Parameter.empty` with `None`\"                                                                                                             (1)\n    return None if p==inspect.Parameter.empty else p                                                                                                    (2)\n========================================================     Investigating empty2none     ========================================================\n===============================================================     on line 1     ================================================================\n=============================================================     with example \n     =============================================================\n\nprint selected srcline with expands below--------\ndef empty2none(p):                                                                                                                                      (0)\n    \"Replace `Parameter.empty` with `None`\"=============================================================================================================(1)\n                                                                           to use empty2none, I need to make sure p is not a parameter, but parameter.default\n    return None if p==inspect.Parameter.empty else p                                                                                                    (2)\n                                                                                                                                                        (3)\n\nReview srcode with all comments added so far======================================================================================================\ndef empty2none(p):========================================================================(0) # p is the Parameter.default value; \n    \"Replace `Parameter.empty` with `None`\"===============================================(1) # to use empty2none, I need to make sure p is not a parameter, but parameter.default; \n    return None if p==inspect.Parameter.empty else p======================================(2)       \n                                                                                                                                                        (3)\n                                                                                                                                     part No.1 out of 1 parts\n\n========================================================     Investigating empty2none     ========================================================\n===============================================================     on line 2     ================================================================\n============================================================     with example \n\n     =============================================================\n\nprint selected srcline with expands below--------\ndef empty2none(p):                                                                                                                                      (0)\n    \"Replace `Parameter.empty` with `None`\"                                                                                                             (1)\n    return None if p==inspect.Parameter.empty else p====================================================================================================(2)\n                                                                                                      how to check whether a parameter default value is empty\n                                                                                                                                                        (3)\n\nReview srcode with all comments added so far======================================================================================================\ndef empty2none(p):========================================================================(0) # p is the Parameter.default value; \n    \"Replace `Parameter.empty` with `None`\"===============================================(1) # to use empty2none, I need to make sure p is not a parameter, but parameter.default; \n    return None if p==inspect.Parameter.empty else p======================================(2) # how to check whether a parameter default value is empty; \n                                                                                                                                                        (3)\n                                                                                                                                     part No.1 out of 1 parts\n\n\n\n\n# def foo(a, b=1): pass\n# sig = inspect.signature(foo)\n# print(sig.parameters.items())\n# for k,v in sig.parameters.items():\n#     print(f'{k} : {v.default} => empty2none => {empty2none(v.default)}')\n\n\nfdbe.eg = \"\"\"\ndef foo(a, b=1): pass\nsig = inspect.signature(foo)\nprint(sig.parameters.items())\nfor k,v in sig.parameters.items():\n    print(f'{k} : {v.default} => empty2none => {empty2none(v.default)}')\n\"\"\"\n\n\nfdbe.snoop()\n\n22:14:40.57 >>> Call to empty2none in File \"/tmp/empty2none.py\", line 3\n22:14:40.57 ...... p = <class 'inspect._empty'>\n22:14:40.57    3 | def empty2none(p):\n22:14:40.57    5 |     return None if p==inspect.Parameter.empty else p\n22:14:40.57 <<< Return value from empty2none: None\n22:14:40.57 >>> Call to empty2none in File \"/tmp/empty2none.py\", line 3\n22:14:40.57 ...... p = 1\n22:14:40.57    3 | def empty2none(p):\n22:14:40.57    5 |     return None if p==inspect.Parameter.empty else p\n22:14:40.57 <<< Return value from empty2none: 1\n\n\n========================================================     Investigating empty2none     ========================================================\n==============================================================     on line None     ==============================================================\n     with example \ndef foo(a, b=1): pass\nsig = inspect.signature(foo)\nprint(sig.parameters.items())\nfor k,v in sig.parameters.items():\n    print(f'{k} : {v.default} => empty2none => {empty2none(v.default)}')\n     \n\nodict_items([('a', <Parameter \"a\">), ('b', <Parameter \"b=1\">)])\na : <class 'inspect._empty'> => empty2none => None\nb : 1 => empty2none => 1"
  },
  {
    "objectID": "demos/use_kwargs_dict.html#mk_param",
    "href": "demos/use_kwargs_dict.html#mk_param",
    "title": "08_use_kwargs_dict",
    "section": "_mk_param",
    "text": "_mk_param\n\nfdb = Fastdb(_mk_param)\nfdb.print()\n\n========================================================     Investigating _mk_param     =========================================================\n==============================================================     on line None     ==============================================================\n=============================================================     with example      ==============================================================\n\ndef _mk_param(n,d=None): return inspect.Parameter(n, inspect.Parameter.KEYWORD_ONLY, default=d)                                                         (0)\n                                                                                                                                                        (1)\n\n\n\nfdb.eg = \"\"\"\nprint(_mk_param(\"a\", 1))\n\"\"\"\n\n\nfdb.snoop()\n\n22:14:40.58 >>> Call to _mk_param in File \"/tmp/_mk_param.py\", line 3\n22:14:40.58 ...... n = 'a'\n22:14:40.58 ...... d = 1\n22:14:40.58    3 | def _mk_param(n,d=None): return inspect.Parameter(n, inspect.Parameter.KEYWORD_ONLY, default=d)\n22:14:40.58    3 | def _mk_param(n,d=None): return inspect.Parameter(n, inspect.Parameter.KEYWORD_ONLY, default=d)\n22:14:40.58 <<< Return value from _mk_param: <Parameter \"a=1\">\n\n\n========================================================     Investigating _mk_param     =========================================================\n==============================================================     on line None     ==============================================================\n================================================     with example \nprint(_mk_param(\"a\", 1))\n     =================================================\n\na=1\n\n\n\nfdb.docsrc(0, \"_mk_param is to create a new parameter as KEYWORD_ONLY kind; n is its name in string; d is its default value\")\n\n========================================================     Investigating _mk_param     =========================================================\n===============================================================     on line 0     ================================================================\n================================================     with example \nprint(_mk_param(\"a\", 1))\n     =================================================\n\nprint selected srcline with expands below--------\ndef _mk_param(n,d=None): return inspect.Parameter(n, inspect.Parameter.KEYWORD_ONLY, default=d)=========================================================(0)\n                                                 _mk_param is to create a new parameter as KEYWORD_ONLY kind; n is its name in string; d is its default value\n                                                                                                                                                        (1)\na=1"
  },
  {
    "objectID": "demos/use_kwargs_dict.html#use_kwargs_dict",
    "href": "demos/use_kwargs_dict.html#use_kwargs_dict",
    "title": "08_use_kwargs_dict",
    "section": "use_kwargs_dict",
    "text": "use_kwargs_dict\n\nReading docs\nReplace all **kwargs with named arguments like so:\n@use_kwargs_dict(y=1,z=None)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None)')\nAdd named arguments, but optionally keep **kwargs by setting keep=True:\n@use_kwargs_dict(y=1,z=None, keep=True)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None, **kwargs)')\n\nprint(inspect.getsource(use_kwargs_dict))\n\ndef use_kwargs_dict(keep=False, **kwargs):\n    \"Decorator: replace `**kwargs` in signature with `names` params\"\n    def _f(f):\n        sig = inspect.signature(f)\n        sigd = dict(sig.parameters)\n        k = sigd.pop('kwargs')\n        s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}\n        sigd.update(s2)\n        if keep: sigd['kwargs'] = k\n        f.__signature__ = sig.replace(parameters=sigd.values())\n        return f\n    return _f\n\n\n\n\nfdb = Fastdb(use_kwargs_dict)\nfdb.eg = \"\"\"\n@use_kwargs_dict(y=1,z=None)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None)')\n\"\"\"\n\nfdb.eg = \"\"\"\n@use_kwargs_dict(y=1,z=None, keep=True)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None, **kwargs)')\n\"\"\"\n\n\nfdb.print()\n\n=====================================================     Investigating use_kwargs_dict     ======================================================\n==============================================================     on line None     ==============================================================\n     with example \n@use_kwargs_dict(y=1,z=None, keep=True)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None, **kwargs)')\n     \n\ndef use_kwargs_dict(keep=False, **kwargs):================================================(0)       \n    \"Decorator: replace `**kwargs` in signature with `names` params\"======================(1)       \n    def _f(f):============================================================================(2)       \n        sig = inspect.signature(f)========================================================(3)       \n        sigd = dict(sig.parameters)=======================================================(4)       \n        k = sigd.pop('kwargs')============================================================(5)       \n        s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}================(6)       \n        sigd.update(s2)===================================================================(7)       \n        if keep: sigd['kwargs'] = k=======================================================(8)       \n        f.__signature__ = sig.replace(parameters=sigd.values())===========================(9)       \n        return f==========================================================================(10)      \n    return _f=============================================================================(11)      \n                                                                                                                                                        (12)\n\n\n\nfdb.docsrc(1, \"how to use use_kwargs_dict; use_kwargs_dict is to replace **kwargs with newly created KEYWORD_ONLY params based on a dict; \\\nf's signature is saved inside f.__signature__\")\nfdb.docsrc(3, \"how to get the signature from an object\")\nfdb.docsrc(4, \"how to get all parameters of a signature; how to make it into a dict; \")\nfdb.docsrc(5, \"how to pop out an item from a dict\")\nfdb.docsrc(6, \"how to create a dict of params based on a dict\")\nfdb.docsrc(7, \"how to udpate one dict into another dict\")\nfdb.docsrc(8, \"how to create a new item in a dict\")\nfdb.docsrc(9, \"how to update a signature with a new set of parameters in the form of a dict values\")\n\n=====================================================     Investigating use_kwargs_dict     ======================================================\n===============================================================     on line 1     ================================================================\n     with example \n@use_kwargs_dict(y=1,z=None, keep=True)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None, **kwargs)')\n     \n\nprint selected srcline with expands below--------\ndef use_kwargs_dict(keep=False, **kwargs):                                                                                                              (0)\n    \"Decorator: replace `**kwargs` in signature with `names` params\"====================================================================================(1)\nhow to use use_kwargs_dict; use_kwargs_dict is to replace **kwargs with newly created KEYWORD_ONLY params based on a dict; f's signature is saved inside f.__signature__\n    def _f(f):                                                                                                                                          (2)\n        sig = inspect.signature(f)                                                                                                                      (3)\n\nReview srcode with all comments added so far======================================================================================================\ndef use_kwargs_dict(keep=False, **kwargs):================================================(0)       \n    \"Decorator: replace `**kwargs` in signature with `names` params\"======================(1) # how to use use_kwargs_dict; use_kwargs_dict is to replace **kwargs with newly created KEYWORD_ONLY params based on a dict; f's signature is saved inside f.__signature__; \n    def _f(f):============================================================================(2)       \n        sig = inspect.signature(f)========================================================(3)       \n        sigd = dict(sig.parameters)=======================================================(4)       \n        k = sigd.pop('kwargs')============================================================(5)       \n        s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}================(6)       \n        sigd.update(s2)===================================================================(7)       \n        if keep: sigd['kwargs'] = k=======================================================(8)       \n        f.__signature__ = sig.replace(parameters=sigd.values())===========================(9)       \n        return f==========================================================================(10)      \n    return _f=============================================================================(11)      \n                                                                                                                                                        (12)\n                                                                                                                                     part No.1 out of 1 parts\n\n=====================================================     Investigating use_kwargs_dict     ======================================================\n===============================================================     on line 3     ================================================================\n     with example \n@use_kwargs_dict(y=1,z=None, keep=True)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None, **kwargs)')\n     \n\nprint selected srcline with expands below--------\n    \"Decorator: replace `**kwargs` in signature with `names` params\"                                                                                    (1)\n    def _f(f):                                                                                                                                          (2)\n        sig = inspect.signature(f)======================================================================================================================(3)\n                                                                                                                      how to get the signature from an object\n        sigd = dict(sig.parameters)                                                                                                                     (4)\n        k = sigd.pop('kwargs')                                                                                                                          (5)\n\nReview srcode with all comments added so far======================================================================================================\ndef use_kwargs_dict(keep=False, **kwargs):================================================(0)       \n    \"Decorator: replace `**kwargs` in signature with `names` params\"======================(1) # how to use use_kwargs_dict; use_kwargs_dict is to replace **kwargs with newly created KEYWORD_ONLY params based on a dict; f's signature is saved inside f.__signature__; \n    def _f(f):============================================================================(2)       \n        sig = inspect.signature(f)========================================================(3) # how to get the signature from an object; \n        sigd = dict(sig.parameters)=======================================================(4)       \n        k = sigd.pop('kwargs')============================================================(5)       \n        s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}================(6)       \n        sigd.update(s2)===================================================================(7)       \n        if keep: sigd['kwargs'] = k=======================================================(8)       \n        f.__signature__ = sig.replace(parameters=sigd.values())===========================(9)       \n        return f==========================================================================(10)      \n    return _f=============================================================================(11)      \n                                                                                                                                                        (12)\n                                                                                                                                     part No.1 out of 1 parts\n\n=====================================================     Investigating use_kwargs_dict     ======================================================\n===============================================================     on line 4     ================================================================\n     with example \n@use_kwargs_dict(y=1,z=None, keep=True)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None, **kwargs)')\n     \n\nprint selected srcline with expands below--------\n    def _f(f):                                                                                                                                          (2)\n        sig = inspect.signature(f)                                                                                                                      (3)\n        sigd = dict(sig.parameters)=====================================================================================================================(4)\n                                                                                       how to get all parameters of a signature; how to make it into a dict; \n        k = sigd.pop('kwargs')                                                                                                                          (5)\n        s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}                                                                              (6)\n\nReview srcode with all comments added so far======================================================================================================\ndef use_kwargs_dict(keep=False, **kwargs):================================================(0)       \n    \"Decorator: replace `**kwargs` in signature with `names` params\"======================(1) # how to use use_kwargs_dict; use_kwargs_dict is to replace **kwargs with newly created KEYWORD_ONLY params based on a dict; f's signature is saved inside f.__signature__; \n    def _f(f):============================================================================(2)       \n        sig = inspect.signature(f)========================================================(3) # how to get the signature from an object; \n        sigd = dict(sig.parameters)=======================================================(4) # how to get all parameters of a signature; how to make it into a dict; ; \n        k = sigd.pop('kwargs')============================================================(5)       \n        s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}================(6)       \n        sigd.update(s2)===================================================================(7)       \n        if keep: sigd['kwargs'] = k=======================================================(8)       \n        f.__signature__ = sig.replace(parameters=sigd.values())===========================(9)       \n        return f==========================================================================(10)      \n    return _f=============================================================================(11)      \n                                                                                                                                                        (12)\n                                                                                                                                     part No.1 out of 1 parts\n\n=====================================================     Investigating use_kwargs_dict     ======================================================\n===============================================================     on line 5     ================================================================\n     with example \n@use_kwargs_dict(y=1,z=None, keep=True)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None, **kwargs)')\n     \n\nprint selected srcline with expands below--------\n        sig = inspect.signature(f)                                                                                                                      (3)\n        sigd = dict(sig.parameters)                                                                                                                     (4)\n        k = sigd.pop('kwargs')==========================================================================================================================(5)\n                                                                                                                           how to pop out an item from a dict\n        s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}                                                                              (6)\n        sigd.update(s2)                                                                                                                                 (7)\n\nReview srcode with all comments added so far======================================================================================================\ndef use_kwargs_dict(keep=False, **kwargs):================================================(0)       \n    \"Decorator: replace `**kwargs` in signature with `names` params\"======================(1) # how to use use_kwargs_dict; use_kwargs_dict is to replace **kwargs with newly created KEYWORD_ONLY params based on a dict; f's signature is saved inside f.__signature__; \n    def _f(f):============================================================================(2)       \n        sig = inspect.signature(f)========================================================(3) # how to get the signature from an object; \n        sigd = dict(sig.parameters)=======================================================(4) # how to get all parameters of a signature; how to make it into a dict; ; \n        k = sigd.pop('kwargs')============================================================(5) # how to pop out an item from a dict; \n        s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}================(6)       \n        sigd.update(s2)===================================================================(7)       \n        if keep: sigd['kwargs'] = k=======================================================(8)       \n        f.__signature__ = sig.replace(parameters=sigd.values())===========================(9)       \n        return f==========================================================================(10)      \n    return _f=============================================================================(11)      \n                                                                                                                                                        (12)\n                                                                                                                                     part No.1 out of 1 parts\n\n=====================================================     Investigating use_kwargs_dict     ======================================================\n===============================================================     on line 6     ================================================================\n     with example \n@use_kwargs_dict(y=1,z=None, keep=True)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None, **kwargs)')\n     \n\nprint selected srcline with expands below--------\n        sigd = dict(sig.parameters)                                                                                                                     (4)\n        k = sigd.pop('kwargs')                                                                                                                          (5)\n        s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}==============================================================================(6)\n                                                                                                               how to create a dict of params based on a dict\n        sigd.update(s2)                                                                                                                                 (7)\n        if keep: sigd['kwargs'] = k                                                                                                                     (8)\n\nReview srcode with all comments added so far======================================================================================================\ndef use_kwargs_dict(keep=False, **kwargs):================================================(0)       \n    \"Decorator: replace `**kwargs` in signature with `names` params\"======================(1) # how to use use_kwargs_dict; use_kwargs_dict is to replace **kwargs with newly created KEYWORD_ONLY params based on a dict; f's signature is saved inside f.__signature__; \n    def _f(f):============================================================================(2)       \n        sig = inspect.signature(f)========================================================(3) # how to get the signature from an object; \n        sigd = dict(sig.parameters)=======================================================(4) # how to get all parameters of a signature; how to make it into a dict; ; \n        k = sigd.pop('kwargs')============================================================(5) # how to pop out an item from a dict; \n        s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}================(6) # how to create a dict of params based on a dict; \n        sigd.update(s2)===================================================================(7)       \n        if keep: sigd['kwargs'] = k=======================================================(8)       \n        f.__signature__ = sig.replace(parameters=sigd.values())===========================(9)       \n        return f==========================================================================(10)      \n    return _f=============================================================================(11)      \n                                                                                                                                                        (12)\n                                                                                                                                     part No.1 out of 1 parts\n\n=====================================================     Investigating use_kwargs_dict     ======================================================\n===============================================================     on line 7     ================================================================\n     with example \n@use_kwargs_dict(y=1,z=None, keep=True)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None, **kwargs)')\n     \n\nprint selected srcline with expands below--------\n        k = sigd.pop('kwargs')                                                                                                                          (5)\n        s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}                                                                              (6)\n        sigd.update(s2)=================================================================================================================================(7)\n                                                                                                                     how to udpate one dict into another dict\n        if keep: sigd['kwargs'] = k                                                                                                                     (8)\n        f.__signature__ = sig.replace(parameters=sigd.values())                                                                                         (9)\n\nReview srcode with all comments added so far======================================================================================================\ndef use_kwargs_dict(keep=False, **kwargs):================================================(0)       \n    \"Decorator: replace `**kwargs` in signature with `names` params\"======================(1) # how to use use_kwargs_dict; use_kwargs_dict is to replace **kwargs with newly created KEYWORD_ONLY params based on a dict; f's signature is saved inside f.__signature__; \n    def _f(f):============================================================================(2)       \n        sig = inspect.signature(f)========================================================(3) # how to get the signature from an object; \n        sigd = dict(sig.parameters)=======================================================(4) # how to get all parameters of a signature; how to make it into a dict; ; \n        k = sigd.pop('kwargs')============================================================(5) # how to pop out an item from a dict; \n        s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}================(6) # how to create a dict of params based on a dict; \n        sigd.update(s2)===================================================================(7) # how to udpate one dict into another dict; \n        if keep: sigd['kwargs'] = k=======================================================(8)       \n        f.__signature__ = sig.replace(parameters=sigd.values())===========================(9)       \n        return f==========================================================================(10)      \n    return _f=============================================================================(11)      \n                                                                                                                                                        (12)\n                                                                                                                                     part No.1 out of 1 parts\n\n=====================================================     Investigating use_kwargs_dict     ======================================================\n===============================================================     on line 8     ================================================================\n     with example \n@use_kwargs_dict(y=1,z=None, keep=True)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None, **kwargs)')\n     \n\nprint selected srcline with expands below--------\n        s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}                                                                              (6)\n        sigd.update(s2)                                                                                                                                 (7)\n        if keep: sigd['kwargs'] = k=====================================================================================================================(8)\n                                                                                                                           how to create a new item in a dict\n        f.__signature__ = sig.replace(parameters=sigd.values())                                                                                         (9)\n        return f                                                                                                                                        (10)\n\nReview srcode with all comments added so far======================================================================================================\ndef use_kwargs_dict(keep=False, **kwargs):================================================(0)       \n    \"Decorator: replace `**kwargs` in signature with `names` params\"======================(1) # how to use use_kwargs_dict; use_kwargs_dict is to replace **kwargs with newly created KEYWORD_ONLY params based on a dict; f's signature is saved inside f.__signature__; \n    def _f(f):============================================================================(2)       \n        sig = inspect.signature(f)========================================================(3) # how to get the signature from an object; \n        sigd = dict(sig.parameters)=======================================================(4) # how to get all parameters of a signature; how to make it into a dict; ; \n        k = sigd.pop('kwargs')============================================================(5) # how to pop out an item from a dict; \n        s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}================(6) # how to create a dict of params based on a dict; \n        sigd.update(s2)===================================================================(7) # how to udpate one dict into another dict; \n        if keep: sigd['kwargs'] = k=======================================================(8) # how to create a new item in a dict; \n        f.__signature__ = sig.replace(parameters=sigd.values())===========================(9)       \n        return f==========================================================================(10)      \n    return _f=============================================================================(11)      \n                                                                                                                                                        (12)\n                                                                                                                                     part No.1 out of 1 parts\n\n=====================================================     Investigating use_kwargs_dict     ======================================================\n===============================================================     on line 9     ================================================================\n     with example \n@use_kwargs_dict(y=1,z=None, keep=True)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None, **kwargs)')\n     \n\nprint selected srcline with expands below--------\n        sigd.update(s2)                                                                                                                                 (7)\n        if keep: sigd['kwargs'] = k                                                                                                                     (8)\n        f.__signature__ = sig.replace(parameters=sigd.values())=========================================================================================(9)\n                                                                          how to update a signature with a new set of parameters in the form of a dict values\n        return f                                                                                                                                        (10)\n    return _f                                                                                                                                           (11)\n\nReview srcode with all comments added so far======================================================================================================\ndef use_kwargs_dict(keep=False, **kwargs):================================================(0)       \n    \"Decorator: replace `**kwargs` in signature with `names` params\"======================(1) # how to use use_kwargs_dict; use_kwargs_dict is to replace **kwargs with newly created KEYWORD_ONLY params based on a dict; f's signature is saved inside f.__signature__; \n    def _f(f):============================================================================(2)       \n        sig = inspect.signature(f)========================================================(3) # how to get the signature from an object; \n        sigd = dict(sig.parameters)=======================================================(4) # how to get all parameters of a signature; how to make it into a dict; ; \n        k = sigd.pop('kwargs')============================================================(5) # how to pop out an item from a dict; \n        s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}================(6) # how to create a dict of params based on a dict; \n        sigd.update(s2)===================================================================(7) # how to udpate one dict into another dict; \n        if keep: sigd['kwargs'] = k=======================================================(8) # how to create a new item in a dict; \n        f.__signature__ = sig.replace(parameters=sigd.values())===========================(9) # how to update a signature with a new set of parameters in the form of a dict values; \n        return f==========================================================================(10)      \n    return _f=============================================================================(11)      \n                                                                                                                                                        (12)\n                                                                                                                                     part No.1 out of 1 parts\n\n\n\n\nfdb.snoop(deco=True) # how to use snoop on decorator\n\n22:14:40.62 >>> Call to use_kwargs_dict in File \"/tmp/use_kwargs_dict.py\", line 3\n22:14:40.62 ...... keep = True\n22:14:40.62 ...... kwargs = {'y': 1, 'z': None}\n22:14:40.62 ...... len(kwargs) = 2\n22:14:40.62    3 | def use_kwargs_dict(keep=False, **kwargs):\n22:14:40.62    5 |     import snoop\n22:14:40.62 .......... snoop = <class 'snoop.configuration.Config.__init__.<locals>.ConfiguredTracer'>\n22:14:40.62    6 |     @snoop\n22:14:40.62    7 |     def _f(f):\n22:14:40.62 .......... _f = <function use_kwargs_dict.<locals>._f>\n22:14:40.62   16 |     return _f\n22:14:40.62 <<< Return value from use_kwargs_dict: <function use_kwargs_dict.<locals>._f>\n22:14:40.62 >>> Call to use_kwargs_dict.<locals>._f in File \"/tmp/use_kwargs_dict.py\", line 7\n22:14:40.62 .......... f = <function foo>\n22:14:40.62 .......... keep = True\n22:14:40.62 .......... kwargs = {'y': 1, 'z': None}\n22:14:40.62 .......... len(kwargs) = 2\n22:14:40.62    7 |     def _f(f):\n22:14:40.62    8 |         sig = inspect.signature(f)\n22:14:40.62 .............. sig = <Signature (a, b=1, **kwargs)>\n22:14:40.62    9 |         sigd = dict(sig.parameters)\n22:14:40.62 .............. sigd = {'a': <Parameter \"a\">, 'b': <Parameter \"b=1\">, 'kwargs': <Parameter \"**kwargs\">}\n22:14:40.62 .............. len(sigd) = 3\n22:14:40.62   10 |         k = sigd.pop('kwargs')\n22:14:40.62 .............. k = <Parameter \"**kwargs\">\n22:14:40.62 .............. sigd = {'a': <Parameter \"a\">, 'b': <Parameter \"b=1\">}\n22:14:40.62 .............. len(sigd) = 2\n22:14:40.62   11 |         s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}\n    22:14:40.62 Dict comprehension:\n    22:14:40.62   11 |         s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}\n    22:14:40.62 .............. Iterating over <dict_itemiterator object>\n    22:14:40.62 .............. Values of sigd: {'a': <Parameter \"a\">, 'b': <Parameter \"b=1\">}\n    22:14:40.62 .............. Values of len(sigd): 2\n    22:14:40.62 .............. Values of n: 'y', 'z'\n    22:14:40.62 .............. Values of d: 1, None\n    22:14:40.62 Result: {'y': <Parameter \"y=1\">, 'z': <Parameter \"z=None\">}\n22:14:40.62   11 |         s2 = {n:_mk_param(n,d) for n,d in kwargs.items() if n not in sigd}\n22:14:40.62 .............. s2 = {'y': <Parameter \"y=1\">, 'z': <Parameter \"z=None\">}\n22:14:40.62 .............. len(s2) = 2\n22:14:40.62   12 |         sigd.update(s2)\n22:14:40.62 .............. sigd = {'a': <Parameter \"a\">, 'b': <Parameter \"b=1\">, 'y': <Parameter \"y=1\">, 'z': <Parameter \"z=None\">}\n22:14:40.62 .............. len(sigd) = 4\n22:14:40.62   13 |         if keep: sigd['kwargs'] = k\n22:14:40.62 ...... sigd = {'a': <Parameter \"a\">, 'b': <Parameter \"b=1\">, 'y': <Parameter \"y=1\">, 'z': <Parameter \"z=None\">, ...}\n22:14:40.62 ...... len(sigd) = 5\n22:14:40.62   14 |         f.__signature__ = sig.replace(parameters=sigd.values())\n22:14:40.63   15 |         return f\n22:14:40.63 <<< Return value from use_kwargs_dict.<locals>._f: <function foo>\n\n\n=====================================================     Investigating use_kwargs_dict     ======================================================\n==============================================================     on line None     ==============================================================\n     with example \n@use_kwargs_dict(y=1,z=None, keep=True)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None, **kwargs)')"
  },
  {
    "objectID": "demos/use_kwargs_dict.html#use_kwargs",
    "href": "demos/use_kwargs_dict.html#use_kwargs",
    "title": "08_use_kwargs_dict",
    "section": "use_kwargs",
    "text": "use_kwargs\n\nReading docs\nuse_kwargs is different than use_kwargs_dict as it only replaces **kwargs with named parameters without any default values:\n@use_kwargs(['y', 'z'])\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=None, z=None)')\nYou may optionally keep the **kwargs argument in your signature by setting keep=True:\n@use_kwargs(['y', 'z'], keep=True)\ndef foo(a, *args, b=1, **kwargs): pass\ntest_sig(foo, '(a, *args, b=1, y=None, z=None, **kwargs)')\n\nprint(inspect.getsource(use_kwargs))\n\ndef use_kwargs(names, keep=False):\n    \"Decorator: replace `**kwargs` in signature with `names` params\"\n    def _f(f):\n        sig = inspect.signature(f)\n        sigd = dict(sig.parameters)\n        k = sigd.pop('kwargs')\n        s2 = {n:_mk_param(n) for n in names if n not in sigd}\n        sigd.update(s2)\n        if keep: sigd['kwargs'] = k\n        f.__signature__ = sig.replace(parameters=sigd.values())\n        return f\n    return _f\n\n\n\n\nfdb = Fastdb(use_kwargs)\nfdb.eg = \"\"\"\n@use_kwargs(['y', 'z'])\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=None, z=None)')\n\"\"\"\n\nfdb.eg = \"\"\"\n@use_kwargs(['y', 'z'], keep=True)\ndef foo(a, *args, b=1, **kwargs): pass\ntest_sig(foo, '(a, *args, b=1, y=None, z=None, **kwargs)')\n\"\"\"\n\n\nfdb.print()\n\n========================================================     Investigating use_kwargs     ========================================================\n==============================================================     on line None     ==============================================================\n     with example \n@use_kwargs(['y', 'z'], keep=True)\ndef foo(a, *args, b=1, **kwargs): pass\ntest_sig(foo, '(a, *args, b=1, y=None, z=None, **kwargs)')\n     \n\ndef use_kwargs(names, keep=False):========================================================(0)       \n    \"Decorator: replace `**kwargs` in signature with `names` params\"======================(1)       \n    def _f(f):============================================================================(2)       \n        sig = inspect.signature(f)========================================================(3)       \n        sigd = dict(sig.parameters)=======================================================(4)       \n        k = sigd.pop('kwargs')============================================================(5)       \n        s2 = {n:_mk_param(n) for n in names if n not in sigd}=============================(6)       \n        sigd.update(s2)===================================================================(7)       \n        if keep: sigd['kwargs'] = k=======================================================(8)       \n        f.__signature__ = sig.replace(parameters=sigd.values())===========================(9)       \n        return f==========================================================================(10)      \n    return _f=============================================================================(11)      \n                                                                                                                                                        (12)\n\n\n\nfdb.docsrc(0, \"How to use use_kwargs; use_kwargs has names as a list of strings; all the newly created params have None as default value; f's signature \\\nis saved inside f.__signature__\")\n\n========================================================     Investigating use_kwargs     ========================================================\n===============================================================     on line 0     ================================================================\n     with example \n@use_kwargs(['y', 'z'], keep=True)\ndef foo(a, *args, b=1, **kwargs): pass\ntest_sig(foo, '(a, *args, b=1, y=None, z=None, **kwargs)')\n     \n\nprint selected srcline with expands below--------\ndef use_kwargs(names, keep=False):======================================================================================================================(0)\nHow to use use_kwargs; use_kwargs has names as a list of strings; all the newly created params have None as default value; f's signature is saved inside f.__signature__\n    \"Decorator: replace `**kwargs` in signature with `names` params\"                                                                                    (1)\n    def _f(f):                                                                                                                                          (2)\n\n\n\nfdb.snoop(deco=True)\n\n22:14:40.65 >>> Call to use_kwargs in File \"/tmp/use_kwargs.py\", line 3\n22:14:40.65 ...... names = ['y', 'z']\n22:14:40.65 ...... len(names) = 2\n22:14:40.65 ...... keep = True\n22:14:40.65    3 | def use_kwargs(names, keep=False):\n22:14:40.65    5 |     import snoop\n22:14:40.65 .......... snoop = <class 'snoop.configuration.Config.__init__.<locals>.ConfiguredTracer'>\n22:14:40.65    6 |     @snoop\n22:14:40.65    7 |     def _f(f):\n22:14:40.65 .......... _f = <function use_kwargs.<locals>._f>\n22:14:40.65   16 |     return _f\n22:14:40.65 <<< Return value from use_kwargs: <function use_kwargs.<locals>._f>\n22:14:40.65 >>> Call to use_kwargs.<locals>._f in File \"/tmp/use_kwargs.py\", line 7\n22:14:40.65 .......... f = <function foo>\n22:14:40.65 .......... keep = True\n22:14:40.65 .......... names = ['y', 'z']\n22:14:40.65 .......... len(names) = 2\n22:14:40.65    7 |     def _f(f):\n22:14:40.65    8 |         sig = inspect.signature(f)\n22:14:40.65 .............. sig = <Signature (a, *args, b=1, **kwargs)>\n22:14:40.65    9 |         sigd = dict(sig.parameters)\n22:14:40.65 .............. sigd = {'a': <Parameter \"a\">, 'args': <Parameter \"*args\">, 'b': <Parameter \"b=1\">, 'kwargs': <Parameter \"**kwargs\">}\n22:14:40.65 .............. len(sigd) = 4\n22:14:40.65   10 |         k = sigd.pop('kwargs')\n22:14:40.65 .............. k = <Parameter \"**kwargs\">\n22:14:40.65 .............. sigd = {'a': <Parameter \"a\">, 'args': <Parameter \"*args\">, 'b': <Parameter \"b=1\">}\n22:14:40.65 .............. len(sigd) = 3\n22:14:40.65   11 |         s2 = {n:_mk_param(n) for n in names if n not in sigd}\n    22:14:40.65 Dict comprehension:\n    22:14:40.65   11 |         s2 = {n:_mk_param(n) for n in names if n not in sigd}\n    22:14:40.65 .............. Iterating over <list_iterator object>\n    22:14:40.65 .............. Values of sigd: {'a': <Parameter \"a\">, 'args': <Parameter \"*args\">, 'b': <Parameter \"b=1\">}\n    22:14:40.65 .............. Values of len(sigd): 3\n    22:14:40.65 .............. Values of n: 'y', 'z'\n    22:14:40.65 Result: {'y': <Parameter \"y=None\">, 'z': <Parameter \"z=None\">}\n22:14:40.65   11 |         s2 = {n:_mk_param(n) for n in names if n not in sigd}\n22:14:40.65 .............. s2 = {'y': <Parameter \"y=None\">, 'z': <Parameter \"z=None\">}\n22:14:40.65 .............. len(s2) = 2\n22:14:40.65   12 |         sigd.update(s2)\n22:14:40.65 .............. sigd = {'a': <Parameter \"a\">, 'args': <Parameter \"*args\">, 'b': <Parameter \"b=1\">, 'y': <Parameter \"y=None\">, ...}\n22:14:40.65 .............. len(sigd) = 5\n22:14:40.65   13 |         if keep: sigd['kwargs'] = k\n22:14:40.65 ...... len(sigd) = 6\n22:14:40.65   14 |         f.__signature__ = sig.replace(parameters=sigd.values())\n22:14:40.65   15 |         return f\n22:14:40.65 <<< Return value from use_kwargs.<locals>._f: <function foo>\n\n\n========================================================     Investigating use_kwargs     ========================================================\n==============================================================     on line None     ==============================================================\n     with example \n@use_kwargs(['y', 'z'], keep=True)\ndef foo(a, *args, b=1, **kwargs): pass\ntest_sig(foo, '(a, *args, b=1, y=None, z=None, **kwargs)')"
  },
  {
    "objectID": "demos/fastdb.html",
    "href": "demos/fastdb.html",
    "title": "0011_Fastdb",
    "section": "",
    "text": "fdb = Fastdb(Fastdb.printtitle)\n\n\nfdb.docsrc(5, \"how to use :=<, :=>, :=^ with format to align text to left, right, and middle\")\nfdb.print()\n\n========================================================     Investigating printtitle     ========================================================\n===============================================================     on line 5     ================================================================\n=============================================================     with example      ==============================================================\n\nprint selected srcline with expands below--------\n    if 'self.dbsrc' not in self.eg:                                                                                                                     (3)\n        self.orieg = self.eg  # make sure self.orieg has no self inside                                                                                 (4)\n    print('{:=^157}'.format(f\"     Investigating {colorize(self.orisrc.__name__, color='r')}     \")) ===================================================(5)\n                                                                                how to use :=<, :=>, :=^ with format to align text to left, right, and middle\n    print('{:=^157}'.format(f\"     on line {colorize(str(self.idxsrc), color='r')}     \"))                                                              (6)\n    print('{:=^157}'.format(f\"     with example {colorize(self.orieg, color='r')}     \"))                                                               (7)\n========================================================     Investigating printtitle     ========================================================\n===============================================================     on line 5     ================================================================\n=============================================================     with example      ==============================================================\n\n@patch====================================================================================(0)       \ndef printtitle(self:Fastdb):==============================================================(1)       \n                                                                                                                                                        (2)\n    if 'self.dbsrc' not in self.eg:=======================================================(3)       \n        self.orieg = self.eg  # make sure self.orieg has no self inside===================(4)       \n    print('{:=^157}'.format(f\"     Investigating {colorize(self.orisrc.__name__, color='r')}     \"))  # how to use :=<, :=>, :=^ with format to align text to left, right, and middle;  (5)\n    print('{:=^157}'.format(f\"     on line {colorize(str(self.idxsrc), color='r')}     \"))                                                              (6)\n    print('{:=^157}'.format(f\"     with example {colorize(self.orieg, color='r')}     \"))                                                               (7)\n    print()===============================================================================(8)       \n                                                                                                                                                        (9)\n\n\n\nfdb = Fastdb(Fastdb.snoop)\n\n\nfdb.print()\n\n==========================================================     Investigating snoop     ===========================================================\n==============================================================     on line None     ==============================================================\n=============================================================     with example      ==============================================================\n\ndef create_snoop_from_string(self:Fastdb, db=False):======================================(0)       \n    # learn about /tmp folder https://www.fosslinux.com/41739/linux-tmp-directory-everything-you-need-to-know.htm                                       (1)\n    file_name ='/tmp/' + self.orisrc.__name__ + '.py' ====================================(2)       \n    with open(file_name, 'w') as f:=======================================================(3)       \n        f.write(self.dbsrcstr)============================================================(4)       \n    code = compile(self.dbsrcstr, file_name, 'exec')======================================(5)       \n#             exec(dbsrc, locals(), self.egEnv)                ===========================(6)       \n#     exec(code, globals().update(self.outenv), locals()) # when dbsrc is a method, it will update as part of a class                                   (7)\n    exec(code, globals().update(self.outenv)) # when dbsrc is a method, it will update as part of a class                                               (8)\n    # store dbsrc func inside Fastdb obj==================================================(9)       \n    self.dbsrc = locals()[self.orisrc.__name__]===========================================(10)      \n                                                                                                                                                        (11)\n\n\n\nfdb = Fastdb(Fastdb.create_explore_str)\n\n\nfdb.print()\n\n====================================================     Investigating create_explore_str     ====================================================\n==============================================================     on line None     ==============================================================\n=============================================================     with example      ==============================================================\n\n@patch====================================================================================(0)       \ndef create_explore_str(self:Fastdb):======================================================(1)       \n    dbsrc = \"\"============================================================================(2)       \n    indent = 4============================================================================(3)       \n                                                                                                                                                        (4)\n    lst = inspect.getsource(self.orisrc).split('\\n')======================================(5)       \n    if not bool(lst[-1]): lst = lst[:-1]==================================================(6)       \n                                                                                                                                                        (7)\n    srclines = None=======================================================================(8)       \n    idxlst = None=========================================================================(9)       \n    if type(self.idxsrc) == int:==========================================================(10)      \n        srclines = lst[self.idxsrc]=======================================================(11)      \n    elif type(self.idxsrc) == list:=======================================================(12)      \n        idxlst = self.idxsrc==============================================================(13)      \n    else:=================================================================================(14)      \n        raise TypeError(\"decode must be an integer or a list.\")===========================(15)      \n                                                                                                                                                        (16)\n    for idx, l in zip(range(len(lst)), lst):==============================================(17)      \n                                                                                                                                                        (18)\n        if bool(l.strip()) and type(self.idxsrc) == int and idx == self.idxsrc:===========(19)      \n            numindent = len(l) - len(l.lstrip()) =========================================(20)      \n            dbcodes = \"import ipdb; ipdb.set_trace()\"=====================================(21)      \n            dbsrc = dbsrc + \" \"*numindent + dbcodes + '\\n'================================(22)      \n            dbsrc = dbsrc + l + '\\n'     =================================================(23)      \n        elif type(self.idxsrc) == list and idx in idxlst:=================================(24)      \n            numindent = len(l) - len(l.lstrip()) =========================================(25)      \n            dbcodes = \"import ipdb; ipdb.set_trace()\"=====================================(26)      \n            dbsrc = dbsrc + \" \"*numindent + dbcodes + '\\n'================================(27)      \n            dbsrc = dbsrc + l + '\\n'  ====================================================(28)      \n            idxlst.remove(idx)============================================================(29)      \n        elif bool(l.strip()) and idx + 1 == len(lst):=====================================(30)      \n            dbsrc = dbsrc + l=============================================================(31)      \n        else: # make sure this printout is identical to the printsrc output===============(32)      \n            dbsrc = dbsrc + l + '\\n'======================================================(33)      \n                                                                                                                                                        (34)\n    self.dbsrcstr = dbsrc=================================================================(35)      \n                                                                                                                                                        (36)\n\n\n\nfastview(Fastdb.printtitle)\n\n@patch====================================================================================(0)       \ndef printtitle(self:Fastdb):==============================================================(1)       \n                                                                                                                                                        (2)\n    if 'self.dbsrc' not in self.eg:=======================================================(3)       \n        self.orieg = self.eg  # make sure self.orieg has no self inside===================(4)       \n    print('{:=^157}'.format(f\"     Investigating {colorize(self.orisrc.__name__, color='r')}     \"))  # how to use :=<, :=>, :=^ with format to align text to left, right, and middle;  (5)\n    print('{:=^157}'.format(f\"     on line {colorize(str(self.idxsrc), color='r')}     \"))                                                              (6)\n    print('{:=^157}'.format(f\"     with example {colorize(self.orieg, color='r')}     \"))                                                               (7)\n    print()===============================================================================(8)       \n                                                                                                                                                        (9)"
  },
  {
    "objectID": "demos/tour.html",
    "href": "demos/tour.html",
    "title": "0000_tour",
    "section": "",
    "text": "funcs_kwargs??\n\n\n_funcs_kwargs??\n\nHere’s a (somewhat) quick tour of a few higlights from fastcore.\n\nDocumentation\nAll fast.ai projects, including this one, are built with nbdev, which is a full literate programming environment built on Jupyter Notebooks.\nI can easily open a notebook on colab with colab_link. Note: the repo should already have the notebook I want to use with colab.\n\ncolab_link('00_fastcore_meta_delegates')\n\nOpen 00_fastcore_meta_delegates in Colab\n\n\nThe full docs are available at fastcore.fast.ai.\nThe code in the examples and in all fast.ai libraries follow the fast.ai style guide.\nAll fast.ai libraries are designed to allow for import * to be used safely, particular by ensuring that __all__ is defined in all packages.\nIn order to see where a function is from, just type it:\n\ncoll_repr\n\n<function fastcore.foundation.coll_repr(c, max_n=10)>\n\n\n\ndoc(coll_repr)\n\n\ncoll_repr\ncoll_repr(c, max_n=10)String repr of up to `max_n` items of (possibly lazy) collection `c`\nShow in docs\n\n\nFor more details, including a link to the full documentation and source code, use doc, which pops up a window with this information:\ndoc(coll_repr)\n\nThe documentation also contains links to any related functions or classes, which appear like this: coll_repr (in the notebook itself you will just see a word with back-ticks around it; the links are auto-generated in the documentation site). The documentation will generally show one or more examples of use, along with any background context necessary to understand them. As you’ll see, the examples for each function and method are shown as tests, rather than example outputs, so let’s start by explaining that.\n\n\nTesting\nfastcore’s testing module is designed to work well with nbdev, which is a full literate programming environment built on Jupyter Notebooks. That means that your tests, docs, and code all live together in the same notebook. fastcore and nbdev’s approach to testing starts with the premise that all your tests should pass. If one fails, no more tests in a notebook are run.\nTests look like this:\n\ntest_eq(coll_repr(range(1000), 5), '(#1000) [0,1,2,3,4...]')\n\nThat’s an example from the docs for coll_repr. As you see, it’s not showing you the output directly. Here’s what that would look like:\n\ncoll_repr(range(1000), 5)\n\n'(#1000) [0,1,2,3,4...]'\n\n\nSo, the test is actually showing you what the output looks like, because if the function call didn’t return '(#1000) [0,1,2,3,4...]', then the test would have failed.\nSo every test shown in the docs is also showing you the behavior of the library — and vice versa!\nTest functions always start with test_, and then follow with the operation being tested. So test_eq tests for equality (as you saw in the example above). This includes tests for equality of arrays and tensors, lists and generators, and many more:\n\ntest_eq([0,1,2,3], np.arange(4))\n\nWhen a test fails, it prints out information about what was expected:\ntest_eq([0,1,2,3], np.arange(3))\n----\n  AssertionError: ==:\n  [0, 1, 2, 3]\n  [0 1 2]\nIf you want to check that objects are the same type, rather than the just contain the same collection, use test_eq_type.\nYou can test with any comparison function using test, e.g test whether an object is less than:\n\ntest(2, 3, operator.lt)\n\nYou can even test that exceptions are raised:\n\ndef divide_zero(): return 1/0\ntest_fail(divide_zero)\n\n…and test that things are printed to stdout:\n\ntest_stdout(lambda: print('hi'), 'hi')\n\n\n\nFoundations\nfast.ai is unusual in that we often use mixins in our code. Mixins are widely used in many programming languages, such as Ruby, but not so much in Python. We use mixins to attach new behavior to existing libraries, or to allow modules to add new behavior to our own classes, such as in extension modules. One useful example of a mixin we define is Path.ls, which lists a directory and returns an L (an extended list class which we’ll discuss shortly):\n\np = Path('images')\np.ls()\n\n(#6) [Path('images/mnist3.png'),Path('images/att_00000.png'),Path('images/puppy.jpg'),Path('images/att_00005.png'),Path('images/att_00007.png'),Path('images/att_00006.png')]\n\n\nYou can easily add you own mixins with the patch decorator, which takes advantage of Python 3 function annotations to say what class to patch:\n\n@patch\ndef num_items(self:Path): return len(self.ls())\n\np.num_items()\n\n6\n\n\nWe also use **kwargs frequently. In python **kwargs in a parameter like means “put any additional keyword arguments into a dict called kwargs”. Normally, using kwargs makes an API quite difficult to work with, because it breaks things like tab-completion and popup lists of signatures. utils provides use_kwargs and delegates to avoid this problem. See our detailed article on delegation on this topic.\nGetAttr solves a similar problem (and is also discussed in the article linked above): it’s allows you to use Python’s exceptionally useful __getattr__ magic method, but avoids the problem that normally in Python tab-completion and docs break when using this. For instance, you can see here that Python’s dir function, which is used to find the attributes of a python object, finds everything inside the self.default attribute here:\n\nclass Author:\n    def __init__(self, name): self.name = name\n\nclass ProductPage(GetAttr):\n    _default = 'author'\n    def __init__(self,author,price,cost): self.author,self.price,self.cost = author,price,cost\n\np = ProductPage(Author(\"Jeremy\"), 1.50, 0.50)\n[o for o in dir(p) if not o.startswith('_')]\n\n['author', 'cost', 'name', 'price']\n\n\nLooking at that ProductPage example, it’s rather verbose and duplicates a lot of attribute names, which can lead to bugs later if you change them only in one place. fastcore provides store_attr to simplify this common pattern. It also provides basic_repr to give simple objects a useful repr:\n\nclass ProductPage:\n    def __init__(self,author,price,cost): store_attr()\n    __repr__ = basic_repr('author,price,cost')\n\nProductPage(\"Jeremy\", 1.50, 0.50)\n\n__main__.ProductPage(author='Jeremy', price=1.5, cost=0.5)\n\n\nOne of the most interesting fastcore functions is the funcs_kwargs decorator. This allows class behavior to be modified without sub-classing. This can allow folks that aren’t familiar with object-oriented programming to customize your class more easily. Here’s an example of a class that uses funcs_kwargs:\n\n@funcs_kwargs\nclass T:\n    _methods=['some_method']\n    def __init__(self, **kwargs): assert not kwargs, f'Passed unknown args: {kwargs}'\n\np = T(some_method = print)\np.some_method(\"hello\")\n\nhello\n\n\nThe assert not kwargs above is used to ensure that the user doesn’t pass an unknown parameter (i.e one that’s not in _methods). fastai uses funcs_kwargs in many places, for instance, you can customize any part of a DataLoader by passing your own methods.\nfastcore also provides many utility functions that make a Python programmer’s life easier, in fastcore.utils. We won’t look at many here, since you can easily look at the docs yourself. To get you started, have a look at the docs for chunked (remember, if you’re in a notebook, type doc(chunked)), which is a handy function for creating lazily generated batches from a collection.\nPython’s ProcessPoolExecutor is extended to allow max_workers to be set to 0, to easily turn off parallel processing. This makes it easy to debug your code in serial, then run it in parallel. It also allows you to pass arguments to your parallel function, and to ensure there’s a pause between calls, in case the process you are running has race conditions. parallel makes parallel processing even easier to use, and even adds an optional progress bar.\n\n\nL\nLike most languages, Python allows for very concise syntax for some very common types, such as list, which can be constructed with [1,2,3]. Perl’s designer Larry Wall explained the reasoning for this kind of syntax:\n\nIn metaphorical honor of Huffman’s compression code that assigns smaller numbers of bits to more common bytes. In terms of syntax, it simply means that commonly used things should be shorter, but you shouldn’t waste short sequences on less common constructs.\n\nOn this basis, fastcore has just one type that has a single letter name: L. The reason for this is that it is designed to be a replacement for list, so we want it to be just as easy to use as [1,2,3]. Here’s how to create that as an L:\n\nL(1,2,3)\n\n(#3) [1,2,3]\n\n\nThe first thing to notice is that an L object includes in its representation its number of elements; that’s the (#3) in the output above. If there’s more than 10 elements, it will automatically truncate the list:\n\np = L.range(20).shuffle()\np\n\n(#20) [5,1,9,10,18,13,6,17,3,16...]\n\n\nL contains many of the same indexing ideas that NumPy’s array does, including indexing with a list of indexes, or a boolean mask list:\n\np[2,4,6]\n\n(#3) [9,18,6]\n\n\nIt also contains other methods used in array, such as L.argwhere:\n\np.argwhere(ge(15))\n\n(#5) [4,7,9,18,19]\n\n\nAs you can see from this example, fastcore also includes a number of features that make a functional style of programming easier, such as a full range of boolean functions (e.g ge, gt, etc) which give the same answer as the functions from Python’s operator module if given two parameters, but return a curried function if given one parameter.\nThere’s too much functionality to show it all here, so be sure to check the docs. Many little things are added that we thought should have been in list in the first place, such as making this do what you’d expect (which is an error with list, but works fine with L):\n\n1 + L(2,3,4)\n\n(#4) [1,2,3,4]\n\n\n\n\nTransforms\nA Transform is the main building block of the fastai data pipelines. In the most general terms a transform can be any function you want to apply to your data, however the Transform class provides several mechanisms that make the process of building them easy and flexible (see the docs for information about each of these):\n\nType dispatch\nDispatch over tuples\nReversability\nType propagation\nPreprocessing\nFiltering based on the dataset type\nOrdering\nAppending new behavior with decorators\n\nTransform looks for three special methods, encodes, decodes, and setups, which provide the implementation for __call__, decode, and setup respectively. For instance:\n\nclass A(Transform):\n    def encodes(self, x): return x+1\n\nA()(1)\n\n2\n\n\nFor simple transforms like this, you can also use Transform as a decorator:\n\n@Transform\ndef f(x): return x+1\n\nf(1)\n\n2\n\n\nTransforms can be composed into a Pipeline:\n\n@Transform\ndef g(x): return x/2\n\npipe = Pipeline([f,g])\npipe(3)\n\n2.0\n\n\nThe power of Transform and Pipeline is best understood by seeing how they’re used to create a complete data processing pipeline. This is explained in chapter 11 of the fastai book, which is available for free in Jupyter Notebook format."
  },
  {
    "objectID": "Interesting_fastai/the_origin_of_apl .html",
    "href": "Interesting_fastai/the_origin_of_apl .html",
    "title": "0001_The_origin_of_APL",
    "section": "",
    "text": "The end of summary: of Everson\n- their [paper](https://www.jsoftware.com/papers/APLDesign.htm): the design of APL\nFallkoff start talking\nIverson continued\none of The first implementer speaks\nmore informative of APL books"
  },
  {
    "objectID": "Interesting_fastai/Interesting_things_fastai.html",
    "href": "Interesting_fastai/Interesting_things_fastai.html",
    "title": "fastdebug",
    "section": "",
    "text": "integrate fastai with huggingface transformer library"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptmatmul.html",
    "href": "fastai_notebooks/fastai_ptmatmul.html",
    "title": "0017_fastai_pt2_2019_matmul",
    "section": "",
    "text": "The foundations we’ll assume throughout this course are:\n\nPython\nPython modules (non-DL)\npytorch indexable tensor, and tensor creation (including RNGs - random number generators)\nfastai.datasets"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptmatmul.html#check-imports",
    "href": "fastai_notebooks/fastai_ptmatmul.html#check-imports",
    "title": "0017_fastai_pt2_2019_matmul",
    "section": "Check imports",
    "text": "Check imports\nJump_to lesson 8 video\n\n31:11 - how to build a test framework using the source code of test, test_eq, and run tests for all notebooks (fastforward to 2022, we have the test source code in fastcore.test nbdev_test to run tests for all notebooks) 35:23 - why it is great to have a unit testing with jupyter\n\n#export\nfrom exp.nb_00 import *\nimport operator\n\ndef test(a,b,cmp,cname=None):\n    if cname is None: cname=cmp.__name__\n    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n\ndef test_eq(a,b): test(a,b,operator.eq,'==')\n\n\ntest_eq(TEST,'test')\n\n\n# To run tests in console:\n# ! python run_notebook.py 01_matmul.ipynb"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptmatmul.html#get-data",
    "href": "fastai_notebooks/fastai_ptmatmul.html#get-data",
    "title": "0017_fastai_pt2_2019_matmul",
    "section": "Get data",
    "text": "Get data\nJump_to lesson 8 video\n\n35:59 - what are the basic libs needed to create our matrix multiplication notebook/module\n\n#export\nfrom pathlib import Path\nfrom IPython.core.debugger import set_trace\nfrom fastai import datasets\nimport pickle, gzip, math, torch, matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom torch import tensor\n\n\n\n36:25 - how to download and extract mnist dataset using the most basic libraries: fastai.datasets, gzip, pickle\n\nMNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'\npath = datasets.download_data(MNIST_URL, ext='.gz'); path\n\n\nwith gzip.open(path, 'rb') as f:\n    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n\n\n\n36:57 - how to convert numpy array from mnist dataset into pytorch tensor using map and tensor; why Jeremy would like us to use pytorch tensor instead of numpy array; 37:42 - how to find out about the structure of the mnist dataset using tensor.shape and min, max\n\nx_train,y_train,x_valid,y_valid = map(tensor, (x_train,y_train,x_valid,y_valid))\nn,c = x_train.shape\nx_train, x_train.shape, y_train, y_train.shape, y_train.min(), y_train.max()\n\n\n\n38:15 - how to build a test to check the dataset has the structure we expect using assert and test_eq\n\nassert n==y_train.shape[0]==50000\ntest_eq(c,28*28)\ntest_eq(y_train.min(),0)\ntest_eq(y_train.max(),9)\n\n\n\n38:39 - how to turn a long vector tensor into a 2d tensor using img.view(28, 28); how to display image from a torch.FloatTensor using plt.imshow(img.view(28,28))\n\nmpl.rcParams['image.cmap'] = 'gray'\n\n\nimg = x_train[0]\n\n\nimg.view(28,28).type()\n\n\nplt.imshow(img.view((28,28)));"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptmatmul.html#initial-python-model",
    "href": "fastai_notebooks/fastai_ptmatmul.html#initial-python-model",
    "title": "0017_fastai_pt2_2019_matmul",
    "section": "Initial python model",
    "text": "Initial python model\nJump_to lesson 8 video\nJump_to lesson 8 video\n\n39:04 - If we are to build a simplest linear model for mnist dataset, how to create the weights and biases for the model using weights = torch.randn(784,10) and bias = torch.zeros(10). check the notebook\n\nweights = torch.randn(784,10)\n\n\nbias = torch.zeros(10)"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptmatmul.html#matrix-multiplication",
    "href": "fastai_notebooks/fastai_ptmatmul.html#matrix-multiplication",
    "title": "0017_fastai_pt2_2019_matmul",
    "section": "Matrix multiplication",
    "text": "Matrix multiplication\n\n39:49 - how to understand the matrix multiplication calculation process (see animation); how to implement the matrix multiplication with 3 loops (see src code below); imagine an input matrix rows=5, cols=28*28 and output matrix rows=5, cols=10, what would the weights matrix be? (rows=28*28, cols=10) In the src below, a would be the input matrix and b be the weights, we want to find out about the output matrix c. how to use assert (I found a useful link here)\n\ndef matmul(a,b):\n    ar,ac = a.shape # n_rows * n_cols\n    br,bc = b.shape\n    assert ac==br\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc):\n            for k in range(ac): # or br\n                c[i,j] += a[i,k] * b[k,j]\n    return c\n\n\n\n42:57 - run an example on matmul and test it and check how long does it take to calc a matrix of 5 rows; python is 1000 times slower than pytorch\n\nm1 = x_valid[:5]\nm2 = weights\n\n\nm1.shape,m2.shape\n\n\nt1.shape\n\nThis is kinda slow - what if we could speed it up by 50,000 times? Let’s try!\n\nlen(x_train)"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptmatmul.html#elementwise-ops",
    "href": "fastai_notebooks/fastai_ptmatmul.html#elementwise-ops",
    "title": "0017_fastai_pt2_2019_matmul",
    "section": "Elementwise ops",
    "text": "Elementwise ops\n\n44:27 - how to speed up the matrix multiplication by 50000 times by using pytorch (which uses a different lib called aten (the difference between aten and c10) to replace each loop at a time 45:11 - what is elementwise operation notebook from aten or c10 of pytorch; what does elementwise operation do between vectors and between matricies;\nOperators (+,-,*,/,>,<,==) are usually element-wise.\nExamples of element-wise operations:\nJump_to lesson 8 video\n\na = tensor([10., 6, -4])\nb = tensor([2., 8, 7])\na,b\n\n\na + b\n\n\n(a < b).float().mean()\n\n\nm = tensor([[1., 2, 3], [4,5,6], [7,8,9]]); m\n\n\n\n46:24 - how to translate equations into codes; how to read Frobenius norm equation; how often it appears in deep learning papers; 47:38 - how to get latex for math equations without actually writing them\nFrobenius norm:\n\\[\\| A \\|_F = \\left( \\sum_{i,j=1}^n | a_{ij} |^2 \\right)^{1/2}\\]\nHint: you don’t normally need to write equations in LaTeX yourself, instead, you can click ‘edit’ in Wikipedia and copy the LaTeX from there (which is what I did for the above equation). Or on arxiv.org, click “Download: Other formats” in the top right, then “Download source”; rename the downloaded file to end in .tgz if it doesn’t already, and you should find the source there, including the equations to copy and paste.\n\n(m*m).sum().sqrt()"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptmatmul.html#elementwise-matmul",
    "href": "fastai_notebooks/fastai_ptmatmul.html#elementwise-matmul",
    "title": "0017_fastai_pt2_2019_matmul",
    "section": "Elementwise matmul",
    "text": "Elementwise matmul\n\n48:52 - how to use elementwise vector-vector multiplication to replace the last loop of scalar-scalar multiplication below, and how much faster do we get (178 times); question: what does %timeit -n 10 mean (doing matmul(m1,m2 10 times?);\n\ndef matmul(a,b):\n    ar,ac = a.shape\n    br,bc = b.shape\n    assert ac==br\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc):\n            # Any trailing \",:\" can be removed\n            c[i,j] = (a[i,:] * b[:,j]).sum()\n    return c\n\n\n890.1/5\n\n\n\n50:59 - which language is this elementwise operation written in (c language); how does test_near and torch.allclose check whether two numbers are real close to each other is not exact the same;\n\n#export\ndef near(a,b): return torch.allclose(a, b, rtol=1e-3, atol=1e-5)\ndef test_near(a,b): test(a,b,near)\n\n\ntest_near(t1,matmul(m1, m2))"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptmatmul.html#broadcasting",
    "href": "fastai_notebooks/fastai_ptmatmul.html#broadcasting",
    "title": "0017_fastai_pt2_2019_matmul",
    "section": "Broadcasting",
    "text": "Broadcasting\n\n51:49 - how to get rid of the inner most loop now with broadcasting; what broadcasting does is to getting rid of all loops at the speed of Cuda written in C language; Where and when is broadcasting originated (APL in 1960s); What is this APL broadcasting (remove all the for loop and use implicit broadcasted loops)\nThe term broadcasting describes how arrays with different shapes are treated during arithmetic operations. The term broadcasting was first used by Numpy.\nFrom the Numpy Documentation:\nThe term broadcasting describes how numpy treats arrays with \ndifferent shapes during arithmetic operations. Subject to certain \nconstraints, the smaller array is “broadcast” across the larger \narray so that they have compatible shapes. Broadcasting provides a \nmeans of vectorizing array operations so that looping occurs in C\ninstead of Python. It does this without making needless copies of \ndata and usually leads to efficient algorithm implementations.\nIn addition to the efficiency of broadcasting, it allows developers to write less code, which typically leads to fewer errors.\nThis section was adapted from Chapter 4 of the fast.ai Computational Linear Algebra course.\nJump_to lesson 8 video"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptmatmul.html#broadcasting-with-a-scalar",
    "href": "fastai_notebooks/fastai_ptmatmul.html#broadcasting-with-a-scalar",
    "title": "0017_fastai_pt2_2019_matmul",
    "section": "Broadcasting with a scalar",
    "text": "Broadcasting with a scalar\n\n52:58 - how to do broadcasting on a vector with a scalar or broadcasting a scalar to a tensor a which can be a vector or matrix or more; and broadcasting is at speed of C or cuda;\n\na\n\n\na > 0\n\nHow are we able to do a > 0? 0 is being broadcast to have the same dimensions as a.\nFor instance you can normalize our dataset by subtracting the mean (a scalar) from the entire data set (a matrix) and dividing by the standard deviation (another scalar), using broadcasting.\nOther examples of broadcasting with a scalar:\n\na + 1\n\n\nm\n\n\n2*m"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptmatmul.html#broadcasting-a-vector-to-a-matrix",
    "href": "fastai_notebooks/fastai_ptmatmul.html#broadcasting-a-vector-to-a-matrix",
    "title": "0017_fastai_pt2_2019_matmul",
    "section": "Broadcasting a vector to a matrix",
    "text": "Broadcasting a vector to a matrix\n\n54:10 - how to broadcast a vector to matrix; Jeremy explains how to broadcast a vector to matrix without doing for loop; how to visualize a vector being broadcasted into a matrix using t = c.expand_as(m) (c as a data of column or row, m as matrix)\nWe can also broadcast a vector to a matrix:\n\nc = tensor([10.,20,30]); c\n\n\nm\n\n\nm.shape,c.shape\n\n\nm + c\n\n\nc + m\n\nWe don’t really copy the rows, but it looks as if we did. In fact, the rows are given a stride of 0.\n\nt = c.expand_as(m)\n\n\nt\n\n\nm + t\n\n\n\n55:51 - When broadcasting a vector to matrix, the vector is acting as a matrix but stored as a vector; how do we see this or interpret this using t.storage() and t.stride() and t.shape;\n\nt.storage()\n\n\nt.stride(), t.shape\n\n\n\n57:05 - how to turn a vector or 1d array into a 2d array or matrix using c.unsqueeze(0).shape (1, 3) or c[None,:].shape (1,3) or c.unsqueeze(1).shape (3,1) or c[:,None].shape (3,1), and turn a 1d array into a 3d array using c[None,None,:](1,1,3) or c[None,:,None](1,3,1); we use None over unsqueeze\nYou can index with the special value [None] or use unsqueeze() to convert a 1-dimensional array into a 2-dimensional array (although one of those dimensions has value 1).\n\nc.unsqueeze(0)\n\n\nc.unsqueeze(1)\n\n\nm\n\n\nc.shape, c.unsqueeze(0).shape,c.unsqueeze(1).shape\n\n\nc.shape, c[None].shape,c[:,None].shape\n\n\n\n59:26 - using None or unsqueeze, c + m is the same to c[None,:] + m but very different to c[:,None] + m 1:00:25 - how to make sense/visualize of the broadcasting of c[None] and c[...,None] using excel\nYou can always skip trailling ‘:’s. And’…’ means ‘all preceding dimensions’\n\nc[None].shape,c[...,None].shape\n\n\nc[:,None].expand_as(m)\n\n\nm + c[:,None]\n\n\nc[:,None]"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptmatmul.html#matmul-with-broadcasting",
    "href": "fastai_notebooks/fastai_ptmatmul.html#matmul-with-broadcasting",
    "title": "0017_fastai_pt2_2019_matmul",
    "section": "Matmul with broadcasting",
    "text": "Matmul with broadcasting\n\n1:02:05 - how to simplify the type of c[None,:,:] as c[None] and simplify c[:,:,None] as c[...,None]\n\n\n1:03:37 - how to write the broadcasting code to replace the for loop and how to thoroughly understand the code; what are the benefits of using broadcasting over many for loops (3700 times faster, less code less loops less error)\n\ndef matmul(a,b):\n    ar,ac = a.shape\n    br,bc = b.shape\n    assert ac==br\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc): # previously we have these two lines\n            # Any trailing \",:\" can be removed\n            c[i,j] = (a[i,:] * b[:,j]).sum() # elementwise operation: row x column (both have same length)\n    return c\n\ndef matmul(a,b):\n    ar,ac = a.shape\n    br,bc = b.shape\n    assert ac==br\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n#       c[i,j] = (a[i,:]          * b[:,j]).sum() # previous\n        c[i]   = (a[i  ].unsqueeze(-1) * b).sum(dim=0) # the right side gives a row of summed values by smashing the tensor into one row\n    return c\n\n\n\nhow to understand the second inner most loop is replaced by broadcasting (homework assigned by Jeremy) I have written the following code blocks to understand it.\n\nfrom fastdebug.utils import *\nfrom torch import tensor\n\na = tensor([[1,2,3], [4,5,6], [7,8,9]])\n\na\na.shape\n\n\na[0]\na[0].shape\na[0,:].shape\na[0,...].shape\n\n\na[0][None,:] # 2 dimensions, row dimension set as None, meaning 1 row\na[0][None,:].shape\na[0][None].shape # it can be 1 row, with unknown more dimensions carrying on e.g., [1,3,,,]\na[0, None].shape # even more simplified\na[0].unsqueeze(0).shape # make one row, but more columns\na[0,None].expand_as(a) # expand more rows \na\na[0][None] * a\n(a[0][None] * a).sum(dim=0) # sum up so that (3,3) tensor is smashed into a (3) tensor row\n(a[0][None] * a).sum(dim=0).shape\n(a[0][None] * a).sum(dim=1) # sum up so that (3,3) tensor is smashed into a (3) tensor column\n(a[0][None] * a).sum(dim=1).shape\n\n\na[0][:,None] # two dimensions, col dimension set None meaning 1 column\na[0][:,None].shape\na[0][...,None].shape\na[0].unsqueeze(1).shape\na[0].unsqueeze(-1).shape\na[0][:,None].expand_as(a)\na\na[0][:,None] * a\n(a[0][:,None] * a).sum(dim=0) # sum up so that (3,3) tensor is smashed into a (3) tensor row\n(a[0][:,None] * a).sum(dim=0).shape\n(a[0][:,None] * a).sum(dim=1) # sum up so that (3,3) tensor is smashed into a (3) tensor column\n(a[0][:,None] * a).sum(dim=1).shape\n\n\n885000/277\n\n\ntest_near(t1, matmul(m1, m2))"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptmatmul.html#broadcasting-rules",
    "href": "fastai_notebooks/fastai_ptmatmul.html#broadcasting-rules",
    "title": "0017_fastai_pt2_2019_matmul",
    "section": "Broadcasting Rules",
    "text": "Broadcasting Rules\n\n1:06:21 - How to understand broadcasting rules; two vector or matrix do some operations, we check their shapes side by side, e.g., a.shape==[1,4,5] vs b.shape==[3,1,5], according to the 2 rules, a will broadcast to 3 rows, b will grow to 3 columns, and a and b change nothing on the 3rd dimention. and (a*b).shape == [3,4,5]\n\nc[None,:]\n\n\nc[None,:].shape\n\n\nc[:,None]\n\n\nc[:,None].shape\n\n\nc[None,:] * c[:,None]\n\n\nc[None] > c[:,None]\n\n\n\nHere is my own code for understanding the 2 rules of broadcasting\n\nc = tensor([1,2,3])\nc\nc.shape\nc[:].shape\nc[...].shape\n\n\nc[None,:]\nc[None,:].shape\nc[None,:,].shape\nc[None].shape\nc[None,None,:].shape\nc[None,None].shape\n\n\nc[:,None]\nc[:,None].shape\nc[:,None].shape\nc[:,None,None].shape\n\n\nc[None,:].shape\nc[:,None].shape\n(c[None,:] * c[:,None]).shape\n\n\nc[None,:,None].shape\nc[:,None,None].shape\n(c[None,:,None] * c[:,None,None]).shape\n\n\na = tensor([[1,2,3],[4,5,6],[7,8,9],[9,8,7]])\na.shape\na[None].shape\na[:,None].shape\n(a[None] * a[:,None]).shape\n\nWhen operating on two arrays/tensors, Numpy/PyTorch compares their shapes element-wise. It starts with the trailing dimensions, and works its way forward. Two dimensions are compatible when\n\nthey are equal, or\none of them is 1, in which case that dimension is broadcasted to make it the same size\n\nArrays do not need to have the same number of dimensions. For example, if you have a 256*256*3 array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. Lining up the sizes of the trailing axes of these arrays according to the broadcast rules, shows that they are compatible:\nImage  (3d array): 256 x 256 x 3\nScale  (1d array):             3\nResult (3d array): 256 x 256 x 3\nThe numpy documentation includes several examples of what dimensions can and can not be broadcast together.\n\n\n1:10:02 - why the broadcasting trick is the most important technique in creating fastai from scratch"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptmatmul.html#einstein-summation",
    "href": "fastai_notebooks/fastai_ptmatmul.html#einstein-summation",
    "title": "0017_fastai_pt2_2019_matmul",
    "section": "Einstein summation",
    "text": "Einstein summation\n\n1:10:43 - how to understand Einstein summation and how to use torch.einsum to do matrix multiplication with no loop at all and speed up 16000 times faster than pure python 3-for loop version; how to trick torch.einsum to do batch matrix multiplication and even more transforms and tweaks\nEinstein summation (einsum) is a compact representation for combining products and sums in a general way. From the numpy docs:\n“The subscripts string is a comma-separated list of subscript labels, where each label refers to a dimension of the corresponding operand. Whenever a label is repeated it is summed, so np.einsum('i,i', a, b) is equivalent to np.inner(a,b). If a label appears only once, it is not summed, so np.einsum('i', a) produces a view of a with no changes.”\nJump_to lesson 8 video\n\n# c[i,j] += a[i,k] * b[k,j]\n# c[i,j] = (a[i,:] * b[:,j]).sum()\ndef matmul(a,b): return torch.einsum('ik,kj->ij', a, b)\ndef batch_matmul(a,b): return torch.einsum('bik,bkj->bij', a, b)\n\n\n885000/55\n\n\ntest_near(t1, matmul(m1, m2))\n\n\n\n1:15:48 - what Jeremy does not like about torch.einsum and why APL, J and K are so great and what to expect from swift compiler, Julia"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptmatmul.html#pytorch-op",
    "href": "fastai_notebooks/fastai_ptmatmul.html#pytorch-op",
    "title": "0017_fastai_pt2_2019_matmul",
    "section": "pytorch op",
    "text": "pytorch op\n\n1:18:23 - torch.matmul can do matrix multiplication without loops and 50000 times faster than the pure python 3-for loops version; but the reason why torch.matmul is so much faster is because it uses a lib like BLAS written by Nvdia (cuBLAS) or AMD or Intel (MKL)which split the large matricies into smaller ones and doing calc without using up all the ram; what are the problems of using these gpu libraries like MKL and cuBLAS;\n\n\n1:21:48 - torch.matmul and @ are the same thing, but they can handle a lot more including batch matrix multiplication\nWe can use pytorch’s function or operator directly for matrix multiplication.\nJump_to lesson 8 video\n\n# time comparison vs pure python:\n885000/18\n\n\nt2 = m1@m2\n\n\ntest_near(t1, t2)\n\n\nm1.shape,m2.shape\n\n\n\n1:22:33 - What to do next; after having matrix multiplication fast enough, we need to initialize weights and biases, then create ReLU, then backward"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptmatmul.html#export",
    "href": "fastai_notebooks/fastai_ptmatmul.html#export",
    "title": "0017_fastai_pt2_2019_matmul",
    "section": "Export",
    "text": "Export\n\n!python notebook2script.py 01_matmul.ipynb"
  },
  {
    "objectID": "fastai_notebooks/fastai_which_image_model_best.html",
    "href": "fastai_notebooks/fastai_which_image_model_best.html",
    "title": "0003_fastai_which_image_model_best",
    "section": "",
    "text": "The data, concept, and initial implementation of this notebook was done in Colab by Ross Wightman, the creator of timm. I (Jeremy Howard) did some refactoring, curating, and expanding of the analysis, and added prose."
  },
  {
    "objectID": "fastai_notebooks/fastai_which_image_model_best.html#timm",
    "href": "fastai_notebooks/fastai_which_image_model_best.html#timm",
    "title": "0003_fastai_which_image_model_best",
    "section": "timm",
    "text": "timm\nPyTorch Image Models (timm) is a wonderful library by Ross Wightman which provides state-of-the-art pre-trained computer vision models. It’s like Huggingface Transformers, but for computer vision instead of NLP (and it’s not restricted to transformers-based models)!\nRoss has been kind enough to help me understand how to best take advantage of this library by identifying the top models. I’m going to share here so of what I’ve learned from him, plus some additional ideas."
  },
  {
    "objectID": "fastai_notebooks/fastai_which_image_model_best.html#how-to-git-clone-timm-analysis-data-how-to-enter-a-directory-with-cd",
    "href": "fastai_notebooks/fastai_which_image_model_best.html#how-to-git-clone-timm-analysis-data-how-to-enter-a-directory-with-cd",
    "title": "0003_fastai_which_image_model_best",
    "section": "how to git clone TIMM analysis data; how to enter a directory with %cd",
    "text": "how to git clone TIMM analysis data; how to enter a directory with %cd\nRoss regularly benchmarks new models as they are added to timm, and puts the results in a CSV in the project’s GitHub repo. To analyse the data, we’ll first clone the repo:\n\n! git clone --depth 1 https://github.com/rwightman/pytorch-image-models.git"
  },
  {
    "objectID": "fastai_notebooks/fastai_which_image_model_best.html#how-to-read-a-csv-file-with-pandas",
    "href": "fastai_notebooks/fastai_which_image_model_best.html#how-to-read-a-csv-file-with-pandas",
    "title": "0003_fastai_which_image_model_best",
    "section": "how to read a csv file with pandas",
    "text": "how to read a csv file with pandas\nUsing Pandas, we can read the two CSV files we need, and merge them together.\n\nimport pandas as pd\ndf_results = pd.read_csv('results-imagenet.csv')"
  },
  {
    "objectID": "fastai_notebooks/fastai_which_image_model_best.html#how-to-merge-data-with-pandas-how-to-create-new-column-with-pandas-how-to-string-extract-with-regex-expression-how-to-select-columns-up-to-a-particular-column-with-pandas-how-to-do-loc-in-pandas-how-to-select-a-group-of-columns-using-str.contains-and-regex",
    "href": "fastai_notebooks/fastai_which_image_model_best.html#how-to-merge-data-with-pandas-how-to-create-new-column-with-pandas-how-to-string-extract-with-regex-expression-how-to-select-columns-up-to-a-particular-column-with-pandas-how-to-do-loc-in-pandas-how-to-select-a-group-of-columns-using-str.contains-and-regex",
    "title": "0003_fastai_which_image_model_best",
    "section": "how to merge data with pandas; how to create new column with pandas; how to string extract with regex expression; how to select columns up to a particular column with pandas; how to do loc in pandas; how to select a group of columns using str.contains and regex",
    "text": "how to merge data with pandas; how to create new column with pandas; how to string extract with regex expression; how to select columns up to a particular column with pandas; how to do loc in pandas; how to select a group of columns using str.contains and regex\nWe’ll also add a “family” column that will allow us to group architectures into categories with similar characteristics:\nRoss has told me which models he’s found the most usable in practice, so I’ll limit the charts to just look at these. (I also include VGG, not because it’s good, but as a comparison to show how far things have come in the last few years.)\n\ndef get_data(part, col):\n    df = pd.read_csv(f'benchmark-{part}-amp-nhwc-pt111-cu113-rtx3090.csv').merge(df_results, on='model')\n    df['secs'] = 1. / df[col]\n    df['family'] = df.model.str.extract('^([a-z]+?(?:v2)?)(?:\\d|_|$)')\n    df = df[~df.model.str.endswith('gn')]\n    df.loc[df.model.str.contains('in22'),'family'] = df.loc[df.model.str.contains('in22'),'family'] + '_in22'\n    df.loc[df.model.str.contains('resnet.*d'),'family'] = df.loc[df.model.str.contains('resnet.*d'),'family'] + 'd'\n    return df[df.family.str.contains('^re[sg]netd?|beit|convnext|levit|efficient|vit|vgg')]\n\n\ndf = get_data('infer', 'infer_samples_per_sec')"
  },
  {
    "objectID": "fastai_notebooks/fastai_which_image_model_best.html#inference-results",
    "href": "fastai_notebooks/fastai_which_image_model_best.html#inference-results",
    "title": "0003_fastai_which_image_model_best",
    "section": "Inference results",
    "text": "Inference results\n\nhow to scatterplot with plotly.express; how to set the plot’s width, height, size, title, x, y, log_x, color, hover_name, hover_data;\nHere’s the results for inference performance (see the last section for training performance). In this chart:\n\nthe x axis shows how many seconds it takes to process one image (note: it’s a log scale)\nthe y axis is the accuracy on Imagenet\nthe size of each bubble is proportional to the size of images used in testing\nthe color shows what “family” the architecture is from.\n\nHover your mouse over a marker to see details about the model. Double-click in the legend to display just one family. Single-click in the legend to show or hide a family.\nNote: on my screen, Kaggle cuts off the family selector and some plotly functionality – to see the whole thing, collapse the table of contents on the right by clicking the little arrow to the right of “Contents”.\n\nimport plotly.express as px\nw,h = 1000,800\n\ndef show_all(df, title, size):\n    return px.scatter(df, width=w, height=h, size=df[size]**2, title=title,\n        x='secs',  y='top1', log_x=True, color='family', hover_name='model', hover_data=[size])\n\n\nshow_all(df, 'Inference', 'infer_img_size')\n\nThat number of families can be a bit overwhelming, so I’ll just pick a subset which represents a single key model from each of the families that are looking best in our plot. I’ve also separated convnext models into those which have been pretrained on the larger 22,000 category imagenet sample (convnext_in22) vs those that haven’t (convnext). (Note that many of the best performing models were trained on the larger sample – see the papers for details before coming to conclusions about the effectiveness of these architectures more generally.)\n\n\nhow to scatterplot on a subgroup of data using regex and plotly\n\nsubs = 'levit|resnetd?|regnetx|vgg|convnext.*|efficientnetv2|beit'\n\nIn this chart, I’ll add lines through the points of each family, to help see how they compare – but note that we can see that a linear fit isn’t actually ideal here! It’s just there to help visually see the groups.\n\ndef show_subs(df, title, size):\n    df_subs = df[df.family.str.fullmatch(subs)]\n    return px.scatter(df_subs, width=w, height=h, size=df_subs[size]**2, title=title,\n        trendline=\"ols\", trendline_options={'log_x':True},\n        x='secs',  y='top1', log_x=True, color='family', hover_name='model', hover_data=[size])\n\n\nshow_subs(df, 'Inference', 'infer_img_size')\n\nFrom this, we can see that the levit family models are extremely fast for image recognition, and clearly the most accurate amongst the faster models. That’s not surprising, since these models are a hybrid of the best ideas from CNNs and transformers, so get the benefit of each. In fact, we see a similar thing even in the middle category of speeds – the best is the ConvNeXt, which is a pure CNN, but which takes advantage of ideas from the transformers literature.\nFor the slowest models, beit is the most accurate – although we need to be a bit careful of interpreting this, since it’s trained on a larger dataset (ImageNet-21k, which is also used for vit models).\nI’ll add one other plot here, which is of speed vs parameter count. Often, parameter count is used in papers as a proxy for speed. However, as we see, there is a wide variation in speeds at each level of parameter count, so it’s really not a useful proxy.\n(Parameter count may be be useful for identifying how much memory a model needs, but even for that it’s not always a great proxy.)\n\npx.scatter(df, width=w, height=h,\n    x='param_count_x',  y='secs', log_x=True, log_y=True, color='infer_img_size',\n    hover_name='model', hover_data=['infer_samples_per_sec', 'family']\n)"
  },
  {
    "objectID": "fastai_notebooks/fastai_which_image_model_best.html#training-results",
    "href": "fastai_notebooks/fastai_which_image_model_best.html#training-results",
    "title": "0003_fastai_which_image_model_best",
    "section": "Training results",
    "text": "Training results\nWe’ll now replicate the above analysis for training performance. First we grab the data:\n\ntdf = get_data('train', 'train_samples_per_sec')\n\nNow we can repeat the same family plot we did above:\n\nshow_all(tdf, 'Training', 'train_img_size')\n\n…and we’ll also look at our chosen subset of models:\n\nshow_subs(tdf, 'Training', 'train_img_size')\n\nFinally, we should remember that speed depends on hardware. If you’re using something other than a modern NVIDIA GPU, your results may be different. In particular, I suspect that transformers-based models might have worse performance in general on CPUs (although I need to study this more to be sure).\n\nconvert ipynb to md\n\nfrom fastdebug.utils import *\n\n\n\n\n\nipy2md()\n\n[jupytext] Reading /Users/Natsume/Documents/fastdebug/nbs/2022part1/0003_fastai_which_image_model_best.ipynb in format ipynb\n[jupytext] Writing /Users/Natsume/Documents/fastdebug/nbs/2022part1/0003_fastai_which_image_model_best.md\ncp to : /Users/Natsume/Documents/divefastai/Debuggable/jupytext\nmove to : /Users/Natsume/Documents/fastdebug/mds/2022part1/\n\n\n[NbConvertApp] Converting notebook /Users/Natsume/Documents/fastdebug/nbs/2022part1/0003_fastai_which_image_model_best.ipynb to markdown\n[NbConvertApp] Writing 7289 bytes to /Users/Natsume/Documents/fastdebug/nbs/2022part1/0003_fastai_which_image_model_best.md\n\n\nmove to : /Users/Natsume/Documents/fastdebug/mds_output\n\n\n\nfastnbs(\"export model\")\n\nhow to export model to a pickle file and download it from kaggle\n\n\nNow we can export our trained Learner. This contains all the information needed to run the model:\n#|eval: false\nlearn.export('model.pkl')\nFinally, open the Kaggle sidebar on the right if it’s not already, and find the section marked “Output”. Open the /kaggle/working folder, and you’ll see model.pkl. Click on it, then click on the menu on the right that appears, and choose “Download”. After a few seconds, your model will be downloaded to your computer, where you can then create your app that uses the model.\n\n\nOpen 0002_fastai_Saving_Model_fastai in Jupyter Notebook\n\n\n\nfastlistnbs()\n\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0001_fastai_is_it_a_bird.md\n## Useful Course sites\n## How to use autoreload\n## How to install and update libraries\n## Know a little about the libraries\n### what is fastai\n### what is duckduckgo\n## How to use fastdebug with fastai notebooks\n### how to use fastdebug\n### Did I document it in a notebook before?\n### Did I document it in a src before?\n## how to search and get a url of an image; how to download with an url; how to view an image;\n### how to create folders using path; how to search and download images in folders; how to resize images \n## Train my model\n### How to find and unlink images not properly downloaded\n### How to create a DataLoaders with DataBlock; how to view data with it\n### How to build my model with dataloaders and pretrained model; how to train my model\n### How to predict with my model; how to avoid running cells in nbdev_prepare\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0002_fastai_Saving_Model_fastai.md\n## what to import to handle vision problems in fastai\n## how to download and decompress datasets prepared by fastai\n## how to tell it is a cat by reading filename\n## how to create dataloaders with `from_name_func`\n## how to create a pretrained model with resnet18 and error_rate; how to fine tune it 3 epochs\n## how to export model to a pickle file and download it from Kaggle\n## how to convert ipynb to md\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0003_fastai_which_image_model_best.md\n## timm\n## how to git clone TIMM analysis data; how to enter a directory with %cd\n## how to read a csv file with pandas\n## how to merge data with pandas; how to create new column with pandas; how to string extract with regex expression; how to select columns up to a particular column with pandas; how to do loc in pandas; how to select a group of columns using str.contains and regex\n## Inference results\n### how to scatterplot with plotly.express; how to set the plot's width, height, size, title, x, y, log_x, color, hover_name, hover_data; \n### how to scatterplot on a subgroup of data using regex and plotly\n## Training results\n### convert ipynb to md\n\n/Users/Natsume/Documents/fastdebug/mds/lib/utils.md\n## setup for exporting to a module\n## how to get current notebook's name, path and url\n## how to convert ipynb to md automatically; how to run commands in python\n## Autoreload for every notebook\n## Expand cells\n## Import fastcore env\n## to inspect a class\n### get the docs for each function of a class\n## is it a metaclass?\n## is it a decorator\n### handle all kinds of exceptions for evaluating retn \n## whatinside a module of a library\n### show the type of objects inside `__all__`\n### working for fastdebug.core\n### to show Fastdb methods\n## whichversion of a library\n## fastview\n## fastscrs\n## getrootport\n## jn_link\n## get_all_nbs\n### get all nbs path for both md and ipynb\n### add index.ipynb\n## openNB\n## highlight\n## display_md\n## display_block\n### handle both file path and file content at the same time\n## fastnbs\n## fastcodes\n## fastnotes\n### multiple folders\n## fastlistnbs\n## fastlistsrcs\n## Best practice of fastdebug.core\n## Best practice of fastdebug.utils\n## Export\n\n/Users/Natsume/Documents/fastdebug/mds/lib/00_core.md\n## make life easier with defaults  \n## globals() and locals()\n## Execute strings\n### new variable or updated variable by exec will only be accessible from locals()\n### eval can override its own globals() and locals()\n### when exec update existing functions\n### when the func to be udpated involve other libraries\n### inside a function, exec() allow won't give you necessary env from function namespace\n### magic of `exec(b, globals().update(locals()))`\n### Bring variables from a func namespace to the sideout world\n### globals() in a cell vs globals() in a func\n## make a colorful string\n## align text to the most right\n## printsrcwithidx\n### print the entire source code with idx from 0\n### print the whole src with idx or print them in parts\n### use cmts from dbprint to print out src with comments\n### no more update for printsrcwithidx, for the latest see Fastdb.print\n## print out src code\n### basic version\n### print src with specific number of lines\n### make the naming more sensible\n### Allow a dbline occur more than once\n### adding idx to the selected srclines\n#### printsrclinewithidx\n### dblines can be string of code or idx number\n### avoid multi-occurrance of the same srcline\n## dbprint on expression\n### basic version\n### insert dbcode and make a new dbfunc\n### Bring outside namespace variables into exec()\n### Bring what inside the func namespace variables to the outside world\n### Adding g = locals() to dbprintinsert to avoid adding env individually\n### enable srclines to be either string or int \n### enable = to be used as assignment in codes\n### avoid adding \"env=g\" for dbprintinsert\n### collect cmt for later printsrcwithidx to print comments together\n### make sure only one line with correct idx is debugged\n### avoid typing \"\" when there is no codes\n### no more update for dbprint, for the latest see Fastdb.dbprint\n### use dbprint to override the original official code without changing its own pyfile\n## dbprintinsert\n### Run and display the inserted dbcodes \n### use locals() inside the dbsrc code to avoid adding env individually\n### enable dbprintinsert to do exec on a block of code\n## printrunsrclines() \n### Examples\n#### simple example\n#### complex example\n### insert a line after each srcline to add idx\n### add correct indentation to each inserted line\n#### count the indentation for each srcline\n### indentation special case: if, else, for, def\n### remove pure comments or docs from dbsrc\n### print out the srclines which get run\n### Make sure all if, else, for get printed\n### Put all together into the function printrunsrclines()\n#### no more renaming of foo\n#### add example as a param into the function\n#### improve on search for `if`, else, for, def to avoid errors for more examples\n#### remove an empty line with indentation\n### make it work\n### more difficult examples to test printrunsrc()\n## Make fastdebug a class\n### improve on the line idx readability\n### collect cmt from dbprint and print\n### make sure only the line with correct idx is debugged\n### having \"\" or \"   \" inside codes without causing error\n### replace Fastdb.printsrcwithdix with Fastdb.print\n### add idx to dbsrc when showdbsrc=True\n### not load the inner locals() to outenv can prevent mysterious printing of previous db messages\n### using @patch to enable docs for instance methods like `dbprint` and `print`\n### move param env into `__init__`\n### Add example to the obj\n### Take not only function but also class\n### To remove the necessity of self.takExample()\n### Try to remove g = locals()\n### Make sure `showdbsrc=True` give us the line starting with 'dbprintinsert'\n### Make sure `showdbsrc=True` give us info on changes in g or outenv\n### exit and print a warning message: idx has to be int\n### handle errors by codes with trailing spaces \n### showdbsrc=True, check whether Fastdb.dbprint and fdb.dbprint are same object using `is`\n### remove unnecessary db printout when showdbsrc=True and add printout to display sections\n### raise TypeError when decode are not integer and showdbsrc=true working on both method and function\n### when debugging dbprint, make sure dbsrc is printed with the same idx as original\n### update dbsrc to the global env\n### go back to normal before running dbprint again\n### auto print src with cmt and idx as the ending part of dbprint\n### to mark my explorations (expressions to evaluate) to stand out\n### Add the print of src with idx and comments at the end of dbsrc\n### embed example and autoprint to shorten the code to type\n### Make title for dbprint\n### Adding self.eg info and color group into dbprint and print\n#### todo: make the comments with same self.eg have the same color\n### make dbsrc print idx right\n### add self.eg to a dict with keys are idxsrc\n### handle both function and class as src\n### documenting on Fastdb.dbprint itself\n## mk_dbsrc\n## Turn mk_dbsrc into docsrc \n### handle when no codes are given\n## create_dbsrc_from_string\n## replaceWithDbsrc\n### handle class and metaclass\n### improve on handling function as decorator\n### Handling `inspect._signature_from_callable` to become `self.dbsrc`\n### handling usage of `@delegates`\n### handling `@delegates` with indentation before it\n### handling classes by inspect.isclass() rather than == type and add more class situations\n### handling `class _T(_TestA, metaclass=BypassNewMeta): `\n## run_example\n### `exec(self.eg, globals().update(self.egEnv), locals())` works better than `...update(locals()), self.egEnv)\n### no more env cells run before `fdb.eg` to make `fdb.run_example` work\n## Autoprint\n## Take an example and its env into Fastdb obj\n## print src with idx and cmt in whole or parts\n### print self.eg after each comment and colorize comments\n### color examples and cmts separately and make the func simpler\n### split each cmt and colorize parts randomly\n### printcmts1 while saving into a file\n## goback\n## Fastdb.explore\n### adding one breakpoint with comment\n### Adding multiple breakpoints by multiple set_trace()\n### Go back to normal before running explore again\n### enable fdb.takExample(\"whatinside(fu), ...) without using `fu.whatinside`\n### refactory explore\n## snoop\n### snoop on both function and class\n### snoop on class and method and all???\n### snoop\n### simplify adding @snoop for both normal function and decorator\n### handling classes\n### add watch\n## Snoop\n### add watch\n### use guide on Fastdb.dbprint\n## reliveonce\n## Fastdb.debug\n## Export\n## Send to Obsidian\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0001_fastcore_meta_delegates.md\n## Import\n## Initiate Fastdb and example in str\n## Example\n## docsrc\n## Snoop\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0003_Explore_document_FixSigMeta_PrePostInitMeta_AutoInit.md\n## Initialize fastdebug objects\n## class FixSigMeta(type) vs class Foo(type)\n## class Foo()\n## class PrePostInitMeta(FixSigMeta)\n## class Foo(metaclass=FixSigMeta)\n## class AutoInit(metaclass=PrePostInitMeta)\n## Prepare examples for FixSigMeta, PrePostInitMeta, AutoInit \n## Snoop them together in one go\n### embed the dbsrc of FixSigMeta into PrePostInitMeta\n### embed dbsrc of PrePostInitMeta into AutoInit\n## Explore and Document on them together \n\n/Users/Natsume/Documents/fastdebug/mds/demos/0004_fastcore.meta._rm_self.md\n## imports\n## set up\n## document\n## snoop\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0005_fastcore.meta.test_sig.md\n## imports\n## setups\n## documents\n## snoop\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0007_fastcore.meta.BypassNewMeta.md\n## Reading official docs\n## Inspecting class\n## Initiating with examples\n## Snoop\n## Document\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0002_signature_from_callable.md\n## Expand cell\n## Imports and initiate\n## Examples\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0008_use_kwargs_dict.md\n## Imports\n## Reading official docs\n## empty2none\n## `_mk_param`\n## use_kwargs_dict\n### Reading docs\n## use_kwargs\n### Reading docs\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0006_fastcore.meta.NewChkMeta.md\n## Import and Initalization\n## Official docs\n## Prepare Example\n## Inspect classes\n## Snoop\n## Document\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0000_tour.md\n### Documentation\n### Testing\n### Foundations\n### L\n### Transforms\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0012_fastcore_foundation_L.md\n## Document `L` with fastdebug\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0011_Fastdb.md\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0009_funcs_kwargs.md\n## fastcore.meta.method\n### Reading Docs\n### Running codes\n### Document\n### snoop\n## funcs_kwargs\n### Official docs\n### snoop: from _funcs_kwargs to funcs_kwargs\n### snoop only '_funcs_kwargs' by breaking up 'funcs_kwargs'\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0010_fastcore_meta_summary.md\n## import\n## fastcore and fastcore.meta\n### What's inside fastcore.meta\n## Review individual funcs and classes\n### What is fastcore.meta all about? \n### What can these metaclasses do for me?\n#### FixSigMeta\n#### PrePostInitMeta\n#### AutoInit\n#### NewChkMeta\n#### BypassNewMeta\n### What can those decorators do for me?\n#### use_kwargs_dict\n#### use_kwargs\n#### delegates\n#### funcs_kwargs\n### The remaining functions\n## What is fastcore.meta all about\n\n/Users/Natsume/Documents/fastdebug/mds/questions/00_question_anno_dict.md\n## `anno_dict` docs\n## Dive in\n## `anno_dict` seems not add anything new to `__annotations__`\n## use fastdebug to double check\n## Does fastcore want anno_dict to include params with no annos?\n## Jeremy's response"
  },
  {
    "objectID": "fastai_notebooks/fastai_which_image_model_best.html#how-to-export-model-to-a-pickle-file-and-download-it-from-kaggle",
    "href": "fastai_notebooks/fastai_which_image_model_best.html#how-to-export-model-to-a-pickle-file-and-download-it-from-kaggle",
    "title": "0003_fastai_which_image_model_best",
    "section": "how to export model to a pickle file and download it from kaggle",
    "text": "how to export model to a pickle file and download it from kaggle"
  },
  {
    "objectID": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html",
    "href": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html",
    "title": "0015_getting_started_with_nlp_for_absolute_beginner",
    "section": "",
    "text": "One area where deep learning has dramatically improved in the last couple of years is natural language processing (NLP). Computers can now generate text, translate automatically from one language to another, analyze comments, label words in sentences, and much more.\nPerhaps the most widely practically useful application of NLP is classification – that is, classifying a document automatically into some category. This can be used, for instance, for:\n\nSentiment analysis (e.g are people saying positive or negative things about your product)\nAuthor identification (what author most likely wrote some document)\nLegal discovery (which documents are in scope for a trial)\nOrganizing documents by topic\nTriaging inbound emails\n…and much more!\n\nClassification models can also be used to solve problems that are not, at first, obviously appropriate. For instance, consider the Kaggle U.S. Patent Phrase to Phrase Matching competition. In this, we are tasked with comparing two words or short phrases, and scoring them based on whether they’re similar or not, based on which patent class they were used in. With a score of 1 it is considered that the two inputs have identical meaning, and 0 means they have totally different meaning. For instance, abatement and eliminating process have a score of 0.5, meaning they’re somewhat similar, but not identical.\nIt turns out that this can be represented as a classification problem. How? By representing the question like this:\n\nFor the following text…: “TEXT1: abatement; TEXT2: eliminating process” …chose a category of meaning similarity: “Different; Similar; Identical”.\n\nIn this notebook we’ll see how to solve the Patent Phrase Matching problem by treating it as a classification task, by representing it in a very similar way to that shown above.\n\n\nKaggle is an awesome resource for aspiring data scientists or anyone looking to improve their machine learning skills. There is nothing like being able to get hands-on practice and receiving real-time feedback to help you improve your skills. It provides:\n\nInteresting data sets\nFeedback on how you’re doing\nA leader board to see what’s good, what’s possible, and what’s state-of-art\nNotebooks and blog posts by winning contestants share useful tips and techniques.\n\nThe dataset we will be using here is only available from Kaggle. Therefore, you will need to register on the site, then go to the page for the competition. On that page click “Rules,” then “I Understand and Accept.” (Although the competition has finished, and you will not be entering it, you still have to agree to the rules to be allowed to download the data.)\nThere are two ways to then use this data:\n\nEasiest: run this notebook directly on Kaggle, or\nMost flexible: download the data locally and run it on your PC or GPU server\n\nIf you are running this on Kaggle.com, you can skip the next section. Just make sure that on Kaggle you’ve selected to use a GPU during your session, by clicking on the hamburger menu (3 dots in the top right) and clicking “Accelerator” – it should look like this:\n!\nWe’ll need slightly different code depending on whether we’re running on Kaggle or not, so we’ll use this variable to track where we are:\n\nimport os\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n\n\n\n\nKaggle limits your weekly time using a GPU machine. The limits are very generous, but you may well still find it’s not enough! In that case, you’ll want to use your own GPU server, or a cloud server such as Colab, Paperspace Gradient, or SageMaker Studio Lab (all of which have free options). To do so, you’ll need to be able to download Kaggle datasets.\nThe easiest way to download Kaggle datasets is to use the Kaggle API. You can install this using pip by running this in a notebook cell:\n!pip install kaggle\nYou need an API key to use the Kaggle API; to get one, click on your profile picture on the Kaggle website, and choose My Account, then click Create New API Token. This will save a file called kaggle.json to your PC. You need to copy this key on your GPU server. To do so, open the file you downloaded, copy the contents, and paste them in the following cell (e.g., creds = '{\"username\":\"xxx\",\"key\":\"xxx\"}'):\n\ncreds = ''\n\nThen execute this cell (this only needs to be run once):\n\n# for working with paths in Python, I recommend using `pathlib.Path`\nfrom pathlib import Path\n\ncred_path = Path('~/.kaggle/kaggle.json').expanduser()\nif not cred_path.exists():\n    cred_path.parent.mkdir(exist_ok=True)\n    cred_path.write_text(creds)\n    cred_path.chmod(0o600)\n\nNow you can download datasets from Kaggle.\n\npath = Path('us-patent-phrase-to-phrase-matching')\n\nAnd use the Kaggle API to download the dataset to that path, and extract it:\n\nif not iskaggle and not path.exists():\n    import zipfile,kaggle\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f'{path}.zip').extractall(path)\n\nNote that you can easily download notebooks from Kaggle and upload them to other cloud services. So if you’re low on Kaggle GPU credits, give this a try!"
  },
  {
    "objectID": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html#import-and-eda",
    "href": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html#import-and-eda",
    "title": "0015_getting_started_with_nlp_for_absolute_beginner",
    "section": "Import and EDA",
    "text": "Import and EDA\n\nif iskaggle:\n    path = Path('../input/us-patent-phrase-to-phrase-matching')\n    ! pip install -q datasets\n\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n\n\nDocuments in NLP datasets are generally in one of two main forms:\n\nLarger documents: One text file per document, often organised into one folder per category\nSmaller documents: One document (or document pair, optionally with metadata) per row in a CSV file.\n\nLet’s look at our data and see what we’ve got. In Jupyter you can use any bash/shell command by starting a line with a !, and use {} to include python variables, like so:\n\n!ls {path}\n\nsample_submission.csv  test.csv  train.csv\n\n\nIt looks like this competition uses CSV files. For opening, manipulating, and viewing CSV files, it’s generally best to use the Pandas library, which is explained brilliantly in this book by the lead developer (it’s also an excellent introduction to matplotlib and numpy, both of which I use in this notebook). Generally it’s imported as the abbreviation pd.\n\nimport pandas as pd\n\nLet’s set a path to our data:\n\ndf = pd.read_csv(path/'train.csv')\n\nThis creates a DataFrame, which is a table of named columns, a bit like a database table. To view the first and last rows, and row count of a DataFrame, just type its name:\n\ndf\n\n\n\n\n\n  \n    \n      \n      id\n      anchor\n      target\n      context\n      score\n    \n  \n  \n    \n      0\n      37d61fd2272659b1\n      abatement\n      abatement of pollution\n      A47\n      0.50\n    \n    \n      1\n      7b9652b17b68b7a4\n      abatement\n      act of abating\n      A47\n      0.75\n    \n    \n      2\n      36d72442aefd8232\n      abatement\n      active catalyst\n      A47\n      0.25\n    \n    \n      3\n      5296b0c19e1ce60e\n      abatement\n      eliminating process\n      A47\n      0.50\n    \n    \n      4\n      54c1e3b9184cb5b6\n      abatement\n      forest region\n      A47\n      0.00\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      36468\n      8e1386cbefd7f245\n      wood article\n      wooden article\n      B44\n      1.00\n    \n    \n      36469\n      42d9e032d1cd3242\n      wood article\n      wooden box\n      B44\n      0.50\n    \n    \n      36470\n      208654ccb9e14fa3\n      wood article\n      wooden handle\n      B44\n      0.50\n    \n    \n      36471\n      756ec035e694722b\n      wood article\n      wooden material\n      B44\n      0.75\n    \n    \n      36472\n      8d135da0b55b8c88\n      wood article\n      wooden substrate\n      B44\n      0.50\n    \n  \n\n36473 rows × 5 columns\n\n\n\nIt’s important to carefully read the dataset description to understand how each of these columns is used.\nOne of the most useful features of DataFrame is the describe() method:\n\ndf.describe(include='object')\n\n\n\n\n\n  \n    \n      \n      id\n      anchor\n      target\n      context\n    \n  \n  \n    \n      count\n      36473\n      36473\n      36473\n      36473\n    \n    \n      unique\n      36473\n      733\n      29340\n      106\n    \n    \n      top\n      37d61fd2272659b1\n      component composite coating\n      composition\n      H01\n    \n    \n      freq\n      1\n      152\n      24\n      2186\n    \n  \n\n\n\n\nWe can see that in the 36473 rows, there are 733 unique anchors, 106 contexts, and nearly 30000 targets. Some anchors are very common, with “component composite coating” for instance appearing 152 times.\nEarlier, I suggested we could represent the input to the model as something like “TEXT1: abatement; TEXT2: eliminating process”. We’ll need to add the context to this too. In Pandas, we just use + to concatenate, like so:\n\ndf['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor\n\nWe can refer to a column (also known as a series) either using regular python “dotted” notation, or access it like a dictionary. To get the first few rows, use head():\n\ndf.input.head()\n\n0    TEXT1: A47; TEXT2: abatement of pollution; ANC...\n1    TEXT1: A47; TEXT2: act of abating; ANC1: abate...\n2    TEXT1: A47; TEXT2: active catalyst; ANC1: abat...\n3    TEXT1: A47; TEXT2: eliminating process; ANC1: ...\n4    TEXT1: A47; TEXT2: forest region; ANC1: abatement\nName: input, dtype: object"
  },
  {
    "objectID": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html#tokenization",
    "href": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html#tokenization",
    "title": "0015_getting_started_with_nlp_for_absolute_beginner",
    "section": "Tokenization",
    "text": "Tokenization\nTransformers uses a Dataset object for storing a… well a dataset, of course! We can create one like so:\n\nfrom datasets import Dataset,DatasetDict\n\nds = Dataset.from_pandas(df)\n\nHere’s how it’s displayed in a notebook:\n\nds\n\nDataset({\n    features: ['id', 'anchor', 'target', 'context', 'score', 'input'],\n    num_rows: 36473\n})\n\n\nBut we can’t pass the texts directly into a model. A deep learning model expects numbers as inputs, not English sentences! So we need to do two things:\n\nTokenization: Split each text up into words (or actually, as we’ll see, into tokens)\nNumericalization: Convert each word (or token) into a number.\n\nThe details about how this is done actually depend on the particular model we use. So first we’ll need to pick a model. There are thousands of models available, but a reasonable starting point for nearly any NLP problem is to use this (replace “small” with “large” for a slower but more accurate model, once you’ve finished exploring):\n\nmodel_nm = 'microsoft/deberta-v3-small'\n\nAutoTokenizer will create a tokenizer appropriate for a given model:\n\nfrom transformers import AutoModelForSequenceClassification,AutoTokenizer\ntokz = AutoTokenizer.from_pretrained(model_nm)\n\n\n\n\n\n\n\n\n\n\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n\n\nHere’s an example of how the tokenizer splits a text into “tokens” (which are like words, but can be sub-word pieces, as you see below):\n\ntokz.tokenize(\"G'day folks, I'm Jeremy from fast.ai!\")\n\n['▁G',\n \"'\",\n 'day',\n '▁folks',\n ',',\n '▁I',\n \"'\",\n 'm',\n '▁Jeremy',\n '▁from',\n '▁fast',\n '.',\n 'ai',\n '!']\n\n\nUncommon words will be split into pieces. The start of a new word is represented by ▁:\n\ntokz.tokenize(\"A platypus is an ornithorhynchus anatinus.\")\n\n['▁A',\n '▁platypus',\n '▁is',\n '▁an',\n '▁or',\n 'ni',\n 'tho',\n 'rhynch',\n 'us',\n '▁an',\n 'at',\n 'inus',\n '.']\n\n\nHere’s a simple function which tokenizes our inputs:\n\ndef tok_func(x): return tokz(x[\"input\"])\n\nTo run this quickly in parallel on every row in our dataset, use map:\n\ntok_ds = ds.map(tok_func, batched=True)\n\n\n\n\nThis adds a new item to our dataset called input_ids. For instance, here is the input and IDs for the first row of our data:\n\nrow = tok_ds[0]\nrow['input'], row['input_ids']\n\n('TEXT1: A47; TEXT2: abatement of pollution; ANC1: abatement',\n [1,\n  54453,\n  435,\n  294,\n  336,\n  5753,\n  346,\n  54453,\n  445,\n  294,\n  47284,\n  265,\n  6435,\n  346,\n  23702,\n  435,\n  294,\n  47284,\n  2])\n\n\nSo, what are those IDs and where do they come from? The secret is that there’s a list called vocab in the tokenizer which contains a unique integer for every possible token string. We can look them up like this, for instance to find the token for the word “of”:\n\ntokz.vocab['▁of']\n\n265\n\n\nLooking above at our input IDs, we do indeed see that 265 appears as expected.\nFinally, we need to prepare our labels. Transformers always assumes that your labels has the column name labels, but in our dataset it’s currently score. Therefore, we need to rename it:\n\ntok_ds = tok_ds.rename_columns({'score':'labels'})\n\nNow that we’ve prepared our tokens and labels, we need to create our validation set."
  },
  {
    "objectID": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html#test-and-validation-sets",
    "href": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html#test-and-validation-sets",
    "title": "0015_getting_started_with_nlp_for_absolute_beginner",
    "section": "Test and validation sets",
    "text": "Test and validation sets\nYou may have noticed that our directory contained another file:\n\neval_df = pd.read_csv(path/'test.csv')\neval_df.describe()\n\n\n\n\n\n  \n    \n      \n      id\n      anchor\n      target\n      context\n    \n  \n  \n    \n      count\n      36\n      36\n      36\n      36\n    \n    \n      unique\n      36\n      34\n      36\n      29\n    \n    \n      top\n      4112d61851461f60\n      el display\n      inorganic photoconductor drum\n      G02\n    \n    \n      freq\n      1\n      2\n      1\n      3\n    \n  \n\n\n\n\nThis is the test set. Possibly the most important idea in machine learning is that of having separate training, validation, and test data sets.\n\nValidation set\nTo explain the motivation, let’s start simple, and imagine we’re trying to fit a model where the true relationship is this quadratic:\n\ndef f(x): return -3*x**2 + 2*x + 20\n\nUnfortunately matplotlib (the most common library for plotting in Python) doesn’t come with a way to visualize a function, so we’ll write something to do this ourselves:\n\nimport numpy as np, matplotlib.pyplot as plt\n\ndef plot_function(f, min=-2.1, max=2.1, color='r'):\n    x = np.linspace(min,max, 100)[:,None]\n    plt.plot(x, f(x), color)\n\nHere’s what our function looks like:\n\nplot_function(f)\n\n\n\n\nFor instance, perhaps we’ve measured the height above ground of an object before and after some event. The measurements will have some random error. We can use numpy’s random number generator to simulate that. I like to use seed when writing about simulations like this so that I know you’ll see the same thing I do:\n\nfrom numpy.random import normal,seed,uniform\nnp.random.seed(42)\n\nHere’s a function add_noise that adds some random variation to an array:\n\ndef noise(x, scale): return normal(scale=scale, size=x.shape)\ndef add_noise(x, mult, add): return x * (1+noise(x,mult)) + noise(x,add)\n\nLet’s use it to simulate some measurements evenly distributed over time:\n\nx = np.linspace(-2, 2, num=20)[:,None]\ny = add_noise(f(x), 0.2, 1.3)\nplt.scatter(x,y);\n\n\n\n\nNow let’s see what happens if we underfit or overfit these predictions. To do that, we’ll create a function that fits a polynomial of some degree (e.g. a line is degree 1, quadratic is degree 2, cubic is degree 3, etc). The details of how this function works don’t matter too much so feel free to skip over it if you like! (PS: if you’re not sure about the jargon around polynomials, here’s a great video which teaches you what you’ll need to know.)\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\n\ndef plot_poly(degree):\n    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n    model.fit(x, y)\n    plt.scatter(x,y)\n    plot_function(model.predict)\n\nSo, what happens if we fit a line (a “degree 1 polynomial”) to our measurements?\n\nplot_poly(1)\n\n\n\n\nAs you see, the points on the red line (the line we fitted) aren’t very close at all. This is under-fit – there’s not enough detail in our function to match our data.\nAnd what happens if we fit a degree 10 polynomial to our measurements?\n\nplot_poly(10)\n\n\n\n\nWell now it fits our data better, but it doesn’t look like it’ll do a great job predicting points other than those we measured – especially those in earlier or later time periods. This is over-fit – there’s too much detail such that the model fits our points, but not the underlying process we really care about.\nLet’s try a degree 2 polynomial (a quadratic), and compare it to our “true” function (in blue):\n\nplot_poly(2)\nplot_function(f, color='b')\n\n\n\n\nThat’s not bad at all!\nSo, how do we recognise whether our models are under-fit, over-fit, or “just right”? We use a validation set. This is a set of data that we “hold out” from training – we don’t let our model see it at all. If you use the fastai library, it automatically creates a validation set for you if you don’t have one, and will always report metrics (measurements of the accuracy of a model) using the validation set.\nThe validation set is only ever used to see how we’re doing. It’s never used as inputs to training the model.\nTransformers uses a DatasetDict for holding your training and validation sets. To create one that contains 25% of our data for the validation set, and 75% for the training set, use train_test_split:\n\ndds = tok_ds.train_test_split(0.25, seed=42)\ndds\n\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 27354\n    })\n    test: Dataset({\n        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 9119\n    })\n})\n\n\nAs you see above, the validation set here is called test and not validate, so be careful!\nIn practice, a random split like we’ve used here might not be a good idea – here’s what Dr Rachel Thomas has to say about it:\n\n“One of the most likely culprits for this disconnect between results in development vs results in production is a poorly chosen validation set (or even worse, no validation set at all). Depending on the nature of your data, choosing a validation set can be the most important step. Although sklearn offers a train_test_split method, this method takes a random subset of the data, which is a poor choice for many real-world problems.”\n\nI strongly recommend reading her article How (and why) to create a good validation set to more fully understand this critical topic.\n\n\nTest set\nSo that’s the validation set explained, and created. What about the “test set” then – what’s that for?\nThe test set is yet another dataset that’s held out from training. But it’s held out from reporting metrics too! The accuracy of your model on the test set is only ever checked after you’ve completed your entire training process, including trying different models, training methods, data processing, etc.\nYou see, as you try all these different things, to see their impact on the metrics on the validation set, you might just accidentally find a few things that entirely coincidentally improve your validation set metrics, but aren’t really better in practice. Given enough time and experiments, you’ll find lots of these coincidental improvements. That means you’re actually over-fitting to your validation set!\nThat’s why we keep a test set held back. Kaggle’s public leaderboard is like a test set that you can check from time to time. But don’t check too often, or you’ll be even over-fitting to the test set!\nKaggle has a second test set, which is yet another held-out dataset that’s only used at the end of the competition to assess your predictions. That’s called the “private leaderboard”. Here’s a great post about what can happen if you overfit to the public leaderboard.\nWe’ll use eval as our name for the test set, to avoid confusion with the test dataset that was created above.\n\neval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\neval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)"
  },
  {
    "objectID": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html#metrics-and-correlation",
    "href": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html#metrics-and-correlation",
    "title": "0015_getting_started_with_nlp_for_absolute_beginner",
    "section": "Metrics and correlation",
    "text": "Metrics and correlation\nWhen we’re training a model, there will be one or more metrics that we’re interested in maximising or minimising. These are the measurements that should, hopefully, represent how well our model will works for us.\nIn real life, outside of Kaggle, things not easy… As my partner Dr Rachel Thomas notes in The problem with metrics is a big problem for AI:\n\nAt their heart, what most current AI approaches do is to optimize metrics. The practice of optimizing metrics is not new nor unique to AI, yet AI can be particularly efficient (even too efficient!) at doing so. This is important to understand, because any risks of optimizing metrics are heightened by AI. While metrics can be useful in their proper place, there are harms when they are unthinkingly applied. Some of the scariest instances of algorithms run amok all result from over-emphasizing metrics. We have to understand this dynamic in order to understand the urgent risks we are facing due to misuse of AI.\n\nIn Kaggle, however, it’s very straightforward to know what metric to use: Kaggle will tell you! According to this competition’s evaluation page, “submissions are evaluated on the Pearson correlation coefficient between the predicted and actual similarity scores.” This coefficient is usually abbreviated using the single letter r. It is the most widely used measure of the degree of relationship between two variables.\nr can vary between -1, which means perfect inverse correlation, and +1, which means perfect positive correlation. The mathematical formula for it is much less important than getting a good intuition for what the different values look like. To start to get that intuition, let’s look at some examples using the California Housing dataset, which shows “is the median house value for California districts, expressed in hundreds of thousands of dollars”. This dataset is provided by the excellent scikit-learn library, which is the most widely used library for machine learning outside of deep learning.\n\nfrom sklearn.datasets import fetch_california_housing\nhousing = fetch_california_housing(as_frame=True)\nhousing = housing['data'].join(housing['target']).sample(1000, random_state=52)\nhousing.head()\n\n\n\n\n\n  \n    \n      \n      MedInc\n      HouseAge\n      AveRooms\n      AveBedrms\n      Population\n      AveOccup\n      Latitude\n      Longitude\n      MedHouseVal\n    \n  \n  \n    \n      7506\n      3.0550\n      37.0\n      5.152778\n      1.048611\n      729.0\n      5.062500\n      33.92\n      -118.28\n      1.054\n    \n    \n      4720\n      3.0862\n      35.0\n      4.697897\n      1.055449\n      1159.0\n      2.216061\n      34.05\n      -118.37\n      3.453\n    \n    \n      12888\n      2.5556\n      24.0\n      4.864905\n      1.129222\n      1631.0\n      2.395007\n      38.66\n      -121.35\n      1.057\n    \n    \n      13344\n      3.0057\n      32.0\n      4.212687\n      0.936567\n      1378.0\n      5.141791\n      34.05\n      -117.64\n      0.969\n    \n    \n      7173\n      1.9083\n      42.0\n      3.888554\n      1.039157\n      1535.0\n      4.623494\n      34.05\n      -118.19\n      1.192\n    \n  \n\n\n\n\nWe can see all the correlation coefficients for every combination of columns in this dataset by calling np.corrcoef:\n\nnp.set_printoptions(precision=2, suppress=True)\n\nnp.corrcoef(housing, rowvar=False)\n\narray([[ 1.  , -0.12,  0.43, -0.08,  0.01, -0.07, -0.12,  0.04,  0.68],\n       [-0.12,  1.  , -0.17, -0.06, -0.31,  0.  ,  0.03, -0.13,  0.12],\n       [ 0.43, -0.17,  1.  ,  0.76, -0.09, -0.07,  0.12, -0.03,  0.21],\n       [-0.08, -0.06,  0.76,  1.  , -0.08, -0.07,  0.09,  0.  , -0.04],\n       [ 0.01, -0.31, -0.09, -0.08,  1.  ,  0.16, -0.15,  0.13,  0.  ],\n       [-0.07,  0.  , -0.07, -0.07,  0.16,  1.  , -0.16,  0.17, -0.27],\n       [-0.12,  0.03,  0.12,  0.09, -0.15, -0.16,  1.  , -0.93, -0.16],\n       [ 0.04, -0.13, -0.03,  0.  ,  0.13,  0.17, -0.93,  1.  , -0.03],\n       [ 0.68,  0.12,  0.21, -0.04,  0.  , -0.27, -0.16, -0.03,  1.  ]])\n\n\nThis works well when we’re getting a bunch of values at once, but it’s overkill when we want a single coefficient:\n\nnp.corrcoef(housing.MedInc, housing.MedHouseVal)\n\narray([[1.  , 0.68],\n       [0.68, 1.  ]])\n\n\nTherefore, we’ll create this little function to just return the single number we need given a pair of variables:\n\ndef corr(x,y): return np.corrcoef(x,y)[0][1]\n\ncorr(housing.MedInc, housing.MedHouseVal)\n\n0.6760250732906\n\n\nNow we’ll look at a few examples of correlations, using this function (the details of the function don’t matter too much):\n\ndef show_corr(df, a, b):\n    x,y = df[a],df[b]\n    plt.scatter(x,y, alpha=0.5, s=4)\n    plt.title(f'{a} vs {b}; r: {corr(x, y):.2f}')\n\nOK, let’s check out the correlation between income and house value:\n\nshow_corr(housing, 'MedInc', 'MedHouseVal')\n\n\n\n\nSo that’s what a correlation of 0.68 looks like. It’s quite a close relationship, but there’s still a lot of variation. (Incidentally, this also shows why looking at your data is so important – we can see clearly in this plot that house prices above $500,000 seem to have been truncated to that maximum value).\nLet’s take a look at another pair:\n\nshow_corr(housing, 'MedInc', 'AveRooms')\n\n\n\n\nThe relationship looks like it is similarly close to the previous example, but r is much lower than the income vs valuation case. Why is that? The reason is that there are a lot of outliers – values of AveRooms well outside the mean.\nr is very sensitive to outliers. If there’s outliers in your data, then the relationship between them will dominate the metric. In this case, the houses with a very high number of rooms don’t tend to be that valuable, so it’s decreasing r from where it would otherwise be.\nLet’s remove the outliers and try again:\n\nsubset = housing[housing.AveRooms<15]\nshow_corr(subset, 'MedInc', 'AveRooms')\n\n\n\n\nAs we expected, now the correlation is very similar to our first comparison.\nHere’s another relationship using AveRooms on the subset:\n\nshow_corr(subset, 'MedHouseVal', 'AveRooms')\n\n\n\n\nAt this level, with r of 0.34, the relationship is becoming quite weak.\nLet’s look at one more:\n\nshow_corr(subset, 'HouseAge', 'AveRooms')\n\n\n\n\nAs you see here, a correlation of -0.2 shows a very weak negative trend.\nWe’ve seen now examples of a variety of levels of correlation coefficient, so hopefully you’re getting a good sense of what this metric means.\nTransformers expects metrics to be returned as a dict, since that way the trainer knows what label to use, so let’s create a function to do that:\n\ndef corr_d(eval_pred): return {'pearson': corr(*eval_pred)}"
  },
  {
    "objectID": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html#training",
    "href": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html#training",
    "title": "0015_getting_started_with_nlp_for_absolute_beginner",
    "section": "Training",
    "text": "Training"
  },
  {
    "objectID": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html#training-our-model",
    "href": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html#training-our-model",
    "title": "0015_getting_started_with_nlp_for_absolute_beginner",
    "section": "Training our model",
    "text": "Training our model\nTo train a model in Transformers we’ll need this:\n\nfrom transformers import TrainingArguments,Trainer\n\nWe pick a batch size that fits our GPU, and small number of epochs so we can run experiments quickly:\n\nbs = 128\nepochs = 4\n\nThe most important hyperparameter is the learning rate. fastai provides a learning rate finder to help you figure this out, but Transformers doesn’t, so you’ll just have to use trial and error. The idea is to find the largest value you can, but which doesn’t result in training failing.\n\nlr = 8e-5\n\nTransformers uses the TrainingArguments class to set up arguments. Don’t worry too much about the values we’re using here – they should generally work fine in most cases. It’s just the 3 parameters above that you may need to change for different models.\n\nargs = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\n\nWe can now create our model, and Trainer, which is a class which combines the data and model together (just like Learner in fastai):\n\nmodel = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\ntrainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                  tokenizer=tokz, compute_metrics=corr_d)\n\n\n\n\nSome weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias']\n- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['pooler.dense.weight', 'classifier.bias', 'pooler.dense.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nUsing amp half precision backend\n\n\nAs you see, Transformers spits out lots of warnings. You can safely ignore them.\nLet’s train our model!\n\ntrainer.train();\n\nThe following columns in the training set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, id, target, anchor, input.\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 27354\n  Num Epochs = 4\n  Instantaneous batch size per device = 128\n  Total train batch size (w. parallel, distributed & accumulation) = 128\n  Gradient Accumulation steps = 1\n  Total optimization steps = 856\n/opt/conda/lib/python3.7/site-packages/transformers/trainer.py:1410: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n  args.max_grad_norm,\n\n\n\n\n    \n      \n      \n      [856/856 04:58, Epoch 4/4]\n    \n    \n  \n \n      Epoch\n      Training Loss\n      Validation Loss\n      Pearson\n    \n  \n  \n    \n      1\n      No log\n      0.024492\n      0.800443\n    \n    \n      2\n      No log\n      0.022003\n      0.826113\n    \n    \n      3\n      0.041600\n      0.021423\n      0.834453\n    \n    \n      4\n      0.041600\n      0.022275\n      0.834767\n    \n  \n\n\n\nThe following columns in the evaluation set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, id, target, anchor, input.\n***** Running Evaluation *****\n  Num examples = 9119\n  Batch size = 256\nThe following columns in the evaluation set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, id, target, anchor, input.\n***** Running Evaluation *****\n  Num examples = 9119\n  Batch size = 256\nSaving model checkpoint to outputs/checkpoint-500\nConfiguration saved in outputs/checkpoint-500/config.json\nModel weights saved in outputs/checkpoint-500/pytorch_model.bin\ntokenizer config file saved in outputs/checkpoint-500/tokenizer_config.json\nSpecial tokens file saved in outputs/checkpoint-500/special_tokens_map.json\nadded tokens file saved in outputs/checkpoint-500/added_tokens.json\nThe following columns in the evaluation set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, id, target, anchor, input.\n***** Running Evaluation *****\n  Num examples = 9119\n  Batch size = 256\nThe following columns in the evaluation set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, id, target, anchor, input.\n***** Running Evaluation *****\n  Num examples = 9119\n  Batch size = 256\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n\n\nLots more warning from Transformers again – you can ignore these as before.\nThe key thing to look at is the “Pearson” value in table above. As you see, it’s increasing, and is already above 0.8. That’s great news! We can now submit our predictions to Kaggle if we want them to be scored on the official leaderboard. Let’s get some predictions on the test set:\n\npreds = trainer.predict(eval_ds).predictions.astype(float)\npreds\n\nThe following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, id, target, anchor, input.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 256\n\n\n\n    \n      \n      \n      [1/1 : < :]\n    \n    \n\n\narray([[ 0.51],\n       [ 0.65],\n       [ 0.5 ],\n       [ 0.32],\n       [-0.04],\n       [ 0.52],\n       [ 0.52],\n       [ 0.07],\n       [ 0.28],\n       [ 1.11],\n       [ 0.25],\n       [ 0.22],\n       [ 0.71],\n       [ 0.88],\n       [ 0.73],\n       [ 0.41],\n       [ 0.33],\n       [ 0.  ],\n       [ 0.69],\n       [ 0.35],\n       [ 0.4 ],\n       [ 0.25],\n       [ 0.12],\n       [ 0.27],\n       [ 0.56],\n       [-0.  ],\n       [-0.03],\n       [-0.01],\n       [-0.03],\n       [ 0.59],\n       [ 0.29],\n       [ 0.03],\n       [ 0.74],\n       [ 0.57],\n       [ 0.46],\n       [ 0.21]])\n\n\nLook out - some of our predictions are <0, or >1! This once again shows the value of remember to actually look at your data. Let’s fix those out-of-bounds predictions:\n\npreds = np.clip(preds, 0, 1)\n\n\npreds\n\narray([[0.51],\n       [0.65],\n       [0.5 ],\n       [0.32],\n       [0.  ],\n       [0.52],\n       [0.52],\n       [0.07],\n       [0.28],\n       [1.  ],\n       [0.25],\n       [0.22],\n       [0.71],\n       [0.88],\n       [0.73],\n       [0.41],\n       [0.33],\n       [0.  ],\n       [0.69],\n       [0.35],\n       [0.4 ],\n       [0.25],\n       [0.12],\n       [0.27],\n       [0.56],\n       [0.  ],\n       [0.  ],\n       [0.  ],\n       [0.  ],\n       [0.59],\n       [0.29],\n       [0.03],\n       [0.74],\n       [0.57],\n       [0.46],\n       [0.21]])\n\n\nOK, now we’re ready to create our submission file. If you save a CSV in your notebook, you will get the option to submit it later.\n\nimport datasets\n\nsubmission = datasets.Dataset.from_dict({\n    'id': eval_ds['id'],\n    'score': preds\n})\n\nsubmission.to_csv('submission.csv', index=False)\n\n\n\n\n857\n\n\nUnfortunately this is a code competition and internet access is disabled. That means the pip install datasets command we used above won’t work if you want to submit to Kaggle. To fix this, you’ll need to download the pip installers to Kaggle first, as described here. Once you’ve done that, disable internet in your notebook, go to the Kaggle leaderboards page, and click the Submission button."
  },
  {
    "objectID": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html#the-end",
    "href": "fastai_notebooks/getting_started_with_nlp_for_absolute_beginner.html#the-end",
    "title": "0015_getting_started_with_nlp_for_absolute_beginner",
    "section": "The end",
    "text": "The end\nOnce you’re ready to go deeper, take a look at my Iterate Like a Grandmaster notebook.\nThanks for reading! This has been a bit of an experiment for me – I’ve never done an “absolute beginners” guide before on Kaggle. I hope you like it! If you do, I’d greatly appreciate an upvote. Don’t hesitate to add a comment if you have any questions or thoughts to add."
  },
  {
    "objectID": "fastai_notebooks/best_vision_models_for_fine_tuning.html",
    "href": "fastai_notebooks/best_vision_models_for_fine_tuning.html",
    "title": "0013_best_vision_models_for_fine_tuning",
    "section": "",
    "text": "In a recent notebook I tried to answer the question “Which image models are best?” This showed which models in Ross Wightman’s PyTorch Image Models (timm) were the fastest and most accurate for training from scratch with Imagenet.\nHowever, this is not what most of us use models for. Most of us fine-tune pretrained models. Therefore, what most of us really want to know is which models are the fastest and most accurate for fine-tuning. However, this analysis has not, to my knowledge, previously existed.\nTherefore I teamed up with Thomas Capelle of Weights and Biases to answer this question. In this notebook, I present our results."
  },
  {
    "objectID": "fastai_notebooks/best_vision_models_for_fine_tuning.html#the-analysis",
    "href": "fastai_notebooks/best_vision_models_for_fine_tuning.html#the-analysis",
    "title": "0013_best_vision_models_for_fine_tuning",
    "section": "The analysis",
    "text": "The analysis\n\nhow to evaluate or compare models for fine tuning\nThere are two key dimensions on which datasets can vary when it comes to how well they fine-tune a model:\n\nHow similar they are to the pre-trained model’s dataset\nHow large they are.\n\nTherefore, we decided to test on two datasets that were very different on both of these axes. We tested pre-trained models that were trained on Imagenet, and tested fine-tuning on two different datasets:\n\nThe Oxford IIT-Pet Dataset, which is very similar to Imagenet. Imagenet contains many pictures of animals, and each picture is a photo in which the animal is the main subject. IIT-Pet contains nearly 15,000 images, that are also of this type.\nThe Kaggle Planet sample contains 1,000 satellite images of Earth. There are no images of this kind in Imagenet.\n\nSo these two datasets are of very different sizes, and very different in terms of their similarity to Imagenet. Furthermore, they have different types of labels - Planet is a multi-label problem, whereas IIT-Pet is a single label problem.\n\n\nhow to use Weights and Biases with fastai\nTo test the fine-tuning accuracy of different models, Thomas put together this script. The basic script contains the standard 4 lines of code needed for fastai image recognition models, plus some code to handle various configuration options, such as learning rate and batch size. It was particularly easy to handle in fastai since fastai supports all timm models directly.\nThen, to allow us to easily try different configuration options, Thomas created Weights and Biases (wandb) YAML files such as this one. This takes advantage of the convenient wandb “sweeps” feature which tries a range of different levels of a model input and tracks the results.\nwandb makes it really easy for a group of people to run these kinds of analyses on whatever GPUs they have access to. When you create a sweep using the command-line wandb client, it gives you a command to run to have a computer run experiments for the project. You run that same command on each computer where you want to run experiments. The wandb client automatically ensures that each computer runs different parts of the sweep, and has each on report back its results to the wandb server. You can look at the progress in the wandb web GUI at any time during or after the run. I’ve got three GPUs in my PC at home, so I ran three copies of the client, with each using a different GPU. Thomas also ran the client on a Paperspace Gradient server.\nI liked this approach because I could start and stop the clients any time I wanted, and wandb would automatically handle keeping all the results in sync. When I restarted a client, it would automatically grab from the server whatever the next set of sweep settings were needed. Furthermore, the integration in fastai is really exceptional, thanks particularly to Boris Dayma, who worked tirelessly to ensure that wandb automatically tracks every aspect of all fastai data processing, model architectures, and optimisation."
  },
  {
    "objectID": "fastai_notebooks/best_vision_models_for_fine_tuning.html#hyperparameters",
    "href": "fastai_notebooks/best_vision_models_for_fine_tuning.html#hyperparameters",
    "title": "0013_best_vision_models_for_fine_tuning",
    "section": "Hyperparameters",
    "text": "Hyperparameters\n\nhow to decide hyperparameters to create all the possible and meaningful models for testing\nWe decided to try out all the timm models which had reasonable performance on timm, and which are capable of working with 224x224 px images. We ended up with a list of 86 models and variants to try.\nOur first step was to find a good set of hyper-parameters for each model variant and for each dataset. Our experience at fast.ai has been that there’s generally not much difference between models and datasets in terms of what hyperparameter settings work well – and that experience was repeated in this project. Based on some initial sweeps across a smaller number of representative models, on which we found little variation in optimal hyperparameters, in our final sweep we included all combinations of the following options:\n\nLearning rate (AdamW): 0.008 and 0.02\nResize method: Squish\nPooling type: Concat and Average Pooling\n\nFor other parameters, we used defaults that we’ve previously found at fast.ai to be reliable across a range of models and datasets (see the fastai docs for details)."
  },
  {
    "objectID": "fastai_notebooks/best_vision_models_for_fine_tuning.html#analysis",
    "href": "fastai_notebooks/best_vision_models_for_fine_tuning.html#analysis",
    "title": "0013_best_vision_models_for_fine_tuning",
    "section": "Analysis",
    "text": "Analysis\n\nhow to analyse the sweep results from W&B\nLet’s take a look at the data. I’ve put a CSV of the results into a gist:\n\nfrom fastai.vision.all import *\nimport plotly.express as px\n\nurl = 'https://gist.githubusercontent.com/jph00/959aaf8695e723246b5e21f3cd5deb02/raw/sweep.csv'\n\nFor each model variant and dataset, for each hyperparameter setting, we did three runs. For the final sweep, we just used the hyperparameter settings listed above.\nFor each model variant and dataset, I create a group with the minimum error and fit time, and GPU memory use if used. I use the minimum because there might be some reason that a particular run didn’t do so well (e.g. maybe there was some resource contention), and I’m mainly interested in knowing what the best case results for a model can be.\nI create a “score” which, somewhat arbitrarily combines the accuracy and speed into a single number. I tried a few options until I came up with something that closely matched my own opinions about the tradeoffs between the two. (Feel free of course to fork this notebook and adjust how that’s calculated.)\n\ndf = pd.read_csv(url)\ndf['family'] = df.model_name.str.extract('^([a-z]+?(?:v2)?)(?:\\d|_|$)')\ndf.loc[df.family=='swinv2', 'family'] = 'swin'\npt_all = df.pivot_table(values=['error_rate','fit_time','GPU_mem'], index=['dataset', 'family', 'model_name'],\n                        aggfunc=np.min).reset_index()\npt_all['score'] = pt_all.error_rate*(pt_all.fit_time+80)\n\n\n\nIIT Pet\nHere’s the top 15 models on the IIT Pet dataset, ordered by score:\n\npt = pt_all[pt_all.dataset=='pets'].sort_values('score').reset_index(drop=True)\npt.head(15)\n\n\n\n\n\n  \n    \n      \n      dataset\n      family\n      model_name\n      GPU_mem\n      error_rate\n      fit_time\n      score\n    \n  \n  \n    \n      0\n      pets\n      convnext\n      convnext_tiny_in22k\n      2.660156\n      0.044655\n      94.557838\n      7.794874\n    \n    \n      1\n      pets\n      swin\n      swin_s3_tiny_224\n      3.126953\n      0.041949\n      112.282200\n      8.065961\n    \n    \n      2\n      pets\n      convnext\n      convnext_tiny\n      2.660156\n      0.047361\n      92.761599\n      8.182216\n    \n    \n      3\n      pets\n      vit\n      vit_small_r26_s32_224\n      3.367188\n      0.045332\n      103.240067\n      8.306554\n    \n    \n      4\n      pets\n      mobilevit\n      mobilevit_s\n      2.781250\n      0.046685\n      100.770686\n      8.439222\n    \n    \n      5\n      pets\n      resnetv2\n      resnetv2_50x1_bit_distilled\n      3.892578\n      0.047361\n      105.952172\n      8.806939\n    \n    \n      6\n      pets\n      vit\n      vit_small_patch16_224\n      2.111328\n      0.054804\n      80.739517\n      8.809135\n    \n    \n      7\n      pets\n      swin\n      swin_tiny_patch4_window7_224\n      2.796875\n      0.048038\n      105.797015\n      8.925296\n    \n    \n      8\n      pets\n      swin\n      swinv2_cr_tiny_ns_224\n      3.302734\n      0.042625\n      129.435368\n      8.927222\n    \n    \n      9\n      pets\n      resnetrs\n      resnetrs50\n      2.419922\n      0.047361\n      109.549398\n      8.977309\n    \n    \n      10\n      pets\n      levit\n      levit_384\n      1.699219\n      0.054127\n      86.199098\n      8.995895\n    \n    \n      11\n      pets\n      resnet\n      resnet26d\n      1.412109\n      0.060216\n      69.395598\n      8.996078\n    \n    \n      12\n      pets\n      convnext\n      convnext_tiny_hnf\n      2.970703\n      0.049391\n      103.014163\n      9.039269\n    \n    \n      13\n      pets\n      regnety\n      regnety_006\n      0.914062\n      0.052097\n      93.912189\n      9.060380\n    \n    \n      14\n      pets\n      levit\n      levit_256\n      1.031250\n      0.056157\n      82.682410\n      9.135755\n    \n  \n\n\n\n\nAs you can see, the convnext, swin, and vit families are fairly dominent. The excellent showing of convnext_tiny matches my view that we should think of this as our default baseline for image recognition today. It’s fast, accurate, and not too much of a memory hog. (And according to Ross Wightman, it could be even faster if NVIDIA and PyTorch make some changes to better optimise the operations it relies on!)\nvit_small_patch16 is also a good option – it’s faster and leaner on memory than convnext_tiny, although there is some performance cost too.\nInterestingly, resnets are still a great option – especially the resnet26d variant, which is the fastest in our top 15.\nHere’s a quick visual representation of the seven model families which look best in the above analysis (the “fit lines” are just there to help visually show where the different families are – they don’t necessarily actually follow a linear fit):\n\nw,h = 900,700\nfaves = ['vit','convnext','resnet','levit', 'regnetx', 'swin']\npt2 = pt[pt.family.isin(faves)]\npx.scatter(pt2, width=w, height=h, x='fit_time', y='error_rate', color='family', hover_name='model_name', trendline=\"ols\",)\n\n\n                                                \n\n\nThis chart shows that there’s a big drop-off in performance towards the far left. It seems like there’s a big compromise if we want the fastest possible model. It also seems that the best models in terms of accuracy, convnext and swin, aren’t able to make great use of the larger capacity of larger models. So an ensemble of smaller models may be effective in some situations.\nNote that vit doesn’t include any larger/slower models, since they only work with larger images. We would recommend trying larger models on your dataset if you have larger images and the resources to handle them.\nI particularly like using fast and small models, since I wanted to be able to iterate rapidly to try lots of ideas (see this notebook for more on this). Here’s the top models (based on accuracy) that are smaller and faster than the median model:\n\npt.query(\"(GPU_mem<2.7) & (fit_time<110)\").sort_values(\"error_rate\").head(15).reset_index(drop=True)\n\n\n\n\n\n  \n    \n      \n      dataset\n      family\n      model_name\n      GPU_mem\n      error_rate\n      fit_time\n      score\n    \n  \n  \n    \n      0\n      pets\n      convnext\n      convnext_tiny_in22k\n      2.660156\n      0.044655\n      94.557838\n      7.794874\n    \n    \n      1\n      pets\n      convnext\n      convnext_tiny\n      2.660156\n      0.047361\n      92.761599\n      8.182216\n    \n    \n      2\n      pets\n      resnetrs\n      resnetrs50\n      2.419922\n      0.047361\n      109.549398\n      8.977309\n    \n    \n      3\n      pets\n      regnety\n      regnety_006\n      0.914062\n      0.052097\n      93.912189\n      9.060380\n    \n    \n      4\n      pets\n      levit\n      levit_384\n      1.699219\n      0.054127\n      86.199098\n      8.995895\n    \n    \n      5\n      pets\n      vit\n      vit_small_patch16_224\n      2.111328\n      0.054804\n      80.739517\n      8.809135\n    \n    \n      6\n      pets\n      resnet\n      resnet50d\n      2.037109\n      0.055480\n      92.989515\n      9.597521\n    \n    \n      7\n      pets\n      levit\n      levit_256\n      1.031250\n      0.056157\n      82.682410\n      9.135755\n    \n    \n      8\n      pets\n      regnetx\n      regnetx_016\n      1.369141\n      0.059540\n      88.658087\n      10.041888\n    \n    \n      9\n      pets\n      resnet\n      resnet26d\n      1.412109\n      0.060216\n      69.395598\n      8.996078\n    \n    \n      10\n      pets\n      levit\n      levit_192\n      0.781250\n      0.060893\n      82.385787\n      9.888177\n    \n    \n      11\n      pets\n      resnetblur\n      resnetblur50\n      2.195312\n      0.061570\n      96.008735\n      10.836803\n    \n    \n      12\n      pets\n      mobilevit\n      mobilevit_xs\n      2.349609\n      0.062923\n      98.758011\n      11.247972\n    \n    \n      13\n      pets\n      vit\n      vit_tiny_patch16_224\n      1.074219\n      0.064276\n      65.670202\n      9.363104\n    \n    \n      14\n      pets\n      regnety\n      regnety_008\n      1.044922\n      0.064953\n      94.741903\n      11.349943\n    \n  \n\n\n\n\n…and here’s the top 15 models that are the very fastest and most memory efficient:\n\npt.query(\"(GPU_mem<1.6) & (fit_time<90)\").sort_values(\"error_rate\").head(15).reset_index(drop=True)\n\n\n\n\n\n  \n    \n      \n      dataset\n      family\n      model_name\n      GPU_mem\n      error_rate\n      fit_time\n      score\n    \n  \n  \n    \n      0\n      pets\n      levit\n      levit_256\n      1.031250\n      0.056157\n      82.682410\n      9.135755\n    \n    \n      1\n      pets\n      regnetx\n      regnetx_016\n      1.369141\n      0.059540\n      88.658087\n      10.041888\n    \n    \n      2\n      pets\n      resnet\n      resnet26d\n      1.412109\n      0.060216\n      69.395598\n      8.996078\n    \n    \n      3\n      pets\n      levit\n      levit_192\n      0.781250\n      0.060893\n      82.385787\n      9.888177\n    \n    \n      4\n      pets\n      vit\n      vit_tiny_patch16_224\n      1.074219\n      0.064276\n      65.670202\n      9.363104\n    \n    \n      5\n      pets\n      vit\n      vit_small_patch32_224\n      0.775391\n      0.065629\n      68.478869\n      9.744556\n    \n    \n      6\n      pets\n      efficientnet\n      efficientnet_es_pruned\n      1.507812\n      0.066306\n      69.601242\n      9.919432\n    \n    \n      7\n      pets\n      efficientnet\n      efficientnet_es\n      1.507812\n      0.066306\n      69.822634\n      9.934112\n    \n    \n      8\n      pets\n      resnet\n      resnet26\n      1.291016\n      0.067659\n      64.398096\n      9.769834\n    \n    \n      9\n      pets\n      resnet\n      resnet34\n      0.951172\n      0.070365\n      66.932345\n      10.338949\n    \n    \n      10\n      pets\n      resnet\n      resnet34d\n      1.056641\n      0.070365\n      71.631269\n      10.669590\n    \n    \n      11\n      pets\n      regnetx\n      regnetx_008\n      0.976562\n      0.070365\n      81.937185\n      11.394770\n    \n    \n      12\n      pets\n      regnetx\n      regnetx_006\n      0.730469\n      0.071042\n      78.592555\n      11.266723\n    \n    \n      13\n      pets\n      mobilevit\n      mobilevit_xxs\n      1.152344\n      0.073072\n      88.449456\n      12.308891\n    \n    \n      14\n      pets\n      levit\n      levit_128\n      0.650391\n      0.077808\n      82.819645\n      12.668646\n    \n  \n\n\n\n\nResNet-RS performs well here, with lower memory use than convnext but nonetheless high accuracy. A version trained on the larger Imagenet-22k dataset (like convnext_tiny_in22k would presumably do even better, and may top the charts!)\nRegNet-y is impressively miserly in terms of memory use, whilst still achieving high accuracy.\n\n\nPlanet\nHere’s the top-15 for Planet:\n\npt = pt_all[pt_all.dataset=='planet'].sort_values('score').reset_index(drop=True)\npt.head(15)\n\n\n\n\n\n  \n    \n      \n      dataset\n      family\n      model_name\n      GPU_mem\n      error_rate\n      fit_time\n      score\n    \n  \n  \n    \n      0\n      planet\n      vit\n      vit_small_patch16_224\n      2.121094\n      0.035000\n      20.075387\n      3.502641\n    \n    \n      1\n      planet\n      swin\n      swin_base_patch4_window7_224_in22k\n      6.283203\n      0.031177\n      37.115593\n      3.651255\n    \n    \n      2\n      planet\n      vit\n      vit_small_patch32_224\n      0.775391\n      0.038529\n      17.817797\n      3.768855\n    \n    \n      3\n      planet\n      convnext\n      convnext_tiny_in22k\n      2.660156\n      0.037647\n      22.014424\n      3.840538\n    \n    \n      4\n      planet\n      vit\n      vit_base_patch32_224\n      2.755859\n      0.038823\n      19.060116\n      3.845859\n    \n    \n      5\n      planet\n      swin\n      swinv2_cr_tiny_ns_224\n      3.302734\n      0.036176\n      26.547731\n      3.854518\n    \n    \n      6\n      planet\n      vit\n      vit_base_patch32_224_sam\n      2.755859\n      0.039412\n      18.567447\n      3.884713\n    \n    \n      7\n      planet\n      swin\n      swin_tiny_patch4_window7_224\n      2.796875\n      0.036765\n      25.790094\n      3.889339\n    \n    \n      8\n      planet\n      vit\n      vit_base_patch16_224_miil\n      4.853516\n      0.036471\n      28.131062\n      3.943604\n    \n    \n      9\n      planet\n      vit\n      vit_base_patch16_224\n      4.853516\n      0.036176\n      29.274090\n      3.953148\n    \n    \n      10\n      planet\n      convnext\n      convnext_small_in22k\n      4.210938\n      0.036471\n      28.446879\n      3.955122\n    \n    \n      11\n      planet\n      vit\n      vit_small_r26_s32_224\n      3.367188\n      0.038529\n      23.008444\n      3.968847\n    \n    \n      12\n      planet\n      vit\n      vit_tiny_patch16_224\n      1.070312\n      0.040588\n      18.103888\n      3.981860\n    \n    \n      13\n      planet\n      swin\n      swin_small_patch4_window7_224\n      4.486328\n      0.035588\n      31.928643\n      3.983339\n    \n    \n      14\n      planet\n      swin\n      swin_s3_tiny_224\n      3.126953\n      0.038235\n      24.459997\n      3.994054\n    \n  \n\n\n\n\nInterestingly, the results look quite different: vit and swin take most of the top positions in terms of the combination of accuracy and speed. vit_small_patch32 is a particular standout with its extremely low memory use and also the fastest in the top 15.\nBecause this dataset is so different to Imagenet, what we’re testing here is more about how quickly and data-efficiently a model can learn new features that it hasn’t seen before. We can see that the transformers-based architectures able to do that better than any other model. convnext_tiny still puts in a good performance, but it’s a bit let down by it’s relatively poor speed – hopefully we’ll see NVIDIA speed it up in the future, because in theory it’s a light-weight architecture which should be able to do better.\nThe downside of vit and swin models, like most transformers-based models, is that they can only handle one input image size. Of course, we can always squish or crop or pad our input images to the required size, but this can have a significant impact on performance. For instance, recently in looking at the Kaggle Paddy Disease competition I’ve found that the ability of convnext models to handle dynamically sized inputs to be very convenient.\nHere’s a chart of the seven top families, this time for the Planet dataset:\n\npt2 = pt[pt.family.isin(faves)]\npx.scatter(pt2, width=w, height=h, x='fit_time', y='error_rate', color='family', hover_name='model_name', trendline=\"ols\")\n\n\n                                                \n\n\nOne striking feature is that for this dataset, there’s little correlation between model size and performance. Regnetx and vit are the only families that show much of a relationship here. This suggests that if you have data that’s very different to your pretrained model’s data, that you might want to focus on smaller models. This makes intuitive sense, since these models have more new features to learn, and if they’re too big they’re either going to overfit, or fail to utilise their capacity effectively.\nHere’s the most accurate small and fast models on the Planet dataset:\n\npt.query(\"(GPU_mem<2.7) & (fit_time<25)\").sort_values(\"error_rate\").head(15).reset_index(drop=True)\n\n\n\n\n\n  \n    \n      \n      dataset\n      family\n      model_name\n      GPU_mem\n      error_rate\n      fit_time\n      score\n    \n  \n  \n    \n      0\n      planet\n      vit\n      vit_small_patch16_224\n      2.121094\n      0.035000\n      20.075387\n      3.502641\n    \n    \n      1\n      planet\n      convnext\n      convnext_tiny_in22k\n      2.660156\n      0.037647\n      22.014424\n      3.840538\n    \n    \n      2\n      planet\n      vit\n      vit_small_patch32_224\n      0.775391\n      0.038529\n      17.817797\n      3.768855\n    \n    \n      3\n      planet\n      convnext\n      convnext_tiny\n      2.660156\n      0.039706\n      23.180807\n      4.096878\n    \n    \n      4\n      planet\n      vit\n      vit_tiny_patch16_224\n      1.070312\n      0.040588\n      18.103888\n      3.981860\n    \n    \n      5\n      planet\n      mobilevit\n      mobilevit_xxs\n      1.152344\n      0.041471\n      20.329964\n      4.160743\n    \n    \n      6\n      planet\n      vit\n      vit_tiny_r_s16_p8_224\n      0.785156\n      0.041765\n      20.520312\n      4.198198\n    \n    \n      7\n      planet\n      resnetblur\n      resnetblur50\n      2.195312\n      0.042353\n      21.530770\n      4.300124\n    \n    \n      8\n      planet\n      resnet\n      resnet18\n      0.634766\n      0.042647\n      17.189185\n      4.144828\n    \n    \n      9\n      planet\n      resnetrs\n      resnetrs50\n      2.419922\n      0.043823\n      23.490568\n      4.535317\n    \n    \n      10\n      planet\n      resnet\n      resnet26\n      1.289062\n      0.044118\n      17.832233\n      4.316120\n    \n    \n      11\n      planet\n      regnetx\n      regnetx_016\n      1.367188\n      0.044118\n      22.212399\n      4.509375\n    \n    \n      12\n      planet\n      resnet\n      resnet26d\n      1.412109\n      0.044412\n      20.341083\n      4.456320\n    \n    \n      13\n      planet\n      regnety\n      regnety_006\n      0.914062\n      0.045000\n      22.715365\n      4.622193\n    \n    \n      14\n      planet\n      levit\n      levit_384\n      1.699219\n      0.045588\n      21.410115\n      4.623098\n    \n  \n\n\n\n\nconvnext_tiny is still the most accurate option amongst architectures that don’t have a fixed resolution. Resnet 18 has very low memory use, is fast, and is still quite accurate.\nHere’s the subset of ultra lean/fast models on the Planet dataset:\n\npt.query(\"(GPU_mem<1.6) & (fit_time<21)\").sort_values(\"error_rate\").head(15).reset_index(drop=True)\n\n\n\n\n\n  \n    \n      \n      dataset\n      family\n      model_name\n      GPU_mem\n      error_rate\n      fit_time\n      score\n    \n  \n  \n    \n      0\n      planet\n      vit\n      vit_small_patch32_224\n      0.775391\n      0.038529\n      17.817797\n      3.768855\n    \n    \n      1\n      planet\n      vit\n      vit_tiny_patch16_224\n      1.070312\n      0.040588\n      18.103888\n      3.981860\n    \n    \n      2\n      planet\n      mobilevit\n      mobilevit_xxs\n      1.152344\n      0.041471\n      20.329964\n      4.160743\n    \n    \n      3\n      planet\n      vit\n      vit_tiny_r_s16_p8_224\n      0.785156\n      0.041765\n      20.520312\n      4.198198\n    \n    \n      4\n      planet\n      resnet\n      resnet18\n      0.634766\n      0.042647\n      17.189185\n      4.144828\n    \n    \n      5\n      planet\n      resnet\n      resnet26\n      1.289062\n      0.044118\n      17.832233\n      4.316120\n    \n    \n      6\n      planet\n      resnet\n      resnet26d\n      1.412109\n      0.044412\n      20.341083\n      4.456320\n    \n    \n      7\n      planet\n      efficientnet\n      efficientnet_es\n      1.507812\n      0.046176\n      17.470632\n      4.500840\n    \n    \n      8\n      planet\n      regnetx\n      regnetx_008\n      0.974609\n      0.048235\n      20.212098\n      4.833754\n    \n    \n      9\n      planet\n      resnet\n      resnet34\n      0.949219\n      0.048823\n      19.884937\n      4.876730\n    \n    \n      10\n      planet\n      efficientnet\n      efficientnet_es_pruned\n      1.507812\n      0.050294\n      17.644619\n      4.910943\n    \n    \n      11\n      planet\n      regnety\n      regnety_002\n      0.490234\n      0.050882\n      20.417092\n      5.109463\n    \n    \n      12\n      planet\n      regnetx\n      regnetx_002\n      0.462891\n      0.051176\n      18.394935\n      5.035501\n    \n    \n      13\n      planet\n      regnetx\n      regnetx_006\n      0.730469\n      0.051765\n      19.354445\n      5.143050\n    \n    \n      14\n      planet\n      efficientnet\n      efficientnet_lite0\n      1.494141\n      0.052059\n      16.381403\n      5.017507"
  },
  {
    "objectID": "fastai_notebooks/best_vision_models_for_fine_tuning.html#conclusions",
    "href": "fastai_notebooks/best_vision_models_for_fine_tuning.html#conclusions",
    "title": "0013_best_vision_models_for_fine_tuning",
    "section": "Conclusions",
    "text": "Conclusions\nIt really seems like it’s time for a changing of the guard when it comes to computer vision models. There are, as at the time of writing (June 2022) three very clear winners when it comes to fine-tuning pretrained models:\n\nconvnext\nvit\nswin (and v2).\n\nTanishq Abraham studied the top results of a recent Kaggle computer vision competition and found that the above three approaches did indeed appear to the best approaches. However, there were two other architectures which were also very strong in that competition, but which aren’t in our top models above:\n\nEfficientNet and v2\nBEiT.\n\nBEiT isn’t there because it’s too big to fit on my GPU (even the smallest BEiT model is too big!) This is fixable with gradient accumulation, so perhaps in a future iteration we’ll add it in. EfficientNet didn’t have any variants that were fast and accurate enough to appear in the top 15 on either dataset. However, it’s notoriously fiddly to train, so there might well be some set of hyperparameters that would work for these datasets. Having said that, I’m mainly interested in knowing which architectures can be trained quickly and easily without to much mucking around, so perhaps EfficientNet doesn’t really fit here anyway!\nThankfully, it’s easy to try lots of different models, especially if you use fastai and timm, because it’s literally as easy as changing the model name in one place in your code. Your existing hyperparameters are most likely going to continue to work fine regardless of what model you try. And it’s particularly easy if you use wandb, since you can start and stop experiments at any time and they’ll all be automatically tracked and managed for you.\nIf you found this notebook useful, please remember to click the little up-arrow at the top to upvote it, since I like to know when people have found my work useful, and it helps others find it too. And if you have any questions or comments, please pop them below – I read every comment I receive!"
  },
  {
    "objectID": "fastai_notebooks/fastai_scaling_up_road_to_top_part_3.html",
    "href": "fastai_notebooks/fastai_scaling_up_road_to_top_part_3.html",
    "title": "0010_fastai_scaling_up_road_to_top_part_3",
    "section": "",
    "text": "# install fastkaggle if not available\ntry: import fastkaggle\nexcept ModuleNotFoundError:\n    !pip install -Uq fastkaggle\n\nfrom fastkaggle import *\nThis is part 3 of the Road to the Top series, in which I show the process I used to tackle the Paddy Doctor competition, leading to four 1st place submissions. The previous notebook is available here: part 2."
  },
  {
    "objectID": "fastai_notebooks/fastai_scaling_up_road_to_top_part_3.html#memory-and-gradient-accumulation",
    "href": "fastai_notebooks/fastai_scaling_up_road_to_top_part_3.html#memory-and-gradient-accumulation",
    "title": "0010_fastai_scaling_up_road_to_top_part_3",
    "section": "Memory and gradient accumulation",
    "text": "Memory and gradient accumulation\n\nhow to get the train_val dataset folder/path ready; how to get the test set images files ready\nFirst we’ll repeat the steps we used last time to access the data and ensure all the latest libraries are installed, and we’ll also grab the files we’ll need for the test set:\n\ncomp = 'paddy-disease-classification'\npath = setup_comp(comp, install='fastai \"timm>=0.6.2.dev0\"')\nfrom fastai.vision.all import *\nset_seed(42)\n\ntst_files = get_image_files(path/'test_images').sorted()\n\n\n\nhow to quickly train an ensemble of larger models with larger inputs on Kaggle\nIn this analysis our goal will be to train an ensemble of larger models with larger inputs. The challenge when training such models is generally GPU memory. Kaggle GPUs have 16280MiB of memory available, as at the time of writing. I like to try out my notebooks on my home PC, then upload them – but I still need them to run OK on Kaggle (especially if it’s a code competition, where this is required). My home PC has 24GiB cards, so just because it runs OK at home doesn’t mean it’ll run OK on Kaggle.\nIt’s really helpful to be able to quickly try a few models and image sizes and find out what will run successfully. To make this quick, we can just grab a small subset of the data for running short epochs – the memory use will still be the same, but it’ll be much faster.\nOne easy way to do this is to simply pick a category with few files in it. Here’s our options:\n\n\nhow to find out the num of files in each disease class using pandas.value_counts\n\ndf = pd.read_csv(path/'train.csv')\ndf.label.value_counts()\n\nnormal                      1764\nblast                       1738\nhispa                       1594\ndead_heart                  1442\ntungro                      1088\nbrown_spot                   965\ndowny_mildew                 620\nbacterial_leaf_blight        479\nbacterial_leaf_streak        380\nbacterial_panicle_blight     337\nName: label, dtype: int64\n\n\n\n\nhow to choose a data folder which has the least num of image files for training\nLet’s use bacterial_panicle_blight since it’s the smallest:\n\ntrn_path = path/'train_images'/'bacterial_panicle_blight'\n\n\n\nhow fine_tune differ from fit_one_cycle\nNow we’ll set up a train function which is very similar to the steps we used for training in the last notebook. But there’s a few significant differences…\nThe first is that I’m using a finetune argument to pick whether we are going to run the fine_tune() method, or the fit_one_cycle() method – the latter is faster since it doesn’t do an initial fine-tuning of the head.\n\n\nhow to create a train function to do either fine_tune + tta or fit_one_cycle for all layers without freezing; how to add gradient accumulation to train\nWhen we fine tune in this function I also have it calculate and return the TTA predictions on the test set, since later on we’ll be ensembling the TTA results of a number of models. Note also that we no longer have seed=42 in the ImageDataLoaders line – that means we’ll have different training and validation sets each time we call this. That’s what we’ll want for ensembling, since it means that each model will use slightly different data.\nThe more important change is that I’ve added an accum argument to implement gradient accumulation. As you’ll see in the code below, this does two things:\n\nDivide the batch size by accum\nAdd the GradientAccumulation callback, passing in accum.\n\n\ndef train(arch, size, item=Resize(480, method='squish'), accum=1, finetune=True, epochs=12):\n    dls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, item_tfms=item,\n        batch_tfms=aug_transforms(size=size, min_scale=0.75), bs=64//accum)\n    cbs = GradientAccumulation(64) if accum else []\n    learn = vision_learner(dls, arch, metrics=error_rate, cbs=cbs).to_fp16()\n    if finetune:\n        learn.fine_tune(epochs, 0.01)\n        return learn.tta(dl=dls.test_dl(tst_files))\n    else:\n        learn.unfreeze()\n        learn.fit_one_cycle(epochs, 0.01)\n\n\n\nwhat does gradient accumulation do?\nGradient accumulation refers to a very simple trick: rather than updating the model weights after every batch based on that batch’s gradients, instead keep accumulating (adding up) the gradients for a few batches, and them update the model weights with those accumulated gradients. In fastai, the parameter you pass to GradientAccumulation defines how many batches of gradients are accumulated. Since we’re adding up the gradients over accum batches, we therefore need to divide the batch size by that same number.\n\n\nWhat benefits does gradient accumulation bring\nThe resulting training loop is nearly mathematically identical to using the original batch size, but the amount of memory used is the same as using a batch size accum times smaller!\n\n\nhow does gradient accumulation work under the hood\nFor instance, here’s a basic example of a single epoch of a training loop without gradient accumulation:\nfor x,y in dl:\n    calc_loss(coeffs, x, y).backward()\n    coeffs.data.sub_(coeffs.grad * lr)\n    coeffs.grad.zero_()\nHere’s the same thing, but with gradient accumulation added (assuming a target effective batch size of 64):\ncount = 0            # track count of items seen since last weight update\nfor x,y in dl:\n    count += len(x)  # update count based on this minibatch size\n    calc_loss(coeffs, x, y).backward()\n    if count>64:     # count is greater than accumulation target, so do weight update\n        coeffs.data.sub_(coeffs.grad * lr)\n        coeffs.grad.zero_()\n        count=0      # reset count\nThe full implementation in fastai is only a few lines of code – here’s the source code.\nTo see the impact of gradient accumulation, consider this small model:\n\ntrain('convnext_small_in22k', 128, epochs=1, accum=1, finetune=False)\n\n\n\nhow to find out how much gpu memory is used; and how to free up the gpu memory\nLet’s create a function to find out how much memory it used, and also to then clear out the memory for the next run:\n\nimport gc\ndef report_gpu():\n    print(torch.cuda.list_gpu_processes())\n    gc.collect()\n    torch.cuda.empty_cache()\n\n\nreport_gpu()\n\nSo with accum=1 the GPU used around 5GB RAM. Let’s try accum=2:\n\ntrain('convnext_small_in22k', 128, epochs=1, accum=2, finetune=False)\nreport_gpu()\n\nAs you see, the RAM usage has now gone down to 4GB. It’s not halved since there’s other overhead involved (for larger models this overhead is likely to be relatively lower).\nLet’s try 4:\n\ntrain('convnext_small_in22k', 128, epochs=1, accum=4, finetune=False)\nreport_gpu()\n\nThe memory use is even lower!"
  },
  {
    "objectID": "fastai_notebooks/fastai_scaling_up_road_to_top_part_3.html#checking-memory-use",
    "href": "fastai_notebooks/fastai_scaling_up_road_to_top_part_3.html#checking-memory-use",
    "title": "0010_fastai_scaling_up_road_to_top_part_3",
    "section": "Checking memory use",
    "text": "Checking memory use\n\nhow to check the gpu memory usage of large models with large image inputs\nWe’ll now check the memory use for each of the architectures and sizes we’ll be training later, to ensure they all fit in 16GB RAM. For each of these, I tried accum=1 first, and then doubled it any time the resulting memory use was over 16GB. As it turns out, accum=2 was what I needed for every case.\nFirst, convnext_large:\n\ntrain('convnext_large_in22k', 224, epochs=1, accum=2, finetune=False)\nreport_gpu()\n\n\ntrain('convnext_large_in22k', (320,240), epochs=1, accum=2, finetune=False)\nreport_gpu()\n\nHere’s vit_large. This one is very close to going over the 16280MiB we’ve got on Kaggle!\n\ntrain('vit_large_patch16_224', 224, epochs=1, accum=2, finetune=False)\nreport_gpu()\n\nThen finally our swinv2 and swin models:\n\ntrain('swinv2_large_window12_192_22k', 192, epochs=1, accum=2, finetune=False)\nreport_gpu()\n\n\ntrain('swin_large_patch4_window7_224', 224, epochs=1, accum=2, finetune=False)\nreport_gpu()"
  },
  {
    "objectID": "fastai_notebooks/fastai_scaling_up_road_to_top_part_3.html#running-the-models",
    "href": "fastai_notebooks/fastai_scaling_up_road_to_top_part_3.html#running-the-models",
    "title": "0010_fastai_scaling_up_road_to_top_part_3",
    "section": "Running the models",
    "text": "Running the models\n\nhow to use a dictionary to organize all models and their item and batch transformation setups\nUsing the previous notebook, I tried a bunch of different architectures and preprocessing approaches on small models, and picked a few which looked good. We’ll using a dict to list our the preprocessing approaches we’ll use for each architecture of interest based on that analysis:\n\nres = 640,480\n\n\nmodels = {\n    'convnext_large_in22k': {\n        (Resize(res), 224),\n        (Resize(res), (320,224)),\n    }, 'vit_large_patch16_224': {\n        (Resize(480, method='squish'), 224),\n        (Resize(res), 224),\n    }, 'swinv2_large_window12_192_22k': {\n        (Resize(480, method='squish'), 192),\n        (Resize(res), 192),\n    }, 'swin_large_patch4_window7_224': {\n        (Resize(480, method='squish'), 224),\n        (Resize(res), 224),\n    }\n}\n\n\n\nhow to train all the selected models with transformation setups and save the tta results into a list\nWe’ll need to switch to using the full training set of course!\n\ntrn_path = path/'train_images'\n\nNow we’re ready to train all these models. Remember that each is using a different training and validation set, so the results aren’t directly comparable.\nWe’ll append each set of TTA predictions on the test set into a list called tta_res.\n\ntta_res = []\n\nfor arch,details in models.items():\n    for item,size in details:\n        print('---',arch)\n        print(size)\n        print(item.name)\n        tta_res.append(train(arch, size, item=item, accum=2)) #, epochs=1))\n        gc.collect()\n        torch.cuda.empty_cache()"
  },
  {
    "objectID": "fastai_notebooks/fastai_scaling_up_road_to_top_part_3.html#ensembling",
    "href": "fastai_notebooks/fastai_scaling_up_road_to_top_part_3.html#ensembling",
    "title": "0010_fastai_scaling_up_road_to_top_part_3",
    "section": "Ensembling",
    "text": "Ensembling\n\nhow to save all the tta results (a list) into a pickle file\nSince this has taken quite a while to run, let’s save the results, just in case something goes wrong!\n\nsave_pickle('tta_res.pkl', tta_res)\n\n\n\nhow to get all the predictions from a list of results in which each result contains a prediction and a target for each row of test set\nLearner.tta returns predictions and targets for each rows. We just want the predictions:\n\ntta_prs = first(zip(*tta_res))\n\n\n\nwhy and how to double the weights for vit models in the ensembles\nOriginally I just used the above predictions, but later I realised in my experiments on smaller models that vit was a bit better than everything else, so I decided to give those double the weight in my ensemble. I did that by simply adding the to the list a second time (we could also do this by using a weighted average):\n\ntta_prs += tta_prs[2:4]\n\n\n\nwhat is the simplest way of doing ensembling\nAn ensemble simply refers to a model which is itself the result of combining a number of other models. The simplest way to do ensembling is to take the average of the predictions of each model:\n\navg_pr = torch.stack(tta_prs).mean(0)\navg_pr.shape\n\n\n\nhow to all the classes or vocab of the dataset using dataloaders; how to prepare the csv for kaggle submission\nThat’s all that’s needed to create an ensemble! Finally, we copy the steps we used in the last notebook to create a submission file:\n\ndls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, item_tfms=Resize(480, method='squish'),\n    batch_tfms=aug_transforms(size=224, min_scale=0.75))\n\n\nidxs = avg_pr.argmax(dim=1)\nvocab = np.array(dls.vocab)\nss = pd.read_csv(path/'sample_submission.csv')\nss['label'] = vocab[idxs]\nss.to_csv('subm.csv', index=False)\n\n\n\nhow to submit to kaggle using fastkaggle api\nNow we can submit:\n\nif not iskaggle:\n    from kaggle import api\n    api.competition_submit_cli('subm.csv', 'part 3 v2', comp)\n\nThat’s it – at the time of creating this analysis, that got easily to the top of the leaderboard! Here are the four submissions I entered, each of which was better than the last, and each of which was ranked #1:\n\nEdit: Actually the one that got to the top of the leaderboard timed out when I ran it on Kaggle Notebooks, so I had to remove two of the runs from the ensemble. There’s only a very small difference in accuracy however.\nGoing from bottom to top, here’s what each one was:\n\nconvnext_small trained for 12 epochs, with TTA\nconvnext_large trained the same way\nThe ensemble in this notebook, with vit models not over-weighted\nThe ensemble in this notebook, with vit models over-weighted."
  },
  {
    "objectID": "fastai_notebooks/fastai_scaling_up_road_to_top_part_3.html#conclusion",
    "href": "fastai_notebooks/fastai_scaling_up_road_to_top_part_3.html#conclusion",
    "title": "0010_fastai_scaling_up_road_to_top_part_3",
    "section": "Conclusion",
    "text": "Conclusion\n\nhow fastai can superbly simply the codes and standardize processes\nThe key takeaway I hope to get across from this series so far is that you can get great results in image recognition using very little code and a very standardised approach, and that with a rigorous process you can improve in significant steps. Our training function, including data processing and TTA, is just half a dozen lines of code, plus another 7 lines of code to ensemble the models and create a submission file!\nIf you found this notebook useful, please remember to click the little up-arrow at the top to upvote it, since I like to know when people have found my work useful, and it helps others find it too. If you have any questions or comments, please pop them below – I read every comment I receive!\n\n# This is what I use to push my notebook from my home PC to Kaggle\n\nif not iskaggle:\n    push_notebook('jhoward', 'scaling-up-road-to-the-top-part-3',\n                  title='Scaling Up: Road to the Top, Part 3',\n                  file='10-scaling-up-road-to-the-top-part-3.ipynb',\n                  competition=comp, private=False, gpu=True)\n\nKernel version 6 successfully pushed.  Please check progress at https://www.kaggle.com/code/jhoward/scaling-up-road-to-the-top-part-3"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptwhy_sqrt5.html",
    "href": "fastai_notebooks/fastai_ptwhy_sqrt5.html",
    "title": "0022_fastai_pt2_2019_why_sqrt5",
    "section": "",
    "text": "01:28 -\n02:28 - how to resize a 3 color channel image into a single changel image 28x28\n03:06 - when would Jeremy create a function during research; experiment to show that the line is not performing well\n08:55 - Jeremy writing his own version of kaiming init\n15:59 - Jeremy reimplemented what pytorch had on kaiming init; Jeremy used an example to test on how useless or useful of the line in pytorch;\n17:30 - using kaiming_uniform_ to test the line, and the result is better but still problematic\n18:58 - look at 2b why need a good init; why in the past neuralnet is so hard to train; why weights initialization is so crucial to training or learning\n21:04 - Sylvian further explained something interesting\n21:30 - how pytorch team responded\n23:52 - many init papers and approaches\n27:11 - ground up so that we can ask questions on pytorch strange and historical edges\n28:56 - let’s train a model with our fully connected architecture with cross-entropy\n30:21 - how to understand log cross-entropy from scratch\n34:26 - how to write negative log likelihood in pytorch with a trick\nJump_to lesson 9 video\n\n#export\nfrom exp.nb_02 import *\n\ndef get_data():\n    path = datasets.download_data(MNIST_URL, ext='.gz')\n    with gzip.open(path, 'rb') as f:\n        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n    return map(tensor, (x_train,y_train,x_valid,y_valid))\n\ndef normalize(x, m, s): return (x-m)/s\n\n\ntorch.nn.modules.conv._ConvNd.reset_parameters??\n\n\nx_train,y_train,x_valid,y_valid = get_data()\ntrain_mean,train_std = x_train.mean(),x_train.std()\nx_train = normalize(x_train, train_mean, train_std)\nx_valid = normalize(x_valid, train_mean, train_std)\n\n\nx_train = x_train.view(-1,1,28,28)\nx_valid = x_valid.view(-1,1,28,28)\nx_train.shape,x_valid.shape\n\n\nn,*_ = x_train.shape\nc = y_train.max()+1\nnh = 32\nn,c\n\n\nl1 = nn.Conv2d(1, nh, 5)\n\n\nx = x_valid[:100]\n\n\nx.shape\n\n\ndef stats(x): return x.mean(),x.std()\n\n\nl1.weight.shape\n\n\nstats(l1.weight),stats(l1.bias)\n\n\nt = l1(x)\n\n\nstats(t)\n\n\ninit.kaiming_normal_(l1.weight, a=1.)\nstats(l1(x))\n\n\nimport torch.nn.functional as F\n\n\ndef f1(x,a=0): return F.leaky_relu(l1(x),a)\n\n\ninit.kaiming_normal_(l1.weight, a=0)\nstats(f1(x))\n\n\nl1 = nn.Conv2d(1, nh, 5)\nstats(f1(x))\n\n\nl1.weight.shape\n\n\n# receptive field size\nrec_fs = l1.weight[0,0].numel()\nrec_fs\n\n\nnf,ni,*_ = l1.weight.shape\nnf,ni\n\n\nfan_in  = ni*rec_fs\nfan_out = nf*rec_fs\nfan_in,fan_out\n\n\ndef gain(a): return math.sqrt(2.0 / (1 + a**2))\n\n\ngain(1),gain(0),gain(0.01),gain(0.1),gain(math.sqrt(5.))\n\n\ntorch.zeros(10000).uniform_(-1,1).std()\n\n\n1/math.sqrt(3.)\n\n\ndef kaiming2(x,a, use_fan_out=False):\n    nf,ni,*_ = x.shape\n    rec_fs = x[0,0].shape.numel()\n    fan = nf*rec_fs if use_fan_out else ni*rec_fs\n    std = gain(a) / math.sqrt(fan)\n    bound = math.sqrt(3.) * std\n    x.data.uniform_(-bound,bound)\n\n\nkaiming2(l1.weight, a=0);\nstats(f1(x))\n\n\nkaiming2(l1.weight, a=math.sqrt(5.))\nstats(f1(x))\n\n\nclass Flatten(nn.Module):\n    def forward(self,x): return x.view(-1)\n\n\nm = nn.Sequential(\n    nn.Conv2d(1,8, 5,stride=2,padding=2), nn.ReLU(),\n    nn.Conv2d(8,16,3,stride=2,padding=1), nn.ReLU(),\n    nn.Conv2d(16,32,3,stride=2,padding=1), nn.ReLU(),\n    nn.Conv2d(32,1,3,stride=2,padding=1),\n    nn.AdaptiveAvgPool2d(1),\n    Flatten(),\n)\n\n\ny = y_valid[:100].float()\n\n\nt = m(x)\nstats(t)\n\n\nl = mse(t,y)\nl.backward()\n\n\nstats(m[0].weight.grad)\n\n\ninit.kaiming_uniform_??\n\n\nfor l in m:\n    if isinstance(l,nn.Conv2d):\n        init.kaiming_uniform_(l.weight)\n        l.bias.data.zero_()\n\n\nt = m(x)\nstats(t)\n\n\nl = mse(t,y)\nl.backward()\nstats(m[0].weight.grad)"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptwhy_sqrt5.html#export",
    "href": "fastai_notebooks/fastai_ptwhy_sqrt5.html#export",
    "title": "0022_fastai_pt2_2019_why_sqrt5",
    "section": "Export",
    "text": "Export\n\n!./notebook2script.py 02a_why_sqrt5.ipynb\n\n\nfrom fastdebug.utils import *\n\n\nfastnbs(\"The forward and backward passes\")\n\nthe forward and backward passes\n\n\nThis section contains only the current heading 2 and its subheadings ### get_data\n\n1:23:03 - how to download and prepare the mnist dataset and wrap the process into a function called get_data;\nJump_to lesson 8 video\n#export\nfrom exp.nb_01 import *\n\ndef get_data():\n    path = datasets.download_data(MNIST_URL, ext='.gz')\n    with gzip.open(path, 'rb') as f:\n        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n    return map(tensor, (x_train,y_train,x_valid,y_valid))\nx_train,y_train,x_valid,y_valid = get_data()\n\n\nnormalize(x, m, s)\n\n1:23:48 - how to create normalize function to use broadcast to normalize the Xs and Ys; what does normalization to Xs and Ys mean (make Xs and Ys to have a distribution whose mean is 0 and std is 1)? how to make the mean and std of Xs and Ys to be 0 and 1 (using the formula of normalization below) Why we don’t use validation set’s mean and std to normalization Xs and Ys of validation set but use those of training set? (make sure validation set and training set share the same scale as training set) What example did Jeremy give to explain the importance of using training set’s mean and std for normalization of validation set\ndef normalize(x, m, s): return (x-m)/s\ntrain_mean,train_std = x_train.mean(),x_train.std()\ntrain_mean,train_std\nx_train = normalize(x_train, train_mean, train_std)\n# NB: Use training, not validation mean for validation set\nx_valid = normalize(x_valid, train_mean, train_std)\n\n\n\ntest_near_zero and assert\n\n1:24:52 - how to check the mean and std values are close to 0 and 1 using test_near_zero using assert\ntrain_mean,train_std = x_train.mean(),x_train.std()\ntrain_mean,train_std\n#export\ndef test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\"\ntest_near_zero(x_train.mean())\ntest_near_zero(1-x_train.std())\n\n\n\ngetting dimensions of weights of different layers\n\n1:25:16 - how to get the number of activations of each layer n (rows of input), m (columns of input), c (number of targets/classes) from the shape of x_train and y_train\nn,m = x_train.shape\nc = y_train.max()+1\nn,m,c\nstart of another heading 2 ## Foundations version\n\n\n\n\nOpen 0021_fastai_pt2_2019_fully_connected in Jupyter Notebook locally\n\n\n1:55:22 - how to put forward pass and backward pass into one function foward_and_backward; and backward pass is the chain rule (people who say no are liars) and saving the gradients as well;\n\n\nThis section contains only the current heading 3 and its subheadings\ndef forward_and_backward(inp, targ):\n    # forward pass:\n    l1 = inp @ w1 + b1\n    l2 = relu(l1)\n    out = l2 @ w2 + b2\n    # we don't actually need the loss in backward!\n    loss = mse(out, targ)\n    \n    # backward pass:\n    mse_grad(out, targ)\n    lin_grad(l2, out, w2, b2)\n    relu_grad(l1, l2)\n    lin_grad(inp, l1, w1, b1)\nforward_and_backward(x_train, y_train)\nstart of another heading 3 ### 1:56:41 - how to use pytorch’s gradient calculation functions to test whether our own gradients are calculated correctly;\n\n\nOpen 0021_fastai_pt2_2019_fully_connected in Jupyter Notebook locally"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptwhy_sqrt5.html#the-forward-and-backward-passes",
    "href": "fastai_notebooks/fastai_ptwhy_sqrt5.html#the-forward-and-backward-passes",
    "title": "0022_fastai_pt2_2019_why_sqrt5",
    "section": "the forward and backward passes",
    "text": "the forward and backward passes"
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "",
    "text": "Official course site: for lesson 3\nOfficial notebooks repo, on nbviewer\nOfficial neuralnet from scratch notebook on kaggle"
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#how-to-not-execute-the-entire-notebook",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#how-to-not-execute-the-entire-notebook",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "how to not execute the entire notebook",
    "text": "how to not execute the entire notebook"
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#introduction",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#introduction",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "Introduction",
    "text": "Introduction\nIn this notebook we’re going to build and train a deep learning model “from scratch” – by which I mean that we’re not going to use any pre-built architecture, or optimizers, or data loading frameworks, etc.\nWe’ll be assuming you already know the basics of how a neural network works. If you don’t, read this notebook first: How does a neural net really work?. We’ll be using Kaggle’s Titanic competition in this notebook, because it’s very small and simple, but also has displays many of the tricky real-life issues that we need to handle in most practical projects. (Note, however, that this competition is a small “learner” competition on Kaggle, so don’t expect to actually see much benefits from using a neural net just yet; that will come once we try our some real competitions!)\nIt’s great to be able to run the same notebook on your own machine or Colab, as well as Kaggle. To allow for this, we use this code to download the data as needed when not on Kaggle (see this notebook for details about this technique):"
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#how-to-download-kaggle-dataset-to-your-local-machine-or-colab-how-to-ues-kaggle-api-and-zipfile-to-download-data-into-specified-folder-how-to-use-pathlib.path-to-create-a-path",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#how-to-download-kaggle-dataset-to-your-local-machine-or-colab-how-to-ues-kaggle-api-and-zipfile-to-download-data-into-specified-folder-how-to-use-pathlib.path-to-create-a-path",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "How to download kaggle dataset to your local machine or colab? how to ues kaggle api and zipfile to download data into specified folder; how to use pathlib.Path to create a path;",
    "text": "How to download kaggle dataset to your local machine or colab? how to ues kaggle api and zipfile to download data into specified folder; how to use pathlib.Path to create a path;\n\nimport os\nfrom pathlib import Path\n\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\nif iskaggle: path = Path('../input/titanic')\nelse:\n    path = Path('titanic')\n    if not path.exists():\n        import zipfile,kaggle\n        kaggle.api.competition_download_cli(str(path))\n        zipfile.ZipFile(f'{path}.zip').extractall(path)\n\nNote that the data for Kaggle comps always lives in the ../input folder. The easiest way to get the path is to click the “K” button in the top-right of the Kaggle notebook, click on the folder shown there, and click the copy button.\nWe’ll be using numpy and pytorch for array calculations in this notebook, and pandas for working with tabular data, so we’ll import them and set them to display using a bit more space than they default to."
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#how-to-set-the-print-display-option-for-numpy-torch-and-pandas",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#how-to-set-the-print-display-option-for-numpy-torch-and-pandas",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "how to set the print display option for numpy, torch and pandas",
    "text": "how to set the print display option for numpy, torch and pandas\n\nimport torch, numpy as np, pandas as pd\nnp.set_printoptions(linewidth=140)\ntorch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\npd.set_option('display.width', 140)"
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#cleaning-the-data",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#cleaning-the-data",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "Cleaning the data",
    "text": "Cleaning the data\n\nhow to read csv file with pandas and path/'subfolder_name'\nThis is a tabular data competition – the data is in the form of a table. It’s provided as a Comma Separated Values (CSV) file. We can open it using the pandas library, which will create a DataFrame.\n\ndf = pd.read_csv(path/'train.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Name\n      Sex\n      Age\n      SibSp\n      Parch\n      Ticket\n      Fare\n      Cabin\n      Embarked\n    \n  \n  \n    \n      0\n      1\n      0\n      3\n      Braund, Mr. Owen Harris\n      male\n      22.0\n      1\n      0\n      A/5 21171\n      7.2500\n      NaN\n      S\n    \n    \n      1\n      2\n      1\n      1\n      Cumings, Mrs. John Bradley (Florence Briggs Th...\n      female\n      38.0\n      1\n      0\n      PC 17599\n      71.2833\n      C85\n      C\n    \n    \n      2\n      3\n      1\n      3\n      Heikkinen, Miss. Laina\n      female\n      26.0\n      0\n      0\n      STON/O2. 3101282\n      7.9250\n      NaN\n      S\n    \n    \n      3\n      4\n      1\n      1\n      Futrelle, Mrs. Jacques Heath (Lily May Peel)\n      female\n      35.0\n      1\n      0\n      113803\n      53.1000\n      C123\n      S\n    \n    \n      4\n      5\n      0\n      3\n      Allen, Mr. William Henry\n      male\n      35.0\n      0\n      0\n      373450\n      8.0500\n      NaN\n      S\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      886\n      887\n      0\n      2\n      Montvila, Rev. Juozas\n      male\n      27.0\n      0\n      0\n      211536\n      13.0000\n      NaN\n      S\n    \n    \n      887\n      888\n      1\n      1\n      Graham, Miss. Margaret Edith\n      female\n      19.0\n      0\n      0\n      112053\n      30.0000\n      B42\n      S\n    \n    \n      888\n      889\n      0\n      3\n      Johnston, Miss. Catherine Helen \"Carrie\"\n      female\n      NaN\n      1\n      2\n      W./C. 6607\n      23.4500\n      NaN\n      S\n    \n    \n      889\n      890\n      1\n      1\n      Behr, Mr. Karl Howell\n      male\n      26.0\n      0\n      0\n      111369\n      30.0000\n      C148\n      C\n    \n    \n      890\n      891\n      0\n      3\n      Dooley, Mr. Patrick\n      male\n      32.0\n      0\n      0\n      370376\n      7.7500\n      NaN\n      Q\n    \n  \n\n891 rows × 12 columns\n\n\n\n\n\nwhy missing value is a problem? how to find out the num of missing values of each column with pandas?\nAs we learned in the How does a neural net really work notebook, we going to want to multiply each column by some coefficients. But we can see in the Cabin column that there are NaN values, which is how Pandas refers to missing values. We can’t multiply something by a missing value!\nLet’s check which columns contain NaN values. Pandas’ isna() function returns True (which is treated as 1 when used as a number) for NaN values, so we can just add them up for each column:\n\ndf.isna().sum()\n\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\n\n\n\nwhich value is most used to replace missing value? how to get mode for each column with pandas using iloc[0]\nNotice that by default Pandas sums over columns.\nWe’ll need to replace the missing values with something. It doesn’t generally matter too much what we choose. We’ll use the most common value (the “mode”). We can use the mode function for that. One wrinkle is that it returns more than one row in the case of ties, so we just grab the first row with iloc[0]:\n\nmodes = df.mode().iloc[0]\nmodes\n\nPassengerId                      1\nSurvived                       0.0\nPclass                         3.0\nName           Abbing, Mr. Anthony\nSex                           male\nAge                           24.0\nSibSp                          0.0\nParch                          0.0\nTicket                        1601\nFare                          8.05\nCabin                      B96 B98\nEmbarked                         S\nName: 0, dtype: object\n\n\n\n\nhow to use pandas iloc function\nBTW, it’s never a good idea to use functions without understanding them. So be sure to google for anything you’re not familiar with. E.g if you want to learn about iloc (which is a very important function indeed!) then Google will give you a link to a great tutorial.\n\n\nhow to fill missing values with mode without making a new copy with pandas.fillna\nNow that we’ve got the mode of each column, we can use fillna to replace the missing values with the mode of each column. We’ll do it “in place” – meaning that we’ll change the dataframe itself, rather than returning a new one.\n\ndf.fillna(modes, inplace=True)\n\nWe can now check there’s no missing values left:\n\ndf.isna().sum()\n\nPassengerId    0\nSurvived       0\nPclass         0\nName           0\nSex            0\nAge            0\nSibSp          0\nParch          0\nTicket         0\nFare           0\nCabin          0\nEmbarked       0\ndtype: int64\n\n\n\n\nhow to get a quick summary of all the numeric columns with pandas and numpy\nHere’s how we get a quick summary of all the numeric columns in the dataset:\n\nimport numpy as np\n\ndf.describe(include=(np.number))\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Age\n      SibSp\n      Parch\n      Fare\n    \n  \n  \n    \n      count\n      891.000000\n      891.000000\n      891.000000\n      891.000000\n      891.000000\n      891.000000\n      891.000000\n    \n    \n      mean\n      446.000000\n      0.383838\n      2.308642\n      28.566970\n      0.523008\n      0.381594\n      32.204208\n    \n    \n      std\n      257.353842\n      0.486592\n      0.836071\n      13.199572\n      1.102743\n      0.806057\n      49.693429\n    \n    \n      min\n      1.000000\n      0.000000\n      1.000000\n      0.420000\n      0.000000\n      0.000000\n      0.000000\n    \n    \n      25%\n      223.500000\n      0.000000\n      2.000000\n      22.000000\n      0.000000\n      0.000000\n      7.910400\n    \n    \n      50%\n      446.000000\n      0.000000\n      3.000000\n      24.000000\n      0.000000\n      0.000000\n      14.454200\n    \n    \n      75%\n      668.500000\n      1.000000\n      3.000000\n      35.000000\n      1.000000\n      0.000000\n      31.000000\n    \n    \n      max\n      891.000000\n      1.000000\n      3.000000\n      80.000000\n      8.000000\n      6.000000\n      512.329200\n    \n  \n\n\n\n\n\n\nwhat is long-tailed data in histogram and why it is a problem for neuralnet\nWe can see that Fare contains mainly values of around 0 to 30, but there’s a few really big ones. This is very common with fields contain monetary values, and it can cause problems for our model, because once that column is multiplied by a coefficient later, the few rows with really big values will dominate the result.\nYou can see the issue most clearly visually by looking at a histogram, which shows a long tail to the right (and don’t forget: if you’re not entirely sure what a histogram is, Google “histogram tutorial” and do a bit of reading before continuing on):\n\n\nhow to plot histogram with pandas on a single column\n\ndf['Fare'].hist();\n\n\n\n\n\n\nhow to fix long-tailed data with logarithm; why should logarithm work; how to handle zero values when applying logarithm\nTo fix this, the most common approach is to take the logarithm, which squishes the big numbers and makes the distribution more reasonable. Note, however, that there are zeros in the Fare column, and log(0) is infinite – to fix this, we’ll simply add 1 to all values first:\n\ndf['LogFare'] = np.log(df['Fare']+1)\n\nThe histogram now shows a more even distribution of values without the long tail:\n\ndf['LogFare'].hist();\n\n\n\n\nIt looks from the describe() output like Pclass contains just 3 values, which we can confirm by looking at the Data Dictionary (which you should always study carefully for any project!) –\n\npclasses = sorted(df.Pclass.unique())\npclasses\n\n[1, 2, 3]\n\n\n\n\nhow to get a quick summary of all the non-numeric columns with pandas\nHere’s how we get a quick summary of all the non-numeric columns in the dataset:\n\ndf.describe(include=[object])\n\n\n\n\n\n  \n    \n      \n      Name\n      Sex\n      Ticket\n      Cabin\n      Embarked\n    \n  \n  \n    \n      count\n      891\n      891\n      891\n      891\n      891\n    \n    \n      unique\n      891\n      2\n      681\n      147\n      3\n    \n    \n      top\n      Braund, Mr. Owen Harris\n      male\n      347082\n      B96 B98\n      S\n    \n    \n      freq\n      1\n      577\n      7\n      691\n      646\n    \n  \n\n\n\n\n\n\nwhen do we need dummy variables and how to create dummy variables with pandas\nClearly we can’t multiply strings like male or S by coefficients, so we need to replace those with numbers.\nWe do that by creating new columns containing dummy variables. A dummy variable is a column that contains a 1 where a particular column contains a particular value, or a 0 otherwise. For instance, we could create a dummy variable for Sex='male', which would be a new column containing 1 for rows where Sex is 'male', and 0 for rows where it isn’t.\nPandas can create these automatically using get_dummies, which also remove the original columns. We’ll create dummy variables for Pclass, even although it’s numeric, since the numbers 1, 2, and 3 correspond to first, second, and third class cabins - not to counts or measures that make sense to multiply by. We’ll also create dummies for Sex and Embarked since we’ll want to use those as predictors in our model. On the other hand, Cabin, Name, and Ticket have too many unique values for it to make sense creating dummy variables for them.\n\ndf = pd.get_dummies(df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\ndf.columns\n\nIndex(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Sex_female', 'Sex_male',\n       'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n      dtype='object')\n\n\n\n\nhow to check the first few rows of selected columns with pandas\nWe can see that 5 columns have been added to the end – one for each of the possible values of each of the three columns we requested, and that those three requested columns have been removed.\nHere’s what the first few rows of those newly added columns look like:\n\nadded_cols = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\ndf[added_cols].head()\n\n\n\n\n\n  \n    \n      \n      Sex_male\n      Sex_female\n      Pclass_1\n      Pclass_2\n      Pclass_3\n      Embarked_C\n      Embarked_Q\n      Embarked_S\n    \n  \n  \n    \n      0\n      1\n      0\n      0\n      0\n      1\n      0\n      0\n      1\n    \n    \n      1\n      0\n      1\n      1\n      0\n      0\n      1\n      0\n      0\n    \n    \n      2\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      1\n    \n    \n      3\n      0\n      1\n      1\n      0\n      0\n      0\n      0\n      1\n    \n    \n      4\n      1\n      0\n      0\n      0\n      1\n      0\n      0\n      1\n    \n  \n\n\n\n\n\n\nhow to create dependent/target variable and independent/predictor variables in PyTorch tensors; how to create variables in tensor from pandas dataframe\nNow we can create our independent (predictors) and dependent (target) variables. They both need to be PyTorch tensors. Our dependent variable is Survived:\n\nfrom torch import tensor\n\nt_dep = tensor(df.Survived)\n\nOur independent variables are all the continuous variables of interest plus all the dummy variables we just created:\n\nindep_cols = ['Age', 'SibSp', 'Parch', 'LogFare'] + added_cols\n\nt_indep = tensor(df[indep_cols].values, dtype=torch.float)\nt_indep\n\ntensor([[22.0000,  1.0000,  0.0000,  2.1102,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n        [38.0000,  1.0000,  0.0000,  4.2806,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n        [26.0000,  0.0000,  0.0000,  2.1889,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n        [35.0000,  1.0000,  0.0000,  3.9908,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n        [35.0000,  0.0000,  0.0000,  2.2028,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n        [24.0000,  0.0000,  0.0000,  2.2469,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n        [54.0000,  0.0000,  0.0000,  3.9677,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n        ...,\n        [25.0000,  0.0000,  0.0000,  2.0857,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n        [39.0000,  0.0000,  5.0000,  3.4054,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n        [27.0000,  0.0000,  0.0000,  2.6391,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n        [19.0000,  0.0000,  0.0000,  3.4340,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n        [24.0000,  1.0000,  2.0000,  3.1966,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n        [26.0000,  0.0000,  0.0000,  3.4340,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n        [32.0000,  0.0000,  0.0000,  2.1691,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000]])\n\n\n\n\nhow to check the size (rows and columns) of independent variables in tensor\nHere’s the number of rows and columns we have for our independent variables:\n\nt_indep.shape\n\ntorch.Size([891, 12])"
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#setting-up-a-linear-model",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#setting-up-a-linear-model",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "Setting up a linear model",
    "text": "Setting up a linear model\n\nhow to create coefficients for each (column) of our independent variables; how to get random seed in torch; how to get the num of columns; how to create random number between -0.5 and 0.5;\nNow that we’ve got a matrix of independent variables and a dependent variable vector, we can work on calculating our predictions and our loss. In this section, we’re going to manually do a single step of calculating predictions and loss for every row of our data.\nOur first model will be a simple linear model. We’ll need a coefficient for each column in t_indep. We’ll pick random numbers in the range (-0.5,0.5), and set our manual seed so that my explanations in the prose in this notebook will be consistent with what you see when you run it.\n\ntorch.manual_seed(442)\nn_coeff = t_indep.shape[1]\ncoeffs = torch.rand(n_coeff)-0.5\ncoeffs\n\ntensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])\n\n\n\n\nwhy no bias or a constant is needed for this Titanic dataset?\nOur predictions will be calculated by multiplying each row by the coefficients, and adding them up. One interesting point here is that we don’t need a separate constant term (also known as a “bias” or “intercept” term), or a column of all 1s to give the same effect has having a constant term. That’s because our dummy variables already cover the entire dataset – e.g. there’s a column for “male” and a column for “female”, and everyone in the dataset is in exactly one of these; therefore, we don’t need a separate intercept term to cover rows that aren’t otherwise part of a column.\nHere’s what the multiplication looks like:\n\nt_indep*coeffs\n\ntensor([[-10.1838,   0.1386,   0.0000,  -0.4772,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n        [-17.5902,   0.1386,   0.0000,  -0.9681,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.4392,   0.0000,   0.0000],\n        [-12.0354,   0.0000,   0.0000,  -0.4950,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n        [-16.2015,   0.1386,   0.0000,  -0.9025,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],\n        [-16.2015,   0.0000,   0.0000,  -0.4982,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n        [-11.1096,   0.0000,   0.0000,  -0.5081,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000],\n        [-24.9966,   0.0000,   0.0000,  -0.8973,  -0.2632,  -0.0000,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],\n        ...,\n        [-11.5725,   0.0000,   0.0000,  -0.4717,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n        [-18.0531,   0.0000,   1.2045,  -0.7701,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000],\n        [-12.4983,   0.0000,   0.0000,  -0.5968,  -0.2632,  -0.0000,   0.0000,   0.3136,   0.0000,  -0.0000,   0.0000,   0.3625],\n        [ -8.7951,   0.0000,   0.0000,  -0.7766,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],\n        [-11.1096,   0.1386,   0.4818,  -0.7229,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n        [-12.0354,   0.0000,   0.0000,  -0.7766,  -0.2632,  -0.0000,   0.4876,   0.0000,   0.0000,  -0.4392,   0.0000,   0.0000],\n        [-14.8128,   0.0000,   0.0000,  -0.4905,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000]])\n\n\n\n\nwhy a column Age having higher values than other columns can cause problem for our model; how to solve this problem by making them the same scale; how to get the max value of each column with pandas dataframe max func\nWe can see we’ve got a problem here. The sums of each row will be dominated by the first column, which is Age, since that’s bigger on average than all the others.\nLet’s make all the columns contain numbers from 0 to 1, by dividing each column by its max():\n\nvals,indices = t_indep.max(dim=0)\nt_indep = t_indep / vals\n\nAs we see, that removes the problem of one column dominating all the others:\n\nt_indep*coeffs\n\ntensor([[-0.1273,  0.0173,  0.0000, -0.0765, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n        [-0.2199,  0.0173,  0.0000, -0.1551, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],\n        [-0.1504,  0.0000,  0.0000, -0.0793, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n        [-0.2025,  0.0173,  0.0000, -0.1446, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n        [-0.2025,  0.0000,  0.0000, -0.0798, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n        [-0.1389,  0.0000,  0.0000, -0.0814, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],\n        [-0.3125,  0.0000,  0.0000, -0.1438, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n        ...,\n        [-0.1447,  0.0000,  0.0000, -0.0756, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n        [-0.2257,  0.0000,  0.2008, -0.1234, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],\n        [-0.1562,  0.0000,  0.0000, -0.0956, -0.2632, -0.0000,  0.0000,  0.3136,  0.0000, -0.0000,  0.0000,  0.3625],\n        [-0.1099,  0.0000,  0.0000, -0.1244, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n        [-0.1389,  0.0173,  0.0803, -0.1158, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n        [-0.1504,  0.0000,  0.0000, -0.1244, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],\n        [-0.1852,  0.0000,  0.0000, -0.0786, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000]])\n\n\n\n\nwhat is maxtrix by vector operation (multiply or divide)\nOne thing you hopefully noticed is how amazingly cool this line of code is:\nt_indep = t_indep / vals\nThat is dividing a matrix by a vector – what on earth does that mean?!? The trick here is that we’re taking advantage of a technique in numpy and PyTorch (and many other languages, going all the way back to APL) called broadcasting. In short, this acts as if there’s a separate copy of the vector for every row of the matrix, so it divides each row of the matrix by the vector. In practice, it doesn’t actually make any copies, and does the whole thing in a highly optimized way, taking full advantage of modern CPUs (or, indeed, GPUs, if we’re using them). Broadcasting is one of the most important techniques for making your code concise, maintainable, and fast, so it’s well worth studying and practicing.\n\n\nHow to calculate the prediction of a linear model\nWe can now create predictions from our linear model, by adding up the rows of the product:\n\npreds = (t_indep*coeffs).sum(axis=1)\n\n\n\nhow to look at the first 10 values of predictions\nLet’s take a look at the first few:\n\npreds[:10]\n\ntensor([ 0.1927, -0.6239,  0.0979,  0.2056,  0.0968,  0.0066,  0.1306,  0.3476,  0.1613, -0.6285])\n\n\n\n\nhow to calc mean absolute error\nOf course, these predictions aren’t going to be any use, since our coefficients are random – they’re just a starting point for our gradient descent process.\nTo do gradient descent, we need a loss function. Taking the average error of the rows (i.e. the absolute value of the difference between the prediction and the dependent) is generally a reasonable approach:\n\nloss = torch.abs(preds-t_dep).mean()\nloss\n\ntensor(0.5382)\n\n\n\n\nhow to calc predictions with a func calc_preds; how to calc loss with a func calc_loss\nNow that we’ve tested out a way of calculating predictions, and loss, let’s pop them into functions to make life easier:\n\ndef calc_preds(coeffs, indeps): return (indeps*coeffs).sum(axis=1)\ndef calc_loss(coeffs, indeps, deps): return torch.abs(calc_preds(coeffs, indeps)-deps).mean()"
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#doing-a-gradient-descent-step",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#doing-a-gradient-descent-step",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "Doing a gradient descent step",
    "text": "Doing a gradient descent step\nIn this section, we’re going to do a single “epoch” of gradient descent manually. The only thing we’re going to automate is calculating gradients, because let’s face it that’s pretty tedious and entirely pointless to do by hand! To get PyTorch to calculate gradients, we’ll need to call requires_grad_() on our coeffs (if you’re not sure why, review the previous notebook, How does a neural net really work?, before continuing):\n\ncoeffs.requires_grad_()\n\nNow when we calculate our loss, PyTorch will keep track of all the steps, so we’ll be able to get the gradients afterwards:\n\nloss = calc_loss(coeffs, t_indep, t_dep)\nloss\n\ntensor(0.5382, grad_fn=<MeanBackward0>)\n\n\nUse backward() to ask PyTorch to calculate gradients now:\n\nloss.backward()\n\nLet’s see what they look like:\n\ncoeffs.grad\n\ntensor([-0.0106,  0.0129, -0.0041, -0.0484,  0.2099, -0.2132, -0.1212, -0.0247,  0.1425, -0.1886, -0.0191,  0.2043])\n\n\n\nHow to cacl gradients for coefficients\nNote that each time we call backward, the gradients are actually added to whatever is in the .grad attribute. Let’s try running the above steps again:\n\nloss = calc_loss(coeffs, t_indep, t_dep)\nloss.backward()\ncoeffs.grad\n\ntensor([-0.0212,  0.0258, -0.0082, -0.0969,  0.4198, -0.4265, -0.2424, -0.0494,  0.2851, -0.3771, -0.0382,  0.4085])\n\n\n\n\nwhy set gradients to zero after each gradient descent step; how to set gradient to zero; how to do one iteration of training\nAs you see, our .grad values are have doubled. That’s because it added the gradients a second time. For this reason, after we use the gradients to do a gradient descent step, we need to set them back to zero.\nWe can now do one gradient descent step, and check that our loss decreases:\n\nloss = calc_loss(coeffs, t_indep, t_dep)\nloss.backward()\nwith torch.no_grad():\n    coeffs.sub_(coeffs.grad * 0.1)\n    coeffs.grad.zero_()\n    print(calc_loss(coeffs, t_indep, t_dep))\n\ntensor(0.4945)\n\n\n\n\nwhat does _ mean for coeffs.sub_() and grad.zero_()\nNote that a.sub_(b) subtracts b from a in-place. In PyTorch, any method that ends in _ changes its object in-place. Similarly, a.zero_() sets all elements of a tensor to zero."
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#training-the-linear-model",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#training-the-linear-model",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "Training the linear model",
    "text": "Training the linear model\n\nhow to split the dataset by using train and valid idx produced by fastai.data.transforms.RandomSplitter\nBefore we begin training our model, we’ll need to ensure that we hold out a validation set for calculating our metrics (for details on this, see “Getting started with NLP for absolute beginners”.\nThere’s lots of different ways we can do this. In the next notebook we’ll be comparing our approach here to what the fastai library does, so we’ll want to ensure we split the data in the same way. So let’s use RandomSplitter to get indices that will split our data into training and validation sets:\n\nfrom fastai.data.transforms import RandomSplitter\ntrn_split,val_split=RandomSplitter(seed=42)(df)\n\nNow we can apply those indicies to our independent and dependent variables:\n\ntrn_indep,val_indep = t_indep[trn_split],t_indep[val_split]\ntrn_dep,val_dep = t_dep[trn_split],t_dep[val_split]\nlen(trn_indep),len(val_indep)\n\n(713, 178)\n\n\nWe’ll create functions for the three things we did manually above: updating coeffs, doing one full gradient descent step, and initilising coeffs to random numbers:\n\n\nhow to udpate coefficients in a function update_coeffs\n\ndef update_coeffs(coeffs, lr):\n    coeffs.sub_(coeffs.grad * lr)\n    coeffs.grad.zero_()\n\n\n\nhow to do one epoch training in a function one_epoch\n\ndef one_epoch(coeffs, lr):\n    loss = calc_loss(coeffs, trn_indep, trn_dep)\n    loss.backward()\n    with torch.no_grad(): update_coeffs(coeffs, lr)\n    print(f\"{loss:.3f}\", end=\"; \")\n\n\n\nhow to initializing coefficients in a function init_coeffs\n\ndef init_coeffs(): return (torch.rand(n_coeff)-0.5).requires_grad_()\n\n\n\nhow to integrate funcs above to form a function train_model on multiple epochs\nWe can now use these functions to train our model:\n\ndef train_model(epochs=30, lr=0.01):\n    torch.manual_seed(442)\n    coeffs = init_coeffs()\n    for i in range(epochs): one_epoch(coeffs, lr=lr)\n    return coeffs\n\nLet’s try it. Our loss will print at the end of every step, so we hope we’ll see it going down:\n\ncoeffs = train_model(18, lr=0.2)\n\n0.536; 0.502; 0.477; 0.454; 0.431; 0.409; 0.388; 0.367; 0.349; 0.336; 0.330; 0.326; 0.329; 0.304; 0.314; 0.296; 0.300; 0.289; \n\n\n\n\nhow to display coefficients of the model with func show_coeffs\nIt does!\nLet’s take a look at the coefficients for each column:\n\ndef show_coeffs(): return dict(zip(indep_cols, coeffs.requires_grad_(False)))\nshow_coeffs()\n\n{'Age': tensor(-0.2694),\n 'SibSp': tensor(0.0901),\n 'Parch': tensor(0.2359),\n 'LogFare': tensor(0.0280),\n 'Sex_male': tensor(-0.3990),\n 'Sex_female': tensor(0.2345),\n 'Pclass_1': tensor(0.7232),\n 'Pclass_2': tensor(0.4112),\n 'Pclass_3': tensor(0.3601),\n 'Embarked_C': tensor(0.0955),\n 'Embarked_Q': tensor(0.2395),\n 'Embarked_S': tensor(0.2122)}"
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#measuring-accuracy",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#measuring-accuracy",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "Measuring accuracy",
    "text": "Measuring accuracy\n\nThere are many possible loss options such as accuracy other than mean absolute error\nThe Kaggle competition is not, however, scored by absolute error (which is our loss function). It’s scored by accuracy – the proportion of rows where we correctly predict survival. Let’s see how accurate we were on the validation set. First, calculate the predictions:\n\npreds = calc_preds(coeffs, val_indep)\n\n\n\nhow to calc accuracy for the binary dependent variable\nWe’ll assume that any passenger with a score of over 0.5 is predicted to survive. So that means we’re correct for each row where preds>0.5 is the same as the dependent variable:\n\nresults = val_dep.bool()==(preds>0.5)\nresults[:16]\n\ntensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True, False, False, False,  True,  True, False])\n\n\nLet’s see what our average accuracy is:\n\nresults.float().mean()\n\ntensor(0.7865)\n\n\n\n\nhow to wrap the process of calc accuracy using coeffs into a func acc(coeffs)\nThat’s not a bad start at all! We’ll create a function so we can calcuate the accuracy easy for other models we train:\n\ndef acc(coeffs): return (val_dep.bool()==(calc_preds(coeffs, val_indep)>0.5)).float().mean()\nacc(coeffs)\n\ntensor(0.7865)"
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#using-sigmoid",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#using-sigmoid",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "Using sigmoid",
    "text": "Using sigmoid\n\nwhen will we be needing something like sigmoid\nLooking at our predictions, there’s one obvious problem – some of our predictions of the probability of survival are >1, and some are <0:\n\npreds[:28]\n\ntensor([ 0.8160,  0.1295, -0.0148,  0.1831,  0.1520,  0.1350,  0.7279,  0.7754,  0.3222,  0.6740,  0.0753,  0.0389,  0.2216,  0.7631,\n         0.0678,  0.3997,  0.3324,  0.8278,  0.1078,  0.7126,  0.1023,  0.3627,  0.9937,  0.8050,  0.1153,  0.1455,  0.8652,  0.3425])\n\n\n\n\nhow to write and plot a func like sigmoid using sympy\nTo fix this, we should pass every prediction through the sigmoid function, which has a minimum at zero and maximum at one, and is defined as follows:\n\nimport sympy\nsympy.plot(\"1/(1+exp(-x))\", xlim=(-5,5));\n\n\n\n\n\n\nhow to update calc_preds by wrapping torch.sigmoid around prediction\nPyTorch already defines that function for us, so we can modify calc_preds to use it:\n\ndef calc_preds(coeffs, indeps): return torch.sigmoid((indeps*coeffs).sum(axis=1))\n\nLet’s train a new model now, using this updated function to calculate predictions:\n\ncoeffs = train_model(lr=100)\n\n0.510; 0.327; 0.294; 0.207; 0.201; 0.199; 0.198; 0.197; 0.196; 0.196; 0.196; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; \n\n\nThe loss has improved by a lot. Let’s check the accuracy:\n\nacc(coeffs)\n\ntensor(0.8258)\n\n\nThat’s improved too! Here’s the coefficients of our trained model:\n\nshow_coeffs()\n\n{'Age': tensor(-1.5061),\n 'SibSp': tensor(-1.1575),\n 'Parch': tensor(-0.4267),\n 'LogFare': tensor(0.2543),\n 'Sex_male': tensor(-10.3320),\n 'Sex_female': tensor(8.4185),\n 'Pclass_1': tensor(3.8389),\n 'Pclass_2': tensor(2.1398),\n 'Pclass_3': tensor(-6.2331),\n 'Embarked_C': tensor(1.4771),\n 'Embarked_Q': tensor(2.1168),\n 'Embarked_S': tensor(-4.7958)}\n\n\nThese coefficients seem reasonable – in general, older people and males were less likely to survive, and first class passengers were more likely to survive."
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#submitting-to-kaggle",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#submitting-to-kaggle",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "Submitting to Kaggle",
    "text": "Submitting to Kaggle\nNow that we’ve got a trained model, we can prepare a submission to Kaggle. To do that, first we need to read the test set:\n\nread test data using pandas.read_csv\n\ntst_df = pd.read_csv(path/'test.csv')\n\n\n\nwhy and how to fill the missing value in Fare column with 0 instead of mode\nIn this case, it turns out that the test set is missing Fare for one passenger. We’ll just fill it with 0 to avoid problems:\n\ntst_df['Fare'] = tst_df.Fare.fillna(0)\n\n\n\nhow to handle missing values, long-tailed distribution and dummies together for test data\nNow we can just copy the same steps we did to our training set and do the same exact things on our test set to preprocess the data:\n\ntst_df.fillna(modes, inplace=True)\ntst_df['LogFare'] = np.log(tst_df['Fare']+1)\ntst_df = pd.get_dummies(tst_df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n\n\n\nhow to turn independent variable values into tensor\n\ntst_indep = tensor(tst_df[indep_cols].values, dtype=torch.float)\n\n\n\nhow to make sure independent variable in test data share the same value scare with those in training data\n\ntst_indep = tst_indep / vals\n\n\n\nhow to turn true or false into 1 or 0 and save them into a column\nLet’s calculate our predictions of which passengers survived in the test set:\n\ntst_df['Survived'] = (calc_preds(tst_indep, coeffs)>0.5).int()\n\n\n\nhow to select two columns of a dataframe and save them into a csv file using to_csv\nThe sample submission on the Kaggle competition site shows that we’re expected to upload a CSV with just PassengerId and Survived, so let’s create that and save it:\n\nsub_df = tst_df[['PassengerId','Survived']]\nsub_df.to_csv('sub.csv', index=False)\n\n\n\nhow to check the first few lines of the csv file using !head\nWe can check the first few rows of the file to make sure it looks reasonable:\n\n!head sub.csv\n\nPassengerId,Survived\n892,0\n893,0\n894,0\n895,0\n896,0\n897,0\n898,1\n899,0\n900,1\n\n\nWhen you click “save version” in Kaggle, and wait for the notebook to run, you’ll see that sub.csv appears in the “Data” tab. Clicking on that file will show a Submit button, which allows you to submit to the competition."
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#using-matrix-product",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#using-matrix-product",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "Using matrix product",
    "text": "Using matrix product\n\nhow to do matrix product @ between a matrix and a vector with PyTorch; how to use @ instead of doing multiplication and then addition together\nWe can make things quite a bit neater…\nTake a look at the inner-most calculation we’re doing to get the predictions:\n\n(val_indep*coeffs).sum(axis=1)\n\ntensor([ 12.3288, -14.8119, -15.4540, -13.1513, -13.3512, -13.6469,   3.6248,   5.3429, -22.0878,   3.1233, -21.8742, -15.6421, -21.5504,\n          3.9393, -21.9190, -12.0010, -12.3775,   5.3550, -13.5880,  -3.1015, -21.7237, -12.2081,  12.9767,   4.7427, -21.6525, -14.9135,\n         -2.7433, -12.3210, -21.5886,   3.9387,   5.3890,  -3.6196, -21.6296, -21.8454,  12.2159,  -3.2275, -12.0289,  13.4560, -21.7230,\n         -3.1366, -13.2462, -21.7230, -13.6831,  13.3092, -21.6477,  -3.5868, -21.6854, -21.8316, -14.8158,  -2.9386,  -5.3103, -22.2384,\n        -22.1097, -21.7466, -13.3780, -13.4909, -14.8119, -22.0690, -21.6666, -21.7818,  -5.4439, -21.7407, -12.6551, -21.6671,   4.9238,\n        -11.5777, -13.3323, -21.9638, -15.3030,   5.0243, -21.7614,   3.1820, -13.4721, -21.7170, -11.6066, -21.5737, -21.7230, -11.9652,\n        -13.2382, -13.7599, -13.2170,  13.1347, -21.7049, -21.7268,   4.9207,  -7.3198,  -5.3081,   7.1065,  11.4948, -13.3135, -21.8723,\n        -21.7230,  13.3603, -15.5670,   3.4105,  -7.2857, -13.7197,   3.6909,   3.9763, -14.7227, -21.8268,   3.9387, -21.8743, -21.8367,\n        -11.8518, -13.6712, -21.8299,   4.9440,  -5.4471, -21.9666,   5.1333,  -3.2187, -11.6008,  13.7920, -21.7230,  12.6369,  -3.7268,\n        -14.8119, -22.0637,  12.9468, -22.1610,  -6.1827, -14.8119,  -3.2838, -15.4540, -11.6950,  -2.9926,  -3.0110, -21.5664, -13.8268,\n          7.3426, -21.8418,   5.0744,   5.2582,  13.3415, -21.6289, -13.9898, -21.8112,  -7.3316,   5.2296, -13.4453,  12.7891, -22.1235,\n        -14.9625,  -3.4339,   6.3089, -21.9839,   3.1968,   7.2400,   2.8558,  -3.1187,   3.7965,   5.4667, -15.1101, -15.0597, -22.9391,\n        -21.7230,  -3.0346, -13.5206, -21.7011,  13.4425,  -7.2690, -21.8335, -12.0582,  13.0489,   6.7993,   5.2160,   5.0794, -12.6957,\n        -12.1838,  -3.0873, -21.6070,   7.0744, -21.7170, -22.1001,   6.8159, -11.6002, -21.6310])\n\n\nMultiplying elements together and then adding across rows is identical to doing a matrix-vector product! Python uses the @ operator to indicate matrix products, and is supported by PyTorch tensors. Therefore, we can replicate the above calculate more simply like so:\n\nval_indep@coeffs\n\ntensor([ 12.3288, -14.8119, -15.4540, -13.1513, -13.3511, -13.6468,   3.6248,   5.3429, -22.0878,   3.1233, -21.8742, -15.6421, -21.5504,\n          3.9393, -21.9190, -12.0010, -12.3775,   5.3550, -13.5880,  -3.1015, -21.7237, -12.2081,  12.9767,   4.7427, -21.6525, -14.9135,\n         -2.7433, -12.3210, -21.5886,   3.9387,   5.3890,  -3.6196, -21.6296, -21.8454,  12.2159,  -3.2275, -12.0289,  13.4560, -21.7230,\n         -3.1366, -13.2462, -21.7230, -13.6831,  13.3092, -21.6477,  -3.5868, -21.6854, -21.8316, -14.8158,  -2.9386,  -5.3103, -22.2384,\n        -22.1097, -21.7466, -13.3780, -13.4909, -14.8119, -22.0690, -21.6666, -21.7818,  -5.4439, -21.7407, -12.6551, -21.6671,   4.9238,\n        -11.5777, -13.3323, -21.9638, -15.3030,   5.0243, -21.7614,   3.1820, -13.4721, -21.7170, -11.6066, -21.5737, -21.7230, -11.9652,\n        -13.2382, -13.7599, -13.2170,  13.1347, -21.7049, -21.7268,   4.9207,  -7.3198,  -5.3081,   7.1065,  11.4948, -13.3135, -21.8723,\n        -21.7230,  13.3603, -15.5670,   3.4105,  -7.2857, -13.7197,   3.6909,   3.9763, -14.7227, -21.8268,   3.9387, -21.8743, -21.8367,\n        -11.8518, -13.6712, -21.8299,   4.9440,  -5.4471, -21.9666,   5.1333,  -3.2187, -11.6008,  13.7920, -21.7230,  12.6369,  -3.7268,\n        -14.8119, -22.0637,  12.9468, -22.1610,  -6.1827, -14.8119,  -3.2838, -15.4540, -11.6950,  -2.9926,  -3.0110, -21.5664, -13.8268,\n          7.3426, -21.8418,   5.0744,   5.2582,  13.3415, -21.6289, -13.9898, -21.8112,  -7.3316,   5.2296, -13.4453,  12.7891, -22.1235,\n        -14.9625,  -3.4339,   6.3089, -21.9839,   3.1968,   7.2400,   2.8558,  -3.1187,   3.7965,   5.4667, -15.1101, -15.0597, -22.9391,\n        -21.7230,  -3.0346, -13.5206, -21.7011,  13.4425,  -7.2690, -21.8335, -12.0582,  13.0489,   6.7993,   5.2160,   5.0794, -12.6957,\n        -12.1838,  -3.0873, -21.6070,   7.0744, -21.7170, -22.1001,   6.8159, -11.6002, -21.6310])\n\n\n\n\nupdate calc_preds func using matrix multiplication @\nIt also turns out that this is much faster, because matrix products in PyTorch are very highly optimised.\nLet’s use this to replace how calc_preds works:\n\ndef calc_preds(coeffs, indeps): return torch.sigmoid(indeps@coeffs)\n\n\n\nhow to initialize coeffs and turn it into a matrix with a single column; question: but why make coeffs between 0 and 0.1 instead of -0.5 and 0.5\nIn order to do matrix-matrix products (which we’ll need in the next section), we need to turn coeffs into a column vector (i.e. a matrix with a single column), which we can do by passing a second argument 1 to torch.rand(), indicating that we want our coefficients to have one column:\n\ndef init_coeffs(): return (torch.rand(n_coeff, 1)*0.1).requires_grad_()\n\n\n\nhow to turn a single column of dependent variable into a single column matrix or a column vector\nWe’ll also need to turn our dependent variable into a column vector, which we can do by indexing the column dimension with the special value None, which tells PyTorch to add a new dimension in this position:\n\ntrn_dep = trn_dep[:,None]\nval_dep = val_dep[:,None]\n\n\n\nquestion: why set learning rate to be 100 for this Titanic model\nWe can now train our model as before and confirm we get identical outputs…:\n\ncoeffs = train_model(lr=100)\n\n0.512; 0.323; 0.290; 0.205; 0.200; 0.198; 0.197; 0.197; 0.196; 0.196; 0.196; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; \n\n\n…and identical accuracy:\n\nacc(coeffs)\n\ntensor(0.8258)"
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#a-neural-network",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#a-neural-network",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "A neural network",
    "text": "A neural network\n\nhow to initialize coeffs for a neuralnet with two layers (including a hidden layer of n neurons) and the final output layer is a single neuron with a single coeff; question: how do -0.5 and -0.3 come from?\nWe’ve now got what we need to implement our neural network.\nFirst, we’ll need to create coefficients for each of our layers. Our first set of coefficients will take our n_coeff inputs, and create n_hidden outputs. We can choose whatever n_hidden we like – a higher number gives our network more flexibility, but makes it slower and harder to train. So we need a matrix of size n_coeff by n_hidden. We’ll divide these coefficients by n_hidden so that when we sum them up in the next layer we’ll end up with similar magnitude numbers to what we started with.\nThen our second layer will need to take the n_hidden inputs and create a single output, so that means we need a n_hidden by 1 matrix there. The second layer will also need a constant term added.\n\ndef init_coeffs(n_hidden=20):\n    layer1 = (torch.rand(n_coeff, n_hidden)-0.5)/n_hidden\n    layer2 = torch.rand(n_hidden, 1)-0.3\n    const = torch.rand(1)[0]\n    return layer1.requires_grad_(),layer2.requires_grad_(),const.requires_grad_()\n\n\n\nhow to update calc_preds for this 2 layer neuralnet using F.relu, matrix product @, and torch.sigmoid\nNow we have our coefficients, we can create our neural net. The key steps are the two matrix products, indeps@l1 and res@l2 (where res is the output of the first layer). The first layer output is passed to F.relu (that’s our non-linearity), and the second is passed to torch.sigmoid as before.\n\nimport torch.nn.functional as F\n\ndef calc_preds(coeffs, indeps):\n    l1,l2,const = coeffs\n    res = F.relu(indeps@l1)\n    res = res@l2 + const\n    return torch.sigmoid(res)\n\n\n\nhow to update coeffs layer by layer with layer.sub_ and layer.grad.zero_\nFinally, now that we have more than one set of coefficients, we need to add a loop to update each one:\n\ndef update_coeffs(coeffs, lr):\n    for layer in coeffs:\n        layer.sub_(layer.grad * lr)\n        layer.grad.zero_()\n\n\n\nquestion: how the learning rate is chosen (1.4 or 20) when training\nThat’s it – we’re now ready to train our model!\n\ncoeffs = train_model(lr=1.4)\n\n0.543; 0.532; 0.520; 0.505; 0.487; 0.466; 0.439; 0.407; 0.373; 0.343; 0.319; 0.301; 0.286; 0.274; 0.264; 0.256; 0.250; 0.245; 0.240; 0.237; 0.234; 0.231; 0.229; 0.227; 0.226; 0.224; 0.223; 0.222; 0.221; 0.220; \n\n\n\ncoeffs = train_model(lr=20)\n\n0.543; 0.400; 0.260; 0.390; 0.221; 0.211; 0.197; 0.195; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; \n\n\nIt’s looking good – our loss is lower than before. Let’s see if that translates to a better result on the validation set:\n\nacc(coeffs)\n\ntensor(0.8258)\n\n\nIn this case our neural net isn’t showing better results than the linear model. That’s not surprising; this dataset is very small and very simple, and isn’t the kind of thing we’d expect to see neural networks excel at. Furthermore, our validation set is too small to reliably see much accuracy difference. But the key thing is that we now know exactly what a real neural net looks like!"
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#deep-learning",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#deep-learning",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "Deep learning",
    "text": "Deep learning\n\nhow to move from neuralnet with one hidden layer to a deep learning\nThe neural net in the previous section only uses one hidden layer, so it doesn’t count as “deep” learning. But we can use the exact same technique to make our neural net deep, by adding more matrix multiplications.\nFirst, we’ll need to create additional coefficients for each layer:\n\ndef init_coeffs():\n    hiddens = [10, 10]  # <-- set this to the size of each hidden layer you want\n    sizes = [n_coeff] + hiddens + [1]\n    n = len(sizes)\n    layers = [(torch.rand(sizes[i], sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(n-1)]\n    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)]\n    for l in layers+consts: l.requires_grad_()\n    return layers,consts\n\n\n\nwhy so many messy constants and how they block the progress of deep learning in the early days\nYou’ll notice here that there’s a lot of messy constants to get the random numbers in just the right ranges. When you train the model in a moment, you’ll see that the tiniest changes to these initialisations can cause our model to fail to train at all! This is a key reason that deep learning failed to make much progress in the early days – it’s very finicky to get a good starting point for our coefficients. Nowadays, we have ways to deal with that, which we’ll learn about in other notebooks.\nOur deep learning calc_preds looks much the same as before, but now we loop through each layer, instead of listing them separately:\n\n\nhow to use enumerate to loop both idx and item\n\nimport torch.nn.functional as F\n\ndef calc_preds(coeffs, indeps):\n    layers,consts = coeffs\n    n = len(layers)\n    res = indeps\n    for i,l in enumerate(layers):\n        res = res@l + consts[i]\n        if i!=n-1: res = F.relu(res)\n    return torch.sigmoid(res)\n\nWe also need a minor update to update_coeffs since we’ve got layers and consts separated now:\n\ndef update_coeffs(coeffs, lr):\n    layers,consts = coeffs\n    for layer in layers+consts:\n        layer.sub_(layer.grad * lr)\n        layer.grad.zero_()\n\nLet’s train our model…\n\ncoeffs = train_model(lr=4)\n\n0.521; 0.483; 0.427; 0.379; 0.379; 0.379; 0.379; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.377; 0.376; 0.371; 0.333; 0.239; 0.224; 0.208; 0.204; 0.203; 0.203; 0.207; 0.197; 0.196; 0.195; \n\n\n…and check its accuracy:\n\nacc(coeffs)\n\ntensor(0.8258)"
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#final-thoughts",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#final-thoughts",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "Final thoughts",
    "text": "Final thoughts\n\nHow much similar or different between practical models and the models from scratch above\nIt’s actually pretty cool that we’ve managed to create a real deep learning model from scratch and trained it to get over 80% accuracy on this task, all in the course of a single notebook!\nThe “real” deep learning models that are used in research and industry look very similar to this, and in fact if you look inside the source code of any deep learning model you’ll recognise the basic steps are the same.\nThe biggest differences in practical models to what we have above are:\n\nHow initialisation and normalisation is done to ensure the model trains correctly every time\nRegularization (to avoid over-fitting)\nModifying the neural net itself to take advantage of knowledge of the problem domain\nDoing gradient descent steps on smaller batches, rather than the whole dataset.\n\nI’ll be adding notebooks about all these later, and will add links here once they’re ready.\nIf you found this notebook useful, please remember to click the little up-arrow at the top to upvote it, since I like to know when people have found my work useful, and it helps others find it too. (BTW, be sure you’re looking at my original notebook here when you do that, and are not on your own copy of it, otherwise your upvote won’t get counted!) And if you have any questions or comments, please pop them below – I read every comment I receive!\n\nfrom fastdebug.utils import *\n\n\nfastnbs(\"numpy book\")\n\na numpy book recommended by jeremy; what is a tensor\n\n\nAs you can see, they’re tensors. A tensor is just like an array in numpy (if you’re not familiar with numpy, I strongly recommend reading this great book, because it’s a critical foundation for nearly all numeric programming in Python. Furthermore, PyTorch, which most researchers use for deep learning, is modeled closely on numpy.) A tensor can be a single number (a scalar or rank-0 tensor), a list of numbers (a vector or rank-1 tensor), a table of numbers (a matrix or rank-0 tensor), a table of tables of numbers (a rank-3 tensor), and so forth.\nWe’re not going to learn much about our data by just looking at the raw numbers, so let’s draw a picture:\n\n\nOpen 0004_fastai_how_neuralnet_work in Jupyter Notebook\n\n\n\nfastlistnbs()\n\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0004_fastai_how_neuralnet_work.md\n## Fitting a function with *gradient descent*\n### Is neuralnet just a math function? what does the function look like?\n### why neuralnet is random at first and how to make neuralnet useful\n### `plot_function`: how to plot a function with plt; how to create x input with torch.linspace; how to plot x, y, color and title with plt;\n### how to create a particular quadratic function\n### how to write a function `quad` to create any quadratic function\n### how does `partial` and `quad` work to modify `quad` to a slightly different func?\n### how to add noise to both mult and add of the neuralnet/function; how to create noise using `np.random.normal`\n### how to create a random seed to ensure x and y are the same each run\n## A numpy book recommended by Jeremy; what is a tensor\n### how to scatterplot with plt\n### how to plot a scatterplot and a line and slides for 3 params of the line func\n### why need a loss function? how to write a mean absolute error function with torch.abs and mean\n### how display and change loss by changing values of params with sliders of interactive plot\n### A 15-min calculus video series recommended by Jeremy to watch first\n## Automating gradient descent\n### how derivatives automatically guide params to change for a lower loss\n### how to create a mean absolute error function on any quadratic model\n### how to create an random tensor with 3 values as initialized params\n### how to calc gradients of params? 1. tell PyTorch to get ready for calculating gradients for these params; 2. calc loss; 3. calc the gradients with `loss.backward()`; 4. how to access params' gradients; \n### how to change params with gradients properly to lower loss¶\n### why `with torch.no_grad():` when updating params with gradients\n### how to do 10 iterations of updating params with gradients\n## How a neural network approximates any given function\n## how to combine a linear func with max(x, 0) into a rectified linear function; how to use torch.clip(y, 0.) to perform max(y, 0.)\n## how to use partial to wrap rectified_linear to create a specific rectified_linear func\n## how to use `F.relu` to replace `torch.clip` to create a rectified linear func; \n### create double and quaduple relu func/neuralnet\n## How to recognise an owl\n### deep learning basically is drawing squiggly lines infinitely given computation and time\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0001_fastai_is_it_a_bird.md\n## Useful Course sites\n## How to use autoreload\n## How to install and update libraries\n## Know a little about the libraries\n### what is fastai\n### what is duckduckgo\n## How to use fastdebug with fastai notebooks\n### how to use fastdebug\n### Did I document it in a notebook before?\n### Did I document it in a src before?\n## how to search and get a url of an image; how to download with an url; how to view an image;\n### how to create folders using path; how to search and download images in folders; how to resize images \n## Train my model\n### How to find and unlink images not properly downloaded\n### How to create a DataLoaders with DataBlock; how to view data with it\n### How to build my model with dataloaders and pretrained model; how to train my model\n### How to predict with my model; how to avoid running cells in nbdev_prepare\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0002_fastai_Saving_Model_fastai.md\n## what to import to handle vision problems in fastai\n## how to download and decompress datasets prepared by fastai\n## how to tell it is a cat by reading filename\n## how to create dataloaders with `from_name_func`\n## how to create a pretrained model with resnet18 and error_rate; how to fine tune it 3 epochs\n## how to export model to a pickle file and download it from Kaggle\n## how to convert ipynb to md\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0005_fastai_linear_neuralnet_scratch.md\n## how to not execute the entire notebook\n## Introduction\n## How to download kaggle dataset to your local machine or colab? how to ues kaggle api and zipfile to download data into specified folder; how to use `pathlib.Path` to create a path;\n## how to set the print display option for numpy, torch and pandas\n## Cleaning the data\n### how to read csv file with pandas and `path/'subfolder_name'`\n### why missing value is a problem? how to find out the num of missing values of each column with pandas?\n### which value is most used to replace missing value? how to get mode for each column with pandas using `iloc[0]`\n### how to use pandas `iloc` function\n### how to fill missing values with mode without making a new copy with `pandas.fillna`\n### how to get a quick summary of all the numeric columns with pandas and numpy\n### what is long-tailed data in histogram and why it is a problem for neuralnet\n### how to plot histogram with pandas on a single column\n### how to fix long-tailed data with logarithm; why should logarithm work; how to handle zero values when applying logarithm\n### how to get a quick summary of all the non-numeric columns with pandas\n### when do we need dummy variables and how to create dummy variables with pandas\n### how to check the first few rows of selected columns with pandas\n### how to create dependent/target variable and independent/predictor variables in PyTorch tensors; how to create variables in tensor from pandas dataframe\n### how to check the size (rows and columns) of independent variables in tensor\n## Setting up a linear model\n### how to create coefficients for each (column) of our independent variables; how to get random seed in torch; how to get the num of columns; how to create random number between -0.5 and 0.5;\n### why no bias or a constant is needed for this Titanic dataset?\n### why a column `Age` having higher values than other columns can cause problem for our model; how to solve this problem by making them the same scale; how to get the max value of each column with pandas dataframe max func\n### what is maxtrix by vector operation (multiply or divide)\n### How to calculate the prediction of a linear model\n### how to look at the first 10 values of predictions\n### how to calc mean absolute error\n### how to calc predictions with a func `calc_preds`; how to calc loss with a func `calc_loss`\n## Doing a gradient descent step\n### How to cacl gradients for coefficients\n### why set gradients to zero after each gradient descent step; how to set gradient to zero; how to do one iteration of training\n### what does _ mean for `coeffs.sub_()` and `grad.zero_()`\n## Training the linear model\n### how to split the dataset by using train and valid idx produced by `fastai.data.transforms.RandomSplitter`\n### how to udpate coefficients in a function `update_coeffs`\n### how to do one epoch training in a function `one_epoch`\n### how to initializing coefficients in a function `init_coeffs`\n### how to integrate funcs above to form a function `train_model` on multiple epochs\n### how to display coefficients of the model with func `show_coeffs`\n## Measuring accuracy\n### There are many possible loss options such as accuracy other than mean absolute error\n### how to calc accuracy for the binary dependent variable\n### how to wrap the process of calc accuracy using coeffs into a func `acc(coeffs)`\n## Using sigmoid\n### when will we be needing something like sigmoid\n### how to write and plot a func like `sigmoid` using sympy\n### how to update `calc_preds` by wrapping `torch.sigmoid` around prediction\n## Submitting to Kaggle\n### read test data using `pandas.read_csv`\n### why and how to fill the missing value in Fare column with 0 instead of mode\n### how to handle missing values, long-tailed distribution and dummies together for test data\n### how to turn independent variable values into tensor\n### how to make sure independent variable in test data share the same value scare with those in training data\n### how to turn true or false into 1 or 0 and save them into a column\n### how to select two columns of a dataframe and save them into a csv file using `to_csv`\n### how to check the first few lines of the csv file using `!head`\n## Using matrix product\n### how to do matrix product `@` between a matrix and a vector with PyTorch; how to use `@` instead of doing multiplication and then addition together\n### update `calc_preds` func using matrix multiplication `@`\n### how to initialize coeffs and turn it into a matrix with a single column; question: but why make coeffs between 0 and 0.1 instead of -0.5 and 0.5\n### how to turn a single column of dependent variable into a single column matrix or a column vector\n### question: why set learning rate to be 100 for this Titanic model\n## A neural network\n### how to initialize coeffs for a neuralnet with two layers (including a hidden layer of n neurons) and the final output layer is a single neuron with a single coeff; question: how do `-0.5` and `-0.3` come from?\n### how to update `calc_preds` for this 2 layer neuralnet using `F.relu`, matrix product `@`, and `torch.sigmoid`\n### how to update coeffs layer by layer with `layer.sub_` and `layer.grad.zero_`\n### question: how the learning rate is chosen (1.4 or 20) when training\n## Deep learning\n### how to move from neuralnet with one hidden layer to a deep learning\n### why so many messy constants and how they block the progress of deep learning in the early days\n### how to use `enumerate` to loop both idx and item\n## Final thoughts\n### How much similar or different between practical models and the models from scratch above\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0003_fastai_which_image_model_best.md\n## timm\n## how to git clone TIMM analysis data; how to enter a directory with %cd\n## how to read a csv file with pandas\n## how to merge data with pandas; how to create new column with pandas; how to string extract with regex expression; how to select columns up to a particular column with pandas; how to do loc in pandas; how to select a group of columns using str.contains and regex\n## Inference results\n### how to scatterplot with plotly.express; how to set the plot's width, height, size, title, x, y, log_x, color, hover_name, hover_data; \n### how to scatterplot on a subgroup of data using regex and plotly\n## Training results\n### convert ipynb to md\n\n/Users/Natsume/Documents/fastdebug/mds/lib/utils.md\n## setup for exporting to a module\n## how to get current notebook's name, path and url\n## how to convert ipynb to md automatically; how to run commands in python\n## Autoreload for every notebook\n## Expand cells\n## Import fastcore env\n## to inspect a class\n### get the docs for each function of a class\n## is it a metaclass?\n## is it a decorator\n### handle all kinds of exceptions for evaluating retn \n## whatinside a module of a library\n### show the type of objects inside `__all__`\n### working for fastdebug.core\n### to show Fastdb methods\n## whichversion of a library\n## fastview\n## fastscrs\n## getrootport\n## jn_link\n## get_all_nbs\n### get all nbs path for both md and ipynb\n### add index.ipynb\n## openNB\n## highlight\n## display_md\n## display_block\n### handle both file path and file content at the same time\n## fastnbs\n## fastcodes\n## fastnotes\n### multiple folders\n## fastlistnbs\n## fastlistsrcs\n## Best practice of fastdebug.core\n## Best practice of fastdebug.utils\n## Export\n\n/Users/Natsume/Documents/fastdebug/mds/lib/00_core.md\n## make life easier with defaults  \n## globals() and locals()\n## Execute strings\n### new variable or updated variable by exec will only be accessible from locals()\n### eval can override its own globals() and locals()\n### when exec update existing functions\n### when the func to be udpated involve other libraries\n### inside a function, exec() allow won't give you necessary env from function namespace\n### magic of `exec(b, globals().update(locals()))`\n### Bring variables from a func namespace to the sideout world\n### globals() in a cell vs globals() in a func\n## make a colorful string\n## align text to the most right\n## printsrcwithidx\n### print the entire source code with idx from 0\n### print the whole src with idx or print them in parts\n### use cmts from dbprint to print out src with comments\n### no more update for printsrcwithidx, for the latest see Fastdb.print\n## print out src code\n### basic version\n### print src with specific number of lines\n### make the naming more sensible\n### Allow a dbline occur more than once\n### adding idx to the selected srclines\n#### printsrclinewithidx\n### dblines can be string of code or idx number\n### avoid multi-occurrance of the same srcline\n## dbprint on expression\n### basic version\n### insert dbcode and make a new dbfunc\n### Bring outside namespace variables into exec()\n### Bring what inside the func namespace variables to the outside world\n### Adding g = locals() to dbprintinsert to avoid adding env individually\n### enable srclines to be either string or int \n### enable = to be used as assignment in codes\n### avoid adding \"env=g\" for dbprintinsert\n### collect cmt for later printsrcwithidx to print comments together\n### make sure only one line with correct idx is debugged\n### avoid typing \"\" when there is no codes\n### no more update for dbprint, for the latest see Fastdb.dbprint\n### use dbprint to override the original official code without changing its own pyfile\n## dbprintinsert\n### Run and display the inserted dbcodes \n### use locals() inside the dbsrc code to avoid adding env individually\n### enable dbprintinsert to do exec on a block of code\n## printrunsrclines() \n### Examples\n#### simple example\n#### complex example\n### insert a line after each srcline to add idx\n### add correct indentation to each inserted line\n#### count the indentation for each srcline\n### indentation special case: if, else, for, def\n### remove pure comments or docs from dbsrc\n### print out the srclines which get run\n### Make sure all if, else, for get printed\n### Put all together into the function printrunsrclines()\n#### no more renaming of foo\n#### add example as a param into the function\n#### improve on search for `if`, else, for, def to avoid errors for more examples\n#### remove an empty line with indentation\n### make it work\n### more difficult examples to test printrunsrc()\n## Make fastdebug a class\n### improve on the line idx readability\n### collect cmt from dbprint and print\n### make sure only the line with correct idx is debugged\n### having \"\" or \"   \" inside codes without causing error\n### replace Fastdb.printsrcwithdix with Fastdb.print\n### add idx to dbsrc when showdbsrc=True\n### not load the inner locals() to outenv can prevent mysterious printing of previous db messages\n### using @patch to enable docs for instance methods like `dbprint` and `print`\n### move param env into `__init__`\n### Add example to the obj\n### Take not only function but also class\n### To remove the necessity of self.takExample()\n### Try to remove g = locals()\n### Make sure `showdbsrc=True` give us the line starting with 'dbprintinsert'\n### Make sure `showdbsrc=True` give us info on changes in g or outenv\n### exit and print a warning message: idx has to be int\n### handle errors by codes with trailing spaces \n### showdbsrc=True, check whether Fastdb.dbprint and fdb.dbprint are same object using `is`\n### remove unnecessary db printout when showdbsrc=True and add printout to display sections\n### raise TypeError when decode are not integer and showdbsrc=true working on both method and function\n### when debugging dbprint, make sure dbsrc is printed with the same idx as original\n### update dbsrc to the global env\n### go back to normal before running dbprint again\n### auto print src with cmt and idx as the ending part of dbprint\n### to mark my explorations (expressions to evaluate) to stand out\n### Add the print of src with idx and comments at the end of dbsrc\n### embed example and autoprint to shorten the code to type\n### Make title for dbprint\n### Adding self.eg info and color group into dbprint and print\n#### todo: make the comments with same self.eg have the same color\n### make dbsrc print idx right\n### add self.eg to a dict with keys are idxsrc\n### handle both function and class as src\n### documenting on Fastdb.dbprint itself\n## mk_dbsrc\n## Turn mk_dbsrc into docsrc \n### handle when no codes are given\n## create_dbsrc_from_string\n## replaceWithDbsrc\n### handle class and metaclass\n### improve on handling function as decorator\n### Handling `inspect._signature_from_callable` to become `self.dbsrc`\n### handling usage of `@delegates`\n### handling `@delegates` with indentation before it\n### handling classes by inspect.isclass() rather than == type and add more class situations\n### handling `class _T(_TestA, metaclass=BypassNewMeta): `\n## run_example\n### `exec(self.eg, globals().update(self.egEnv), locals())` works better than `...update(locals()), self.egEnv)\n### no more env cells run before `fdb.eg` to make `fdb.run_example` work\n## Autoprint\n## Take an example and its env into Fastdb obj\n## print src with idx and cmt in whole or parts\n### print self.eg after each comment and colorize comments\n### color examples and cmts separately and make the func simpler\n### split each cmt and colorize parts randomly\n### printcmts1 while saving into a file\n## goback\n## Fastdb.explore\n### adding one breakpoint with comment\n### Adding multiple breakpoints by multiple set_trace()\n### Go back to normal before running explore again\n### enable fdb.takExample(\"whatinside(fu), ...) without using `fu.whatinside`\n### refactory explore\n## snoop\n### snoop on both function and class\n### snoop on class and method and all???\n### snoop\n### simplify adding @snoop for both normal function and decorator\n### handling classes\n### add watch\n## Snoop\n### add watch\n### use guide on Fastdb.dbprint\n## reliveonce\n## Fastdb.debug\n## Export\n## Send to Obsidian\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0001_fastcore_meta_delegates.md\n## Import\n## Initiate Fastdb and example in str\n## Example\n## docsrc\n## Snoop\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0003_Explore_document_FixSigMeta_PrePostInitMeta_AutoInit.md\n## Initialize fastdebug objects\n## class FixSigMeta(type) vs class Foo(type)\n## class Foo()\n## class PrePostInitMeta(FixSigMeta)\n## class Foo(metaclass=FixSigMeta)\n## class AutoInit(metaclass=PrePostInitMeta)\n## Prepare examples for FixSigMeta, PrePostInitMeta, AutoInit \n## Snoop them together in one go\n### embed the dbsrc of FixSigMeta into PrePostInitMeta\n### embed dbsrc of PrePostInitMeta into AutoInit\n## Explore and Document on them together \n\n/Users/Natsume/Documents/fastdebug/mds/demos/0004_fastcore.meta._rm_self.md\n## imports\n## set up\n## document\n## snoop\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0005_fastcore.meta.test_sig.md\n## imports\n## setups\n## documents\n## snoop\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0007_fastcore.meta.BypassNewMeta.md\n## Reading official docs\n## Inspecting class\n## Initiating with examples\n## Snoop\n## Document\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0002_signature_from_callable.md\n## Expand cell\n## Imports and initiate\n## Examples\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0008_use_kwargs_dict.md\n## Imports\n## Reading official docs\n## empty2none\n## `_mk_param`\n## use_kwargs_dict\n### Reading docs\n## use_kwargs\n### Reading docs\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0006_fastcore.meta.NewChkMeta.md\n## Import and Initalization\n## Official docs\n## Prepare Example\n## Inspect classes\n## Snoop\n## Document\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0000_tour.md\n### Documentation\n### Testing\n### Foundations\n### L\n### Transforms\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0012_fastcore_foundation_L.md\n## Document `L` with fastdebug\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0011_Fastdb.md\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0009_funcs_kwargs.md\n## fastcore.meta.method\n### Reading Docs\n### Running codes\n### Document\n### snoop\n## funcs_kwargs\n### Official docs\n### snoop: from _funcs_kwargs to funcs_kwargs\n### snoop only '_funcs_kwargs' by breaking up 'funcs_kwargs'\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0010_fastcore_meta_summary.md\n## import\n## fastcore and fastcore.meta\n### What's inside fastcore.meta\n## Review individual funcs and classes\n### What is fastcore.meta all about? \n### What can these metaclasses do for me?\n#### FixSigMeta\n#### PrePostInitMeta\n#### AutoInit\n#### NewChkMeta\n#### BypassNewMeta\n### What can those decorators do for me?\n#### use_kwargs_dict\n#### use_kwargs\n#### delegates\n#### funcs_kwargs\n### The remaining functions\n## What is fastcore.meta all about\n\n/Users/Natsume/Documents/fastdebug/mds/questions/00_question_anno_dict.md\n## `anno_dict` docs\n## Dive in\n## `anno_dict` seems not add anything new to `__annotations__`\n## use fastdebug to double check\n## Does fastcore want anno_dict to include params with no annos?\n## Jeremy's response\n\n\n\nipy2md()\n\n[jupytext] Reading /Users/Natsume/Documents/fastdebug/nbs/2022part1/0005_fastai_linear_neuralnet_scratch.ipynb in format ipynb\n[jupytext] Writing /Users/Natsume/Documents/fastdebug/nbs/2022part1/0005_fastai_linear_neuralnet_scratch.md\ncp to : /Users/Natsume/Documents/divefastai/Debuggable/jupytext\nmove to : /Users/Natsume/Documents/fastdebug/mds/2022part1/\n\n\n[NbConvertApp] Converting notebook /Users/Natsume/Documents/fastdebug/nbs/2022part1/0005_fastai_linear_neuralnet_scratch.ipynb to markdown\n\n\ncopy to : /Users/Natsume/Documents/fastdebug/mds_output\nmove to : /Users/Natsume/Documents/divefastai/Debuggable/nbconvert\n\n\n[NbConvertApp] Support files will be in 0005_fastai_linear_neuralnet_scratch_files/\n[NbConvertApp] Making directory /Users/Natsume/Documents/fastdebug/nbs/2022part1/0005_fastai_linear_neuralnet_scratch_files\n[NbConvertApp] Making directory /Users/Natsume/Documents/fastdebug/nbs/2022part1/0005_fastai_linear_neuralnet_scratch_files\n[NbConvertApp] Making directory /Users/Natsume/Documents/fastdebug/nbs/2022part1/0005_fastai_linear_neuralnet_scratch_files\n[NbConvertApp] Writing 54964 bytes to /Users/Natsume/Documents/fastdebug/nbs/2022part1/0005_fastai_linear_neuralnet_scratch.md"
  },
  {
    "objectID": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#a-numpy-book-recommended-by-jeremy-what-is-a-tensor",
    "href": "fastai_notebooks/fastai_linear_neuralnet_scratch.html#a-numpy-book-recommended-by-jeremy-what-is-a-tensor",
    "title": "0005_fastai_linear_neuralnet_scratch",
    "section": "a numpy book recommended by jeremy; what is a tensor",
    "text": "a numpy book recommended by jeremy; what is a tensor"
  },
  {
    "objectID": "fastai_notebooks/fastai_multi_target_road_to_top_part_4.html",
    "href": "fastai_notebooks/fastai_multi_target_road_to_top_part_4.html",
    "title": "0011_fastai_multi_target_road_to_top_part_4",
    "section": "",
    "text": "# install fastkaggle if not available\ntry: import fastkaggle\nexcept ModuleNotFoundError:\n    !pip install -Uq fastkaggle\n\nfrom fastkaggle import *\n\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv"
  },
  {
    "objectID": "fastai_notebooks/fastai_multi_target_road_to_top_part_4.html#multi-output-dataloader",
    "href": "fastai_notebooks/fastai_multi_target_road_to_top_part_4.html#multi-output-dataloader",
    "title": "0011_fastai_multi_target_road_to_top_part_4",
    "section": "Multi-output DataLoader",
    "text": "Multi-output DataLoader\n\nhow to get dataset and libraries ready for Kaggle’s Paddy Doctor competition\nFirst we’ll repeat the steps we used last time to access the data and ensure all the latest libraries are installed:\n\ncomp = 'paddy-disease-classification'\npath = setup_comp(comp, install='fastai \"timm>=0.6.2.dev0\"')\nfrom fastai.vision.all import *\nset_seed(42)\n\nfrom fastcore.parallel import *\ntrn_path = path/'train_images'\n\n\n\nhow to read a csv into a pandas dataframe and select a column to be its index column\nHere’s the CSV that Kaggle provides, showing the variety of rice contained in each image – we’ll make image_id the index of our data frame so that we can look up images directly to grab their variety:\n\ndf = pd.read_csv(path/'train.csv', index_col='image_id')\ndf.head()\n\n\n\n\n\n  \n    \n      \n      label\n      variety\n      age\n    \n    \n      image_id\n      \n      \n      \n    \n  \n  \n    \n      100330.jpg\n      bacterial_leaf_blight\n      ADT45\n      45\n    \n    \n      100365.jpg\n      bacterial_leaf_blight\n      ADT45\n      45\n    \n    \n      100382.jpg\n      bacterial_leaf_blight\n      ADT45\n      45\n    \n    \n      100632.jpg\n      bacterial_leaf_blight\n      ADT45\n      45\n    \n    \n      101918.jpg\n      bacterial_leaf_blight\n      ADT45\n      45\n    \n  \n\n\n\n\n\n\nhow to extract a particular info from a row using an index from the index column and the column of interest with df.loc\nPandas uses the loc attribute to look up rows by index. Here’s how we can get the variety of image 100330.jpg, for instance:\n\ndf.loc['100330.jpg', 'variety']\n\n'ADT45'\n\n\n\n\nhow to get the rice variety of each image with df.loc and the path from get_image_files\nOur DataBlock will be using get_image_files to get the list of training images, which returns Path objects. Therefore, to look up an item to get its variety, we’ll need to pass its name. Here’s a function which does just that:\n\ndef get_variety(p): return df.loc[p.name, 'variety']\n\n\n\nhow to use DataBlock to create dataloaders; what is DataBlock\nWe’re now ready to create our DataLoaders. To do this, we’ll use the DataBlock API, which is a flexible and convenient way to plug pieces of a data processing pipeline together:\n\ndls = DataBlock(\n    blocks=(ImageBlock,CategoryBlock,CategoryBlock),\n    n_inp=1,\n    get_items=get_image_files,\n    get_y = [parent_label,get_variety],\n    splitter=RandomSplitter(0.2, seed=42),\n    item_tfms=Resize(192, method='squish'),\n    batch_tfms=aug_transforms(size=128, min_scale=0.75)\n).dataloaders(trn_path)\n\nHere’s an explanation of each line:\nblocks=(ImageBlock,CategoryBlock,CategoryBlock),\nThe DataBlock will create 3 things from each file: an image (the contents of the file), and 2 categorical variables (the disease and the variety).\nn_inp=1,\nThere is 1 input (the image) – and therefore the other two variables (the two categories) are outputs.\nget_items=get_image_files,\nUse get_image_files to get a list of inputs.\nget_y = [parent_label,get_variety],\nTo create the two outputs for each file, call two functions: parent_label (from fastai) and get_variety (defined above).\nsplitter=RandomSplitter(0.2, seed=42),\nRandomly split the input into 80% train and 20% validation sets.\nitem_tfms=Resize(192, method='squish'),\nbatch_tfms=aug_transforms(size=128, min_scale=0.75)\nThese are the same item and batch transforms we’ve used in previous notebooks.\n\n\nhow to display 6 images from a batch\nLet’s take a look at part of a batch of this data:\n\ndls.show_batch(max_n=6)\n\n\n\n\nWe can see that fastai has created both the image input and two categorical outputs that we requested!"
  },
  {
    "objectID": "fastai_notebooks/fastai_multi_target_road_to_top_part_4.html#replicating-the-disease-model",
    "href": "fastai_notebooks/fastai_multi_target_road_to_top_part_4.html#replicating-the-disease-model",
    "title": "0011_fastai_multi_target_road_to_top_part_4",
    "section": "Replicating the disease model",
    "text": "Replicating the disease model\n\nhow to create disease error-rate and disease entropy loss functions to receive 3 instead of 2 inputs\nNow we’ll replicate the same disease model we’ve made before, but have it work with this new data.\nThe key difference is that our metrics and loss will now receive three things instead of two: the model outputs (i.e. the metric and loss function inputs), and the two targets (disease and variety). Therefore, we need to define slight variations of our metric (error_rate) and loss function (cross_entropy) to pass on just the disease target:\n\ndef disease_err(inp,disease,variety): return error_rate(inp,disease)\ndef disease_loss(inp,disease,variety): return F.cross_entropy(inp,disease)\n\n\n\nhow to create a vision learner using vision_learner which specifies loss_func, metrics, n_out (num of outputs)\nWe’re now ready to create our learner.\nThere’s just one wrinkle to be aware of. Now that our DataLoaders is returning multiple targets, fastai doesn’t know how many outputs our model will need. Therefore we have to pass n_out when we create our Learner – we need 10 outputs, one for each possible disease:\n\narch = 'convnext_small_in22k'\nlearn = vision_learner(dls, arch, loss_func=disease_loss, metrics=disease_err, n_out=10).to_fp16()\nlr = 0.01\n\nDownloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_224.pth\" to /root/.cache/torch/hub/checkpoints/convnext_small_22k_224.pth\n\n\nWhen we train this model we should get similar results to what we’ve seen with similar models before:\n\nlearn.fine_tune(5, lr)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      disease_err\n      time\n    \n  \n  \n    \n      0\n      1.367007\n      0.755765\n      0.248919\n      02:00\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      disease_err\n      time\n    \n  \n  \n    \n      0\n      0.699962\n      0.519963\n      0.168669\n      01:57\n    \n    \n      1\n      0.548859\n      0.298034\n      0.101874\n      01:55\n    \n    \n      2\n      0.322040\n      0.197317\n      0.057184\n      01:54\n    \n    \n      3\n      0.209926\n      0.137812\n      0.041326\n      01:54\n    \n    \n      4\n      0.153729\n      0.128756\n      0.038443\n      01:54"
  },
  {
    "objectID": "fastai_notebooks/fastai_multi_target_road_to_top_part_4.html#multi-target-model",
    "href": "fastai_notebooks/fastai_multi_target_road_to_top_part_4.html#multi-target-model",
    "title": "0011_fastai_multi_target_road_to_top_part_4",
    "section": "Multi-target model",
    "text": "Multi-target model\n\nhow to make the vision_learner to return 20 outputs, 10 for diseases, 10 for varieties; how to use to_fp16\nIn order to predict both the probability of each disease, and of each variety, we’ll now need the model to output a tensor of length 20, since there are 10 possible diseases, and 10 possible varieties. We can do this by setting n_out=20:\n\nlearn = vision_learner(dls, arch, n_out=20).to_fp16()\n\n\n\nhow to split the inputs for creating entropy loss for disease and variety\nWe can define disease_loss just like we did previously, but with one important change: the input tensor is now length 20, not 10, so it doesn’t match the number of possible diseases. We can pick whatever part of the input we want to be used to predict disease. Let’s use the first 10 values:\n\ndef disease_loss(inp,disease,variety): return F.cross_entropy(inp[:,:10],disease)\n\nThat means we can do the same thing for predicting variety, but use the last 10 values of the input, and set the target to variety instead of disease:\n\ndef variety_loss(inp,disease,variety): return F.cross_entropy(inp[:,10:],variety)\n\n\n\nhow to combine both disease loss and variety loss together to be the model loss\nOur overall loss will then be the sum of these two losses:\n\ndef combine_loss(inp,disease,variety): return disease_loss(inp,disease,variety)+variety_loss(inp,disease,variety)\n\n\n\nhow to split the input data to calc both disease error rate and variety error rate\nIt would be useful to view the error rate for each of the outputs too, so let’s do the same thing for out metrics:\n\ndef disease_err(inp,disease,variety): return error_rate(inp[:,:10],disease)\ndef variety_err(inp,disease,variety): return error_rate(inp[:,10:],variety)\n\nerr_metrics = (disease_err,variety_err)\n\n\n\nhow to wrap all error rates and losses into a tuple all_metrics and give it to metrics of vision_learner\nIt’s useful to see the loss for each of the outputs too, so we’ll add those as metrics:\n\nall_metrics = err_metrics+(disease_loss,variety_loss)\n\nWe’re now ready to create and train our Learner:\n\nlearn = vision_learner(dls, arch, loss_func=combine_loss, metrics=all_metrics, n_out=20).to_fp16()\n\n\nlearn.fine_tune(5, lr)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      disease_err\n      variety_err\n      disease_loss\n      variety_loss\n      time\n    \n  \n  \n    \n      0\n      2.415001\n      1.208315\n      0.245074\n      0.139356\n      0.762428\n      0.445887\n      01:47\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      disease_err\n      variety_err\n      disease_loss\n      variety_loss\n      time\n    \n  \n  \n    \n      0\n      1.095675\n      0.736918\n      0.169630\n      0.081211\n      0.507069\n      0.229849\n      01:54\n    \n    \n      1\n      0.789853\n      0.598383\n      0.123018\n      0.071600\n      0.380146\n      0.218237\n      01:54\n    \n    \n      2\n      0.497091\n      0.307715\n      0.074964\n      0.026910\n      0.221378\n      0.086336\n      01:55\n    \n    \n      3\n      0.300630\n      0.225282\n      0.049976\n      0.022105\n      0.164723\n      0.060559\n      01:53\n    \n    \n      4\n      0.209699\n      0.189986\n      0.040846\n      0.018260\n      0.134375\n      0.055611\n      01:57"
  },
  {
    "objectID": "fastai_notebooks/fastai_multi_target_road_to_top_part_4.html#conclusion",
    "href": "fastai_notebooks/fastai_multi_target_road_to_top_part_4.html#conclusion",
    "title": "0011_fastai_multi_target_road_to_top_part_4",
    "section": "Conclusion",
    "text": "Conclusion\n\nhow can multi-target model be useful to us\nSo, is this useful?\nWell… if you actually want a model that predicts multiple things, then yes, definitely! But as to whether it’s going to help us better predict rice disease, I honestly don’t know. I haven’t come across any research that tackles this important question: when can a multi-target model improve the accuracy of the individual targets compared to a single target model? (That doesn’t mean it doesn’t exist of course – perhaps it does and I haven’t found it yet…)\nI’ve certainly found in previous projects that there are cases where improvements to single targets can be made by using a multi-target model. I’d guess that it’ll be most useful when you’re having problems with overfitting. So try doing this with more epochs, and let me know how you go!\nIf you found this notebook useful, please remember to click the little up-arrow at the top to upvote it, since I like to know when people have found my work useful, and it helps others find it too. And if you have any questions or comments, please pop them below – I read every comment I receive.\n\n# This is what I use to push my notebook from my home PC to Kaggle\nif not iskaggle:\n    push_notebook('jhoward', 'multi-target-road-to-the-top-part-4',\n                  title='Multi-target: Road to the Top, Part 4',\n                  file='11-multitask.ipynb',\n                  competition=comp, private=False, gpu=True)"
  },
  {
    "objectID": "fastai_notebooks/iterate_like_grandmaster.html",
    "href": "fastai_notebooks/iterate_like_grandmaster.html",
    "title": "0014_iterate_like_grandmaster",
    "section": "",
    "text": "Note: If you’re fairly new to Kaggle, NLP, or Transformers, I strongly recommend you read my Getting Started notebook first, and then come back to this one.\n\n\n\nThere’s a lot of impressive notebooks around on Kaggle, but they often fall into one of two categories:\n\nExploratory Data Analysis (EDA) notebooks with lots of pretty charts, but not much focus on understanding the key issues that will make a difference in the competition\nTraining/inference notebooks with little detail about why each step was chosen.\n\n\n\n\nIn this notebook I’ll try to give a taste of how a competitions grandmaster might tackle the U.S. Patent Phrase to Phrase Matching competition. The focus generally should be two things:\n\nCreating an effective validation set\nIterating rapidly to find changes which improve results on the validation set.\n\nIf you can do these two things, then you can try out lots of experiments and find what works, and what doesn’t. Without these two things, it will be nearly impossible to do well in a Kaggle competition (and, indeed, to create highly accurate models in real life!)\n\n\n\nI will show a couple of different ways to create an appropriate validation set, and will explain how to expand them into an appropriate cross-validation system. I’ll use just plain HuggingFace Transformers for everything, and will keep the code concise and simple. The more code you have, the more you have to maintain, and the more chances there are to make mistakes. So keep it simple!\nOK, let’s get started…\n\n\n\nIt’s nice to be able to run things locally too, to save your Kaggle GPU hours, so set a variable to make it easy to see where we are, and download what we need:\n\nfrom pathlib import Path\nimport os\n\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\nif iskaggle:\n    !pip install -Uqq fastai\nelse:\n    import zipfile,kaggle\n    path = Path('us-patent-phrase-to-phrase-matching')\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f'{path}.zip').extractall(path)\n\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\nexplainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\ntensorflow 2.6.2 requires numpy~=1.19.2, but you have numpy 1.20.3 which is incompatible.\ntensorflow 2.6.2 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\ntensorflow 2.6.2 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\ntensorflow 2.6.2 requires wrapt~=1.12.1, but you have wrapt 1.13.3 which is incompatible.\ntensorflow-transform 1.5.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.15.0 which is incompatible.\ntensorflow-transform 1.5.0 requires numpy<1.20,>=1.16, but you have numpy 1.20.3 which is incompatible.\ntensorflow-transform 1.5.0 requires pyarrow<6,>=1, but you have pyarrow 6.0.1 which is incompatible.\ntensorflow-transform 1.5.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.2, but you have tensorflow 2.6.2 which is incompatible.\ntensorflow-serving-api 2.7.0 requires tensorflow<3,>=2.7.0, but you have tensorflow 2.6.2 which is incompatible.\nflake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.11.3 which is incompatible.\napache-beam 2.34.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\napache-beam 2.34.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.2 which is incompatible.\napache-beam 2.34.0 requires pyarrow<6.0.0,>=0.15.1, but you have pyarrow 6.0.1 which is incompatible.\naioitertools 0.10.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.10.0.2 which is incompatible.\naiobotocore 2.1.2 requires botocore<1.23.25,>=1.23.24, but you have botocore 1.24.20 which is incompatible.\n\n\n\n\n\nA lot of the basic imports you’ll want (np, pd, plt, etc) are provided by fastai, so let’s grab them in one line:\n\nfrom fastai.imports import *"
  },
  {
    "objectID": "fastai_notebooks/iterate_like_grandmaster.html#import-and-eda",
    "href": "fastai_notebooks/iterate_like_grandmaster.html#import-and-eda",
    "title": "0014_iterate_like_grandmaster",
    "section": "Import and EDA",
    "text": "Import and EDA\n\nhow to check what inside the dataset folder\nSet a path to our data. Use pathlib.Path because it makes everything so much easier, and make it work automatically regardless if you’re working on your own PC or on Kaggle!\n\nif iskaggle: path = Path('../input/us-patent-phrase-to-phrase-matching')\npath.ls()\n\n(#3) [Path('../input/us-patent-phrase-to-phrase-matching/sample_submission.csv'),Path('../input/us-patent-phrase-to-phrase-matching/train.csv'),Path('../input/us-patent-phrase-to-phrase-matching/test.csv')]\n\n\n\n\nhow to check what inside the train.csv file in the dataset folder\nLet’s look at the training set:\n\ndf = pd.read_csv(path/'train.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      id\n      anchor\n      target\n      context\n      score\n    \n  \n  \n    \n      0\n      37d61fd2272659b1\n      abatement\n      abatement of pollution\n      A47\n      0.50\n    \n    \n      1\n      7b9652b17b68b7a4\n      abatement\n      act of abating\n      A47\n      0.75\n    \n    \n      2\n      36d72442aefd8232\n      abatement\n      active catalyst\n      A47\n      0.25\n    \n    \n      3\n      5296b0c19e1ce60e\n      abatement\n      eliminating process\n      A47\n      0.50\n    \n    \n      4\n      54c1e3b9184cb5b6\n      abatement\n      forest region\n      A47\n      0.00\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      36468\n      8e1386cbefd7f245\n      wood article\n      wooden article\n      B44\n      1.00\n    \n    \n      36469\n      42d9e032d1cd3242\n      wood article\n      wooden box\n      B44\n      0.50\n    \n    \n      36470\n      208654ccb9e14fa3\n      wood article\n      wooden handle\n      B44\n      0.50\n    \n    \n      36471\n      756ec035e694722b\n      wood article\n      wooden material\n      B44\n      0.75\n    \n    \n      36472\n      8d135da0b55b8c88\n      wood article\n      wooden substrate\n      B44\n      0.50\n    \n  \n\n36473 rows × 5 columns\n\n\n\n\n\nhow to check what inside the test.csv file in the dataset folder\n…and the test set:\n\neval_df = pd.read_csv(path/'test.csv')\nlen(eval_df)\n\n36\n\n\n\neval_df.head()\n\n\n\n\n\n  \n    \n      \n      id\n      anchor\n      target\n      context\n    \n  \n  \n    \n      0\n      4112d61851461f60\n      opc drum\n      inorganic photoconductor drum\n      G02\n    \n    \n      1\n      09e418c93a776564\n      adjust gas flow\n      altering gas flow\n      F23\n    \n    \n      2\n      36baf228038e314b\n      lower trunnion\n      lower locating\n      B60\n    \n    \n      3\n      1f37ead645e7f0c8\n      cap component\n      upper portion\n      D06\n    \n    \n      4\n      71a5b6ad068d531f\n      neural stimulation\n      artificial neural network\n      H04\n    \n  \n\n\n\n\n\n\nhow to check the distribution of the column target of the training set dataframe\nLet’s look at the distribution of values of target:\n\ndf.target.value_counts()\n\ncomposition                    24\ndata                           22\nmetal                          22\nmotor                          22\nassembly                       21\n                               ..\nswitching switch over valve     1\nswitching switch off valve      1\nswitching over valve            1\nswitching off valve             1\nwooden substrate                1\nName: target, Length: 29340, dtype: int64\n\n\n\n\nwhat info do we get from reading the distribution of different values of the target column of the training set\nWe see that there’s nearly as many unique targets as items in the training set, so they’re nearly but not quite unique. Most importantly, we can see that these generally contain very few words (1-4 words in the above sample).\nLet’s check anchor:\n\ndf.anchor.value_counts()\n\ncomponent composite coating              152\nsheet supply roller                      150\nsource voltage                           140\nperfluoroalkyl group                     136\nel display                               135\n                                        ... \nplug nozzle                                2\nshannon                                    2\ndry coating composition1                   2\nperipheral nervous system stimulation      1\nconduct conducting material                1\nName: anchor, Length: 733, dtype: int64\n\n\n\n\nhow to check the distribution of different values of the context column of training set\nWe can see here that there’s far fewer unique values (just 733) and that again they’re very short (2-4 words in this sample).\nNow we’ll do context\n\ndf.context.value_counts()\n\nH01    2186\nH04    2177\nG01    1812\nA61    1477\nF16    1091\n       ... \nB03      47\nF17      33\nB31      24\nA62      23\nF26      18\nName: context, Length: 106, dtype: int64\n\n\n\n\nhow to get the distribution of the different section names embedded inside the context column, and create a column named section based on the data\nThese are just short codes. Some of them have very few examples (18 in the smallest case) The first character is the section the patent was filed under – let’s create a column for that and look at the distribution:\n\ndf['section'] = df.context.str[0]\ndf.section.value_counts()\n\nB    8019\nH    6195\nG    6013\nC    5288\nA    4094\nF    4054\nE    1531\nD    1279\nName: section, dtype: int64\n\n\n\n\nhow to view the distribution of continuous data or column like the column score of the training set\nIt seems likely that these sections might be useful, since they’ve got quite a bit more data in each.\nFinally, we’ll take a look at a histogram of the scores:\n\ndf.score.hist();\n\n\n\n\nThere’s a small number that are scored 1.0 - here’s a sample:\n\ndf[df.score==1]\n\n\n\n\n\n  \n    \n      \n      id\n      anchor\n      target\n      context\n      score\n      section\n    \n  \n  \n    \n      28\n      473137168ebf7484\n      abatement\n      abating\n      F24\n      1.0\n      F\n    \n    \n      158\n      621b048d70aa8867\n      absorbent properties\n      absorbent characteristics\n      D01\n      1.0\n      D\n    \n    \n      161\n      bc20a1c961cb073a\n      absorbent properties\n      absorption properties\n      D01\n      1.0\n      D\n    \n    \n      311\n      e955700dffd68624\n      acid absorption\n      absorption of acid\n      B08\n      1.0\n      B\n    \n    \n      315\n      3a09aba546aac675\n      acid absorption\n      acid absorption\n      B08\n      1.0\n      B\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      36398\n      913141526432f1d6\n      wiring trough\n      wiring troughs\n      F16\n      1.0\n      F\n    \n    \n      36435\n      ee0746f2a8ecef97\n      wood article\n      wood articles\n      B05\n      1.0\n      B\n    \n    \n      36440\n      ecaf479135cf0dfd\n      wood article\n      wooden article\n      B05\n      1.0\n      B\n    \n    \n      36464\n      8ceaa2b5c2d56250\n      wood article\n      wood article\n      B44\n      1.0\n      B\n    \n    \n      36468\n      8e1386cbefd7f245\n      wood article\n      wooden article\n      B44\n      1.0\n      B\n    \n  \n\n1154 rows × 6 columns\n\n\n\nWe can see from this that these are just minor rewordings of the same concept, and isn’t likely to be specific to context. Any pretrained model should be pretty good at finding these already."
  },
  {
    "objectID": "fastai_notebooks/iterate_like_grandmaster.html#training",
    "href": "fastai_notebooks/iterate_like_grandmaster.html#training",
    "title": "0014_iterate_like_grandmaster",
    "section": "Training",
    "text": "Training\n\nlibraries needed for creating and training models here\nTime to import the stuff we’ll need for training:\n\nfrom torch.utils.data import DataLoader\nimport warnings,transformers,logging,torch\nfrom transformers import TrainingArguments,Trainer\nfrom transformers import AutoModelForSequenceClassification,AutoTokenizer\n\n\nif iskaggle:\n    !pip install -q datasets\nimport datasets\nfrom datasets import load_dataset, Dataset, DatasetDict\n\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n\n\n\n\nhow to quite down warning messages\nHuggingFace Transformers tends to be rather enthusiastic about spitting out lots of warnings, so let’s quieten it down for our sanity:\n\nwarnings.simplefilter('ignore')\nlogging.disable(logging.WARNING)\n\nI tried to find a model that I could train reasonably at home in under two minutes, but got reasonable accuracy from. I found that deberta-v3-small fits the bill, so let’s use it:\n\nmodel_nm = 'microsoft/deberta-v3-small'\n\nWe can now create a tokenizer for this model. Note that pretrained models assume that text is tokenized in a particular way. In order to ensure that your tokenizer matches your model, use the AutoTokenizer, passing in your model name.\n\ntokz = AutoTokenizer.from_pretrained(model_nm)\n\n\n\n\n\n\n\n\n\n\nWe’ll need to combine the context, anchor, and target together somehow. There’s not much research as to the best way to do this, so we may need to iterate a bit. To start with, we’ll just combine them all into a single string. The model will need to know where each section starts, so we can use the special separator token to tell it:\n\nsep = tokz.sep_token\nsep\n\n'[SEP]'\n\n\nLet’s now created our combined column:\n\ndf['inputs'] = df.context + sep + df.anchor + sep + df.target\n\nGenerally we’ll get best performance if we convert pandas DataFrames into HuggingFace Datasets, so we’ll convert them over, and also rename the score column to what Transformers expects for the dependent variable, which is label:\n\nds = Dataset.from_pandas(df).rename_column('score', 'label')\neval_ds = Dataset.from_pandas(eval_df)\n\nTo tokenize the data, we’ll create a function (since that’s what Dataset.map will need):\n\ndef tok_func(x): return tokz(x[\"inputs\"])\n\nLet’s try tokenizing one input and see how it looks\n\ntok_func(ds[0])\n\n{'input_ids': [1, 336, 5753, 2, 47284, 2, 47284, 265, 6435, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n\n\nThe only bit we care about at the moment is input_ids. We can see in the tokens that it starts with a special token 1 (which represents the start of text), and then has our three fields separated by the separator token 2. We can check the indices of the special token IDs like so:\n\ntokz.all_special_tokens\n\n['[CLS]', '[SEP]', '[UNK]', '[PAD]', '[MASK]']\n\n\nWe can now tokenize the input. We’ll use batching to speed it up, and remove the columns we no longer need:\n\ninps = \"anchor\",\"target\",\"context\"\ntok_ds = ds.map(tok_func, batched=True, remove_columns=inps+('inputs','id','section'))\n\n\n\n\nLooking at the first item of the dataset we should see the same information as when we checked tok_func above:\n\ntok_ds[0]\n\n{'label': 0.5,\n 'input_ids': [1, 336, 5753, 2, 47284, 2, 47284, 265, 6435, 2],\n 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
  },
  {
    "objectID": "fastai_notebooks/iterate_like_grandmaster.html#creating-a-validation-set",
    "href": "fastai_notebooks/iterate_like_grandmaster.html#creating-a-validation-set",
    "title": "0014_iterate_like_grandmaster",
    "section": "Creating a validation set",
    "text": "Creating a validation set\nAccording to this post, the private test anchors do not overlap with the training set. So let’s do the same thing for our validation set.\nFirst, create a randomly shuffled list of anchors:\n\nanchors = df.anchor.unique()\nnp.random.seed(42)\nnp.random.shuffle(anchors)\nanchors[:5]\n\narray(['time digital signal', 'antiatherosclerotic', 'filled interior',\n       'dispersed powder', 'locking formation'], dtype=object)\n\n\nNow we can pick some proportion (e.g 25%) of these anchors to go in the validation set:\n\nval_prop = 0.25\nval_sz = int(len(anchors)*val_prop)\nval_anchors = anchors[:val_sz]\n\nNow we can get a list of which rows match val_anchors, and get their indices:\n\nis_val = np.isin(df.anchor, val_anchors)\nidxs = np.arange(len(df))\nval_idxs = idxs[ is_val]\ntrn_idxs = idxs[~is_val]\nlen(val_idxs),len(trn_idxs)\n\n(9116, 27357)\n\n\nOur training and validation Datasets can now be selected, and put into a DatasetDict ready for training:\n\ndds = DatasetDict({\"train\":tok_ds.select(trn_idxs),\n             \"test\": tok_ds.select(val_idxs)})\n\nBTW, a lot of people do more complex stuff for creating their validation set, but with a dataset this large there’s not much point. As you can see, the mean scores in the two groups are very similar despite just doing a random shuffle:\n\ndf.iloc[trn_idxs].score.mean(),df.iloc[val_idxs].score.mean()\n\n(0.3623021530138539, 0.3613426941641071)"
  },
  {
    "objectID": "fastai_notebooks/iterate_like_grandmaster.html#initial-model",
    "href": "fastai_notebooks/iterate_like_grandmaster.html#initial-model",
    "title": "0014_iterate_like_grandmaster",
    "section": "Initial model",
    "text": "Initial model\nLet’s now train our model! We’ll need to specify a metric, which is the correlation coefficient provided by numpy (we need to return a dictionary since that’s how Transformers knows what label to use):\n\ndef corr(eval_pred): return {'pearson': np.corrcoef(*eval_pred)[0][1]}\n\nWe pick a learning rate and batch size that fits our GPU, and pick a reasonable weight decay and small number of epochs:\n\nlr,bs = 8e-5,128\nwd,epochs = 0.01,4\n\nThree epochs might not sound like much, but you’ll see once we train that most of the progress can be made in that time, so this is good for experimentation.\nTransformers uses the TrainingArguments class to set up arguments. We’ll use a cosine scheduler with warmup, since at fast.ai we’ve found that’s pretty reliable. We’ll use fp16 since it’s much faster on modern GPUs, and saves some memory. We evaluate using double-sized batches, since no gradients are stored so we can do twice as many rows at a time.\n\ndef get_trainer(dds):\n    args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n        evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n        num_train_epochs=epochs, weight_decay=wd, report_to='none')\n    model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n    return Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                   tokenizer=tokz, compute_metrics=corr)\n\n\nargs = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=wd, report_to='none')\n\nWe can now create our model, and Trainer, which is a class which combines the data and model together (just like Learner in fastai):\n\nmodel = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\ntrainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n               tokenizer=tokz, compute_metrics=corr)\n\n\n\n\nLet’s train our model!\n\ntrainer.train();\n\n\n\n    \n      \n      \n      [856/856 04:19, Epoch 4/4]\n    \n    \n  \n \n      Epoch\n      Training Loss\n      Validation Loss\n      Pearson\n    \n  \n  \n    \n      1\n      No log\n      0.025167\n      0.798359\n    \n    \n      2\n      No log\n      0.025149\n      0.803286\n    \n    \n      3\n      0.035300\n      0.024344\n      0.815202\n    \n    \n      4\n      0.035300\n      0.024549\n      0.815378"
  },
  {
    "objectID": "fastai_notebooks/iterate_like_grandmaster.html#improving-the-model",
    "href": "fastai_notebooks/iterate_like_grandmaster.html#improving-the-model",
    "title": "0014_iterate_like_grandmaster",
    "section": "Improving the model",
    "text": "Improving the model\nWe now want to start iterating to improve this. To do that, we need to know whether the model gives stable results. I tried training it 3 times from scratch, and got a range of outcomes from 0.808-0.810. This is stable enough to make a start - if we’re not finding improvements that are visible within this range, then they’re not very significant! Later on, if and when we feel confident that we’ve got the basics right, we can use cross validation and more epochs of training.\nIteration speed is critical, so we need to quickly be able to try different data processing and trainer parameters. So let’s create a function to quickly apply tokenization and create our DatasetDict:\n\ndef get_dds(df):\n    ds = Dataset.from_pandas(df).rename_column('score', 'label')\n    tok_ds = ds.map(tok_func, batched=True, remove_columns=inps+('inputs','id','section'))\n    return DatasetDict({\"train\":tok_ds.select(trn_idxs), \"test\": tok_ds.select(val_idxs)})\n\n…and also a function to create a Trainer:\n\ndef get_model(): return AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n\ndef get_trainer(dds, model=None):\n    if model is None: model = get_model()\n    args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n        evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n        num_train_epochs=epochs, weight_decay=wd, report_to='none')\n    return Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                   tokenizer=tokz, compute_metrics=corr)\n\nLet’s now try out some ideas…\nPerhaps using the special separator character isn’t a good idea, and we should use something we create instead. Let’s see if that makes things better. First we’ll change the separator and create the DatasetDict:\n\nsep = \" [s] \"\ndf['inputs'] = df.context + sep + df.anchor + sep + df.target\ndds = get_dds(df)\n\n\n\n\n…and create and train a model.\n\nget_trainer(dds).train()\n\n\n\n    \n      \n      \n      [856/856 04:29, Epoch 4/4]\n    \n    \n  \n \n      Epoch\n      Training Loss\n      Validation Loss\n      Pearson\n    \n  \n  \n    \n      1\n      No log\n      0.024909\n      0.797869\n    \n    \n      2\n      No log\n      0.024800\n      0.812953\n    \n    \n      3\n      0.031600\n      0.024418\n      0.818292\n    \n    \n      4\n      0.031600\n      0.024037\n      0.819089\n    \n  \n\n\n\nTrainOutput(global_step=856, training_loss=0.023822079752093165, metrics={'train_runtime': 269.6383, 'train_samples_per_second': 405.833, 'train_steps_per_second': 3.175, 'total_flos': 582160588599300.0, 'train_loss': 0.023822079752093165, 'epoch': 4.0})\n\n\nThat’s looking quite a bit better, so we’ll keep that change.\nOften changing to lowercase is helpful. Let’s see if that helps too:\n\ndf['inputs'] = df.inputs.str.lower()\ndds = get_dds(df)\nget_trainer(dds).train()\n\n\n\n\n\n\n    \n      \n      \n      [856/856 04:34, Epoch 4/4]\n    \n    \n  \n \n      Epoch\n      Training Loss\n      Validation Loss\n      Pearson\n    \n  \n  \n    \n      1\n      No log\n      0.025170\n      0.798002\n    \n    \n      2\n      No log\n      0.024433\n      0.815301\n    \n    \n      3\n      0.031500\n      0.024575\n      0.818443\n    \n    \n      4\n      0.031500\n      0.024150\n      0.818868\n    \n  \n\n\n\nTrainOutput(global_step=856, training_loss=0.023811190484840178, metrics={'train_runtime': 274.7918, 'train_samples_per_second': 398.222, 'train_steps_per_second': 3.115, 'total_flos': 582160588599300.0, 'train_loss': 0.023811190484840178, 'epoch': 4.0})\n\n\nThat one is less clear. We’ll keep that change too since most times I run it, it’s a little better."
  },
  {
    "objectID": "fastai_notebooks/iterate_like_grandmaster.html#special-tokens",
    "href": "fastai_notebooks/iterate_like_grandmaster.html#special-tokens",
    "title": "0014_iterate_like_grandmaster",
    "section": "Special tokens",
    "text": "Special tokens\nWhat if we made the patent section a special token? Then potentially the model might learn to recognize that different sections need to be handled in different ways. To do that, we’ll use, e.g. [A] for section A. We’ll then add those as special tokens:\n\ndf['sectok'] = '[' + df.section + ']'\nsectoks = list(df.sectok.unique())\ntokz.add_special_tokens({'additional_special_tokens': sectoks})\n\n8\n\n\nWe concatenate the section token to the start of our inputs:\n\ndf['inputs'] = df.sectok + sep + df.context + sep + df.anchor.str.lower() + sep + df.target\ndds = get_dds(df)\n\n\n\n\nSince we’ve added more tokens, we need to resize the embedding matrix in the model:\n\nmodel = get_model()\nmodel.resize_token_embeddings(len(tokz))\n\nEmbedding(128009, 768)\n\n\nNow we’re ready to train:\n\ntrainer = get_trainer(dds, model=model)\ntrainer.train()\n\n\n\n    \n      \n      \n      [856/856 04:55, Epoch 4/4]\n    \n    \n  \n \n      Epoch\n      Training Loss\n      Validation Loss\n      Pearson\n    \n  \n  \n    \n      1\n      No log\n      0.024835\n      0.797996\n    \n    \n      2\n      No log\n      0.024412\n      0.812386\n    \n    \n      3\n      0.031800\n      0.024019\n      0.820914\n    \n    \n      4\n      0.031800\n      0.024220\n      0.820187\n    \n  \n\n\n\nTrainOutput(global_step=856, training_loss=0.023861238889605084, metrics={'train_runtime': 296.1519, 'train_samples_per_second': 369.5, 'train_steps_per_second': 2.89, 'total_flos': 695409809982180.0, 'train_loss': 0.023861238889605084, 'epoch': 4.0})\n\n\nIt looks like we’ve made another bit of an improvement!\nThere’s plenty more things you could try. Here’s some thoughts:\n\nTry a model pretrained on legal vocabulary. E.g. how about BERT for patents?\nYou’d likely get better results by using a sentence similarity model. Did you know that there’s a patent similarity model you could try?\nYou could also fine-tune any HuggingFace model using the full patent database (which is provided in BigQuery), before applying it to this dataset\nReplace the patent context field with the description of that context provided by the patent office\n…and try out your own ideas too!\n\nBefore submitting a model, retrain it on the full dataset, rather than just the 75% training subset we’ve used here. Create a function like the ones above to make that easy for you!”"
  },
  {
    "objectID": "fastai_notebooks/iterate_like_grandmaster.html#cross-validation",
    "href": "fastai_notebooks/iterate_like_grandmaster.html#cross-validation",
    "title": "0014_iterate_like_grandmaster",
    "section": "Cross-validation",
    "text": "Cross-validation\n\nn_folds = 4\n\nOnce you’ve gotten the low hanging fruit, you might want to use cross-validation to see the impact of minor changes. This time we’ll use StratifiedGroupKFold, partly just to show a different approach to before, and partly because it will give us slightly better balanced datasets.\n\nfrom sklearn.model_selection import StratifiedGroupKFold\ncv = StratifiedGroupKFold(n_splits=n_folds)\n\nHere’s how to split the data frame into n_folds groups, with non-overlapping anchors and matched scores, after randomly shuffling the rows:\n\ndf = df.sample(frac=1, random_state=42)\nscores = (df.score*100).astype(int)\nfolds = list(cv.split(idxs, scores, df.anchor))\nfolds\n\n[(array([    0,     1,     2, ..., 36469, 36471, 36472]),\n  array([    8,    13,    14, ..., 36453, 36464, 36470])),\n (array([    0,     1,     5, ..., 36470, 36471, 36472]),\n  array([    2,     3,     4, ..., 36459, 36461, 36462])),\n (array([    1,     2,     3, ..., 36467, 36470, 36472]),\n  array([    0,     7,    11, ..., 36468, 36469, 36471])),\n (array([    0,     2,     3, ..., 36469, 36470, 36471]),\n  array([    1,     5,     9, ..., 36465, 36467, 36472]))]\n\n\nWe can now create a little function to split into training and validation sets based on a fold:\n\ndef get_fold(folds, fold_num):\n    trn,val = folds[fold_num]\n    return DatasetDict({\"train\":tok_ds.select(trn), \"test\": tok_ds.select(val)})\n\nLet’s try it out:\n\ndds = get_fold(folds, 0)\ndds\n\nDatasetDict({\n    train: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 27346\n    })\n    test: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 9127\n    })\n})\n\n\nWe can now pass this into get_trainer as we did before. If we have, say, 4 folds, then doing that for each fold will give us 4 models, and 4 sets of predictions and metrics. You could ensemble the 4 models to get a stronger model, and can also average the 4 metrics to get a more accurate assessment of your model. Here’s how to get the final epoch metrics from a trainer:\n\nmetrics = [o['eval_pearson'] for o in trainer.state.log_history if 'eval_pearson' in o]\nmetrics[-1]\n\n0.8201874392079798\n\n\nI hope you’ve found this a helpful guide to improving your results in this competition - and on Kaggle more generally! If you like it, please remember to give it an upvote, and don’t hesitate to add a comment if you have any questions or thoughts to add. And if the ideas here are helpful to you in creating your models, I’d really appreciate a link back to this notebook or a comment below to let me know what helped."
  },
  {
    "objectID": "fastai_notebooks/fastai_using_nbdev_export_in_kaggle_notebook.html",
    "href": "fastai_notebooks/fastai_using_nbdev_export_in_kaggle_notebook.html",
    "title": "0012_fastai_using_nbdev_export_in_kaggle_notebook",
    "section": "",
    "text": "default_exp\nwhich pyfile I am export the notebook to\n\n\nwhat to export from the notebook to the pyfile\n\n\n%notebook\nhow to export the current current IPython history to a notebook file using %notebook\n\n# NB: This only works if you run all the cells in order - click \"Save Version\" to do this automatically\n\n\n\n%lsmagic\n\n\n\nAvailable line magics:\n%aimport  %alias  %alias_magic  %autoawait  %autocall  %automagic  %autoreload  %autosave  %bookmark  %cat  %cd  %clear  %colors  %conda  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %man  %matplotlib  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n\nAvailable cell magics:\n%%!  %%HTML  %%SVG  %%bash  %%capture  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n\nAutomagic is ON, % prefix IS NOT needed for line magics.\n\n\n\n\nhow to export the specified kaggle notebook to the pyfile module\n\nfrom nbdev.export import nb_export\n\n\nnb_export('testnbdev.ipynb', '.')\n\n\n\nhow to check the pyfile/module on kaggle\n\n!cat app.py\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: testnbdev.ipynb.\n\n# %% auto 0\n__all__ = ['a']\n\n# %% testnbdev.ipynb 2\na=1"
  },
  {
    "objectID": "fastai_notebooks/fastai_how_neuralnet_work.html",
    "href": "fastai_notebooks/fastai_how_neuralnet_work.html",
    "title": "0004_fastai_how_neuralnet_work",
    "section": "",
    "text": "Official course site: for lesson 3\nOfficial notebooks repo, on nbviewer\nOfficial how neuralnet work notebook on kaggle\nImportant: The interactive features of this notebook don’t work in Kaggle’s Reader mode. They only work in Edit mode. Therefore, before starting reading this, please click “Copy & Edit” in the top right of this window, then in the menu click Run and then Run all. Then you’ll be able to use all the interactive sliders in this notebook."
  },
  {
    "objectID": "fastai_notebooks/fastai_how_neuralnet_work.html#fitting-a-function-with-gradient-descent",
    "href": "fastai_notebooks/fastai_how_neuralnet_work.html#fitting-a-function-with-gradient-descent",
    "title": "0004_fastai_how_neuralnet_work",
    "section": "Fitting a function with gradient descent",
    "text": "Fitting a function with gradient descent\n\nIs neuralnet just a math function? what does the function look like?\nA neural network is just a mathematical function. In the most standard kind of neural network, the function:\n\nMultiplies each input by a number of values. These values are known as parameters\nAdds them up for each group of values\nReplaces the negative numbers with zeros\n\n\n\nwhy neuralnet is random at first and how to make neuralnet useful\nThis represents one “layer”. Then these three steps are repeated, using the outputs of the previous layer as the inputs to the next layer. Initially, the parameters in this function are selected randomly. Therefore a newly created neural network doesn’t do anything useful at all – it’s just random!\nTo get the function to “learn” to do something useful, we have to change the parameters to make them “better” in some way. We do this using gradient descent. Let’s see how this works…\n\n\nplot_function: how to plot a function with plt; how to create x input with torch.linspace; how to plot x, y, color and title with plt;\n\nfrom ipywidgets import interact\nfrom fastai.basics import *\n\nplt.rc('figure', dpi=90)\n\ndef plot_function(f, title=None, min=-2.1, max=2.1, color='r', ylim=None):\n    x = torch.linspace(min,max, 100)[:,None]\n    if ylim: plt.ylim(ylim)\n    plt.plot(x, f(x), color)\n    if title is not None: plt.title(title)\n\n\n\nhow to create a particular quadratic function\nTo learn how gradient descent works, we’re going to start by fitting a quadratic, since that’s a function most of us are probably more familiar with than a neural network. Here’s the quadratic we’re going to try to fit:\n\ndef f(x): return 3*x**2 + 2*x + 1\n\nplot_function(f, \"$3x^2 + 2x + 1$\")\n\n\n\n\n\n\nhow to write a function quad to create any quadratic function\nThis quadratic is of the form \\(ax^2+bx+c\\), with parameters \\(a=3\\), \\(b=2\\), \\(c=1\\). To make it easier to try out different quadratics for fitting a model to the data we’ll create, let’s create a function that calculates the value of a point on any quadratic:\n\ndef quad(a, b, c, x): return a*x**2 + b*x + c\n\n\n\nhow does partial and quad work to modify quad to a slightly different func?\nIf we fix some particular values of a, b, and c, then we’ll have made a quadratic. To fix values passed to a function in python, we use the partial function, like so:\n\ndef mk_quad(a,b,c): return partial(quad, a,b,c)\n\nSo for instance, we can recreate our previous quadratic:\n\nf2 = mk_quad(3,2,1)\nplot_function(f2)\n\n\n\n\n\n\nhow to add noise to both mult and add of the neuralnet/function; how to create noise using np.random.normal\nNow let’s simulate making some noisy measurements of our quadratic f. We’ll then use gradient descent to see if we can recreate the original function from the data.\nHere’s a couple of functions to add some random noise to data:\n\ndef noise(x, scale): return np.random.normal(scale=scale, size=x.shape)\ndef add_noise(x, mult, add): return x * (1+noise(x,mult)) + noise(x,add)\n\n\n\nhow to create a random seed to ensure x and y are the same each run\nLet’s use the now to create our noisy measurements based on the quadratic above:\n\nnp.random.seed(42)\n\nx = torch.linspace(-2, 2, steps=20)[:,None]\ny = add_noise(f(x), 0.15, 1.5)\n\nHere’s the first few values of each of x and y:\n\nx[:5],y[:5]\n\n(tensor([[-2.0000],\n         [-1.7895],\n         [-1.5789],\n         [-1.3684],\n         [-1.1579]]),\n tensor([[11.8690],\n         [ 6.5433],\n         [ 5.9396],\n         [ 2.6304],\n         [ 1.7947]], dtype=torch.float64))"
  },
  {
    "objectID": "fastai_notebooks/fastai_how_neuralnet_work.html#a-numpy-book-recommended-by-jeremy-what-is-a-tensor",
    "href": "fastai_notebooks/fastai_how_neuralnet_work.html#a-numpy-book-recommended-by-jeremy-what-is-a-tensor",
    "title": "0004_fastai_how_neuralnet_work",
    "section": "A numpy book recommended by Jeremy; what is a tensor",
    "text": "A numpy book recommended by Jeremy; what is a tensor\nAs you can see, they’re tensors. A tensor is just like an array in numpy (if you’re not familiar with numpy, I strongly recommend reading this great book, because it’s a critical foundation for nearly all numeric programming in Python. Furthermore, PyTorch, which most researchers use for deep learning, is modeled closely on numpy.) A tensor can be a single number (a scalar or rank-0 tensor), a list of numbers (a vector or rank-1 tensor), a table of numbers (a matrix or rank-0 tensor), a table of tables of numbers (a rank-3 tensor), and so forth.\nWe’re not going to learn much about our data by just looking at the raw numbers, so let’s draw a picture:\n\nhow to scatterplot with plt\n\nplt.scatter(x,y);\n\n\n\n\n\n\nhow to plot a scatterplot and a line and slides for 3 params of the line func\nHow do we find values of a, b, and c which fit this data? One approach is to try a few values and see what fits. Here’s a function which overlays a quadratic on top of our data, along with some sliders to change a, b, and c, and see how it looks:\n\n@interact(a=1.1, b=1.1, c=1.1)\ndef plot_quad(a, b, c):\n    plt.scatter(x,y)\n    plot_function(mk_quad(a,b,c), ylim=(-3,13))\n\n\n\n\nReminder: If the sliders above aren’t working for you, that’s because the interactive features of this notebook don’t work in Kaggle’s Reader mode. They only work in Edit mode. Please click “Copy & Edit” in the top right of this window, then in the menu click Run and then Run all. Then you’ll be able to use all the interactive sliders in this notebook.\n\n\nwhy need a loss function? how to write a mean absolute error function with torch.abs and mean\nTry moving slider a a bit to the left. Does that look better or worse? How about if you move it a bit to the right? Find out which direction seems to improve the fit of the quadratic to the data, and move the slider a bit in that direction. Next, do the same for slider b: first figure out which direction improves the fit, then move it a bit in that direction. Then do the same for c.\nOK, now go back to slider a and repeat the process. Do it again for b and c as well.\nDid you notice that by going back and doing the sliders a second time that you were able to improve things a bit further? That’s an important insight – it’s only after changing b and c, for instance, that you realise that a actually needs some adjustment based on those new values.\nOne thing that’s making this tricky is that we don’t really have a great sense of whether our fit is really better or worse. It would be easier if we had a numeric measure of that. On easy metric we could use is mean absolute error – which is the distance from each data point to the curve:\n\ndef mae(preds, acts): return (torch.abs(preds-acts)).mean()\n\nWe’ll update our interactive function to print this at the top for us.\nUse this to repeat the approach we took before to try to find the best fit, but this time just use the value of the metric to decide which direction to move each slider, and how far to move it.\nThis time around, try doing it in the opposite order: c, then b, then a.\nYou’ll probably find that you have to go through the set of sliders a couple of times to get the best fit.\n\n\nhow display and change loss by changing values of params with sliders of interactive plot\n\n@interact(a=1.1, b=1.1, c=1.1)\ndef plot_quad(a, b, c):\n    f = mk_quad(a,b,c)\n    plt.scatter(x,y)\n    loss = mae(f(x), y)\n    plot_function(f, ylim=(-3,12), title=f\"MAE: {loss:.2f}\")\n\n\n\n\n\n\nA 15-min calculus video series recommended by Jeremy to watch first\nIn a modern neural network we’ll often have tens of millions of parameters to fit, or more, and thousands or millions of data points to fit them to. We’re not going to be able to do that by moving sliders around! We’ll need to automate this process.\nThankfully, that turns out to be pretty straightforward. We can use calculus to figure out, for each parameter, whether we should increase or decrease it.\nUh oh, calculus! If you haven’t touched calculus since school, you might be getting ready to run away at this point. But don’t worry, we don’t actually need much calculus at all. Just derivatives, which measure the rate of change of a function. We don’t even need to calculate them ourselves, because the computer will do it for us! If you’ve forgotten what a derivitive is, then watch the first three of these fantastic videos by Professor Dave. It’s only 15 minutes in total, so give it a go! Then come back here and we’ll continue on our journey…"
  },
  {
    "objectID": "fastai_notebooks/fastai_how_neuralnet_work.html#automating-gradient-descent",
    "href": "fastai_notebooks/fastai_how_neuralnet_work.html#automating-gradient-descent",
    "title": "0004_fastai_how_neuralnet_work",
    "section": "Automating gradient descent",
    "text": "Automating gradient descent\n\nhow derivatives automatically guide params to change for a lower loss\nThe basic idea is this: if we know the gradient of our mae() function with respect to our parameters, a, b, and c, then that means we know how adjusting (for instance) a will change the value of mae(). If, say, a has a negative gradient, then we know that increasing a will decrease mae(). Then we know that’s what we need to do, since we trying to make mae() as low as possible.\nSo, we find the gradient of mae() for each of our parameters, and then adjust our parameters a bit in the opposite direction to the sign of the gradient.\nTo do this, first we need a function that takes all the parameters a, b, and c as a single vector input, and returns the value mae() based on those parameters:\n\n\nhow to create a mean absolute error function on any quadratic model\n\ndef quad_mae(params):\n    f = mk_quad(*params)\n    return mae(f(x), y)\n\nLet’s try it:\n\nquad_mae([1.1, 1.1, 1.1])\n\ntensor(2.4219, dtype=torch.float64)\n\n\n\n\nhow to create an random tensor with 3 values as initialized params\nYup, that’s the same as the starting mae() we had in our plot before.\nWe’re first going to do exactly the same thing as we did manually – pick some arbritrary starting point for our parameters. We’ll put them all into a single tensor:\n\nabc = torch.tensor([1.1,1.1,1.1])\n\n\n\nhow to calc gradients of params? 1. tell PyTorch to get ready for calculating gradients for these params; 2. calc loss; 3. calc the gradients with loss.backward(); 4. how to access params’ gradients;\nTo tell PyTorch that we want it to calculate gradients for these parameters, we need to call requires_grad_():\n\nabc.requires_grad_()\n\ntensor([1.1000, 1.1000, 1.1000], requires_grad=True)\n\n\nWe can now calculate mae(). Generally, when doing gradient descent, the thing we’re trying to minimise is called the loss:\n\nloss = quad_mae(abc)\nloss\n\ntensor(2.4219, dtype=torch.float64, grad_fn=<MeanBackward0>)\n\n\nTo get PyTorch to now calculate the gradients, we need to call backward()\n\nloss.backward()\n\nThe gradients will be stored for us in an attribute called grad:\n\nabc.grad\n\ntensor([-1.3529, -0.0316, -0.5000])\n\n\n\n\nhow to change params with gradients properly to lower loss¶\nAccording to these gradients, all our parameters are a little low. So let’s increase them a bit. If we subtract the gradient, multiplied by a small number, that should improve them a bit:\n\nwith torch.no_grad():\n    abc -= abc.grad*0.01\n    loss = quad_mae(abc)\n    \nprint(f'loss={loss:.2f}')\n\nloss=2.40\n\n\n\n\nwhy with torch.no_grad(): when updating params with gradients\nYes, our loss has gone down!\nThe “small number” we multiply is called the learning rate, and is the most important hyper-parameter to set when training a neural network.\nBTW, you’ll see we had to wrap our calculation of the new parameters in with torch.no_grad(). That disables the calculation of gradients for any operations inside that context manager. We have to do that, because abc -= abc.grad*0.01 isn’t actually part of our quadratic model, so we don’t want derivitives to include that calculation.\nWe can use a loop to do a few more iterations of this:\n\n\nhow to do 10 iterations of updating params with gradients\n\nfor i in range(10):\n    loss = quad_mae(abc)\n    loss.backward()\n    with torch.no_grad(): abc -= abc.grad*0.01\n    print(f'step={i}; loss={loss:.2f}')\n\nstep=0; loss=2.40\nstep=1; loss=2.36\nstep=2; loss=2.30\nstep=3; loss=2.21\nstep=4; loss=2.11\nstep=5; loss=1.98\nstep=6; loss=1.85\nstep=7; loss=1.72\nstep=8; loss=1.58\nstep=9; loss=1.46\n\n\nAs you can see, our loss keeps going down!\nIf you keep running this loop for long enough however, you’ll see that the loss eventually starts increasing for a while. That’s because once the parameters get close to the correct answer, our parameter updates will jump right over the correct answer! To avoid this, we need to decrease our learning rate as we train. This is done using a learning rate schedule, and can be automated in most deep learning frameworks, such as fastai and PyTorch."
  },
  {
    "objectID": "fastai_notebooks/fastai_how_neuralnet_work.html#how-a-neural-network-approximates-any-given-function",
    "href": "fastai_notebooks/fastai_how_neuralnet_work.html#how-a-neural-network-approximates-any-given-function",
    "title": "0004_fastai_how_neuralnet_work",
    "section": "How a neural network approximates any given function",
    "text": "How a neural network approximates any given function\nBut neural nets are much more convenient and powerful than this example showed, because we can learn much more than just a quadratic with them. How does that work?\nThe trick is that a neural network is a very expressive function. In fact – it’s infinitely expressive. A neural network can approximate any computable function, given enough parameters. A “computable function” can cover just about anything you can imagine: understand and translate human speech; paint a picture; diagnose a disease from medical imaging; write an essay; etc…\nThe way a neural network approximates a function actually turns out to be very simple. The key trick is to combine two extremely basic steps:\n\nMatrix multiplication, which is just multiplying things together and then adding them up\nThe function \\(max(x,0)\\), which simply replaces all negative numbers with zero."
  },
  {
    "objectID": "fastai_notebooks/fastai_how_neuralnet_work.html#how-to-combine-a-linear-func-with-maxx-0-into-a-rectified-linear-function-how-to-use-torch.clipy-0.-to-perform-maxy-0.",
    "href": "fastai_notebooks/fastai_how_neuralnet_work.html#how-to-combine-a-linear-func-with-maxx-0-into-a-rectified-linear-function-how-to-use-torch.clipy-0.-to-perform-maxy-0.",
    "title": "0004_fastai_how_neuralnet_work",
    "section": "how to combine a linear func with max(x, 0) into a rectified linear function; how to use torch.clip(y, 0.) to perform max(y, 0.)",
    "text": "how to combine a linear func with max(x, 0) into a rectified linear function; how to use torch.clip(y, 0.) to perform max(y, 0.)\nIn PyTorch, the function \\(max(x,0)\\) is written as np.clip(x,0). The combination of a linear function and this max() is called a rectified linear function, and it can be implemented like this:\n\ndef rectified_linear(m,b,x):\n    y = m*x+b\n    return torch.clip(y, 0.)"
  },
  {
    "objectID": "fastai_notebooks/fastai_how_neuralnet_work.html#how-to-use-partial-to-wrap-rectified_linear-to-create-a-specific-rectified_linear-func",
    "href": "fastai_notebooks/fastai_how_neuralnet_work.html#how-to-use-partial-to-wrap-rectified_linear-to-create-a-specific-rectified_linear-func",
    "title": "0004_fastai_how_neuralnet_work",
    "section": "how to use partial to wrap rectified_linear to create a specific rectified_linear func",
    "text": "how to use partial to wrap rectified_linear to create a specific rectified_linear func\nHere’s what it looks like:\n\nplot_function(partial(rectified_linear, 1,1))"
  },
  {
    "objectID": "fastai_notebooks/fastai_how_neuralnet_work.html#how-to-use-f.relu-to-replace-torch.clip-to-create-a-rectified-linear-func",
    "href": "fastai_notebooks/fastai_how_neuralnet_work.html#how-to-use-f.relu-to-replace-torch.clip-to-create-a-rectified-linear-func",
    "title": "0004_fastai_how_neuralnet_work",
    "section": "how to use F.relu to replace torch.clip to create a rectified linear func;",
    "text": "how to use F.relu to replace torch.clip to create a rectified linear func;\nBTW, instead of torch.clip(y, 0.), we can instead use F.relu(x), which does exactly the same thing. In PyTorch, F refers to the torch.nn.functional module.\n\nimport torch.nn.functional as F\ndef rectified_linear2(m,b,x): return F.relu(m*x+b)\nplot_function(partial(rectified_linear2, 1,1))\n\n\n\n\nTo understand how this function works, try using this interactive version to play around with the parameters m and b:\n\n@interact(m=1.5, b=1.5)\ndef plot_relu(m, b):\n    plot_function(partial(rectified_linear, m,b), ylim=(-1,4))\n\n\n\n\n\ncreate double and quaduple relu func/neuralnet\nAs you see, m changes the slope, and b changes where the “hook” appears. This function doesn’t do much on its own, but look what happens when we add two of them together:\n\ndef double_relu(m1,b1,m2,b2,x):\n    return rectified_linear(m1,b1,x) + rectified_linear(m2,b2,x)\n\n@interact(m1=-1.5, b1=-1.5, m2=1.5, b2=1.5)\ndef plot_double_relu(m1, b1, m2, b2):\n    plot_function(partial(double_relu, m1,b1,m2,b2), ylim=(-1,6))\n\n\n\n\nIf you play around with that for a while, you notice something quite profound: with enough of these rectified linear functions added together, you could approximate any function with a single input, to whatever accuracy you like! Any time the function doesn’t quite match, you can just add a few more additions to the mix to make it a bit closer. As an experiment, perhaps you’d like to try creating your own plot_triple_relu interactive function, and maybe even include the scatter plot of our data from before, to see how close you can get?\nThis exact same approach can be expanded to functions of 2, 3, or more parameters.\n\ndef double_relu(m1,b1,m2,b2,m3,b3,m4,b4,x):\n    return rectified_linear(m1,b1,x) + rectified_linear(m2,b2,x) + rectified_linear(m3,b3,x) \\\n+ rectified_linear(m4,b4,x) \n\n@interact(m1=-1.5, b1=-1.5, m2=1.5, b2=1.5, m3=3, b3=3, m4=-3, b4=-3)\ndef plot_double_relu(m1, b1, m2, b2, m3, b3, m4, b4):\n    plot_function(partial(double_relu, m1,b1,m2,b2,m3,b3,m4,b4), ylim=(-1,6))"
  },
  {
    "objectID": "fastai_notebooks/fastai_how_neuralnet_work.html#how-to-recognise-an-owl",
    "href": "fastai_notebooks/fastai_how_neuralnet_work.html#how-to-recognise-an-owl",
    "title": "0004_fastai_how_neuralnet_work",
    "section": "How to recognise an owl",
    "text": "How to recognise an owl\n\ndeep learning basically is drawing squiggly lines infinitely given computation and time\nOK great, we’ve created a nifty little example showing that we can drawing squiggly lines that go through some points. So what?\nWell… the truth is that actually drawing squiggly lines (or planes, or high-dimensional hyperplanes…) through some points is literally all that deep learning does! If your data points are, say, the RGB values of pixels in photos of owls, then you can create an owl-recogniser model by following the exact steps above.\nThis may, at first, sound about as useful as the classic “how to draw an owl” guide:\n\n\n\nimage.png\n\n\nStudents often ask me at this point “OK Jeremy, but how do neural nets actually work”. But at a foundational level, there is no “step 2”. We’re done – the above steps will, given enough time and enough data, create (for example) an owl recogniser, if you feed in enough owls (and non-owls).\nThe devil, I guess, is in the “given enough time and enough data” part of the above sentence. There’s a lot of tweaks we can make to reduce both of these things. For instance, instead of running our calculations on a normal CPU, as we’ve done above, we could do thousands of them simultaneously by taking advantage of a GPU. We could greatly reduce the amount of computation and data needed by using a convolution instead of a matrix multiplication, which basically means skipping over a bunch of the multiplications and additions for bits that you’d guess won’t be important. We could make things much faster if, instead of starting with random parameters, we start with parameters of someone else’s model that does something similar to what we want (this is called transfer learning).\nAnd, of course, there’s lots of helpful software out there to do this stuff for you without too much fuss. Like, say, fastai.\nLearning these things is what we teach in our course, which, like everything we make, is totally free. So if you’re interested in learning more, do check it out!\nAs always, if you enjoyed this notebook, please upvote it to help others find it, and to encourage me to write more. If you upvote it, be careful you don’t accidentally upvote your copy that’s created when you click “Copy & Edit” – you can find my original at this link."
  },
  {
    "objectID": "fastai_notebooks/collaborative_filtering_deep_dive.html",
    "href": "fastai_notebooks/collaborative_filtering_deep_dive.html",
    "title": "0016_collaborative_filtering_deep_dive",
    "section": "",
    "text": "from fastai.collab import *\nfrom fastai.tabular.all import *\nset_seed(42)\nOne very common problem to solve is when you have a number of users and a number of products, and you want to recommend which products are most likely to be useful for which users. There are many variations of this: for example, recommending movies (such as on Netflix), figuring out what to highlight for a user on a home page, deciding what stories to show in a social media feed, and so forth. There is a general solution to this problem, called collaborative filtering, which works like this: look at what products the current user has used or liked, find other users that have used or liked similar products, and then recommend other products that those users have used or liked.\nFor example, on Netflix you may have watched lots of movies that are science fiction, full of action, and were made in the 1970s. Netflix may not know these particular properties of the films you have watched, but it will be able to see that other people that have watched the same movies that you watched also tended to watch other movies that are science fiction, full of action, and were made in the 1970s. In other words, to use this approach we don’t necessarily need to know anything about the movies, except who like to watch them.\nThere is actually a more general class of problems that this approach can solve, not necessarily involving users and products. Indeed, for collaborative filtering we more commonly refer to items, rather than products. Items could be links that people click on, diagnoses that are selected for patients, and so forth.\nThe key foundational idea is that of latent factors. In the Netflix example, we started with the assumption that you like old, action-packed sci-fi movies. But you never actually told Netflix that you like these kinds of movies. And Netflix never actually needed to add columns to its movies table saying which movies are of these types. Still, there must be some underlying concept of sci-fi, action, and movie age, and these concepts must be relevant for at least some people’s movie watching decisions.\nFor this chapter we are going to work on this movie recommendation problem. We’ll start by getting some data suitable for a collaborative filtering model."
  },
  {
    "objectID": "fastai_notebooks/collaborative_filtering_deep_dive.html#a-first-look-at-the-data",
    "href": "fastai_notebooks/collaborative_filtering_deep_dive.html#a-first-look-at-the-data",
    "title": "0016_collaborative_filtering_deep_dive",
    "section": "A First Look at the Data",
    "text": "A First Look at the Data\nWe do not have access to Netflix’s entire dataset of movie watching history, but there is a great dataset that we can use, called MovieLens. This dataset contains tens of millions of movie rankings (a combination of a movie ID, a user ID, and a numeric rating), although we will just use a subset of 100,000 of them for our example. If you’re interested, it would be a great learning project to try and replicate this approach on the full 25-million recommendation dataset, which you can get from their website.\nThe dataset is available through the usual fastai function:\n\npath = untar_data(URLs.ML_100k)\n\n\n\n\n\n\n    \n      \n      100.15% [4931584/4924029 00:00<00:00]\n    \n    \n\n\nAccording to the README, the main table is in the file u.data. It is tab-separated and the columns are, respectively user, movie, rating, and timestamp. Since those names are not encoded, we need to indicate them when reading the file with Pandas. Here is a way to open this table and take a look:\n\nratings = pd.read_csv(path/'u.data', delimiter='\\t', header=None,\n                      names=['user','movie','rating','timestamp'])\nratings.head()\n\n\n\n\n\n  \n    \n      \n      user\n      movie\n      rating\n      timestamp\n    \n  \n  \n    \n      0\n      196\n      242\n      3\n      881250949\n    \n    \n      1\n      186\n      302\n      3\n      891717742\n    \n    \n      2\n      22\n      377\n      1\n      878887116\n    \n    \n      3\n      244\n      51\n      2\n      880606923\n    \n    \n      4\n      166\n      346\n      1\n      886397596\n    \n  \n\n\n\n\nAlthough this has all the information we need, it is not a particularly helpful way for humans to look at this data. Here is the same data cross-tabulated into a human-friendly table:\n\n\n\nimage.png\n\n\nWe have selected just a few of the most popular movies, and users who watch the most movies, for this crosstab example. The empty cells in this table are the things that we would like our model to learn to fill in. Those are the places where a user has not reviewed the movie yet, presumably because they have not watched it. For each user, we would like to figure out which of those movies they might be most likely to enjoy.\nIf we knew for each user to what degree they liked each important category that a movie might fall into, such as genre, age, preferred directors and actors, and so forth, and we knew the same information about each movie, then a simple way to fill in this table would be to multiply this information together for each movie and use a combination. For instance, assuming these factors range between -1 and +1, with positive numbers indicating stronger matches and negative numbers weaker ones, and the categories are science-fiction, action, and old movies, then we could represent the movie The Last Skywalker as:\n\nlast_skywalker = np.array([0.98,0.9,-0.9])\n\nHere, for instance, we are scoring very science-fiction as 0.98, very action as 0.9, and very not old as -0.9. We could represent a user who likes modern sci-fi action movies as:\n\nuser1 = np.array([0.9,0.8,-0.6])\n\nand we can now calculate the match between this combination:\n\n(user1*last_skywalker).sum()\n\n2.1420000000000003\n\n\nWhen we multiply two vectors together and add up the results, this is known as the dot product. It is used a lot in machine learning, and forms the basis of matrix multiplication. We will be looking a lot more at matrix multiplication and dot products in <>.\n\njargon: dot product: The mathematical operation of multiplying the elements of two vectors together, and then summing up the result.\n\nOn the other hand, we might represent the movie Casablanca as:\n\ncasablanca = np.array([-0.99,-0.3,0.8])\n\nThe match between this combination is:\n\n(user1*casablanca).sum()\n\n-1.611\n\n\nSince we don’t know what the latent factors actually are, and we don’t know how to score them for each user and movie, we should learn them."
  },
  {
    "objectID": "fastai_notebooks/collaborative_filtering_deep_dive.html#learning-the-latent-factors",
    "href": "fastai_notebooks/collaborative_filtering_deep_dive.html#learning-the-latent-factors",
    "title": "0016_collaborative_filtering_deep_dive",
    "section": "Learning the Latent Factors",
    "text": "Learning the Latent Factors\nThere is surprisingly little difference between specifying the structure of a model, as we did in the last section, and learning one, since we can just use our general gradient descent approach.\nStep 1 of this approach is to randomly initialize some parameters. These parameters will be a set of latent factors for each user and movie. We will have to decide how many to use. We will discuss how to select this shortly, but for illustrative purposes let’s use 5 for now. Because each user will have a set of these factors and each movie will have a set of these factors, we can show these randomly initialized values right next to the users and movies in our crosstab, and we can then fill in the dot products for each of these combinations in the middle. For example, this is what it looks like in Microsoft Excel, with the top-left cell formula displayed as an example:\n\n\n\nimage.png\n\n\nStep 2 of this approach is to calculate our predictions. As we’ve discussed, we can do this by simply taking the dot product of each movie with each user. If, for instance, the first latent user factor represents how much the user likes action movies and the first latent movie factor represents if the movie has a lot of action or not, the product of those will be particularly high if either the user likes action movies and the movie has a lot of action in it or the user doesn’t like action movies and the movie doesn’t have any action in it. On the other hand, if we have a mismatch (a user loves action movies but the movie isn’t an action film, or the user doesn’t like action movies and it is one), the product will be very low.\nStep 3 is to calculate our loss. We can use any loss function that we wish; let’s pick mean squared error for now, since that is one reasonable way to represent the accuracy of a prediction.\nThat’s all we need. With this in place, we can optimize our parameters (that is, the latent factors) using stochastic gradient descent, such as to minimize the loss. At each step, the stochastic gradient descent optimizer will calculate the match between each movie and each user using the dot product, and will compare it to the actual rating that each user gave to each movie. It will then calculate the derivative of this value and will step the weights by multiplying this by the learning rate. After doing this lots of times, the loss will get better and better, and the recommendations will also get better and better.\nTo use the usual Learner.fit function we will need to get our data into a DataLoaders, so let’s focus on that now."
  },
  {
    "objectID": "fastai_notebooks/collaborative_filtering_deep_dive.html#creating-the-dataloaders",
    "href": "fastai_notebooks/collaborative_filtering_deep_dive.html#creating-the-dataloaders",
    "title": "0016_collaborative_filtering_deep_dive",
    "section": "Creating the DataLoaders",
    "text": "Creating the DataLoaders\nWhen showing the data, we would rather see movie titles than their IDs. The table u.item contains the correspondence of IDs to titles:\n\nmovies = pd.read_csv(path/'u.item',  delimiter='|', encoding='latin-1',\n                     usecols=(0,1), names=('movie','title'), header=None)\nmovies.head()\n\n\n\n\n\n  \n    \n      \n      movie\n      title\n    \n  \n  \n    \n      0\n      1\n      Toy Story (1995)\n    \n    \n      1\n      2\n      GoldenEye (1995)\n    \n    \n      2\n      3\n      Four Rooms (1995)\n    \n    \n      3\n      4\n      Get Shorty (1995)\n    \n    \n      4\n      5\n      Copycat (1995)\n    \n  \n\n\n\n\nWe can merge this with our ratings table to get the user ratings by title:\n\nratings = ratings.merge(movies)\nratings.head()\n\n\n\n\n\n  \n    \n      \n      user\n      movie\n      rating\n      timestamp\n      title\n    \n  \n  \n    \n      0\n      196\n      242\n      3\n      881250949\n      Kolya (1996)\n    \n    \n      1\n      63\n      242\n      3\n      875747190\n      Kolya (1996)\n    \n    \n      2\n      226\n      242\n      5\n      883888671\n      Kolya (1996)\n    \n    \n      3\n      154\n      242\n      3\n      879138235\n      Kolya (1996)\n    \n    \n      4\n      306\n      242\n      5\n      876503793\n      Kolya (1996)\n    \n  \n\n\n\n\nWe can then build a DataLoaders object from this table. By default, it takes the first column for the user, the second column for the item (here our movies), and the third column for the ratings. We need to change the value of item_name in our case to use the titles instead of the IDs:\n\ndls = CollabDataLoaders.from_df(ratings, item_name='title', bs=64)\ndls.show_batch()\n\n\n\n  \n    \n      \n      user\n      title\n      rating\n    \n  \n  \n    \n      0\n      518\n      Richard III (1995)\n      3\n    \n    \n      1\n      546\n      Star Wars (1977)\n      5\n    \n    \n      2\n      264\n      Adventures of Priscilla, Queen of the Desert, The (1994)\n      4\n    \n    \n      3\n      201\n      Kolya (1996)\n      4\n    \n    \n      4\n      664\n      Dances with Wolves (1990)\n      3\n    \n    \n      5\n      391\n      Jerry Maguire (1996)\n      4\n    \n    \n      6\n      401\n      Beauty and the Beast (1991)\n      2\n    \n    \n      7\n      771\n      Strictly Ballroom (1992)\n      5\n    \n    \n      8\n      330\n      101 Dalmatians (1996)\n      4\n    \n    \n      9\n      594\n      One Flew Over the Cuckoo's Nest (1975)\n      4\n    \n  \n\n\n\nTo represent collaborative filtering in PyTorch we can’t just use the crosstab representation directly, especially if we want it to fit into our deep learning framework. We can represent our movie and user latent factor tables as simple matrices:\n\nn_users  = len(dls.classes['user'])\nn_movies = len(dls.classes['title'])\nn_factors = 5\n\nuser_factors = torch.randn(n_users, n_factors)\nmovie_factors = torch.randn(n_movies, n_factors)\n\nTo calculate the result for a particular movie and user combination, we have to look up the index of the movie in our movie latent factor matrix and the index of the user in our user latent factor matrix; then we can do our dot product between the two latent factor vectors. But look up in an index is not an operation our deep learning models know how to do. They know how to do matrix products, and activation functions.\nFortunately, it turns out that we can represent look up in an index as a matrix product. The trick is to replace our indices with one-hot-encoded vectors. Here is an example of what happens if we multiply a vector by a one-hot-encoded vector representing the index 3:\n\none_hot_3 = one_hot(3, n_users).float()\n\n\nuser_factors.t() @ one_hot_3\n\ntensor([-1.2493, -0.3099,  1.4229,  0.0840,  0.4132])\n\n\nIt gives us the same vector as the one at index 3 in the matrix:\n\nuser_factors[3]\n\ntensor([-1.2493, -0.3099,  1.4229,  0.0840,  0.4132])\n\n\nIf we do that for a few indices at once, we will have a matrix of one-hot-encoded vectors, and that operation will be a matrix multiplication! This would be a perfectly acceptable way to build models using this kind of architecture, except that it would use a lot more memory and time than necessary. We know that there is no real underlying reason to store the one-hot-encoded vector, or to search through it to find the occurrence of the number one—we should just be able to index into an array directly with an integer. Therefore, most deep learning libraries, including PyTorch, include a special layer that does just this; it indexes into a vector using an integer, but has its derivative calculated in such a way that it is identical to what it would have been if it had done a matrix multiplication with a one-hot-encoded vector. This is called an embedding.\n\njargon: Embedding: Multiplying by a one-hot-encoded matrix, using the computational shortcut that it can be implemented by simply indexing directly. This is quite a fancy word for a very simple concept. The thing that you multiply the one-hot-encoded matrix by (or, using the computational shortcut, index into directly) is called the embedding matrix.\n\nIn computer vision, we have a very easy way to get all the information of a pixel through its RGB values: each pixel in a colored image is represented by three numbers. Those three numbers give us the redness, the greenness and the blueness, which is enough to get our model to work afterward.\nFor the problem at hand, we don’t have the same easy way to characterize a user or a movie. There are probably relations with genres: if a given user likes romance, they are likely to give higher scores to romance movies. Other factors might be whether the movie is more action-oriented versus heavy on dialogue, or the presence of a specific actor that a user might particularly like.\nHow do we determine numbers to characterize those? The answer is, we don’t. We will let our model learn them. By analyzing the existing relations between users and movies, our model can figure out itself the features that seem important or not.\nThis is what embeddings are. We will attribute to each of our users and each of our movies a random vector of a certain length (here, n_factors=5), and we will make those learnable parameters. That means that at each step, when we compute the loss by comparing our predictions to our targets, we will compute the gradients of the loss with respect to those embedding vectors and update them with the rules of SGD (or another optimizer).\nAt the beginning, those numbers don’t mean anything since we have chosen them randomly, but by the end of training, they will. By learning on existing data about the relations between users and movies, without having any other information, we will see that they still get some important features, and can isolate blockbusters from independent cinema, action movies from romance, and so on.\nWe are now in a position that we can create our whole model from scratch."
  },
  {
    "objectID": "fastai_notebooks/collaborative_filtering_deep_dive.html#collaborative-filtering-from-scratch",
    "href": "fastai_notebooks/collaborative_filtering_deep_dive.html#collaborative-filtering-from-scratch",
    "title": "0016_collaborative_filtering_deep_dive",
    "section": "Collaborative Filtering from Scratch",
    "text": "Collaborative Filtering from Scratch\nBefore we can write a model in PyTorch, we first need to learn the basics of object-oriented programming and Python. If you haven’t done any object-oriented programming before, we will give you a quick introduction here, but we would recommend looking up a tutorial and getting some practice before moving on.\nThe key idea in object-oriented programming is the class. We have been using classes throughout this book, such as DataLoader, string, and Learner. Python also makes it easy for us to create new classes. Here is an example of a simple class:\n\nclass Example:\n    def __init__(self, a): self.a = a\n    def say(self,x): return f'Hello {self.a}, {x}.'\n\nThe most important piece of this is the special method called __init__ (pronounced dunder init). In Python, any method surrounded in double underscores like this is considered special. It indicates that there is some extra behavior associated with this method name. In the case of __init__, this is the method Python will call when your new object is created. So, this is where you can set up any state that needs to be initialized upon object creation. Any parameters included when the user constructs an instance of your class will be passed to the __init__ method as parameters. Note that the first parameter to any method defined inside a class is self, so you can use this to set and get any attributes that you will need:\n\nex = Example('Sylvain')\nex.say('nice to meet you')\n\n'Hello Sylvain, nice to meet you.'\n\n\nAlso note that creating a new PyTorch module requires inheriting from Module. Inheritance is an important object-oriented concept that we will not discuss in detail here—in short, it means that we can add additional behavior to an existing class. PyTorch already provides a Module class, which provides some basic foundations that we want to build on. So, we add the name of this superclass after the name of the class that we are defining, as shown in the following example.\nThe final thing that you need to know to create a new PyTorch module is that when your module is called, PyTorch will call a method in your class called forward, and will pass along to that any parameters that are included in the call. Here is the class defining our dot product model:\n\nclass DotProduct(Module):\n    def __init__(self, n_users, n_movies, n_factors):\n        self.user_factors = Embedding(n_users, n_factors)\n        self.movie_factors = Embedding(n_movies, n_factors)\n        \n    def forward(self, x):\n        users = self.user_factors(x[:,0])\n        movies = self.movie_factors(x[:,1])\n        return (users * movies).sum(dim=1)\n\nIf you haven’t seen object-oriented programming before, then don’t worry, you won’t need to use it much in this book. We are just mentioning this approach here, because most online tutorials and documentation will use the object-oriented syntax.\nNote that the input of the model is a tensor of shape batch_size x 2, where the first column (x[:, 0]) contains the user IDs and the second column (x[:, 1]) contains the movie IDs. As explained before, we use the embedding layers to represent our matrices of user and movie latent factors:\n\nx,y = dls.one_batch()\nx.shape\n\ntorch.Size([64, 2])\n\n\nNow that we have defined our architecture, and created our parameter matrices, we need to create a Learner to optimize our model. In the past we have used special functions, such as cnn_learner, which set up everything for us for a particular application. Since we are doing things from scratch here, we will use the plain Learner class:\n\nmodel = DotProduct(n_users, n_movies, 50)\nlearn = Learner(dls, model, loss_func=MSELossFlat())\n\nWe are now ready to fit our model:\n\nlearn.fit_one_cycle(5, 5e-3)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      1.391418\n      1.281064\n      00:10\n    \n    \n      1\n      1.071581\n      1.059740\n      00:10\n    \n    \n      2\n      0.925082\n      0.955736\n      00:10\n    \n    \n      3\n      0.789137\n      0.877227\n      00:09\n    \n    \n      4\n      0.742079\n      0.862848\n      00:09\n    \n  \n\n\n\nThe first thing we can do to make this model a little bit better is to force those predictions to be between 0 and 5. For this, we just need to use sigmoid_range, like in <>. One thing we discovered empirically is that it’s better to have the range go a little bit over 5, so we use (0, 5.5):\n\nclass DotProduct(Module):\n    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n        self.user_factors = Embedding(n_users, n_factors)\n        self.movie_factors = Embedding(n_movies, n_factors)\n        self.y_range = y_range\n        \n    def forward(self, x):\n        users = self.user_factors(x[:,0])\n        movies = self.movie_factors(x[:,1])\n        return sigmoid_range((users * movies).sum(dim=1), *self.y_range)\n\n\nmodel = DotProduct(n_users, n_movies, 50)\nlearn = Learner(dls, model, loss_func=MSELossFlat())\nlearn.fit_one_cycle(5, 5e-3)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.978663\n      0.978617\n      00:09\n    \n    \n      1\n      0.858417\n      0.889232\n      00:09\n    \n    \n      2\n      0.657446\n      0.861478\n      00:09\n    \n    \n      3\n      0.473589\n      0.862058\n      00:08\n    \n    \n      4\n      0.372989\n      0.865978\n      00:08\n    \n  \n\n\n\nThis is a reasonable start, but we can do better. One obvious missing piece is that some users are just more positive or negative in their recommendations than others, and some movies are just plain better or worse than others. But in our dot product representation we do not have any way to encode either of these things. If all you can say about a movie is, for instance, that it is very sci-fi, very action-oriented, and very not old, then you don’t really have any way to say whether most people like it.\nThat’s because at this point we only have weights; we do not have biases. If we have a single number for each user that we can add to our scores, and ditto for each movie, that will handle this missing piece very nicely. So first of all, let’s adjust our model architecture:\n\nclass DotProductBias(Module):\n    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n        self.user_factors = Embedding(n_users, n_factors)\n        self.user_bias = Embedding(n_users, 1)\n        self.movie_factors = Embedding(n_movies, n_factors)\n        self.movie_bias = Embedding(n_movies, 1)\n        self.y_range = y_range\n        \n    def forward(self, x):\n        users = self.user_factors(x[:,0])\n        movies = self.movie_factors(x[:,1])\n        res = (users * movies).sum(dim=1, keepdim=True)\n        res += self.user_bias(x[:,0]) + self.movie_bias(x[:,1])\n        return sigmoid_range(res, *self.y_range)\n\nLet’s try training this and see how it goes:\n\nmodel = DotProductBias(n_users, n_movies, 50)\nlearn = Learner(dls, model, loss_func=MSELossFlat())\nlearn.fit_one_cycle(5, 5e-3)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.943364\n      0.932987\n      00:08\n    \n    \n      1\n      0.824034\n      0.864243\n      00:08\n    \n    \n      2\n      0.586939\n      0.860469\n      00:09\n    \n    \n      3\n      0.409691\n      0.886897\n      00:08\n    \n    \n      4\n      0.303943\n      0.894082\n      00:08\n    \n  \n\n\n\nInstead of being better, it ends up being worse (at least at the end of training). Why is that? If we look at both trainings carefully, we can see the validation loss stopped improving in the middle and started to get worse. As we’ve seen, this is a clear indication of overfitting. In this case, there is no way to use data augmentation, so we will have to use another regularization technique. One approach that can be helpful is weight decay.\n\nWeight Decay\nWeight decay, or L2 regularization, consists in adding to your loss function the sum of all the weights squared. Why do that? Because when we compute the gradients, it will add a contribution to them that will encourage the weights to be as small as possible.\nWhy would it prevent overfitting? The idea is that the larger the coefficients are, the sharper canyons we will have in the loss function. If we take the basic example of a parabola, y = a * (x**2), the larger a is, the more narrow the parabola is:\n\nx = np.linspace(-2,2,100)\na_s = [1,2,5,10,50] \nys = [a * x**2 for a in a_s]\n_,ax = plt.subplots(figsize=(8,6))\nfor a,y in zip(a_s,ys): ax.plot(x,y, label=f'a={a}')\nax.set_ylim([0,5])\nax.legend();\n\n\n\n\nSo, letting our model learn high parameters might cause it to fit all the data points in the training set with an overcomplex function that has very sharp changes, which will lead to overfitting.\nLimiting our weights from growing too much is going to hinder the training of the model, but it will yield a state where it generalizes better. Going back to the theory briefly, weight decay (or just wd) is a parameter that controls that sum of squares we add to our loss (assuming parameters is a tensor of all parameters):\nloss_with_wd = loss + wd * (parameters**2).sum()\nIn practice, though, it would be very inefficient (and maybe numerically unstable) to compute that big sum and add it to the loss. If you remember a little bit of high school math, you might recall that the derivative of p**2 with respect to p is 2*p, so adding that big sum to our loss is exactly the same as doing:\nparameters.grad += wd * 2 * parameters\nIn practice, since wd is a parameter that we choose, we can just make it twice as big, so we don’t even need the *2 in this equation. To use weight decay in fastai, just pass wd in your call to fit or fit_one_cycle:\n\nmodel = DotProductBias(n_users, n_movies, 50)\nlearn = Learner(dls, model, loss_func=MSELossFlat())\nlearn.fit_one_cycle(5, 5e-3, wd=0.1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.964149\n      0.947329\n      00:08\n    \n    \n      1\n      0.853209\n      0.862615\n      00:09\n    \n    \n      2\n      0.734107\n      0.828079\n      00:08\n    \n    \n      3\n      0.595621\n      0.812455\n      00:08\n    \n    \n      4\n      0.490830\n      0.812497\n      00:08\n    \n  \n\n\n\nMuch better!\n\n\nCreating Our Own Embedding Module\nSo far, we’ve used Embedding without thinking about how it really works. Let’s re-create DotProductBias without using this class. We’ll need a randomly initialized weight matrix for each of the embeddings. We have to be careful, however. Recall from <> that optimizers require that they can get all the parameters of a module from the module’s parameters method. However, this does not happen fully automatically. If we just add a tensor as an attribute to a Module, it will not be included in parameters:\n\nclass T(Module):\n    def __init__(self): self.a = torch.ones(3)\n\nL(T().parameters())\n\n(#0) []\n\n\nTo tell Module that we want to treat a tensor as a parameter, we have to wrap it in the nn.Parameter class. This class doesn’t actually add any functionality (other than automatically calling requires_grad_ for us). It’s only used as a “marker” to show what to include in parameters:\n\nclass T(Module):\n    def __init__(self): self.a = nn.Parameter(torch.ones(3))\n\nL(T().parameters())\n\n(#1) [Parameter containing:\ntensor([1., 1., 1.], requires_grad=True)]\n\n\nAll PyTorch modules use nn.Parameter for any trainable parameters, which is why we haven’t needed to explicitly use this wrapper up until now:\n\nclass T(Module):\n    def __init__(self): self.a = nn.Linear(1, 3, bias=False)\n\nt = T()\nL(t.parameters())\n\n(#1) [Parameter containing:\ntensor([[-0.2714],\n        [ 0.3146],\n        [ 0.0898]], requires_grad=True)]\n\n\n\ntype(t.a.weight)\n\ntorch.nn.parameter.Parameter\n\n\nWe can create a tensor as a parameter, with random initialization, like so:\n\ndef create_params(size):\n    return nn.Parameter(torch.zeros(*size).normal_(0, 0.01))\n\nLet’s use this to create DotProductBias again, but without Embedding:\n\nclass DotProductBias(Module):\n    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n        self.user_factors = create_params([n_users, n_factors])\n        self.user_bias = create_params([n_users])\n        self.movie_factors = create_params([n_movies, n_factors])\n        self.movie_bias = create_params([n_movies])\n        self.y_range = y_range\n        \n    def forward(self, x):\n        users = self.user_factors[x[:,0]]\n        movies = self.movie_factors[x[:,1]]\n        res = (users*movies).sum(dim=1)\n        res += self.user_bias[x[:,0]] + self.movie_bias[x[:,1]]\n        return sigmoid_range(res, *self.y_range)\n\nThen let’s train it again to check we get around the same results we saw in the previous section:\n\nmodel = DotProductBias(n_users, n_movies, 50)\nlearn = Learner(dls, model, loss_func=MSELossFlat())\nlearn.fit_one_cycle(5, 5e-3, wd=0.1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.946225\n      0.933384\n      00:09\n    \n    \n      1\n      0.866075\n      0.868197\n      00:09\n    \n    \n      2\n      0.704416\n      0.825246\n      00:10\n    \n    \n      3\n      0.604527\n      0.817444\n      00:10\n    \n    \n      4\n      0.499887\n      0.817852\n      00:09\n    \n  \n\n\n\nNow, let’s take a look at what our model has learned."
  },
  {
    "objectID": "fastai_notebooks/collaborative_filtering_deep_dive.html#interpreting-embeddings-and-biases",
    "href": "fastai_notebooks/collaborative_filtering_deep_dive.html#interpreting-embeddings-and-biases",
    "title": "0016_collaborative_filtering_deep_dive",
    "section": "Interpreting Embeddings and Biases",
    "text": "Interpreting Embeddings and Biases\nOur model is already useful, in that it can provide us with movie recommendations for our users—but it is also interesting to see what parameters it has discovered. The easiest to interpret are the biases. Here are the movies with the lowest values in the bias vector:\n\nmovie_bias = learn.model.movie_bias.squeeze()\nidxs = movie_bias.argsort()[:5]\n[dls.classes['title'][i] for i in idxs]\n\n['Children of the Corn: The Gathering (1996)',\n 'Home Alone 3 (1997)',\n 'Crow: City of Angels, The (1996)',\n 'Mortal Kombat: Annihilation (1997)',\n 'Cable Guy, The (1996)']\n\n\nThink about what this means. What it’s saying is that for each of these movies, even when a user is very well matched to its latent factors (which, as we will see in a moment, tend to represent things like level of action, age of movie, and so forth), they still generally don’t like it. We could have simply sorted the movies directly by their average rating, but looking at the learned bias tells us something much more interesting. It tells us not just whether a movie is of a kind that people tend not to enjoy watching, but that people tend not to like watching it even if it is of a kind that they would otherwise enjoy! By the same token, here are the movies with the highest bias:\n\nidxs = movie_bias.argsort(descending=True)[:5]\n[dls.classes['title'][i] for i in idxs]\n\n['Titanic (1997)',\n \"Schindler's List (1993)\",\n 'Shawshank Redemption, The (1994)',\n 'Star Wars (1977)',\n 'L.A. Confidential (1997)']\n\n\nSo, for instance, even if you don’t normally enjoy detective movies, you might enjoy LA Confidential!\nIt is not quite so easy to directly interpret the embedding matrices. There are just too many factors for a human to look at. But there is a technique that can pull out the most important underlying directions in such a matrix, called principal component analysis (PCA). We will not be going into this in detail in this book, because it is not particularly important for you to understand to be a deep learning practitioner, but if you are interested then we suggest you check out the fast.ai course Computational Linear Algebra for Coders. Here’s what our movies look like based on two of the strongest PCA components.\n\ng = ratings.groupby('title')['rating'].count()\ntop_movies = g.sort_values(ascending=False).index.values[:1000]\ntop_idxs = tensor([learn.dls.classes['title'].o2i[m] for m in top_movies])\nmovie_w = learn.model.movie_factors[top_idxs].cpu().detach()\nmovie_pca = movie_w.pca(3)\nfac0,fac1,fac2 = movie_pca.t()\nidxs = list(range(50))\nX = fac0[idxs]\nY = fac2[idxs]\nplt.figure(figsize=(12,12))\nplt.scatter(X, Y)\nfor i, x, y in zip(top_movies[idxs], X, Y):\n    plt.text(x,y,i, color=np.random.rand(3)*0.7, fontsize=11)\nplt.show()\n\n\n\n\nWe can see here that the model seems to have discovered a concept of classic versus pop culture movies, or perhaps it is critically acclaimed that is represented here.\n\nj: No matter how many models I train, I never stop getting moved and surprised by how these randomly initialized bunches of numbers, trained with such simple mechanics, manage to discover things about my data all by themselves. It almost seems like cheating, that I can create code that does useful things without ever actually telling it how to do those things!\n\nWe defined our model from scratch to teach you what is inside, but you can directly use the fastai library to build it. We’ll look at how to do that next.\n\nUsing fastai.collab\nWe can create and train a collaborative filtering model using the exact structure shown earlier by using fastai’s collab_learner:\n\nlearn = collab_learner(dls, n_factors=50, y_range=(0, 5.5))\n\n\nlearn.fit_one_cycle(5, 5e-3, wd=0.1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.949029\n      0.931003\n      00:09\n    \n    \n      1\n      0.856821\n      0.868256\n      00:09\n    \n    \n      2\n      0.750694\n      0.823566\n      00:09\n    \n    \n      3\n      0.594716\n      0.811999\n      00:08\n    \n    \n      4\n      0.485535\n      0.812199\n      00:09\n    \n  \n\n\n\nThe names of the layers can be seen by printing the model:\n\nlearn.model\n\nEmbeddingDotBias(\n  (u_weight): Embedding(944, 50)\n  (i_weight): Embedding(1665, 50)\n  (u_bias): Embedding(944, 1)\n  (i_bias): Embedding(1665, 1)\n)\n\n\nWe can use these to replicate any of the analyses we did in the previous section—for instance:\n\nmovie_bias = learn.model.i_bias.weight.squeeze()\nidxs = movie_bias.argsort(descending=True)[:5]\n[dls.classes['title'][i] for i in idxs]\n\n['Titanic (1997)',\n \"Schindler's List (1993)\",\n 'Shawshank Redemption, The (1994)',\n 'Casablanca (1942)',\n 'Silence of the Lambs, The (1991)']\n\n\nAnother interesting thing we can do with these learned embeddings is to look at distance.\n\n\nEmbedding Distance\nOn a two-dimensional map we can calculate the distance between two coordinates using the formula of Pythagoras: \\(\\sqrt{x^{2}+y^{2}}\\) (assuming that x and y are the distances between the coordinates on each axis). For a 50-dimensional embedding we can do exactly the same thing, except that we add up the squares of all 50 of the coordinate distances.\nIf there were two movies that were nearly identical, then their embedding vectors would also have to be nearly identical, because the users that would like them would be nearly exactly the same. There is a more general idea here: movie similarity can be defined by the similarity of users that like those movies. And that directly means that the distance between two movies’ embedding vectors can define that similarity. We can use this to find the most similar movie to Silence of the Lambs:\n\nmovie_factors = learn.model.i_weight.weight\nidx = dls.classes['title'].o2i['Silence of the Lambs, The (1991)']\ndistances = nn.CosineSimilarity(dim=1)(movie_factors, movie_factors[idx][None])\nidx = distances.argsort(descending=True)[1]\ndls.classes['title'][idx]\n\n'8 Seconds (1994)'\n\n\nNow that we have succesfully trained a model, let’s see how to deal with the situation where we have no data for a user. How can we make recommendations to new users?"
  },
  {
    "objectID": "fastai_notebooks/collaborative_filtering_deep_dive.html#bootstrapping-a-collaborative-filtering-model",
    "href": "fastai_notebooks/collaborative_filtering_deep_dive.html#bootstrapping-a-collaborative-filtering-model",
    "title": "0016_collaborative_filtering_deep_dive",
    "section": "Bootstrapping a Collaborative Filtering Model",
    "text": "Bootstrapping a Collaborative Filtering Model\nThe biggest challenge with using collaborative filtering models in practice is the bootstrapping problem. The most extreme version of this problem is when you have no users, and therefore no history to learn from. What products do you recommend to your very first user?\nBut even if you are a well-established company with a long history of user transactions, you still have the question: what do you do when a new user signs up? And indeed, what do you do when you add a new product to your portfolio? There is no magic solution to this problem, and really the solutions that we suggest are just variations of use your common sense. You could assign new users the mean of all of the embedding vectors of your other users, but this has the problem that that particular combination of latent factors may be not at all common (for instance, the average for the science-fiction factor may be high, and the average for the action factor may be low, but it is not that common to find people who like science-fiction without action). Better would probably be to pick some particular user to represent average taste.\nBetter still is to use a tabular model based on user meta data to construct your initial embedding vector. When a user signs up, think about what questions you could ask them that could help you to understand their tastes. Then you can create a model where the dependent variable is a user’s embedding vector, and the independent variables are the results of the questions that you ask them, along with their signup metadata. We will see in the next section how to create these kinds of tabular models. (You may have noticed that when you sign up for services such as Pandora and Netflix, they tend to ask you a few questions about what genres of movie or music you like; this is how they come up with your initial collaborative filtering recommendations.)\nOne thing to be careful of is that a small number of extremely enthusiastic users may end up effectively setting the recommendations for your whole user base. This is a very common problem, for instance, in movie recommendation systems. People that watch anime tend to watch a whole lot of it, and don’t watch very much else, and spend a lot of time putting their ratings on websites. As a result, anime tends to be heavily overrepresented in a lot of best ever movies lists. In this particular case, it can be fairly obvious that you have a problem of representation bias, but if the bias is occurring in the latent factors then it may not be obvious at all.\nSuch a problem can change the entire makeup of your user base, and the behavior of your system. This is particularly true because of positive feedback loops. If a small number of your users tend to set the direction of your recommendation system, then they are naturally going to end up attracting more people like them to your system. And that will, of course, amplify the original representation bias. This type of bias has a natural tendency to be amplified exponentially. You may have seen examples of company executives expressing surprise at how their online platforms rapidly deteriorated in such a way that they expressed values at odds with the values of the founders. In the presence of these kinds of feedback loops, it is easy to see how such a divergence can happen both quickly and in a way that is hidden until it is too late.\nIn a self-reinforcing system like this, we should probably expect these kinds of feedback loops to be the norm, not the exception. Therefore, you should assume that you will see them, plan for that, and identify up front how you will deal with these issues. Try to think about all of the ways in which feedback loops may be represented in your system, and how you might be able to identify them in your data. In the end, this is coming back to our original advice about how to avoid disaster when rolling out any kind of machine learning system. It’s all about ensuring that there are humans in the loop; that there is careful monitoring, and a gradual and thoughtful rollout.\nOur dot product model works quite well, and it is the basis of many successful real-world recommendation systems. This approach to collaborative filtering is known as probabilistic matrix factorization (PMF). Another approach, which generally works similarly well given the same data, is deep learning."
  },
  {
    "objectID": "fastai_notebooks/collaborative_filtering_deep_dive.html#deep-learning-for-collaborative-filtering",
    "href": "fastai_notebooks/collaborative_filtering_deep_dive.html#deep-learning-for-collaborative-filtering",
    "title": "0016_collaborative_filtering_deep_dive",
    "section": "Deep Learning for Collaborative Filtering",
    "text": "Deep Learning for Collaborative Filtering\nTo turn our architecture into a deep learning model, the first step is to take the results of the embedding lookup and concatenate those activations together. This gives us a matrix which we can then pass through linear layers and nonlinearities in the usual way.\nSince we’ll be concatenating the embeddings, rather than taking their dot product, the two embedding matrices can have different sizes (i.e., different numbers of latent factors). fastai has a function get_emb_sz that returns recommended sizes for embedding matrices for your data, based on a heuristic that fast.ai has found tends to work well in practice:\n\nembs = get_emb_sz(dls)\nembs\n\n[(944, 74), (1665, 102)]\n\n\nLet’s implement this class:\n\nclass CollabNN(Module):\n    def __init__(self, user_sz, item_sz, y_range=(0,5.5), n_act=100):\n        self.user_factors = Embedding(*user_sz)\n        self.item_factors = Embedding(*item_sz)\n        self.layers = nn.Sequential(\n            nn.Linear(user_sz[1]+item_sz[1], n_act),\n            nn.ReLU(),\n            nn.Linear(n_act, 1))\n        self.y_range = y_range\n        \n    def forward(self, x):\n        embs = self.user_factors(x[:,0]),self.item_factors(x[:,1])\n        x = self.layers(torch.cat(embs, dim=1))\n        return sigmoid_range(x, *self.y_range)\n\nAnd use it to create a model:\n\nmodel = CollabNN(*embs)\n\nCollabNN creates our Embedding layers in the same way as previous classes in this chapter, except that we now use the embs sizes. self.layers is identical to the mini-neural net we created in <> for MNIST. Then, in forward, we apply the embeddings, concatenate the results, and pass this through the mini-neural net. Finally, we apply sigmoid_range as we have in previous models.\nLet’s see if it trains:\n\nlearn = Learner(dls, model, loss_func=MSELossFlat())\nlearn.fit_one_cycle(5, 5e-3, wd=0.01)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.966280\n      0.945594\n      00:12\n    \n    \n      1\n      0.919992\n      0.901902\n      00:14\n    \n    \n      2\n      0.851043\n      0.872732\n      00:11\n    \n    \n      3\n      0.801476\n      0.857287\n      00:12\n    \n    \n      4\n      0.766401\n      0.858708\n      00:11\n    \n  \n\n\n\nfastai provides this model in fastai.collab if you pass use_nn=True in your call to collab_learner (including calling get_emb_sz for you), and it lets you easily create more layers. For instance, here we’re creating two hidden layers, of size 100 and 50, respectively:\n\nlearn = collab_learner(dls, use_nn=True, y_range=(0, 5.5), layers=[100,50])\nlearn.fit_one_cycle(5, 5e-3, wd=0.1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.993280\n      0.972087\n      00:13\n    \n    \n      1\n      0.932168\n      0.910090\n      00:13\n    \n    \n      2\n      0.860546\n      0.885197\n      00:12\n    \n    \n      3\n      0.808683\n      0.851108\n      00:15\n    \n    \n      4\n      0.727542\n      0.849919\n      00:14\n    \n  \n\n\n\nlearn.model is an object of type EmbeddingNN. Let’s take a look at fastai’s code for this class:\n\n@delegates(TabularModel)\nclass EmbeddingNN(TabularModel):\n    def __init__(self, emb_szs, layers, **kwargs):\n        super().__init__(emb_szs, layers=layers, n_cont=0, out_sz=1, **kwargs)\n\nWow, that’s not a lot of code! This class inherits from TabularModel, which is where it gets all its functionality from. In __init__ it calls the same method in TabularModel, passing n_cont=0 and out_sz=1; other than that, it only passes along whatever arguments it received.\n\nSidebar: kwargs and Delegates\nEmbeddingNN includes **kwargs as a parameter to __init__. In Python **kwargs in a parameter list means “put any additional keyword arguments into a dict called kwargs. And **kwargs in an argument list means”insert all key/value pairs in the kwargs dict as named arguments here”. This approach is used in many popular libraries, such as matplotlib, in which the main plot function simply has the signature plot(*args, **kwargs). The plot documentation says “The kwargs are Line2D properties” and then lists those properties.\nWe’re using **kwargs in EmbeddingNN to avoid having to write all the arguments to TabularModel a second time, and keep them in sync. However, this makes our API quite difficult to work with, because now Jupyter Notebook doesn’t know what parameters are available. Consequently things like tab completion of parameter names and pop-up lists of signatures won’t work.\nfastai resolves this by providing a special @delegates decorator, which automatically changes the signature of the class or function (EmbeddingNN in this case) to insert all of its keyword arguments into the signature.\n\n\nEnd sidebar\nAlthough the results of EmbeddingNN are a bit worse than the dot product approach (which shows the power of carefully constructing an architecture for a domain), it does allow us to do something very important: we can now directly incorporate other user and movie information, date and time information, or any other information that may be relevant to the recommendation. That’s exactly what TabularModel does. In fact, we’ve now seen that EmbeddingNN is just a TabularModel, with n_cont=0 and out_sz=1. So, we’d better spend some time learning about TabularModel, and how to use it to get great results! We’ll do that in the next chapter."
  },
  {
    "objectID": "fastai_notebooks/collaborative_filtering_deep_dive.html#conclusion",
    "href": "fastai_notebooks/collaborative_filtering_deep_dive.html#conclusion",
    "title": "0016_collaborative_filtering_deep_dive",
    "section": "Conclusion",
    "text": "Conclusion\nFor our first non-computer vision application, we looked at recommendation systems and saw how gradient descent can learn intrinsic factors or biases about items from a history of ratings. Those can then give us information about the data.\nWe also built our first model in PyTorch. We will do a lot more of this in the next section of the book, but first, let’s finish our dive into the other general applications of deep learning, continuing with tabular data."
  },
  {
    "objectID": "fastai_notebooks/collaborative_filtering_deep_dive.html#questionnaire",
    "href": "fastai_notebooks/collaborative_filtering_deep_dive.html#questionnaire",
    "title": "0016_collaborative_filtering_deep_dive",
    "section": "Questionnaire",
    "text": "Questionnaire\n\nWhat problem does collaborative filtering solve?\nHow does it solve it?\nWhy might a collaborative filtering predictive model fail to be a very useful recommendation system?\nWhat does a crosstab representation of collaborative filtering data look like?\nWrite the code to create a crosstab representation of the MovieLens data (you might need to do some web searching!).\nWhat is a latent factor? Why is it “latent”?\nWhat is a dot product? Calculate a dot product manually using pure Python with lists.\nWhat does pandas.DataFrame.merge do?\nWhat is an embedding matrix?\nWhat is the relationship between an embedding and a matrix of one-hot-encoded vectors?\nWhy do we need Embedding if we could use one-hot-encoded vectors for the same thing?\nWhat does an embedding contain before we start training (assuming we’re not using a pretained model)?\nCreate a class (without peeking, if possible!) and use it.\nWhat does x[:,0] return?\nRewrite the DotProduct class (without peeking, if possible!) and train a model with it.\nWhat is a good loss function to use for MovieLens? Why?\nWhat would happen if we used cross-entropy loss with MovieLens? How would we need to change the model?\nWhat is the use of bias in a dot product model?\nWhat is another name for weight decay?\nWrite the equation for weight decay (without peeking!).\nWrite the equation for the gradient of weight decay. Why does it help reduce weights?\nWhy does reducing weights lead to better generalization?\nWhat does argsort do in PyTorch?\nDoes sorting the movie biases give the same result as averaging overall movie ratings by movie? Why/why not?\nHow do you print the names and details of the layers in a model?\nWhat is the “bootstrapping problem” in collaborative filtering?\nHow could you deal with the bootstrapping problem for new users? For new movies?\nHow can feedback loops impact collaborative filtering systems?\nWhen using a neural network in collaborative filtering, why can we have different numbers of factors for movies and users?\nWhy is there an nn.Sequential in the CollabNN model?\nWhat kind of model should we use if we want to add metadata about users and items, or information such as date and time, to a collaborative filtering model?\n\n\nFurther Research\n\nTake a look at all the differences between the Embedding version of DotProductBias and the create_params version, and try to understand why each of those changes is required. If you’re not sure, try reverting each change to see what happens. (NB: even the type of brackets used in forward has changed!)\nFind three other areas where collaborative filtering is being used, and find out what the pros and cons of this approach are in those areas.\nComplete this notebook using the full MovieLens dataset, and compare your results to online benchmarks. See if you can improve your accuracy. Look on the book’s website and the fast.ai forum for ideas. Note that there are more columns in the full dataset—see if you can use those too (the next chapter might give you ideas).\nCreate a model for MovieLens that works with cross-entropy loss, and compare it to the model in this chapter."
  },
  {
    "objectID": "fastai_notebooks/fastai_why_should_use_framework.html",
    "href": "fastai_notebooks/fastai_why_should_use_framework.html",
    "title": "0006_fastai_why_should_use_framework",
    "section": "",
    "text": "Official course site: for lesson 3\nOfficial notebooks repo, on nbviewer\nOfficial notebooks on kaggle"
  },
  {
    "objectID": "fastai_notebooks/fastai_why_should_use_framework.html#introduction-and-set-up",
    "href": "fastai_notebooks/fastai_why_should_use_framework.html#introduction-and-set-up",
    "title": "0006_fastai_why_should_use_framework",
    "section": "Introduction and set up",
    "text": "Introduction and set up\n\nwhat are the benefits of using fastai and PyTorch frameworks\nIf you’ve finished going through my Linear model and neural net from scratch notebook, then now is a good time to look at how to do the same thing using a library, instead of doing it from scratch. We’ll use fastai and PyTorch. The benefits of using these libraries is:\n\nBest practices are handled for you automatically – fast.ai has done thousands of hours of experiments to figure out what the best settings are for you\nLess time getting set up, which means more time to try out your new ideas\nEach idea you try will be less work, because fastai and PyTorch will do the many of the menial bits for you\nYou can always drop down from fastai to PyTorch if you need to customise any part (or drop down from the fastai Application API to the fastai mid or low tier APIs), or even drop down from PyTorch to plain python for deep customisation.\n\nLet’s see how that looks in practice. We’ll start by doing the same library setup as in the “from scratch” notebook:\n\nfrom pathlib import Path\nimport os\n\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\nif iskaggle:\n    path = Path('../input/titanic')\n    !pip install -Uqq fastai\nelse:\n    import zipfile,kaggle\n    path = Path('titanic')\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f'{path}.zip').extractall(path)\n\n\n\nwhich fastai module is for tabular data; how to set float format display for pandas; how to set random seed;\nWe’ll import the fastai tabular library, set a random seed so the notebook is reproducible, and pick a reasonable number of significant figures to display in our tables:\n\nfrom fastai.tabular.all import *\n\npd.options.display.float_format = '{:.2f}'.format\nset_seed(42)"
  },
  {
    "objectID": "fastai_notebooks/fastai_why_should_use_framework.html#prep-the-data",
    "href": "fastai_notebooks/fastai_why_should_use_framework.html#prep-the-data",
    "title": "0006_fastai_why_should_use_framework",
    "section": "Prep the data",
    "text": "Prep the data\nWe’ll read the CSV file just like we did before:\n\ndf = pd.read_csv(path/'train.csv')\n\n\nno worry of dummy variables, normalization, missing values and so on if using fastai; interesting feature ideas from a nice Titanic feature notebook;\nWhen you do everything from scratch, every bit of feature engineering requires a whole lot of work, since you have to think about things like dummy variables, normalization, missing values, and so on. But with fastai that’s all done for you. So let’s go wild and create lots of new features! We’ll use a bunch of the most interesting ones from this fantastic Titanic feature engineering notebook (and be sure to click that link and upvote that notebook if you like it to thank the author for their hard work!)\n\ndef add_features(df):\n    df['LogFare'] = np.log1p(df['Fare'])\n    df['Deck'] = df.Cabin.str[0].map(dict(A=\"ABC\", B=\"ABC\", C=\"ABC\", D=\"DE\", E=\"DE\", F=\"FG\", G=\"FG\"))\n    df['Family'] = df.SibSp+df.Parch\n    df['Alone'] = df.Family==1\n    df['TicketFreq'] = df.groupby('Ticket')['Ticket'].transform('count')\n    df['Title'] = df.Name.str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n    df['Title'] = df.Title.map(dict(Mr=\"Mr\",Miss=\"Miss\",Mrs=\"Mrs\",Master=\"Master\")).value_counts(dropna=False)\n\nadd_features(df)\n\n\n\nhow to create a tabular dataloaders with TabularPandas which handles all messing processing; how to set the parameters of TabularPandas\nAs we discussed in the last notebook, we can use RandomSplitter to separate out the training and validation sets:\n\nsplits = RandomSplitter(seed=42)(df)\n\nNow the entire process of getting the data ready for training requires just this one cell!:\n\ndls = TabularPandas(\n    df, splits=splits,\n    procs = [Categorify, FillMissing, Normalize],\n    cat_names=[\"Sex\",\"Pclass\",\"Embarked\",\"Deck\", \"Title\"],\n    cont_names=['Age', 'SibSp', 'Parch', 'LogFare', 'Alone', 'TicketFreq', 'Family'],\n    y_names=\"Survived\", y_block = CategoryBlock(),\n).dataloaders(path=\".\")\n\nHere’s what each of the parameters means:\n\nUse splits for indices of training and validation sets:\nsplits=splits,\nTurn strings into categories, fill missing values in numeric columns with the median, normalise all numeric columns:\nprocs = [Categorify, FillMissing, Normalize],\nThese are the categorical independent variables:\ncat_names=[\"Sex\",\"Pclass\",\"Embarked\",\"Deck\", \"Title\"],\nThese are the continuous independent variables:\ncont_names=['Age', 'SibSp', 'Parch', 'LogFare', 'Alone', 'TicketFreq', 'Family'],\nThis is the dependent variable:\ny_names=\"Survived\",\nThe dependent variable is categorical (so build a classification model, not a regression model):\ny_block = CategoryBlock(),"
  },
  {
    "objectID": "fastai_notebooks/fastai_why_should_use_framework.html#train-the-model",
    "href": "fastai_notebooks/fastai_why_should_use_framework.html#train-the-model",
    "title": "0006_fastai_why_should_use_framework",
    "section": "Train the model",
    "text": "Train the model\n\nhow to create a tabular learner using tabular dataloader, metrics and layers\nThe data and model together make up a Learner. To create one, we say what the data is (dls), and the size of each hidden layer ([10,10]), along with any metrics we want to print along the way:\n\nlearn = tabular_learner(dls, metrics=accuracy, layers=[10,10])\n\nYou’ll notice we didn’t have to do any messing around to try to find a set of random coefficients that will train correctly – that’s all handled automatically.\n\n\nhow to find the learning rate automatically in fastai\nOne handy feature that fastai can also tell us what learning rate to use:\n\nlearn.lr_find(suggest_funcs=(slide, valley))\n\n\n\nhow to pick the best learning rate from the learning rate curve; how to train model 16 epochs using learn.fit\nThe two colored points are both reasonable choices for a learning rate. I’ll pick somewhere between the two (0.03) and train for a few epochs:\n\nlearn.fit(16, lr=0.03)\n\nWe’ve got a similar accuracy to our previous “from scratch” model – which isn’t too surprising, since as we discussed, this dataset is too small and simple to really see much difference. A simple linear model already does a pretty good job. But that’s OK – the goal here is to show you how to get started with deep learning and understand how it really works, and the best way to do that is on small and easy to understand datasets."
  },
  {
    "objectID": "fastai_notebooks/fastai_why_should_use_framework.html#submit-to-kaggle",
    "href": "fastai_notebooks/fastai_why_should_use_framework.html#submit-to-kaggle",
    "title": "0006_fastai_why_should_use_framework",
    "section": "Submit to Kaggle",
    "text": "Submit to Kaggle\nOne important feature of fastai is that all the information needed to apply the data transformations and the model to a new dataset are stored in the learner. You can call export to save it to a file to use it later in production, or you can use the trained model right away to get predictions on a test set.\nTo submit to Kaggle, we’ll need to read in the test set, and do the same feature engineering we did for the training set:\n\nhow to prepare test data including added new features\n\ntst_df = pd.read_csv(path/'test.csv')\ntst_df['Fare'] = tst_df.Fare.fillna(0)\nadd_features(tst_df)\n\n\n\nhow to apply all the processing steps of training data to test data with learn.dls.test_dl\nBut we don’t need to manually specify any of the processing steps necessary to get the data ready for modeling, since that’s all saved in the learner. To specify we want to apply the same steps to a new dataset, use the test_dl() method:\n\ntst_dl = learn.dls.test_dl(tst_df)\n\n\n\nhow to calc all predictions for test set using learn.get_preds\nNow we can use get_preds to get the predictions for the test set:\n\npreds,_ = learn.get_preds(dl=tst_dl)\n\n\n\nhow to prepare the results of test set into a csv file for kaggle submission; how to save into csv file without idx number\nFinally, let’s create a submission CSV just like we did in the previous notebook…\n\ntst_df['Survived'] = (preds[:,1]>0.5).int()\nsub_df = tst_df[['PassengerId','Survived']]\nsub_df.to_csv('sub.csv', index=False)\n\n…and check that it looks reasonable:\n\n!head sub.csv"
  },
  {
    "objectID": "fastai_notebooks/fastai_why_should_use_framework.html#ensembling",
    "href": "fastai_notebooks/fastai_why_should_use_framework.html#ensembling",
    "title": "0006_fastai_why_should_use_framework",
    "section": "Ensembling",
    "text": "Ensembling\n\nwhat is ensembling and why it is more robust than any single model\nSince it’s so easy to create a model now, it’s easier to play with more advanced modeling approaches. For instance, we can create five separate models, each trained from different random starting points, and average them. This is the simplest approach of ensembling models, which combines multiple models to generate predictions that are better than any of the single models in the ensemble.\nTo create our ensemble, first we copy the three steps we used above to create and train a model, and apply it to the test set:\n\n\nhow to create an ensemble function to create multiple models and generate predictions from each of them\n\ndef ensemble():\n    learn = tabular_learner(dls, metrics=accuracy, layers=[10,10])\n    with learn.no_bar(),learn.no_logging(): learn.fit(16, lr=0.03)\n    return learn.get_preds(dl=tst_dl)[0]\n\nNow we run this five times, and collect the results into a list:\n\nlearns = [ensemble() for _ in range(5)]\n\n\n\nhow to get the average predictions from all ensembed models\nWe stack this predictions together and take their average predictions:\n\nens_preds = torch.stack(learns).mean(0)\n\nFinally, use the same code as before to generate a submission file, which we can submit to Kaggle after the notebook is saved and run:\n\n\nhow to create the csv file to Titanic competition\n\ntst_df['Survived'] = (ens_preds[:,1]>0.5).int()\nsub_df = tst_df[['PassengerId','Survived']]\nsub_df.to_csv('ens_sub.csv', index=False)\n\nAt the time of writing, this submission is well within the top 25% of entries to the competition.\n(A lot of submissions to this competition use additional external data, but we have restricted ourselves to just using the data provided. We’d probably do a lot better if we used external data too. Feel free to give that a try, and see how you go. Note that you’ll never be able to get to the top of the leaderboard, since a lot of folks in this competition have cheated, by downloading the answers from the internet and uploading them as their submission. In a real competition that’s not possible, because the answers aren’t public, but there’s nothing stopping people from cheating in a tutorial/practice competition like this one. So if you’re ready for a real challenge, take a look at the competitions page and start working on a real competition!)"
  },
  {
    "objectID": "fastai_notebooks/fastai_why_should_use_framework.html#final-thoughts",
    "href": "fastai_notebooks/fastai_why_should_use_framework.html#final-thoughts",
    "title": "0006_fastai_why_should_use_framework",
    "section": "Final thoughts",
    "text": "Final thoughts\n\nWhy you should use a framework like fastai\nAs you can see, using fastai and PyTorch made things much easier than doing it from scratch, but it also hid away a lot of the details. So if you only ever use a framework, you’re not going to as fully understand what’s going on under the hood. That understanding can be really helpful when it comes to debugging and improving your models. But do use fastai when you’re creating models on Kaggle or in “real life”, because otherwise you’re not taking advantage of all the research that’s gone into optimising the models for you, and you’ll end up spending more time debugging and implementing menial boiler-plate than actually solving the real problem!\nIf you found this notebook useful, please remember to click the little up-arrow at the top to upvote it, since I like to know when people have found my work useful, and it helps others find it too. (BTW, be sure you’re looking at my original notebook here when you do that, and are not on your own copy of it, otherwise your upvote won’t get counted!) And if you have any questions or comments, please pop them below – I read every comment I receive!"
  },
  {
    "objectID": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html",
    "href": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html",
    "title": "0002_fastai_saving_a_basic_fastai_model",
    "section": "",
    "text": "This is a minimal example showing how to train a fastai model on Kaggle, and save it so you can use it in your app."
  },
  {
    "objectID": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html#what-to-import-to-handle-vision-problems-in-fastai",
    "href": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html#what-to-import-to-handle-vision-problems-in-fastai",
    "title": "0002_fastai_saving_a_basic_fastai_model",
    "section": "what to import to handle vision problems in fastai",
    "text": "what to import to handle vision problems in fastai\nFirst, import all the stuff we need from fastai:\n\nfrom fastai.vision.all import *"
  },
  {
    "objectID": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html#how-to-download-and-decompress-datasets-prepared-by-fastai",
    "href": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html#how-to-download-and-decompress-datasets-prepared-by-fastai",
    "title": "0002_fastai_saving_a_basic_fastai_model",
    "section": "how to download and decompress datasets prepared by fastai",
    "text": "how to download and decompress datasets prepared by fastai\nThis is a dataset of cats and dogs\n\npath = untar_data(URLs.PETS)/'images'"
  },
  {
    "objectID": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html#how-to-tell-it-is-a-cat-by-reading-filename",
    "href": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html#how-to-tell-it-is-a-cat-by-reading-filename",
    "title": "0002_fastai_saving_a_basic_fastai_model",
    "section": "how to tell it is a cat by reading filename",
    "text": "how to tell it is a cat by reading filename\nWe need a way to label our images as dogs or cats. In this dataset, pictures of cats are given a filename that starts with a capital letter:\n\ndef is_cat(x): return x[0].isupper()"
  },
  {
    "objectID": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html#how-to-create-dataloaders-with-from_name_func",
    "href": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html#how-to-create-dataloaders-with-from_name_func",
    "title": "0002_fastai_saving_a_basic_fastai_model",
    "section": "how to create dataloaders with from_name_func",
    "text": "how to create dataloaders with from_name_func\nNow we can create our DataLoaders:\n\ndls = ImageDataLoaders.from_name_func('.',\n    get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=is_cat,\n    item_tfms=Resize(192))"
  },
  {
    "objectID": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html#how-to-create-a-pretrained-model-with-resnet18-and-error_rate-how-to-fine-tune-it-3-epochs",
    "href": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html#how-to-create-a-pretrained-model-with-resnet18-and-error_rate-how-to-fine-tune-it-3-epochs",
    "title": "0002_fastai_saving_a_basic_fastai_model",
    "section": "how to create a pretrained model with resnet18 and error_rate; how to fine tune it 3 epochs",
    "text": "how to create a pretrained model with resnet18 and error_rate; how to fine tune it 3 epochs\n… and train our model, a resnet18 (to keep it small and fast):\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n/Users/Natsume/mambaforge/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  warnings.warn(\n/Users/Natsume/mambaforge/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/1 00:00<?]\n    \n    \n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n  \n\n\n    \n      \n      20.65% [19/92 00:12<00:48 0.7980]"
  },
  {
    "objectID": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html#how-to-export-model-to-a-pickle-file-and-download-it-from-kaggle",
    "href": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html#how-to-export-model-to-a-pickle-file-and-download-it-from-kaggle",
    "title": "0002_fastai_saving_a_basic_fastai_model",
    "section": "how to export model to a pickle file and download it from Kaggle",
    "text": "how to export model to a pickle file and download it from Kaggle\nNow we can export our trained Learner. This contains all the information needed to run the model:\n\nlearn.export('model.pkl')\n\nFinally, open the Kaggle sidebar on the right if it’s not already, and find the section marked “Output”. Open the /kaggle/working folder, and you’ll see model.pkl. Click on it, then click on the menu on the right that appears, and choose “Download”. After a few seconds, your model will be downloaded to your computer, where you can then create your app that uses the model."
  },
  {
    "objectID": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html#how-to-convert-ipynb-to-md",
    "href": "fastai_notebooks/fastai_saving_a_basic_fastai_model.html#how-to-convert-ipynb-to-md",
    "title": "0002_fastai_saving_a_basic_fastai_model",
    "section": "how to convert ipynb to md",
    "text": "how to convert ipynb to md\n\nfrom fastdebug.utils import *\nimport fastdebug.utils as fu\n\n\n\n\n\nipy2md()\n\n[jupytext] Reading /Users/Natsume/Documents/fastdebug/nbs/2022part1/0002_fastai_Saving_Model_fastai.ipynb in format ipynb\n[jupytext] Writing /Users/Natsume/Documents/fastdebug/nbs/2022part1/0002_fastai_Saving_Model_fastai.md\ncp to : /Users/Natsume/Documents/divefastai/Debuggable/jupytext\nmove to : /Users/Natsume/Documents/fastdebug/mds/2022part1/\n\n\n[NbConvertApp] Converting notebook /Users/Natsume/Documents/fastdebug/nbs/2022part1/0002_fastai_Saving_Model_fastai.ipynb to markdown\n[NbConvertApp] Writing 4849 bytes to /Users/Natsume/Documents/fastdebug/nbs/2022part1/0002_fastai_Saving_Model_fastai.md\n\n\nmove to : /Users/Natsume/Documents/fastdebug/mds_output"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptsource_explained.html",
    "href": "fastai_notebooks/fastai_ptsource_explained.html",
    "title": "0020_fastai_pt2_2019_source_explained",
    "section": "",
    "text": "34:08 - Jeremy explaining the source code of notebook2script.py; Jupyter notebook is just a json data file\n\n#!/usr/bin/env python\n\nimport json,fire,re\nfrom pathlib import Path\nimport io\n\ndef is_export(cell):\n    if cell['cell_type'] != 'code': return False\n    src = cell['source']\n    if len(src) == 0 or len(src[0]) < 7: return False\n    #import pdb; pdb.set_trace()\n    return re.match(r'^\\s*#\\s*export\\s*$', src[0], re.IGNORECASE) is not None\n\ndef getSortedFiles(allFiles, upTo=None):\n    '''Returns all the notebok files sorted by name.\n       allFiles = True : returns all files\n                = '*_*.ipynb' : returns this pattern\n       upTo = None : no upper limit\n            = filter : returns all files up to 'filter' included\n       The sorting optioj is important to ensure that the notebok are executed in correct order.\n    '''\n    import glob\n    ret = []\n    if (allFiles==True): ret = glob.glob('*.ipynb') # Checks both that is bool type and that is True\n    if (isinstance(allFiles,str)): ret = glob.glob(allFiles)\n    if 0==len(ret): \n        print('WARNING: No files found')\n        return ret\n    if upTo is not None: ret = [f for f in ret if str(f)<=str(upTo)]\n    return sorted(ret)\n\ndef notebook2script(fname=None, allFiles=None, upTo=None):\n    '''Finds cells starting with `#export` and puts them into a new module\n       + allFiles: convert all files in the folder\n       + upTo: convert files up to specified one included\n       \n       ES: \n       notebook2script --allFiles=True   # Parse all files\n       notebook2script --allFiles=nb*   # Parse all files starting with nb*\n       notebook2script --upTo=10   # Parse all files with (name<='10')\n       notebook2script --allFiles=*_*.ipynb --upTo=10   # Parse all files with an '_' and (name<='10')\n    '''\n    # initial checks\n    if (allFiles is None) and (upTo is not None): allFiles=True # Enable allFiles if upTo is present\n    if (fname is None) and (not allFiles): print('Should provide a file name')\n    if not allFiles: notebook2scriptSingle(fname)\n    else:\n        print('Begin...')\n        [notebook2scriptSingle(f) for f in getSortedFiles(allFiles,upTo)]\n        print('...End')\n        \n        \ndef notebook2scriptSingle(fname):\n    \"Finds cells starting with `#export` and puts them into a new module\"\n    fname = Path(fname)\n    fname_out = f'nb_{fname.stem.split(\"_\")[0]}.py'\n    main_dic = json.load(open(fname,'r',encoding=\"utf-8\"))\n    code_cells = [c for c in main_dic['cells'] if is_export(c)]\n    module = f'''\n#################################################\n### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###\n#################################################\n# file to edit: dev_nb/{fname.name}\n\n'''\n    for cell in code_cells: module += ''.join(cell['source'][1:]) + '\\n\\n'\n    # remove trailing spaces\n    module = re.sub(r' +$', '', module, flags=re.MULTILINE)\n    if not (fname.parent/'exp').exists(): (fname.parent/'exp').mkdir()\n    output_path = fname.parent/'exp'/fname_out\n    with io.open(output_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(module[:-2])\n    print(f\"Converted {fname} to {output_path}\")\n\nif __name__ == '__main__': fire.Fire(notebook2script)"
  },
  {
    "objectID": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html",
    "href": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html",
    "title": "0009_fastai_small_models_road_to_the_top_part_2",
    "section": "",
    "text": "# install fastkaggle if not available\ntry: import fastkaggle\nexcept ModuleNotFoundError:\n    !pip install -q fastkaggle\n\nfrom fastkaggle import *\n\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nThis is part 2 of the Road to the Top series, in which I show the process I used to tackle the Paddy Doctor competition, leading to four 1st place submissions. If you haven’t already, first check out part 1."
  },
  {
    "objectID": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html#going-faster",
    "href": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html#going-faster",
    "title": "0009_fastai_small_models_road_to_the_top_part_2",
    "section": "Going faster",
    "text": "Going faster\nFirst we’ll repeat the steps we used last time to access the data and ensure all the latest libraries are installed:\n\ncomp = 'paddy-disease-classification'\npath = setup_comp(comp, install='\"fastcore>=1.4.5\" \"fastai>=2.7.1\" \"timm>=0.6.2.dev0\"')\nfrom fastai.vision.all import *\nset_seed(42)\n\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\ntensorflow 2.6.4 requires absl-py~=0.10, but you have absl-py 1.0.0 which is incompatible.\ntensorflow 2.6.4 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\ntensorflow 2.6.4 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\ntensorflow 2.6.4 requires wrapt~=1.12.1, but you have wrapt 1.14.1 which is incompatible.\ntensorflow-transform 1.8.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow-serving-api 2.8.0 requires tensorflow<3,>=2.8.0, but you have tensorflow 2.6.4 which is incompatible.\nrich 12.4.4 requires typing-extensions<5.0,>=4.0.0; python_version < \"3.9\", but you have typing-extensions 3.10.0.2 which is incompatible.\npytorch-lightning 1.6.3 requires typing-extensions>=4.0.0, but you have typing-extensions 3.10.0.2 which is incompatible.\npytools 2022.1.9 requires typing-extensions>=4.0; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\nflax 0.5.0 requires typing-extensions>=4.1.1, but you have typing-extensions 3.10.0.2 which is incompatible.\nflake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.11.4 which is incompatible.\napache-beam 2.38.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\napache-beam 2.38.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.4 which is incompatible.\naioitertools 0.10.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.10.0.2 which is incompatible.\naiobotocore 2.3.2 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.26.7 which is incompatible.\n\n\n\nwhy kaggle gpu is much slower for training and how does fastai to fix it with resize_images\nA big issue I noticed last time was that originally I created the notebook on my home PC, and each epoch of the resnet we created took under 20 seconds to run. But on Kaggle they took over 3 minutes each! Whilst Kaggle’s GPUs are less powerful than what I’ve got at home, that doesn’t come close to explaining this vast difference in speed.\nI noticed when Kaggle was running that the “GPU” indicator in the top right was nearly empty, and the “CPU” one was always full. This strongly suggests that the problem was that Kaggle’s notebook was CPU bound by decoding and resizing the images. This is a common problem on machines with poor CPU performance – and indeed Kaggle only provides 2 virtual CPUs at the time of writing.\nWe really need to fix this, since we need to be able to iterate much more quickly. What we can do is to simply resize all the images to half their height and width – which reduces their number of pixels 4x. This should mean an around 4x increase in performance for training small models.\nLuckily, fastai has a function which does exactly this, whilst maintaining the folder structure of the data: resize_images.\n\n\nhow to create a new folder with Path\n\ntrn_path = Path('sml')\n\n\n\nhow to resize all images (including those in subfolders) of train_images folder and save them into a new destination folder; max_size = 256 does shrink the total size by 4+, but question: how Jeremy pick 256 not 250;\n\nresize_images(path/'train_images', dest=trn_path, max_size=256, recurse=True)\n\n\n\nhow to create an image dataloaders using the resized image folder and specify the resize for each image item; how to display just 3 images in a batch\nThis will give us 192x256px images. Let’s take a look:\n\ndls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, seed=42,\n    item_tfms=Resize((256,192)))\n\ndls.show_batch(max_n=3)\n\n\n\n\n\n\nhow to wrap dataloaders creation, model creation, fine tuning together in a func train and return the trained model; how use model architecture, item transforms, and batch transforms, and num of epochs as the params of the train function;\nIn this notebook, we’ll be experimenting with a few different architectures and image processing approaches (item and batch transforms). In order to make this easier, we’ll put our modeling steps together into a little function which we can pass the architecture, item transforms, and batch transforms to:\n\ndef train(arch, item, batch, epochs=5):\n    dls = ImageDataLoaders.from_folder(trn_path, seed=42, valid_pct=0.2, item_tfms=item, batch_tfms=batch)\n    learn = vision_learner(dls, arch, metrics=error_rate).to_fp16()\n    learn.fine_tune(epochs, 0.01)\n    return learn\n\nOur item_tfms already resize our images to small sizes, so this shouldn’t impact the accuracy of our models much, if at all. Let’s re-run our resnet26d to test.\n\nlearn = train('resnet26d', item=Resize(192),\n              batch=aug_transforms(size=128, min_scale=0.75))\n\nDownloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet26d-69e92c46.pth\" to /root/.cache/torch/hub/checkpoints/resnet26d-69e92c46.pth\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.875997\n      1.478083\n      0.445459\n      00:36\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.268640\n      1.031712\n      0.343585\n      00:33\n    \n    \n      1\n      0.989115\n      0.701631\n      0.223931\n      00:33\n    \n    \n      2\n      0.708181\n      0.527319\n      0.161941\n      00:33\n    \n    \n      3\n      0.522309\n      0.405053\n      0.127343\n      00:33\n    \n    \n      4\n      0.428306\n      0.388762\n      0.121576\n      00:33\n    \n  \n\n\n\nThat’s a big improvement in speed, and the accuracy looks fine."
  },
  {
    "objectID": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html#a-convnext-model",
    "href": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html#a-convnext-model",
    "title": "0009_fastai_small_models_road_to_the_top_part_2",
    "section": "A ConvNeXt model",
    "text": "A ConvNeXt model\n\nHow to tell whether a larger pretrained model would affect our training speed by reading GPU and CPU usage bar? why to pick convnext_small for our second model;\nI noticed that the GPU usage bar in Kaggle was still nearly empty, so we’re still CPU bound. That means we should be able to use a more capable model with little if any speed impact. Let’s look again at the options in The best vision models for fine-tuning. convnext_small tops the performance/accuracy tradeoff score there, so let’s give it a go!\n\n\nhow to load and use a new pretrained model in fastai\n\narch = 'convnext_small_in22k'\n\n\nlearn = train(arch, item=Resize(192, method='squish'),\n              batch=aug_transforms(size=128, min_scale=0.75))\n\nDownloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_224.pth\" to /root/.cache/torch/hub/checkpoints/convnext_small_22k_224.pth\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.371264\n      0.853445\n      0.270062\n      00:42\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.716509\n      0.541614\n      0.186449\n      00:54\n    \n    \n      1\n      0.539565\n      0.378337\n      0.117251\n      00:54\n    \n    \n      2\n      0.362223\n      0.235239\n      0.073522\n      00:53\n    \n    \n      3\n      0.208453\n      0.179712\n      0.058626\n      00:54\n    \n    \n      4\n      0.142692\n      0.157421\n      0.045651\n      00:53\n    \n  \n\n\n\nWow our error rate has halved! That’s a great result. And, as expected, the speed hasn’t gone up much at all. This seems like a great model for iterating on."
  },
  {
    "objectID": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html#preprocessing-experiments",
    "href": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html#preprocessing-experiments",
    "title": "0009_fastai_small_models_road_to_the_top_part_2",
    "section": "Preprocessing experiments",
    "text": "Preprocessing experiments\n\nquestion: why trying different ways of cutting images could possibly improve model performance; what are the proper options for cutting images or preparing images\nSo, what shall we try first? One thing which can make a difference is whether we “squish” a rectangular image into a square shape by changing it’s aspect ratio, or randomly crop out a square from it, or whether we add black padding to the edges to make it a square. In the previous version we “squished”. Let’s try “crop” instead, which is fastai’s default:\n\n\nhow to try cutting image with crop instead of squish\n\nlearn = train(arch, item=Resize(192),\n              batch=aug_transforms(size=128, min_scale=0.75))\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.380402\n      0.855188\n      0.283518\n      00:40\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.758646\n      0.532799\n      0.172513\n      00:51\n    \n    \n      1\n      0.587157\n      0.407430\n      0.133590\n      00:52\n    \n    \n      2\n      0.390106\n      0.260073\n      0.082653\n      00:52\n    \n    \n      3\n      0.245907\n      0.188568\n      0.061028\n      00:52\n    \n    \n      4\n      0.185185\n      0.160873\n      0.049015\n      00:52\n    \n  \n\n\n\n\n\nwhat is transform image with padding and how does it differ from squish and crop\nThat doesn’t seem to have made much difference…\nWe can also try padding, which keeps all the original image without transforming it – here’s what that looks like:\n\ndls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, seed=42,\n    item_tfms=Resize(192, method=ResizeMethod.Pad, pad_mode=PadMode.Zeros))\ndls.show_batch(max_n=3)\n\n\n\n\n\n\nquestion: how resize(256, 192) and size(171, 128) are determined\n\nlearn = train(arch, item=Resize((256,192), method=ResizeMethod.Pad, pad_mode=PadMode.Zeros),\n      batch=aug_transforms(size=(171,128), min_scale=0.75))\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.349685\n      0.873837\n      0.283998\n      00:44\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.727163\n      0.486494\n      0.155214\n      01:01\n    \n    \n      1\n      0.576610\n      0.401801\n      0.127823\n      01:00\n    \n    \n      2\n      0.369458\n      0.265897\n      0.083614\n      01:00\n    \n    \n      3\n      0.214277\n      0.185793\n      0.056704\n      01:01\n    \n    \n      4\n      0.157982\n      0.162269\n      0.045171\n      01:00\n    \n  \n\n\n\nThat’s looking like a pretty good improvement."
  },
  {
    "objectID": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html#test-time-augmentation",
    "href": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html#test-time-augmentation",
    "title": "0009_fastai_small_models_road_to_the_top_part_2",
    "section": "Test time augmentation",
    "text": "Test time augmentation\n\nhow does test time augmentation TTA work; question: what is the rationale behind TTA\nTo make the predictions even better, we can try test time augmentation (TTA), which our book defines as:\n\nDuring inference or validation, creating multiple versions of each image, using data augmentation, and then taking the average or maximum of the predictions for each augmented version of the image.\n\nBefore trying that out, we’ll first see how to check the predictions and error rate of our model without TTA:\n\n\nhow to check the performance of our model on validation set\n\nvalid = learn.dls.valid\npreds,targs = learn.get_preds(dl=valid)\n\n\n\n\n\n\n\n\n\nerror_rate(preds, targs)\n\nTensorBase(0.0452)\n\n\n\n\nhow to display the transformations which have been done to a single image in the training set\nThat’s the same error rate we saw at the end of training, above, so we know that we’re doing that correctly.\nHere’s what our data augmentation is doing – if you look carefully, you can see that each image is a bit lighter or darker, sometimes flipped, zoomed, rotated, warped, and/or zoomed:\n\nlearn.dls.train.show_batch(max_n=6, unique=True)\n\n\n\n\n\n\nhow to do TTA on validation set\nIf we call tta() then we’ll get the average of predictions made for multiple different augmented versions of each image, along with the unaugmented original:\n\ntta_preds,_ = learn.tta(dl=valid)\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\nhow to calc the error rate of the tta_preds\nLet’s check the error rate of this:\n\nerror_rate(tta_preds, targs)\n\nTensorBase(0.0485)\n\n\nThat’s a huge improvement! We’ll definitely want to use this for any submission we make!"
  },
  {
    "objectID": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html#scaling-up",
    "href": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html#scaling-up",
    "title": "0009_fastai_small_models_road_to_the_top_part_2",
    "section": "Scaling up",
    "text": "Scaling up\n\nhow to scale up on the model using padding and the tta approach in terms of image size and epoch number\nNow that we’ve got a pretty good model and preprocessing approach, let’s scale it up to larger images and more epochs. We’ll switch back our path to the original un-resized images, and use 12 epochs using our best settings so far, with larger final augmented images:\n\ntrn_path = path/'train_images'\n\n\nlearn = train(arch, epochs=12,\n              item=Resize((480, 360), method=ResizeMethod.Pad, pad_mode=PadMode.Zeros),\n              batch=aug_transforms(size=(256,192), min_scale=0.75))\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.240577\n      0.803256\n      0.260932\n      02:19\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.622355\n      0.316984\n      0.097069\n      02:35\n    \n    \n      1\n      0.453550\n      0.296619\n      0.094666\n      02:34\n    \n    \n      2\n      0.389912\n      0.296899\n      0.087458\n      02:35\n    \n    \n      3\n      0.344765\n      0.258925\n      0.076406\n      02:33\n    \n    \n      4\n      0.264739\n      0.207181\n      0.058626\n      02:34\n    \n    \n      5\n      0.193956\n      0.128093\n      0.035560\n      02:34\n    \n    \n      6\n      0.149894\n      0.137023\n      0.037482\n      02:33\n    \n    \n      7\n      0.096056\n      0.123581\n      0.033157\n      02:35\n    \n    \n      8\n      0.079198\n      0.102848\n      0.028832\n      02:36\n    \n    \n      9\n      0.055733\n      0.095993\n      0.024988\n      02:35\n    \n    \n      10\n      0.041112\n      0.090146\n      0.022105\n      02:33\n    \n    \n      11\n      0.038906\n      0.090561\n      0.022105\n      02:35\n    \n  \n\n\n\n\n\nhow to check the performance of the scaled up model using validation set\nThis is around twice as accurate as our previous best model - let’s see how it performs with TTA too:\n\ntta_preds,targs = learn.tta(dl=learn.dls.valid)\nerror_rate(tta_preds, targs)\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\nTensorBase(0.0197)\n\n\nOnce again, we get a big boost from TTA. This is one of the most under-appreciated deep learning tricks, in my opinion! (I’m not sure there’s any other frameworks that make it quite so easy, so perhaps that’s part of the reason why…)"
  },
  {
    "objectID": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html#submission",
    "href": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html#submission",
    "title": "0009_fastai_small_models_road_to_the_top_part_2",
    "section": "Submission",
    "text": "Submission\n\nhow to use TTA to predict instead of the usual get_preds to get predictions on the test set\nWe’re now ready to get our Kaggle submission sorted. First, we’ll grab the test set like we did in the last notebook:\n\ntst_files = get_image_files(path/'test_images').sorted()\ntst_dl = learn.dls.test_dl(tst_files)\n\nNext, do TTA on that test set:\n\npreds,_ = learn.tta(dl=tst_dl)\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\nhow to get the index of the predictions\nWe need to indices of the largest probability prediction in each row, since that’s the index of the predicted disease. argmax in PyTorch gives us exactly that:\n\nidxs = preds.argmax(dim=1)\n\n\n\nhow to replace index with vocab or classes\nNow we need to look up those indices in the vocab. Last time we did that using pandas, although since then I realised there’s an even easier way!:\n\nvocab = np.array(learn.dls.vocab)\nresults = pd.Series(vocab[idxs], name=\"idxs\")\n\n\nss = pd.read_csv(path/'sample_submission.csv')\nss['label'] = results\nss.to_csv('subm.csv', index=False)\n!head subm.csv\n\nimage_id,label\n200001.jpg,hispa\n200002.jpg,normal\n200003.jpg,blast\n200004.jpg,blast\n200005.jpg,blast\n200006.jpg,brown_spot\n200007.jpg,dead_heart\n200008.jpg,brown_spot\n200009.jpg,hispa\n\n\n\n\nhow to submit prediction csv to kaggle with comment using fastkaggle api\n\nif not iskaggle:\n    from kaggle import api\n    api.competition_submit_cli('subm.csv', 'convnext small 256x192 12 epochs tta', comp)\n\n\n\nhow to push local notebook to Kaggle online\nThis gets a score of 0.9827, which is well within the top 25% of the competition – that’s a big improvement, and we’re still using a single small model!\n\n# This is what I use to push my notebook from my home PC to Kaggle\n\nif not iskaggle:\n    push_notebook('jhoward', 'small-models-road-to-the-top-part-2',\n                  title='Small models: Road to the Top, Part 2',\n                  file='small-models-road-to-the-top-part-2.ipynb',\n                  competition=comp, private=True, gpu=True)"
  },
  {
    "objectID": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html#conclusion",
    "href": "fastai_notebooks/fastai_small_models_road_to_the_top_part_2.html#conclusion",
    "title": "0009_fastai_small_models_road_to_the_top_part_2",
    "section": "Conclusion",
    "text": "Conclusion\nWe’ve made a big step today, despite just using a single model that trains in under 20 minutes even on Kaggle’s rather under-powered machines. Next time, we’ll try scaling up to some bigger models and doing some ensembling.\nIf you found this notebook useful, please remember to click the little up-arrow at the top to upvote it, since I like to know when people have found my work useful, and it helps others find it too. And if you have any questions or comments, please pop them below – I read every comment I receive!"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptexports.html",
    "href": "fastai_notebooks/fastai_ptexports.html",
    "title": "0018_fastai_pt2_2019_exports",
    "section": "",
    "text": "#export\nTEST = 'test'\n\nExport\n\n!python notebook2script.py 00_exports.ipynb\n\nHow it works:\n\nimport json\nd = json.load(open('00_exports.ipynb','r'))['cells']\n\n\nd[0]"
  },
  {
    "objectID": "fastai_notebooks/fastai_how_random_forests_really_work.html",
    "href": "fastai_notebooks/fastai_how_random_forests_really_work.html",
    "title": "0007_fastai_how_random_forests_really_work",
    "section": "",
    "text": "Previously I’ve shown how to create a linear model and neural net from scratch, and used it to create a solid submission to Kaggle’s Titanic competition. However, for tabular data (i.e data that looks like spreadsheet or database tables, such as the data for the Titanic competition) it’s more common to see good results by using ensembles of decision trees, such as Random Forests and Gradient Boosting Machines.\nIn this notebook, we’re going to learn all about Random Forests, by building one from scratch, and using it to submit to the Titanic competition! That might sound like a pretty big stretch, but I think you’ll be surprised to discover how straightforward it actually is.\nWe’ll start by importing the basic set of libraries we normally need for data science work, and setting numpy to use our display space more efficiently:\n\n\n\n\nfrom fastai.imports import *\nnp.set_printoptions(linewidth=130)"
  },
  {
    "objectID": "fastai_notebooks/fastai_how_random_forests_really_work.html#data-preprocessing",
    "href": "fastai_notebooks/fastai_how_random_forests_really_work.html#data-preprocessing",
    "title": "0007_fastai_how_random_forests_really_work",
    "section": "Data preprocessing",
    "text": "Data preprocessing\n\nhow to get Titanic dataset ready for creating a decision tree model\nWe’ll create DataFrames from the CSV files just like we did in the “linear model and neural net from scratch” notebook, and do much the same preprocessing (so go back and check that out if you’re not already familiar with the dataset):\n\nimport os\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n\nif iskaggle: path = Path('../input/titanic')\nelse:\n    import zipfile,kaggle\n    path = Path('titanic')\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f'{path}.zip').extractall(path)\n\ndf = pd.read_csv(path/'train.csv')\ntst_df = pd.read_csv(path/'test.csv')\nmodes = df.mode().iloc[0]\n\nValueError: Error: Missing username in configuration.\n\n\nOne difference with Random Forests however is that we don’t generally have to create dummy variables like we did for non-numeric columns in the linear models and neural network. Instead, we can just convert those fields to categorical variables, which internally in Pandas makes a list of all the unique values in the column, and replaces each value with a number. The number is just an index for looking up the value in the list of all unique values.\n\ndef proc_data(df):\n    df['Fare'] = df.Fare.fillna(0)\n    df.fillna(modes, inplace=True)\n    df['LogFare'] = np.log1p(df['Fare'])\n    df['Embarked'] = pd.Categorical(df.Embarked)\n    df['Sex'] = pd.Categorical(df.Sex)\n\nproc_data(df)\nproc_data(tst_df)\n\nNameError: name 'df' is not defined\n\n\nWe’ll make a list of the continuous, categorical, and dependent variables. Note that we no longer consider Pclass a categorical variable. That’s because it’s ordered (i.e 1st, 2nd, and 3rd class have an order), and decision trees, as we’ll see, only care about order, not about absolute value.\n\ncats=[\"Sex\",\"Embarked\"]\nconts=['Age', 'SibSp', 'Parch', 'LogFare',\"Pclass\"]\ndep=\"Survived\"\n\nEven although we’ve made the cats columns categorical, they are still shown by Pandas as their original values:\n\ndf.Sex.head()\n\nNameError: name 'df' is not defined\n\n\nHowever behind the scenes they’re now stored as integers, with indices that are looked up in the Categories list shown in the output above. We can view the stored values by looking in the cat.codes attribute:\n\ndf.Sex.cat.codes.head()\n\nNameError: name 'df' is not defined"
  },
  {
    "objectID": "fastai_notebooks/fastai_how_random_forests_really_work.html#binary-splits",
    "href": "fastai_notebooks/fastai_how_random_forests_really_work.html#binary-splits",
    "title": "0007_fastai_how_random_forests_really_work",
    "section": "Binary splits",
    "text": "Binary splits\n\nwhat is binary splits and how does it work\nBefore we create a Random Forest or Gradient Boosting Machine, we’ll first need to learn how to create a decision tree, from which both of these models are built.\nAnd to create a decision tree, we’ll first need to create a binary split, since that’s what a decision tree is built from.\nA binary split is where all rows are placed into one of two groups, based on whether they’re above or below some threshold of some column. For example, we could split the rows of our dataset into males and females, by using the threshold 0.5 and the column Sex (since the values in the column are 0 for female and 1 for male). We can use a plot to see how that would split up our data – we’ll use the Seaborn library, which is a layer on top of matplotlib that makes some useful charts easier to create, and more aesthetically pleasing by default:\n\n\nhow to plot barplot and countplot with Seaborn\n\nimport seaborn as sns\n\nfig,axs = plt.subplots(1,2, figsize=(11,5))\nsns.barplot(data=df, y=dep, x=\"Sex\", ax=axs[0]).set(title=\"Survival rate\")\nsns.countplot(data=df, x=\"Sex\", ax=axs[1]).set(title=\"Histogram\");\n\nModuleNotFoundError: No module named 'seaborn'\n\n\n\n\nCreate a simplest model based on binary split\nHere we see that (on the left) if we split the data into males and females, we’d have groups that have very different survival rates: >70% for females, and <20% for males. We can also see (on the right) that the split would be reasonably even, with over 300 passengers (out of around 900) in each group.\nWe could create a very simple “model” which simply says that all females survive, and no males do. To do so, we better first split our data into a training and validation set, to see how accurate this approach turns out to be:\n\n\nhow to do train and test split using sklearn.model_selection.train_test_split\n\nfrom numpy import random\nfrom sklearn.model_selection import train_test_split\n\nrandom.seed(42)\ntrn_df,val_df = train_test_split(df, test_size=0.25)\ntrn_df[cats] = trn_df[cats].apply(lambda x: x.cat.codes)\nval_df[cats] = val_df[cats].apply(lambda x: x.cat.codes)\n\nNameError: name 'df' is not defined\n\n\n\n\nhow to access dependent and independent values for both training set and test set\n(In the previous step we also replaced the categorical variables with their integer codes, since some of the models we’ll be building in a moment require that.)\nNow we can create our independent variables (the x variables) and dependent (the y variable):\n\ndef xs_y(df):\n    xs = df[cats+conts].copy()\n    return xs,df[dep] if dep in df else None\n\ntrn_xs,trn_y = xs_y(trn_df)\nval_xs,val_y = xs_y(val_df)\n\n\n\ncalc the prediction (the simplest so far)\nHere’s the predictions for our extremely simple model, where female is coded as 0:\n\npreds = val_xs.Sex==0\n\n\n\ncalc loss with mean absolute error using sklearn.metrics.mean_absolute_error\nWe’ll use mean absolute error to measure how good this model is:\n\nfrom sklearn.metrics import mean_absolute_error\nmean_absolute_error(val_y, preds)\n\n\n\nhow to do binary split on a continuous column rather than category column\nAlternatively, we could try splitting on a continuous column. We have to use a somewhat different chart to see how this might work – here’s an example of how we could look at LogFare:\n\n\nhow to plot a boxenplot on survival and non-survival using sns.logFare column; how to a density plot with logFare using sns.kdeplot\n\ndf_fare = trn_df[trn_df.LogFare>0]\nfig,axs = plt.subplots(1,2, figsize=(11,5))\nsns.boxenplot(data=df_fare, x=dep, y=\"LogFare\", ax=axs[0])\nsns.kdeplot(data=df_fare, x=\"LogFare\", ax=axs[1]);\n\n\n\nhow to find the binary split to calc predictions based on logFare using the boxenplot above\nThe boxenplot above shows quantiles of LogFare for each group of Survived==0 and Survived==1. It shows that the average LogFare for passengers that didn’t survive is around 2.5, and for those that did it’s around 3.2. So it seems that people that paid more for their tickets were more likely to get put on a lifeboat.\nLet’s create a simple model based on this observation:\n\npreds = val_xs.LogFare>2.7\n\n\n\nsee how good is this model and prediction using loss (mean absolute error)\n…and test it out:\n\nmean_absolute_error(val_y, preds)\n\nNameError: name 'mean_absolute_error' is not defined\n\n\n\n\nhow does impurity measure the goodness of a split; how to create impurity as a measure for how good of a split\nThis is quite a bit less accurate than our model that used Sex as the single binary split.\nIdeally, we’d like some way to try more columns and breakpoints more easily. We could create a function that returns how good our model is, in order to more quickly try out a few different splits. We’ll create a score function to do this. Instead of returning the mean absolute error, we’ll calculate a measure of impurity – that is, how much the binary split creates two groups where the rows in a group are each similar to each other, or dissimilar.\nWe can measure the similarity of rows inside a group by taking the standard deviation of the dependent variable. If it’s higher, then it means the rows are more different to each other. We’ll then multiply this by the number of rows, since a bigger group as more impact than a smaller group:\n\n\nhow to create a score function for a single side of the split\n\ndef _side_score(side, y):\n    tot = side.sum()\n    if tot<=1: return 0\n    return y[side].std()*tot\n\n\n\nhow to create the score function to measure the goodness of a binary split\nNow we’ve got that written, we can calculate the score for a split by adding up the scores for the “left hand side” (lhs) and “right hand side” (rhs):\n\ndef score(col, y, split):\n    lhs = col<=split\n    return (_side_score(lhs,y) + _side_score(~lhs,y))/len(y)\n\n\n\ncalc the impurity score for sex split and then logFare split\nFor instance, here’s the impurity score for the split on Sex:\n\nscore(trn_xs[\"Sex\"], trn_y, 0.5)\n\nNameError: name 'trn_xs' is not defined\n\n\n…and for LogFare:\n\nscore(trn_xs[\"LogFare\"], trn_y, 2.7)\n\nNameError: name 'trn_xs' is not defined\n\n\n\n\nhow to make interactive on choose different split and calc score on continuous columns\nAs we’d expect from our earlier tests, Sex appears to be a better split.\nTo make it easier to find the best binary split, we can create a simple interactive tool (note that this only works in Kaggle if you click “Copy and Edit” in the top right to open the notebook editor):\n\ndef iscore(nm, split):\n    col = trn_xs[nm]\n    return score(col, trn_y, split)\n\nfrom ipywidgets import interact\ninteract(nm=conts, split=15.5)(iscore);\n\n\n\n\n\n\nhow to make interactive on choose different split and calc score on categorical columns\nTry selecting different columns and split points using the dropdown and slider above. What splits can you find that increase the purity of the data?\nWe can do the same thing for the categorical variables:\n\ninteract(nm=cats, split=2)(iscore);\n\n\n\n\n\n\nhow to make a list of all possible split points\nThat works well enough, but it’s rather slow and fiddly. Perhaps we could get the computer to automatically find the best split point for a column for us? For example, to find the best split point for age we’d first need to make a list of all the possible split points (i.e all the unique values of that field)…:\n\nnm = \"Age\"\ncol = trn_xs[nm]\nunq = col.unique()\nunq.sort()\nunq\n\nNameError: name 'trn_xs' is not defined\n\n\n\n\nhow to get the score for all possible splits of a particular column like Age; how to get the index for the lowest core\n…and find which index of those values is where score() is the lowest:\n\nscores = np.array([score(col, trn_y, o) for o in unq if not np.isnan(o)])\nunq[scores.argmin()]\n\n\n\nhow to write a function to return the best split value and its score on a particular column given the dataframe and the name of the column\nBased on this, it looks like, for instance, that for the Age column, 6 is the optimal cutoff according to our training set.\nWe can write a little function that implements this idea:\n\ndef min_col(df, nm):\n    col,y = df[nm],df[dep]\n    unq = col.dropna().unique()\n    scores = np.array([score(col, y, o) for o in unq if not np.isnan(o)])\n    idx = scores.argmin()\n    return unq[idx],scores[idx]\n\nmin_col(trn_df, \"Age\")\n\n\n\nhow to run this function on all columns of the dataset\nLet’s try all the columns:\n\ncols = cats+conts\n{o:min_col(trn_df, o) for o in cols}\n\n\n\nwhat is OneR classifier; why should it be a baseline to more sophisiticated models\nAccording to this, Sex<=0 is the best split we can use.\nWe’ve just re-invented the OneR classifier (or at least, a minor variant of it), which was found to be one of the most effective classifiers in real-world datasets, compared to the algorithms in use in 1993. Since it’s so simple and surprisingly effective, it makes for a great baseline – that is, a starting point that you can use to compare your more sophisticated models to.\nWe found earlier that out OneR rule had an error of around 0.215, so we’ll keep that in mind as we try out more sophisticated approaches."
  },
  {
    "objectID": "fastai_notebooks/fastai_how_random_forests_really_work.html#creating-a-decision-tree",
    "href": "fastai_notebooks/fastai_how_random_forests_really_work.html#creating-a-decision-tree",
    "title": "0007_fastai_how_random_forests_really_work",
    "section": "Creating a decision tree",
    "text": "Creating a decision tree\n\nhow is to do better than a OneR classifier which predict survival using sex? how about doing another OneR upon the first OneR classifier result (male group and female group)\nHow can we improve our OneR classifier, which predicts survival based only on Sex?\nHow about we take each of our two groups, female and male, and create one more binary split for each of them. That is: fine the single best split for females, and the single best split for males. To do this, all we have to do is repeat the previous section’s steps, once for males, and once for females.\nFirst, we’ll remove Sex from the list of possible splits (since we’ve already used it, and there’s only one possible split for that binary column), and create our two groups:\n\n\nhow to get the dataset splitted by sex in pandas dataframe\n\ncols.remove(\"Sex\")\nismale = trn_df.Sex==1\nmales,females = trn_df[ismale],trn_df[~ismale]\n\nNameError: name 'cols' is not defined\n\n\n\n\nhow to find the best binary splits and score out of all columns in male dataset and then femal dataset\nNow let’s find the single best binary split for males…:\n\n{o:min_col(males, o) for o in cols}\n\nNameError: name 'cols' is not defined\n\n\n…and for females:\n\n{o:min_col(females, o) for o in cols}\n\nNameError: name 'cols' is not defined\n\n\n\n\nwhat does a decision tree mean when the second binary split is done here\nWe can see that the best next binary split for males is Age<=6, and for females is Pclass<=2.\nBy adding these rules, we have created a decision tree, where our model will first check whether Sex is female or male, and depending on the result will then check either the above Age or Pclass rules, as appropriate. We could then repeat the process, creating new additional rules for each of the four groups we’ve now created.\nRather than writing that code manually, we can use DecisionTreeClassifier, from sklearn, which does exactly that for us:\n\n\nhow to do a decision tree automatically using sklearn\n\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\n\nm = DecisionTreeClassifier(max_leaf_nodes=4).fit(trn_xs, trn_y);\n\nNameError: name 'trn_xs' is not defined\n\n\n\n\nhow to visualize the decision tree above\nOne handy feature or this class is that it provides a function for drawing a tree representing the rules:\n\nimport graphviz\n\ndef draw_tree(t, df, size=10, ratio=0.6, precision=2, **kwargs):\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True, rounded=True,\n                      special_characters=True, rotate=False, precision=precision, **kwargs)\n    return graphviz.Source(re.sub('Tree {', f'Tree {{ size={size}; ratio={ratio}', s))\n\n\ndraw_tree(m, trn_xs, size=10)"
  },
  {
    "objectID": "fastai_notebooks/fastai_how_random_forests_really_work.html#how-is-gini-different-from-impurity",
    "href": "fastai_notebooks/fastai_how_random_forests_really_work.html#how-is-gini-different-from-impurity",
    "title": "0007_fastai_how_random_forests_really_work",
    "section": "how is gini different from impurity",
    "text": "how is gini different from impurity\nWe can see that it’s found exactly the same splits as we did!\nIn this picture, the more orange nodes have a lower survival rate, and blue have higher survival. Each node shows how many rows (“samples”) match that set of rules, and shows how many perish or survive (“values”). There’s also something called “gini”. That’s another measure of impurity, and it’s very similar to the score() we created earlier. It’s defined as follows:\n\nhow to cacl gini\n\ndef gini(cond):\n    act = df.loc[cond, dep]\n    return 1 - act.mean()**2 - (1-act).mean()**2\n\nWhat this calculates is the probability that, if you pick two rows from a group, you’ll get the same Survived result each time. If the group is all the same, the probability is 1.0, and 0.0 if they’re all different:\n\ngini(df.Sex=='female'), gini(df.Sex=='male')\n\nLet’s see how this model compares to our OneR version:\n\nmean_absolute_error(val_y, m.predict(val_xs))\n\nIt’s a tiny bit worse. Since this is such a small dataset (we’ve only got around 200 rows in our validation set) this small difference isn’t really meaningful. Perhaps we’ll see better results if we create a bigger tree:\n\nm = DecisionTreeClassifier(min_samples_leaf=50)\nm.fit(trn_xs, trn_y)\ndraw_tree(m, trn_xs, size=25)\n\n\nmean_absolute_error(val_y, m.predict(val_xs))\n\n\n\nhow to wrap the process of preparing submission csv file for kaggle\nIt looks like this is an improvement, although again it’s a bit hard to tell with small datasets like this. Let’s try submitting it to Kaggle:\n\ntst_df[cats] = tst_df[cats].apply(lambda x: x.cat.codes)\ntst_xs,_ = xs_y(tst_df)\n\ndef subm(preds, suff):\n    tst_df['Survived'] = preds\n    sub_df = tst_df[['PassengerId','Survived']]\n    sub_df.to_csv(f'sub-{suff}.csv', index=False)\n\nsubm(m.predict(tst_xs), 'tree')\n\n\n\nwhy no need to worry about dummy variables in decision trees\nWhen I submitted this, I got a score of 0.765, which isn’t as good as our linear models or most of our neural nets, but it’s pretty close to those results.\nHopefully you can now see why we didn’t really need to create dummy variables, but instead just converted the labels into numbers using some (potentially arbitary) ordering of categories. For instance, here’s how the first few items of Embarked are labeled:\n\ndf.Embarked.head()\n\n…resulting in these integer codes:\n\ndf.Embarked.cat.codes.head()\n\nSo let’s say we wanted to split into “C” in one group, vs “Q” or “S” in the other group. Then we just have to split on codes <=0 (since C is mapped to category 0). Note that if we wanted to split into “Q” in one group, we’d need to use two binary splits, first to separate “C” from “Q” and “S”, and then a second split to separate “Q” from “S”. For this reason, sometimes it can still be helpful to use dummy variables for categorical variables with few levels (like this one).\nIn practice, I often use dummy variables for <4 levels, and numeric codes for >=4 levels."
  },
  {
    "objectID": "fastai_notebooks/fastai_how_random_forests_really_work.html#the-random-forest",
    "href": "fastai_notebooks/fastai_how_random_forests_really_work.html#the-random-forest",
    "title": "0007_fastai_how_random_forests_really_work",
    "section": "The random forest",
    "text": "The random forest\n\nwhat is random forest; what is bagging; what is the great insight behind it\nWe can’t make the decision tree much bigger than the example above, since some leaf nodes already have only 50 rows in them. That’s not a lot of data to make a prediction.\nSo how could we use bigger trees? One big insight came from Leo Breiman: what if we create lots of bigger trees, and take the average of their predictions? Taking the average prediction of a bunch of models in this way is known as bagging.\nThe idea is that we want each model’s predictions in the averaged ensemble to be uncorrelated with each other model. That way, if we average the predictions, the average will be equal to the true target value – that’s because the average of lots of uncorrelated random errors is zero. That’s quite an amazing insight!\nOne way we can create a bunch of uncorrelated models is to train each of them on a different random subset of the data. Here’s how we can create a tree on a random subset of the data:\n\n\nhow to create uncorrelated trees using random subset of data\n\ndef get_tree(prop=0.75):\n    n = len(trn_y)\n    idxs = random.choice(n, int(n*prop))\n    return DecisionTreeClassifier(min_samples_leaf=5).fit(trn_xs.iloc[idxs], trn_y.iloc[idxs])\n\nNow we can create as many trees as we want:\n\ntrees = [get_tree() for t in range(100)]\n\n\n\nhow to make prediciton on each tree and take average on them, and then calc the loss\nOur prediction will be the average of these trees’ predictions:\n\nall_probs = [t.predict(val_xs) for t in trees]\navg_probs = np.stack(all_probs).mean(0)\n\nmean_absolute_error(val_y, avg_probs)\n\n\n\nhow is sklearn’s RandomForestClassifier differ from the forest from scratch above; how to do random forest with sklearn\nThis is nearly identical to what sklearn’s RandomForestClassifier does. The main extra piece in a “real” random forest is that as well as choosing a random sample of data for each tree, it also picks a random subset of columns for each split. Here’s how we repeat the above process with a random forest:\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(100, min_samples_leaf=5)\nrf.fit(trn_xs, trn_y);\nmean_absolute_error(val_y, rf.predict(val_xs))\n\nWe can submit that to Kaggle too:\n\nsubm(rf.predict(tst_xs), 'rf')\n\nI found that gave nearly an identical result as our single tree (which, in turn, was slightly lower than our linear and neural net models in the previous notebook).\nOne particularly nice feature of random forests is they can tell us which independent variables were the most important in the model, using feature_importances_:\n\npd.DataFrame(dict(cols=trn_xs.columns, imp=m.feature_importances_)).plot('cols', 'imp', 'barh');\n\nWe can see that Sex is by far the most important predictor, with Pclass a distant second, and LogFare and Age behind that. In datasets with many columns, I generally recommend creating a feature importance plot as soon as possible, in order to find which columns are worth studying more closely. (Note also that we didn’t really need to take the log() of Fare, since random forests only care about order, and log() doesn’t change the order – we only did it to make our graphs earlier easier to read.)\nFor details about deriving and understanding feature importances, and the many other important diagnostic tools provided by random forests, take a look at chapter 8 of our book."
  },
  {
    "objectID": "fastai_notebooks/fastai_how_random_forests_really_work.html#conclusion",
    "href": "fastai_notebooks/fastai_how_random_forests_really_work.html#conclusion",
    "title": "0007_fastai_how_random_forests_really_work",
    "section": "Conclusion",
    "text": "Conclusion\n\nhow should we think of simple models like OneR and decision tree and randomforest\nSo what can we take away from all this?\nI think the first thing I’d note from this is that, clearly, more complex models aren’t always better. Our “OneR” model, consisting of a single binary split, was nearly as good as our more complex models. Perhaps in practice a simple model like this might be much easier to use, and could be worth considering. Our random forest wasn’t an improvement on the single decision tree at all.\nSo we should always be careful to benchmark simple models, as see if they’re good enough for our needs. In practice, you will often find that simple models will have trouble providing adequate accuracy for more complex tasks, such as recommendation systems, NLP, computer vision, or multivariate time series. But there’s no need to guess – it’s so easy to try a few different models, there’s no reason not to give the simpler ones a go too!\nAnother thing I think we can take away is that random forests aren’t actually that complicated at all. We were able to implement the key features of them in a notebook quite quickly. And they aren’t sensitive to issues like normalization, interactions, or non-linear transformations, which make them extremely easy to work with, and hard to mess up!\nIf you found this notebook useful, please remember to click the little up-arrow at the top to upvote it, since I like to know when people have found my work useful, and it helps others find it too. (BTW, be sure you’re looking at my original notebook here when you do that, and are not on your own copy of it, otherwise your upvote won’t get counted!) And if you have any questions or comments, please pop them below – I read every comment I receive!"
  },
  {
    "objectID": "fastai_notebooks/fastai_is_it_a_bird.html",
    "href": "fastai_notebooks/fastai_is_it_a_bird.html",
    "title": "0001_fastai_Is it a bird? Creating a model from your own data",
    "section": "",
    "text": "Official course site: for lesson 1\nOfficial notebooks repo, on nbviewer\nOfficial Is it a bird notebook on kaggle\n\n\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload"
  },
  {
    "objectID": "fastai_notebooks/fastai_is_it_a_bird.html#how-to-use-autoreload",
    "href": "fastai_notebooks/fastai_is_it_a_bird.html#how-to-use-autoreload",
    "title": "0001_fastai_Is it a bird? Creating a model from your own data",
    "section": "How to use autoreload",
    "text": "How to use autoreload\nThis documentation has a helpful example.\nput these two lines in the top of this notebook\n%load_ext autoreload\n%autoreload 2\nso that, when I updated fastdebug library, I don’t need to rerun import fastdebug.utils .... and it should reload the library for me automatically."
  },
  {
    "objectID": "fastai_notebooks/fastai_is_it_a_bird.html#how-to-install-and-update-libraries",
    "href": "fastai_notebooks/fastai_is_it_a_bird.html#how-to-install-and-update-libraries",
    "title": "0001_fastai_Is it a bird? Creating a model from your own data",
    "section": "How to install and update libraries",
    "text": "How to install and update libraries\n\n!mamba update -q -y fastai\n\n\n!pip install -Uqq duckduckgo_search"
  },
  {
    "objectID": "fastai_notebooks/fastai_is_it_a_bird.html#know-a-little-about-the-libraries",
    "href": "fastai_notebooks/fastai_is_it_a_bird.html#know-a-little-about-the-libraries",
    "title": "0001_fastai_Is it a bird? Creating a model from your own data",
    "section": "Know a little about the libraries",
    "text": "Know a little about the libraries\n\nfrom fastdebug.utils import *\nfrom fastdebug.core import *\n\n\n\n\n\nwhat is fastai\n\nimport fastai\n\n\nwhichversion(\"fastai\")\n\nfastai: 2.7.9 \nfastai simplifies training fast and accurate neural nets using modern best practices    \nJeremy Howard, Sylvain Gugger, and contributors \nhttps://github.com/fastai/fastai/tree/master/     \npython_version: >=3.7     \n/Users/Natsume/mambaforge/lib/python3.9/site-packages/fastai\n\n\n\nwhatinside(fastai, lib=True)\n\nThe library has 24 modules\n['_modidx',\n '_nbdev',\n '_pytorch_doc',\n 'basics',\n 'callback',\n 'collab',\n 'data',\n 'distributed',\n 'fp16_utils',\n 'imports',\n 'interpret',\n 'layers',\n 'learner',\n 'losses',\n 'medical',\n 'metrics',\n 'optimizer',\n 'tabular',\n 'test_utils',\n 'text',\n 'torch_basics',\n 'torch_core',\n 'torch_imports',\n 'vision']\n\n\n\nimport fastai.losses as fl\n\n\nwhatinside(fl, dun=True)\n\nfastai.losses has: \n11 items in its __all__, and \n334 user defined functions, \n178 classes or class objects, \n4 builtin funcs and methods, and\n535 callables.\n\nBaseLoss:                           class, type    Same as `loss_cls`, but flattens input and target.\nCrossEntropyLossFlat:               class, type    Same as `nn.CrossEntropyLoss`, but flattens input and target.\nFocalLoss:                          class, PrePostInitMeta    Same as `nn.Module`, but no need for subclasses to call `super().__init__`\nFocalLossFlat:                      class, type    Same as CrossEntropyLossFlat but with focal paramter, `gamma`. Focal loss is introduced by Lin et al. \nhttps://arxiv.org/pdf/1708.02002.pdf. Note the class weighting factor in the paper, alpha, can be \nimplemented through pytorch `weight` argument passed through to F.cross_entropy.\nBCEWithLogitsLossFlat:              class, type    Same as `nn.BCEWithLogitsLoss`, but flattens input and target.\nBCELossFlat:                        function    Same as `nn.BCELoss`, but flattens input and target.\nMSELossFlat:                        function    Same as `nn.MSELoss`, but flattens input and target.\nL1LossFlat:                         function    Same as `nn.L1Loss`, but flattens input and target.\nLabelSmoothingCrossEntropy:         class, PrePostInitMeta    Same as `nn.Module`, but no need for subclasses to call `super().__init__`\nLabelSmoothingCrossEntropyFlat:     class, type    Same as `LabelSmoothingCrossEntropy`, but flattens input and target.\nDiceLoss:                           class, type    Dice loss for segmentation\n\n\n\n\nwhat is duckduckgo\n\nimport duckduckgo_search\n\n\nwhichversion(\"duckduckgo_search\")\n\nduckduckgo-search: 2.1.3 \nSearch for words, documents, images, news, maps and text translation using the DuckDuckGo.com search engine.    \ndeedy5 \nhttps://github.com/deedy5/duckduckgo_search     \npython_version: >=3.7     \n/Users/Natsume/mambaforge/lib/python3.9/site-packages/duckduckgo_search\n\n\n\nwhatinside(duckduckgo_search)\n\nduckduckgo_search has: \n0 items in its __all__, and \n6 user defined functions, \n0 classes or class objects, \n0 builtin funcs and methods, and\n6 callables.\n\n\n\n\nwhatinside(duckduckgo_search, func=True)\n\nduckduckgo_search has: \n0 items in its __all__, and \n6 user defined functions, \n0 classes or class objects, \n0 builtin funcs and methods, and\n6 callables.\n\nThe user defined functions are:\nddg:               function    (keywords, region='wt-wt', safesearch='Moderate', time=None, max_results=25, output=None)\nddg_images:        function    (keywords, region='wt-wt', safesearch='Moderate', time=None, size=None, color=None, type_image=None, layout=None, license_image=None, max_results=100, output=None, download=False)\nddg_maps:          function    (keywords, place=None, street=None, city=None, county=None, state=None, country=None, postalcode=None, latitude=None, longitude=None, radius=0, max_results=None, output=None)\nddg_news:          function    (keywords, region='wt-wt', safesearch='Moderate', time=None, max_results=25, output=None)\nddg_translate:     function    (keywords, from_=None, to='en', output=None)\nddg_videos:        function    (keywords, region='wt-wt', safesearch='Moderate', time=None, resolution=None, duration=None, license_videos=None, max_results=50, output=None)"
  },
  {
    "objectID": "fastai_notebooks/fastai_is_it_a_bird.html#how-to-use-fastdebug-with-fastai-notebooks",
    "href": "fastai_notebooks/fastai_is_it_a_bird.html#how-to-use-fastdebug-with-fastai-notebooks",
    "title": "0001_fastai_Is it a bird? Creating a model from your own data",
    "section": "How to use fastdebug with fastai notebooks",
    "text": "How to use fastdebug with fastai notebooks\n\nhow to use fastdebug\n\nfrom fastdebug.utils import *\nfrom fastdebug.core import *\nimport fastdebug.utils as fu\nimport fastdebug.core as core\n\n\nwhatinside(fu,dun=True)\n\nfastdebug.utils has: \n29 items in its __all__, and \n42 user defined functions, \n3 classes or class objects, \n0 builtin funcs and methods, and\n45 callables.\n\nexpand:NoneType\ntest_eq:           function    `test` that `a==b`\ntest_is:           function    `test` that `a is b`\nFunctionType:      class, type    Create a function object.\n\ncode\n  a code object\nglobals\n  the globals dictionary\nname\n  a string that overrides the name from the code object\nargdefs\n  a tuple that specifies the default argument values\nclosure\n  a tuple that supplies the bindings for free variables\nMethodType:        class, type    method(function, instance)\n\nCreate a bound instance method object.\nnb_url:            function    run this func to get nb_url of this current notebook\nnb_path:           function    run this func to get nb_path of this current notebook\nnb_name:           function    run this func to get nb_path of this current notebook\nipy2md:            function    convert the current notebook to md\nexpandcell:        function    expand cells of the current notebook to its full width\ninspect_class:     function    examine the details of a class\nismetaclass:       function    check whether a class is a metaclass or not\nisdecorator:       decorator, function    check whether a function is a decorator\nwhatinside:        function    Check what inside a module: `__all__`, functions, classes, builtins, and callables\nwhichversion:      function    Give you library version and other basic info.\nfastview:          function    to view the commented src code in color print and with examples\nfastsrcs:          function    to list all commented src files\ngetrootport:       function    get the local port and notebook dir\njn_link:           function    Get a link to the notebook at `path` on Jupyter Notebook\nget_all_nbs:       function    return paths for all nbs both in md and ipynb format into lists\nopenNB:            function    Get a link to the notebook at by searching keyword or notebook name\nhighlight:         function    highlight a string with yellow background\ndisplay_md:        function    Get a link to the notebook at `path` on Jupyter Notebook\ndisplay_block:     function    `line` is a section title, find all subsequent lines which belongs to the same section and display them together\nfastnbs:           function    check with fastlistnbs() to find interesting things to search fastnbs() can use keywords to search learning points (a section title and a section itself) from my documented fastai notebooks\nfastcodes:         function    using keywords to search learning points from commented sources files\nfastnotes:         function    using key words to search notes and display the found line and lines surround it\nfastlistnbs:       function    display all my commented notebooks subheadings in a long list. Best to work with fastnbs together.\nfastlistsrcs:      function    display all my commented src codes learning comments in a long list\n\n\n\nwhatinside(core, dun=True)\n\nfastdebug.core has: \n14 items in its __all__, and \n117 user defined functions, \n18 classes or class objects, \n1 builtin funcs and methods, and\n138 callables.\n\ndefaults:SimpleNamespace\npprint:                       function    Pretty-print a Python object to a stream [default is sys.stdout].\ninspect:module\ndbcolors:                     class, type    None\nrandomColor:                  function    create a random color by return a random dbcolor from dbcolors\ncolorize:                     function    return the string with dbcolors\nstrip_ansi:                   function    to make printright work using regex\nprintright:                   function    print a block of text to the right of the cell\nprintsrclinewithidx:          function    add idx number to a srcline\nprintsrc:                     function    print the seleted srcline with comment, idx and specified num of expanding srclines\ndbprintinsert:                function    insert arbitary code expressions into source code for evaluation\nFastdb:                       class, type    None\nrandomize_cmtparts_color:     function    give each comment a different color for easy viewing\nreliveonce:                   function    Replace current version of srcode with older version, and back to normal\n\n\n\ninspect_class(Fastdb)\n\n\nis Fastdb a metaclass: False\nis Fastdb created by a metaclass: False\nFastdb is created by <class 'type'>\nFastdb.__new__ is object.__new__: True\nFastdb.__new__ is type.__new__: False\nFastdb.__new__: <built-in method __new__ of type object>\nFastdb.__init__ is object.__init__: False\nFastdb.__init__ is type.__init__: False\nFastdb.__init__: <function Fastdb.__init__>\nFastdb.__call__ is object.__call__: False\nFastdb.__call__ is type.__call__: False\nFastdb.__call__: <method-wrapper '__call__' of type object>\nFastdb.__class__: <class 'type'>\nFastdb.__bases__: (<class 'object'>,)\nFastdb.__mro__: (<class 'fastdebug.core.Fastdb'>, <class 'object'>)\n\nFastdb's function members are:\n__init__: Create a Fastdebug class which has two functionalities: dbprint and print.\nautoprint: print srcode with appropriate number of lines automatically\ncreate_dbsrc_from_string: create dbsrc from a string\ncreate_dbsrc_string: create the dbsrc string\ncreate_explore_from_string: evaluate the explore dbsrc from string\ncreate_explore_str: create the explore dbsrc string\ncreate_snoop_from_string: evaluate the snoop dbsrc from string\ncreate_snoop_str: creat the snoop dbsrc string\ndebug: to quickly check for clues of errors\ndocsrc: create dbsrc the string and turn the string into actual dbsrc function, we have self.dbsrcstr and self.dbsrc available from now on.\nexplore: insert 'import ipdb; ipdb.set_trace()' above srcline of idx to create dbsrc, and exec on dbsrc\ngoback: Return src back to original state.\nprint: Print the source code in whole or parts with idx and comments you added with dbprint along the way.\nprintcmts1: print the entire srcode and save it to a file if save=True\nprintcmts2: print the srcodes in parts\nprinttitle: print title which includes src name, line number under investigation, example.\nreplaceWithDbsrc: to replace self.orisrc.__name__ with 'self.dbsrc' and assign this new self.eg to self.eg\nrun_example: run self.eg with self.dbsrc\nsnoop: run snoop on the func or class under investigation only when example is available\ntakeoutExample: get the line of example code with srcode name in it\n\nFastdb's method members are:\n{}\n\nFastdb's class members are:\n{'__class__': <class 'type'>}\n\nFastdb's namespace are:\nmappingproxy({'__dict__': <attribute '__dict__' of 'Fastdb' objects>,\n              '__doc__': None,\n              '__init__': <function Fastdb.__init__>,\n              '__module__': 'fastdebug.core',\n              '__weakref__': <attribute '__weakref__' of 'Fastdb' objects>,\n              'autoprint': <function Fastdb.autoprint>,\n              'create_dbsrc_from_string': <function Fastdb.create_dbsrc_from_string>,\n              'create_dbsrc_string': <function Fastdb.create_dbsrc_string>,\n              'create_explore_from_string': <function Fastdb.create_explore_from_string>,\n              'create_explore_str': <function Fastdb.create_explore_str>,\n              'create_snoop_from_string': <function Fastdb.create_snoop_from_string>,\n              'create_snoop_str': <function Fastdb.create_snoop_str>,\n              'debug': <function Fastdb.debug>,\n              'docsrc': <function Fastdb.docsrc>,\n              'explore': <function Fastdb.explore>,\n              'goback': <function Fastdb.goback>,\n              'print': <function Fastdb.print>,\n              'printcmts1': <function Fastdb.printcmts1>,\n              'printcmts2': <function Fastdb.printcmts2>,\n              'printtitle': <function Fastdb.printtitle>,\n              'replaceWithDbsrc': <function Fastdb.replaceWithDbsrc>,\n              'run_example': <function Fastdb.run_example>,\n              'snoop': <function Fastdb.snoop>,\n              'takeoutExample': <function Fastdb.takeoutExample>})\n\n\n\n\nDid I document it in a notebook before?\nrun push-code-new in teminal to convert all current notebooks into mds\nso that the followign search will get me the latest result if I did document similar things\n\nfastnbs(\"what is fastdebug\")\n\nI can also extract all the notebook subheadings with the function below\nand to check whether I have documented something similar by cmd + f and search keywords there\n\nfastlistnbs()\n\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0002_Saving_Model_fastai.md\n## what to import to handle vision problems in fastai\n## how to download and decompress datasets prepared by fastai\n## how to tell it is a cat by reading filename\n## how to create dataloaders with `from_name_func`\n## how to create a pretrained model with resnet18 and error_rate; how to fine tune it 3 epochs\n## how to export model to a pickle file and download it from Kaggle\n## how to convert ipynb to md\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0002_fastai_Saving_Model_fastai.md\n## what to import to handle vision problems in fastai\n## how to download and decompress datasets prepared by fastai\n## how to tell it is a cat by reading filename\n## how to create dataloaders with `from_name_func`\n## how to create a pretrained model with resnet18 and error_rate; how to fine tune it 3 epochs\n## how to export model to a pickle file and download it from Kaggle\n## how to convert ipynb to md\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0001_is_it_a_bird.md\n## Useful Course sites\n## How to use autoreload\n## How to install and update libraries\n## Know a little about the libraries\n### what is fastai\n### what is duckduckgo\n## How to use fastdebug with fastai notebooks\n### how to use fastdebug\n### Did I document it in a notebook before?\n### Did I document it in a src before?\n## how to search and get a url of an image; how to download with an url; how to view an image;\n### how to create folders using path; how to search and download images in folders; how to resize images \n## Train my model\n### How to find and unlink images not properly downloaded\n### How to create a DataLoaders with DataBlock; how to view data with it\n### How to build my model with dataloaders and pretrained model; how to train my model\n### How to predict with my model; how to avoid running cells in nbdev_prepare\n\n/Users/Natsume/Documents/fastdebug/mds/2022part1/0003_fastai_which_image_model_best.md\n## timm\n## how to git clone TIMM analysis data; how to enter a directory with %cd\n## how to read a csv file with pandas\n## how to merge data with pandas; how to create new column with pandas; how to string extract with regex expression; how to select columns up to a particular column with pandas; how to do loc in pandas; how to select a group of columns using str.contains and regex\n## Inference results\n### how to scatterplot with plotly.express; how to set the plot's width, height, size, title, x, y, log_x, color, hover_name, hover_data; \n### how to scatterplot on a subgroup of data using regex and plotly\n## Training results\n### convert ipynb to md\n\n/Users/Natsume/Documents/fastdebug/mds/lib/utils.md\n## setup for exporting to a module\n## how to get current notebook's name, path and url\n## how to convert ipynb to md automatically; how to run commands in python\n## Autoreload for every notebook\n## Expand cells\n## Import fastcore env\n## to inspect a class\n### get the docs for each function of a class\n## is it a metaclass?\n## is it a decorator\n### handle all kinds of exceptions for evaluating retn \n## whatinside a module of a library\n### show the type of objects inside `__all__`\n### working for fastdebug.core\n### to show Fastdb methods\n## whichversion of a library\n## fastview\n## fastscrs\n## getrootport\n## jn_link\n## get_all_nbs\n### get all nbs path for both md and ipynb\n### add index.ipynb\n## openNB\n## highlight\n## display_md\n## display_block\n### handle both file path and file content at the same time\n## fastnbs\n## fastcodes\n## fastnotes\n### multiple folders\n## fastlistnbs\n## fastlistsrcs\n## Best practice of fastdebug.core\n## Best practice of fastdebug.utils\n## Export\n\n/Users/Natsume/Documents/fastdebug/mds/lib/00_core.md\n## make life easier with defaults  \n## globals() and locals()\n## Execute strings\n### new variable or updated variable by exec will only be accessible from locals()\n### eval can override its own globals() and locals()\n### when exec update existing functions\n### when the func to be udpated involve other libraries\n### inside a function, exec() allow won't give you necessary env from function namespace\n### magic of `exec(b, globals().update(locals()))`\n### Bring variables from a func namespace to the sideout world\n### globals() in a cell vs globals() in a func\n## make a colorful string\n## align text to the most right\n## printsrcwithidx\n### print the entire source code with idx from 0\n### print the whole src with idx or print them in parts\n### use cmts from dbprint to print out src with comments\n### no more update for printsrcwithidx, for the latest see Fastdb.print\n## print out src code\n### basic version\n### print src with specific number of lines\n### make the naming more sensible\n### Allow a dbline occur more than once\n### adding idx to the selected srclines\n#### printsrclinewithidx\n### dblines can be string of code or idx number\n### avoid multi-occurrance of the same srcline\n## dbprint on expression\n### basic version\n### insert dbcode and make a new dbfunc\n### Bring outside namespace variables into exec()\n### Bring what inside the func namespace variables to the outside world\n### Adding g = locals() to dbprintinsert to avoid adding env individually\n### enable srclines to be either string or int \n### enable = to be used as assignment in codes\n### avoid adding \"env=g\" for dbprintinsert\n### collect cmt for later printsrcwithidx to print comments together\n### make sure only one line with correct idx is debugged\n### avoid typing \"\" when there is no codes\n### no more update for dbprint, for the latest see Fastdb.dbprint\n### use dbprint to override the original official code without changing its own pyfile\n## dbprintinsert\n### Run and display the inserted dbcodes \n### use locals() inside the dbsrc code to avoid adding env individually\n### enable dbprintinsert to do exec on a block of code\n## printrunsrclines() \n### Examples\n#### simple example\n#### complex example\n### insert a line after each srcline to add idx\n### add correct indentation to each inserted line\n#### count the indentation for each srcline\n### indentation special case: if, else, for, def\n### remove pure comments or docs from dbsrc\n### print out the srclines which get run\n### Make sure all if, else, for get printed\n### Put all together into the function printrunsrclines()\n#### no more renaming of foo\n#### add example as a param into the function\n#### improve on search for `if`, else, for, def to avoid errors for more examples\n#### remove an empty line with indentation\n### make it work\n### more difficult examples to test printrunsrc()\n## Make fastdebug a class\n### improve on the line idx readability\n### collect cmt from dbprint and print\n### make sure only the line with correct idx is debugged\n### having \"\" or \"   \" inside codes without causing error\n### replace Fastdb.printsrcwithdix with Fastdb.print\n### add idx to dbsrc when showdbsrc=True\n### not load the inner locals() to outenv can prevent mysterious printing of previous db messages\n### using @patch to enable docs for instance methods like `dbprint` and `print`\n### move param env into `__init__`\n### Add example to the obj\n### Take not only function but also class\n### To remove the necessity of self.takExample()\n### Try to remove g = locals()\n### Make sure `showdbsrc=True` give us the line starting with 'dbprintinsert'\n### Make sure `showdbsrc=True` give us info on changes in g or outenv\n### exit and print a warning message: idx has to be int\n### handle errors by codes with trailing spaces \n### showdbsrc=True, check whether Fastdb.dbprint and fdb.dbprint are same object using `is`\n### remove unnecessary db printout when showdbsrc=True and add printout to display sections\n### raise TypeError when decode are not integer and showdbsrc=true working on both method and function\n### when debugging dbprint, make sure dbsrc is printed with the same idx as original\n### update dbsrc to the global env\n### go back to normal before running dbprint again\n### auto print src with cmt and idx as the ending part of dbprint\n### to mark my explorations (expressions to evaluate) to stand out\n### Add the print of src with idx and comments at the end of dbsrc\n### embed example and autoprint to shorten the code to type\n### Make title for dbprint\n### Adding self.eg info and color group into dbprint and print\n#### todo: make the comments with same self.eg have the same color\n### make dbsrc print idx right\n### add self.eg to a dict with keys are idxsrc\n### handle both function and class as src\n### documenting on Fastdb.dbprint itself\n## mk_dbsrc\n## Turn mk_dbsrc into docsrc \n### handle when no codes are given\n## create_dbsrc_from_string\n## replaceWithDbsrc\n### handle class and metaclass\n### improve on handling function as decorator\n### Handling `inspect._signature_from_callable` to become `self.dbsrc`\n### handling usage of `@delegates`\n### handling `@delegates` with indentation before it\n### handling classes by inspect.isclass() rather than == type and add more class situations\n### handling `class _T(_TestA, metaclass=BypassNewMeta): `\n## run_example\n### `exec(self.eg, globals().update(self.egEnv), locals())` works better than `...update(locals()), self.egEnv)\n### no more env cells run before `fdb.eg` to make `fdb.run_example` work\n## Autoprint\n## Take an example and its env into Fastdb obj\n## print src with idx and cmt in whole or parts\n### print self.eg after each comment and colorize comments\n### color examples and cmts separately and make the func simpler\n### split each cmt and colorize parts randomly\n### printcmts1 while saving into a file\n## goback\n## Fastdb.explore\n### adding one breakpoint with comment\n### Adding multiple breakpoints by multiple set_trace()\n### Go back to normal before running explore again\n### enable fdb.takExample(\"whatinside(fu), ...) without using `fu.whatinside`\n### refactory explore\n## snoop\n### snoop on both function and class\n### snoop on class and method and all???\n### snoop\n### simplify adding @snoop for both normal function and decorator\n### handling classes\n### add watch\n## Snoop\n### add watch\n### use guide on Fastdb.dbprint\n## reliveonce\n## Fastdb.debug\n## Export\n## Send to Obsidian\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0001_fastcore_meta_delegates.md\n## Import\n## Initiate Fastdb and example in str\n## Example\n## docsrc\n## Snoop\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0003_Explore_document_FixSigMeta_PrePostInitMeta_AutoInit.md\n## Initialize fastdebug objects\n## class FixSigMeta(type) vs class Foo(type)\n## class Foo()\n## class PrePostInitMeta(FixSigMeta)\n## class Foo(metaclass=FixSigMeta)\n## class AutoInit(metaclass=PrePostInitMeta)\n## Prepare examples for FixSigMeta, PrePostInitMeta, AutoInit \n## Snoop them together in one go\n### embed the dbsrc of FixSigMeta into PrePostInitMeta\n### embed dbsrc of PrePostInitMeta into AutoInit\n## Explore and Document on them together \n\n/Users/Natsume/Documents/fastdebug/mds/demos/0004_fastcore.meta._rm_self.md\n## imports\n## set up\n## document\n## snoop\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0005_fastcore.meta.test_sig.md\n## imports\n## setups\n## documents\n## snoop\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0007_fastcore.meta.BypassNewMeta.md\n## Reading official docs\n## Inspecting class\n## Initiating with examples\n## Snoop\n## Document\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0002_signature_from_callable.md\n## Expand cell\n## Imports and initiate\n## Examples\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0008_use_kwargs_dict.md\n## Imports\n## Reading official docs\n## empty2none\n## `_mk_param`\n## use_kwargs_dict\n### Reading docs\n## use_kwargs\n### Reading docs\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0006_fastcore.meta.NewChkMeta.md\n## Import and Initalization\n## Official docs\n## Prepare Example\n## Inspect classes\n## Snoop\n## Document\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0000_tour.md\n### Documentation\n### Testing\n### Foundations\n### L\n### Transforms\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0012_fastcore_foundation_L.md\n## Document `L` with fastdebug\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0011_Fastdb.md\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0009_funcs_kwargs.md\n## fastcore.meta.method\n### Reading Docs\n### Running codes\n### Document\n### snoop\n## funcs_kwargs\n### Official docs\n### snoop: from _funcs_kwargs to funcs_kwargs\n### snoop only '_funcs_kwargs' by breaking up 'funcs_kwargs'\n\n/Users/Natsume/Documents/fastdebug/mds/demos/0010_fastcore_meta_summary.md\n## import\n## fastcore and fastcore.meta\n### What's inside fastcore.meta\n## Review individual funcs and classes\n### What is fastcore.meta all about? \n### What can these metaclasses do for me?\n#### FixSigMeta\n#### PrePostInitMeta\n#### AutoInit\n#### NewChkMeta\n#### BypassNewMeta\n### What can those decorators do for me?\n#### use_kwargs_dict\n#### use_kwargs\n#### delegates\n#### funcs_kwargs\n### The remaining functions\n## What is fastcore.meta all about\n\n/Users/Natsume/Documents/fastdebug/mds/questions/00_question_anno_dict.md\n## `anno_dict` docs\n## Dive in\n## `anno_dict` seems not add anything new to `__annotations__`\n## use fastdebug to double check\n## Does fastcore want anno_dict to include params with no annos?\n## Jeremy's response\n\n\n\n\nDid I document it in a src before?\n\nfastcodes(\"how to access parameters\")\n\nkeyword match is 1.0 , found a line: in _rm_self.py\n\n\n    sigd = dict(sig.parameters)===========================================================(1) # how to access parameters from a signature; how is parameters stored in sig; how to turn parameters into a dict;; \n\n\n\nthe entire source code in _rm_self.py\n\n\n\nclass Foo:\n    def __init__(self, a, b:int=1): pass\npprint(inspect.signature(Foo.__init__))\npprint(_rm_self(inspect.signature(Foo.__init__)))\n\ndef _rm_self(sig):========================================================================(0) # remove parameter self from a signature which has self;; \n    sigd = dict(sig.parameters)===========================================================(1) # how to access parameters from a signature; how is parameters stored in sig; how to turn parameters into a dict;; \n    sigd.pop('self')======================================================================(2) # how to remove the self parameter from the dict of sig;; \n    return sig.replace(parameters=sigd.values())==========================================(3) # how to update a sig using a updated dict of sig's parameters; \n                                                                                                                                                        (4)\n\n\n\nkeyword match is 1.0 , found a line: in delegates.py\n\n\n        sigd = dict(sig.parameters)=======================================================(12) # How to access parameters of a signature?; How to turn parameters into a dict?; \n\n\n\nthe entire source code in delegates.py\n\n\n\ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n\ndef delegates(to:FunctionType=None, # Delegatee===========================================(0) # how to make delegates(to) to have to as FunctionType and default as None; \n              keep=False, # Keep `kwargs` in decorated function?==========================(1)       \n              but:list=None): # Exclude these parameters from signature===================(2) # how to make delegates(to, but) to have 'but' as list and default as None; \n    \"Decorator: replace `**kwargs` in signature with params from `to`\"====================(3)       \n    if but is None: but = []==============================================================(4)       \n    def _f(f):============================================================================(5)       \n        if to is None: to_f,from_f = f.__base__.__init__,f.__init__=======================(6) # how to write 2 ifs and elses in 2 lines; \n        else:          to_f,from_f = to.__init__ if isinstance(to,type) else to,f=========(7) # how to assign a,b together with if and else; \n        from_f = getattr(from_f,'__func__',from_f)========================================(8) # Is classmethod callable; does classmethod has __func__; can we do inspect.signature(clsmethod); how to use getattr(obj, attr, default); \n        to_f = getattr(to_f,'__func__',to_f)==============================================(9)       \n        if hasattr(from_f,'__delwrap__'): return f========================================(10) # if B has __delwrap__, can we do delegates(A)(B) again?; hasattr(obj, '__delwrap__'); \n        sig = inspect.signature(from_f)===================================================(11) # how to get signature obj of B; what does a signature look like; what is the type; \n        sigd = dict(sig.parameters)=======================================================(12) # How to access parameters of a signature?; How to turn parameters into a dict?; \n        k = sigd.pop('kwargs')============================================================(13) # How to remove an item from a dict?; How to get the removed item from a dict?; How to add the removed item back to the dict?; when writing expressions, as they share environment, so they may affect the following code; \n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items() # How to access a signature's parameters as a dict?; How to replace the kind of a parameter with a different kind?; how to check whether a parameter has a default value?; How to check whether a string is in a dict and a list?; how dict.items() and dict.values() differ;  (14)\n              if v.default != inspect.Parameter.empty and k not in sigd and k not in but}=(15)      \n        anno = {k:v for k,v in getattr(to_f, \"__annotations__\", {}).items() if k not in sigd and k not in but} # How to get A's __annotations__?; How to access it as a dict?; How to select annotations of the right params with names?; How to put them into a dict?; How to do it all in a single line;  (16)\n        sigd.update(s2)===================================================================(17) # How to add the selected params from A's signature to B's signature; How to add items into a dict;; \n        if keep: sigd['kwargs'] = k=======================================================(18) # How to add a new item into a dict;; \n        else: from_f.__delwrap__ = to_f===================================================(19) # How to create a new attr for a function or obj;; \n        from_f.__signature__ = sig.replace(parameters=sigd.values())======================(20) # How to update a signature with a new set of parameters;; \n        if hasattr(from_f, '__annotations__'): from_f.__annotations__.update(anno)========(21) # How to check whether a func has __annotations__; How add selected params' annotations from A to B's annotations;; \n        return f==========================================================================(22)      \n    return _f=============================================================================(23)      \n                                                                                                                                                        (24)\n\n\n\nkeyword match is 1.0 , found a line: in delegates.py\n\n\n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items() # How to access a signature's parameters as a dict?; How to replace the kind of a parameter with a different kind?; how to check whether a parameter has a default value?; How to check whether a string is in a dict and a list?; how dict.items() and dict.values() differ;  (14)\n\n\n\nthe entire source code in delegates.py\n\n\n\ndef low(a, b:int=1): pass\n@delegates(low)\ndef mid(c, d:list=None, **kwargs): pass\npprint(inspect.signature(mid)) # pprint and inspect is loaded from fastdebug\n\ndef delegates(to:FunctionType=None, # Delegatee===========================================(0) # how to make delegates(to) to have to as FunctionType and default as None; \n              keep=False, # Keep `kwargs` in decorated function?==========================(1)       \n              but:list=None): # Exclude these parameters from signature===================(2) # how to make delegates(to, but) to have 'but' as list and default as None; \n    \"Decorator: replace `**kwargs` in signature with params from `to`\"====================(3)       \n    if but is None: but = []==============================================================(4)       \n    def _f(f):============================================================================(5)       \n        if to is None: to_f,from_f = f.__base__.__init__,f.__init__=======================(6) # how to write 2 ifs and elses in 2 lines; \n        else:          to_f,from_f = to.__init__ if isinstance(to,type) else to,f=========(7) # how to assign a,b together with if and else; \n        from_f = getattr(from_f,'__func__',from_f)========================================(8) # Is classmethod callable; does classmethod has __func__; can we do inspect.signature(clsmethod); how to use getattr(obj, attr, default); \n        to_f = getattr(to_f,'__func__',to_f)==============================================(9)       \n        if hasattr(from_f,'__delwrap__'): return f========================================(10) # if B has __delwrap__, can we do delegates(A)(B) again?; hasattr(obj, '__delwrap__'); \n        sig = inspect.signature(from_f)===================================================(11) # how to get signature obj of B; what does a signature look like; what is the type; \n        sigd = dict(sig.parameters)=======================================================(12) # How to access parameters of a signature?; How to turn parameters into a dict?; \n        k = sigd.pop('kwargs')============================================================(13) # How to remove an item from a dict?; How to get the removed item from a dict?; How to add the removed item back to the dict?; when writing expressions, as they share environment, so they may affect the following code; \n        s2 = {k:v.replace(kind=inspect.Parameter.KEYWORD_ONLY) for k,v in inspect.signature(to_f).parameters.items() # How to access a signature's parameters as a dict?; How to replace the kind of a parameter with a different kind?; how to check whether a parameter has a default value?; How to check whether a string is in a dict and a list?; how dict.items() and dict.values() differ;  (14)\n              if v.default != inspect.Parameter.empty and k not in sigd and k not in but}=(15)      \n        anno = {k:v for k,v in getattr(to_f, \"__annotations__\", {}).items() if k not in sigd and k not in but} # How to get A's __annotations__?; How to access it as a dict?; How to select annotations of the right params with names?; How to put them into a dict?; How to do it all in a single line;  (16)\n        sigd.update(s2)===================================================================(17) # How to add the selected params from A's signature to B's signature; How to add items into a dict;; \n        if keep: sigd['kwargs'] = k=======================================================(18) # How to add a new item into a dict;; \n        else: from_f.__delwrap__ = to_f===================================================(19) # How to create a new attr for a function or obj;; \n        from_f.__signature__ = sig.replace(parameters=sigd.values())======================(20) # How to update a signature with a new set of parameters;; \n        if hasattr(from_f, '__annotations__'): from_f.__annotations__.update(anno)========(21) # How to check whether a func has __annotations__; How add selected params' annotations from A to B's annotations;; \n        return f==========================================================================(22)      \n    return _f=============================================================================(23)      \n                                                                                                                                                        (24)\n\n\n\nI can check all the commented src files.\n\nfastsrcs()\n\ntest_sig.py\nBypassNewMeta.py\nsnoop.py\nFixSigMeta.py\nfastnbs.py\nfuncs_kwargs.py\nNewChkMeta.py\nprinttitle.py\nAutoInit.py\nmethod.py\n_rm_self.py\ndelegates.py\ncreate_explore_str.py\nPrePostInitMeta.py\n_funcs_kwargs.py\nwhatinside.py\n\n\nI can print out all the learning points as comments inside each src file\nHowever, I need to figure out a way to extract them nicely from the files\nTodos: how to comment src for list extraction\n\nfastlistsrcs()\n\n test_sig(f:FunctionType or ClassType, b:str); test_sig will get f's signature as a string; b is a signature in string provided by the user; in fact, test_sig is to compare two strings; \n test_sig is to test two strings with test_eq; how to turn a signature into a string;; \n since t2 just references t these will be the same\n likewise, chaning an attribute on t will also affect t2 because they both point to the same object.\n both t and t2's __class__ is _T\n BypassNewMeta allows its instance class e.g., _T to choose a specific class e.g., _TestB and change `__class__` of an object e.g., t of _TestB to _T without creating a new object; \n If the instance class like _T has attr '_new_meta', then run it with param x;; \n when x is not an instance of _T's _bypass_type; or when a positional param is given; or when a keyword arg is given; let's run _T's super's __call__ function with x as param; and assign the result to x;  (4)\n If x.__class__ is not cls or _T, then make it so; \n learn about /tmp folder https://www.fosslinux.com/41739/linux-tmp-directory-everything-you-need-to-know.htm                                       (1)\n             exec(dbsrc, locals(), self.egEnv)                ===========================(6)       \n     exec(code, globals().update(self.outenv), locals())  when dbsrc is a method, it will update as part of a class                                               (8)\n store dbsrc func inside Fastdb obj==================================================(9)       \n using __new__ of  FixSigMeta instead of type\n Base\n Any class having FixSigMeta as metaclass will have its own __init__ func stored in its attr __signature__;FixSigMeta uses its __new__ to create a class instance; then check whether its class instance has its own __init__;if so, remove self from the sig of __init__; then assign this new sig to __signature__ for the class instance;; \n how does a metaclass create a class instance; what does super().__new__() do here;; \n how to remove self from a signature; how to check whether a class' __init__ is inherited from object or not;;  (4)\n allows you to add method b upon instantiation\n don't forget to include **kwargs in __init__\n the attempt to add a is ignored and uses the original method instead.\n access the num attribute from the instance\n adds method b\n self.num + 5 = 10\nmultiply instead of add \n add method b from the super class\n 3 * 5 = 15\n how funcs_kwargs works; it is a wrapper around _funcs_kwargs; it offers two ways of running _funcs_kwargs; the first, default way, is to add a func to a class without using self; second way is to add func to class enabling self use;; \n how to check whether an object is callable; how to return a result of running a func; ; \n how to custom the params of `_funcs_kwargs` for a particular use with partial; \n if `o` is not an object without an attribute `foo`, set foo = 1\n 1 was not of type _T, so foo = 1\n t2 will now reference t\n t and t2 are the same object\n this will also change t.foo to 5 because it is the same object\n without any arguments the constructor will return a reference to the same object\n NewChkMeta is a metaclass inherited from FixSigMea; it makes its own __call__; when its class instance, e.g., _T, create object instances (e.g, t) without args nor kwargs but only x, and x is an object of the instance class, then return x; otherwise, create and return a new object created by the instance class's super class' __call__ method with x as param; In other words, t = _T(3) will create a new obj; _T(t) will return t; _T(t, 1) or _T(t, b=1) will also return a new obj; \n how to create a __call__ method with param cls, x, *args, **kwargs;; \n how to express no args and no kwargs and x is an instance of cls?; \n how to call __call__ of super class with x and consider all possible situations of args and kwargs; \n make sure self.orieg has no self inside===================(4)       \n how to use :=<, :=>, :=^ with format to align text to left, right, and middle;  (5)\n h=10 is initialized in the parent class\n AutoInit inherit __new__ and __init__ from object to create and initialize object instances; AutoInit uses PrePostInitMeta.__new__ or in fact FixSigMeta.__new__ to create its own class instance, which can have __signature__; AutoInit uses PrePostInitMeta.__call__ to specify how its object instance to be created and initialized (with pre_init, init, post_init)); AutoInit as a normal or non-metaclass, it writes its own __pre_init__ method; \n how to run superclass' __init__ function; \n how to test on the type of function or method\n `1` is a dummy instance since Py3 doesn't allow `None` any more=====================(2)       \n remove parameter self from a signature which has self;; \n how to access parameters from a signature; how is parameters stored in sig; how to turn parameters into a dict;; \n how to remove the self parameter from the dict of sig;; \n how to update a sig using a updated dict of sig's parameters; \n pprint and inspect is loaded from fastdebug\n Delegatee===========================================(0)  Keep `kwargs` in decorated function?==========================(1)       \n Exclude these parameters from signature===================(2)  how to write 2 ifs and elses in 2 lines; \n how to assign a,b together with if and else; \n Is classmethod callable; does classmethod has __func__; can we do inspect.signature(clsmethod); how to use getattr(obj, attr, default); \n if B has __delwrap__, can we do delegates(A)(B) again?; hasattr(obj, '__delwrap__'); \n how to get signature obj of B; what does a signature look like; what is the type; \n How to access parameters of a signature?; How to turn parameters into a dict?; \n How to remove an item from a dict?; How to get the removed item from a dict?; How to add the removed item back to the dict?; when writing expressions, as they share environment, so they may affect the following code; \n How to access a signature's parameters as a dict?; How to replace the kind of a parameter with a different kind?; how to check whether a parameter has a default value?; How to check whether a string is in a dict and a list?; how dict.items() and dict.values() differ;  (14)\n How to get A's __annotations__?; How to access it as a dict?; How to select annotations of the right params with names?; How to put them into a dict?; How to do it all in a single line;  (16)\n How to add the selected params from A's signature to B's signature; How to add items into a dict;; \n How to add a new item into a dict;; \n How to create a new attr for a function or obj;; \n How to update a signature with a new set of parameters;; \n How to check whether a func has __annotations__; How add selected params' annotations from A to B's annotations;; \n set with __pre_init__\n set with __init__\n set with __post_init__\n PrePostInitMeta inherit __new__ and __init__ from FixSigMeta as a metaclass (a different type); not from type, nor from object; PrePostInitMeta is itself a metaclass, which is used to create class instance not object instance; PrePostInitMeta writes its own __call__ which regulates how its class instance create and initialize object instance; \n how to create an object instance with a cls; how to check the type of an object is cls; how to run a function without knowing its params;; \n how to run __init__ without knowing its params; \n allows you to add method b upon instantiation\n don't forget to include **kwargs in __init__\n the attempt to add a is ignored and uses the original method instead.\n how does _funcs_kwargs work: _funcs_kwargs is a decorator; it helps class e.g., T to add more methods; I need to give the method a name, and put the name e.g., 'b' inside a list called _methods=['b'] inside class T; then after writing a func e.g., _new_func, I can add it by T(b = _new_func); if I want the func added to class to use self, I shall write @funcs_kwargs(as_method=True); \n how to define a method which can use self and accept any parameters; \n how to pop out the value of an item in a dict (with None as default), and if the item name is not found, pop out None instead; ; \n how to turn a func into a method; \n how to give a method a different instance, like self; \n how to add a method to a class as an attribute; \n how to wrap `_init` around `old_init`, so that `_init` can use `old_init` inside itself; \n how to add a list of names with None as default value to function `_init` to repalce its kwargs param; \n how to make a class.`__init__` signature to be the signature of the class using `__signature__` and `_rm_self`;  (12)\n module, e.g., `import fastcore.all as fa`, use `fa` here=============(0)       \n print all items in __all__===============================(1)       \n print all user defined functions========================(2)       \n print all class objects=================================(3)       \n print all builtin funcs or methods=====================(4)       \n print all the modules of the library it belongs to=======(5)       \n print all callables=======================================(6)       \n how many items inside mo.__all__?; \n get all funcs of a module; \n get all classes from the module; \n get the file path of the module; \n get names of all modules of a lib; \n             print(f\"{i[0]}: {kind}\")  ==================================================(44)      \n             print(f\"{i[0]}: {kind}\")  ==================================================(56)"
  },
  {
    "objectID": "fastai_notebooks/fastai_is_it_a_bird.html#how-to-search-and-get-a-url-of-an-image-how-to-download-with-an-url-how-to-view-an-image",
    "href": "fastai_notebooks/fastai_is_it_a_bird.html#how-to-search-and-get-a-url-of-an-image-how-to-download-with-an-url-how-to-view-an-image",
    "title": "0001_fastai_Is it a bird? Creating a model from your own data",
    "section": "how to search and get a url of an image; how to download with an url; how to view an image;",
    "text": "how to search and get a url of an image; how to download with an url; how to view an image;\n\nfrom duckduckgo_search import ddg_images\nfrom fastcore.all import *\n\n\ndef search_images(term, max_images=30):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\n\n#NB: `search_images` depends on duckduckgo.com, which doesn't always return correct responses.\n#    If you get a JSON error, just try running it again (it may take a couple of tries).\nurls = search_images('bird photos', max_images=1)\nurls[0]\n\nSearching for 'bird photos'\n\n\n'https://amazinganimalphotos.com/wp-content/uploads/2016/11/beautiful-birds.jpeg'\n\n\n\nfrom fastdownload import download_url\ndest = 'bird.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nfrom fastai.vision.all import *\nim = Image.open(dest)\nim.to_thumb(256,256)\n\n\n\n\n\ndownload_url(search_images('forest photos', max_images=1)[0], 'forest.jpg', show_progress=False)\nImage.open('forest.jpg').to_thumb(256,256)\n\nSearching for 'forest photos'\n\n\n\n\n\n\nhow to create folders using path; how to search and download images in folders; how to resize images\nOur searches seem to be giving reasonable results, so let’s grab 200 examples of each of “bird” and “forest” photos, and save each group of photos to a different folder:\n\nsearches = 'forest','bird'\npath = Path('bird_or_not')\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)"
  },
  {
    "objectID": "fastai_notebooks/fastai_is_it_a_bird.html#train-my-model",
    "href": "fastai_notebooks/fastai_is_it_a_bird.html#train-my-model",
    "title": "0001_fastai_Is it a bird? Creating a model from your own data",
    "section": "Train my model",
    "text": "Train my model\n\nHow to find and unlink images not properly downloaded\nSome photos might not download correctly which could cause our model training to fail, so we’ll remove them:\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n\n\nHow to create a DataLoaders with DataBlock; how to view data with it\nTo train a model, we’ll need DataLoaders:\n\na training set (the images used to create a model) and\na validation set (the images used to check the accuracy of a model – not used during training).\n\nWe can view sample images from it:\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path)\n\ndls.show_batch(max_n=6)\n\n\n\nHow to build my model with dataloaders and pretrained model; how to train my model\nNow we’re ready to train our model. The fastest widely used computer vision model is resnet18. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 10 seconds…)\nfastai comes with a helpful fine_tune() method which automatically uses best practices for fine tuning a pre-trained model, so we’ll use that.\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\nHow to predict with my model; how to avoid running cells in nbdev_prepare\n\nis_bird,_,probs = learn.predict(PILImage.create('bird.jpg'))\nprint(f\"This is a: {is_bird}.\")\nprint(f\"Probability it's a bird: {probs[0]:.4f}\")\n\n\nipy2md()\n\n[jupytext] Reading /Users/Natsume/Documents/fastdebug/nbs/2022part1/0001_fastai_is_it_a_bird.ipynb in format ipynb\n[jupytext] Writing /Users/Natsume/Documents/fastdebug/nbs/2022part1/0001_fastai_is_it_a_bird.md\ncp to : /Users/Natsume/Documents/divefastai/Debuggable/jupytext\nmove to : /Users/Natsume/Documents/fastdebug/mds/2022part1/\n\n\n[NbConvertApp] Converting notebook /Users/Natsume/Documents/fastdebug/nbs/2022part1/0001_fastai_is_it_a_bird.ipynb to markdown\n\n\nmove to : /Users/Natsume/Documents/fastdebug/mds_output\n\n\n[NbConvertApp] Support files will be in 0001_fastai_is_it_a_bird_files/\n[NbConvertApp] Making directory /Users/Natsume/Documents/fastdebug/nbs/2022part1/0001_fastai_is_it_a_bird_files\n[NbConvertApp] Making directory /Users/Natsume/Documents/fastdebug/nbs/2022part1/0001_fastai_is_it_a_bird_files\n[NbConvertApp] Writing 57758 bytes to /Users/Natsume/Documents/fastdebug/nbs/2022part1/0001_fastai_is_it_a_bird.md"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptfully_connected.html",
    "href": "fastai_notebooks/fastai_ptfully_connected.html",
    "title": "0021_fastai_pt2_2019_fully_connected",
    "section": "",
    "text": "Jump_to lesson 8 video\n\n#export\nfrom exp.nb_01 import *\n\ndef get_data():\n    path = datasets.download_data(MNIST_URL, ext='.gz')\n    with gzip.open(path, 'rb') as f:\n        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n    return map(tensor, (x_train,y_train,x_valid,y_valid))\n\n\nx_train,y_train,x_valid,y_valid = get_data()\n\n\n\n\n\n\n\n\ndef normalize(x, m, s): return (x-m)/s\n\n\ntrain_mean,train_std = x_train.mean(),x_train.std()\ntrain_mean,train_std\n\n\nx_train = normalize(x_train, train_mean, train_std)\n# NB: Use training, not validation mean for validation set\nx_valid = normalize(x_valid, train_mean, train_std)\n\n\n\n\n\n\n\n\ntrain_mean,train_std = x_train.mean(),x_train.std()\ntrain_mean,train_std\n\n\n#export\ndef test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\"\n\n\ntest_near_zero(x_train.mean())\ntest_near_zero(1-x_train.std())\n\n\n\n\n\n\n\n\nn,m = x_train.shape\nc = y_train.max()+1\nn,m,c"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptfully_connected.html#foundations-version",
    "href": "fastai_notebooks/fastai_ptfully_connected.html#foundations-version",
    "title": "0021_fastai_pt2_2019_fully_connected",
    "section": "Foundations version",
    "text": "Foundations version"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptfully_connected.html#basic-architecture",
    "href": "fastai_notebooks/fastai_ptfully_connected.html#basic-architecture",
    "title": "0021_fastai_pt2_2019_fully_connected",
    "section": "Basic architecture",
    "text": "Basic architecture\n\ninitialize weights/biases using Xavier init to ensure the first layer’s activation with mean 0 and std 1\n\n1:25:36 - Let’s create a simplest neuralnet with one hidden layer and a single output layer using mean absolute error for the single output rather than cross-entropy for 10 output;\nJump_to lesson 8 video\n\n\n1:26:15 - how to use the matricies with random number for creating the weights and biases between input layer and the hidden layer, and the weights and biases between the hidden layer and the output layer; 1:26:46 - with only randomly initialized weights and biases, the activations of the hidden layer will have terrible mean and std 1:27:36 - the simplifed version of Xavier init for initializing weights can ensure the activation to have mean 0 and std 1; and use test_near_zero to test whether the activation mean is near 0 and std is near 1; 1:29:04 - how important is the initialization of weights and biases to make training work; there are even researches to prove with carful initialization of weights without normalization of activations or inputs can make training work for a model with even 10000 layers; and even one-cycle training and super convergence are turned out to be all about initializations\ninput shape [n, m] xx (weights [m, nh] + biases[nh]) => hidden layer (activations or neurons) [nh] hidden layer (activation layer) shape [hn] xx (weights [hn, 1] + biases [1] => output layer (neuron) [1]\n\n# num hidden (neurons)\nnh = 50\n\nTinker practice\n\n\nusing standared xavier init to initialize weights and biases\n\n# standard xavier init\nw1 = torch.randn(m,nh)/math.sqrt(m)\nb1 = torch.zeros(nh)\nw2 = torch.randn(nh,1)/math.sqrt(nh)\nb2 = torch.zeros(1)\n\n\ntest_near_zero(w1.mean())\ntest_near_zero(w1.std()-1/math.sqrt(m))\n\n\n\nx_valid has alread by normalized to have mean 0 and std 1\n\n# This should be ~ (0,1) (mean,std)...\nx_valid.mean(),x_valid.std()\n\n\n\nwrite linear layer from scratch\n\ndef lin(x, w, b): return x@w + b\n\n\n\ncheck mean and std of activations of first layer\n\nt = lin(x_valid, w1, b1)\n\n\n#...so should this, because we used xavier init, which is designed to do this\nt.mean(),t.std()\n\n\n\n\nwriting a linear layer with relu from scratch\n\n1:30:09 - what is the first layer look like; how should we write relu function to maximize the speed x.clamp_min(0.); how should we write functions in pytorch to maximize the speed in general;\n\ndef relu(x): return x.clamp_min(0.)\n\n\nt = relu(lin(x_valid, w1, b1))\n\n\n\n\n1:30:50 - but relu does not return the activation with mean 0 and std 1, (actually halved the std, and the gradients for updating weights will be gone when more layers or more ReLUs applied) and Jeremy explained why it is so\n\n#...actually it really should be this!\nt.mean(),t.std()\n\n\n\n1:31:47 - Jeremy introduced and lead us reading Delving Deep into Rectifiers by He; why we should read papers from competition winners than other papers; 1:32:43 - Jeremy explained Rectifiers in the paper and why random weights/biases won’t get trained well using He’s paper and Xavier’s paper (Xavier’s initialization didn’t account for the impact of ReLU, this is where He’s paper come in); the homework is to read this section (2.2) of the He’s paper.\nFrom pytorch docs: a: the negative slope of the rectifier used after this layer (0 for ReLU by default)\n\\[\\text{std} = \\sqrt{\\frac{2}{(1 + a^2) \\times \\text{fan_in}}}\\]\nThis was introduced in the paper that described the Imagenet-winning approach from He et al: Delving Deep into Rectifiers, which was also the first paper that claimed “super-human performance” on Imagenet (and, most importantly, it introduced resnets!)\nJump_to lesson 8 video\n\n# kaiming init / he init for relu\nw1 = torch.randn(m,nh)*math.sqrt(2/m)\n\n\nw1.mean(),w1.std()\n\n\nt = relu(lin(x_valid, w1, b1))\nt.mean(),t.std()\n\n\n\n1:36:26 - Jeremy provided a guidance to us on how to read the Resnet paper\n\n\n1:39:44 - how to use pytorch function torch.nn.init.kaiming_normal_ to do He init and how to dig into pytorch source code to figure out how to use those functions correctly like why fan_out in init.kaiming_normal_(w1, mode='fan_out')\n\n#export\nfrom torch.nn import init\n\n\nw1 = torch.zeros(m,nh)\ninit.kaiming_normal_(w1, mode='fan_out')\nt = relu(lin(x_valid, w1, b1))\n\n\ninit.kaiming_normal_??\n\n\nw1.mean(),w1.std()\n\n\nt.mean(),t.std()\n\n\nw1.shape\n\n\nimport torch.nn\n\n\ntorch.nn.Linear(m,nh).weight.shape\n\n\ntorch.nn.Linear.forward??\n\n\ntorch.nn.functional.linear??\n\n\n\n1:42:56 - how to find and read source code of convolutional layer in pytorch and why it is a good idea to put the url of the paper you are implementing in the source code\n\ntorch.nn.Conv2d??\n\n\ntorch.nn.modules.conv._ConvNd.reset_parameters??\n\n\n\n1:38:55 - Jeremy noticed a problem of the He initialization on the value of mean and explained why so; then he tried to a simple but natural method to bring the mean to 0 and the result seems very good and ended here at 1:39:44 1:44:35 - how much better does Jeremy’s tweaked ReLU work for getting activation mean to 0 and std to 0.8 rather than previously 0.7\n\n# what if...?\ndef relu(x): return x.clamp_min(0.) - 0.5\n\n\n# kaiming init / he init for relu\nw1 = torch.randn(m,nh)*math.sqrt(2./m )\nt1 = relu(lin(x_valid, w1, b1))\nt1.mean(),t1.std()\n\n\n\n1:45:28 - how to build our model model using the functions lin, relu we built above; how to test how fast it is to run; and how to verify the shape of the model output to be correct\n\ndef model(xb):\n    l1 = lin(xb, w1, b1)\n    l2 = relu(l1)\n    l3 = lin(l2, w2, b2)\n    return l3\n\n\nassert model(x_valid).shape==torch.Size([x_valid.shape[0],1])"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptfully_connected.html#loss-function-mse",
    "href": "fastai_notebooks/fastai_ptfully_connected.html#loss-function-mse",
    "title": "0021_fastai_pt2_2019_fully_connected",
    "section": "Loss function: MSE",
    "text": "Loss function: MSE\n\n1:46:15 - how to write mean squared error as our loss function (we never use it but only use mse as a starting point for our loss); how to squeeze a tensor with shape [n, 1] to just shape [n] using output.squeeze(-1)\nJump_to lesson 8 video\n\nmodel(x_valid).shape\n\nWe need squeeze() to get rid of that trailing (,1), in order to use mse. (Of course, mse is not a suitable loss function for multi-class classification; we’ll use a better loss function soon. We’ll use mse for now to keep things simple.)\n\n#export\ndef mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()\n\n\ny_train,y_valid = y_train.float(),y_valid.float()\n\n\npreds = model(x_train)\n\n\npreds.shape\n\n\nmse(preds, y_train)"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptfully_connected.html#gradients-and-backward-pass",
    "href": "fastai_notebooks/fastai_ptfully_connected.html#gradients-and-backward-pass",
    "title": "0021_fastai_pt2_2019_fully_connected",
    "section": "Gradients and backward pass",
    "text": "Gradients and backward pass\n\n1:48:00 - Jeremy has given us all the matrix calculus we need for deep learning for total beginners; 1:49:12 - how to understand and do the chain rule in terms of getting gradients with respect to params of our model and how to understand derivative in plain language; 1:52:56 - how to calculuate the derivate or gradient with respect to the output of previous layer or funcs ( mse, lin, relu )\nJump_to lesson 8 video\n\ndef mse_grad(inp, targ): \n    # grad of loss with respect to output of previous layer\n    inp.g = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]\n\n\ndef relu_grad(inp, out):\n    # grad of relu with respect to input activations\n    inp.g = (inp>0).float() * out.g\n\n\ndef lin_grad(inp, out, w, b):\n    # grad of matmul with respect to input\n    inp.g = out.g @ w.t()\n    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n    b.g = out.g.sum(0)\n\n\n\n1:55:22 - how to put forward pass and backward pass into one function foward_and_backward; and backward pass is the chain rule (people who say No are liars) and saving the gradients as well;\n\ndef forward_and_backward(inp, targ):\n    # forward pass:\n    l1 = inp @ w1 + b1\n    l2 = relu(l1)\n    out = l2 @ w2 + b2\n    # we don't actually need the loss in backward!\n    loss = mse(out, targ)\n    \n    # backward pass:\n    mse_grad(out, targ)\n    lin_grad(l2, out, w2, b2)\n    relu_grad(l1, l2)\n    lin_grad(inp, l1, w1, b1)\n\n\nforward_and_backward(x_train, y_train)\n\n\n\n1:56:41 - how to use pytorch’s gradient calculation functions to test whether our own gradients are calculated correctly;\n\n# Save for testing against later\nw1g = w1.g.clone()\nw2g = w2.g.clone()\nb1g = b1.g.clone()\nb2g = b2.g.clone()\nig  = x_train.g.clone()\n\nWe cheat a little bit and use PyTorch autograd to check our results.\n\nxt2 = x_train.clone().requires_grad_(True)\nw12 = w1.clone().requires_grad_(True)\nw22 = w2.clone().requires_grad_(True)\nb12 = b1.clone().requires_grad_(True)\nb22 = b2.clone().requires_grad_(True)\n\n\ndef forward(inp, targ):\n    # forward pass:\n    l1 = inp @ w12 + b12\n    l2 = relu(l1)\n    out = l2 @ w22 + b22\n    # we don't actually need the loss in backward!\n    return mse(out, targ)\n\n\nloss = forward(xt2, y_train)\n\n\nloss.backward()\n\n\ntest_near(w22.grad, w2g)\ntest_near(b22.grad, b2g)\ntest_near(w12.grad, w1g)\ntest_near(b12.grad, b1g)\ntest_near(xt2.grad, ig )"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptfully_connected.html#refactor-model",
    "href": "fastai_notebooks/fastai_ptfully_connected.html#refactor-model",
    "title": "0021_fastai_pt2_2019_fully_connected",
    "section": "Refactor model",
    "text": "Refactor model"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptfully_connected.html#layers-as-classes",
    "href": "fastai_notebooks/fastai_ptfully_connected.html#layers-as-classes",
    "title": "0021_fastai_pt2_2019_fully_connected",
    "section": "Layers as classes",
    "text": "Layers as classes\n\n1:58:16 - how to refactor the previous funcs into classes; After Jeremy has done the refactory work, it becomes almost identical to pytorch api\nJump_to lesson 8 video\n\nclass Relu():\n    def __call__(self, inp):\n        self.inp = inp\n        self.out = inp.clamp_min(0.)-0.5\n        return self.out\n    \n    def backward(self): self.inp.g = (self.inp>0).float() * self.out.g\n\n\nclass Lin():\n    def __init__(self, w, b): self.w,self.b = w,b\n        \n    def __call__(self, inp):\n        self.inp = inp\n        self.out = inp@self.w + self.b\n        return self.out\n    \n    def backward(self):\n        self.inp.g = self.out.g @ self.w.t()\n        # Creating a giant outer product, just to sum it, is inefficient!\n        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n        self.b.g = self.out.g.sum(0)\n\n\nclass Mse():\n    def __call__(self, inp, targ):\n        self.inp = inp\n        self.targ = targ\n        self.out = (inp.squeeze() - targ).pow(2).mean()\n        return self.out\n    \n    def backward(self):\n        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]\n\n\nclass Model():\n    def __init__(self, w1, b1, w2, b2):\n        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n        self.loss = Mse()\n        \n    def __call__(self, x, targ):\n        for l in self.layers: x = l(x)\n        return self.loss(x, targ)\n    \n    def backward(self):\n        self.loss.backward()\n        for l in reversed(self.layers): l.backward()\n\n\nw1.g,b1.g,w2.g,b2.g = [None]*4\nmodel = Model(w1, b1, w2, b2)\n\n\ntest_near(w2g, w2.g)\ntest_near(b2g, b2.g)\ntest_near(w1g, w1.g)\ntest_near(b1g, b1.g)\ntest_near(ig, x_train.g)"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptfully_connected.html#module.forward",
    "href": "fastai_notebooks/fastai_ptfully_connected.html#module.forward",
    "title": "0021_fastai_pt2_2019_fully_connected",
    "section": "Module.forward()",
    "text": "Module.forward()\n\n2:02:36 - how to remove duplicated codes by adding another class Module and using einsum, and as a result, our refactor codes become identical to pytorch api; this step truly help make sense pytorch api\n\nclass Module():\n    def __call__(self, *args):\n        self.args = args\n        self.out = self.forward(*args)\n        return self.out\n    \n    def forward(self): raise Exception('not implemented')\n    def backward(self): self.bwd(self.out, *self.args)\n\n\nclass Relu(Module):\n    def forward(self, inp): return inp.clamp_min(0.)-0.5\n    def bwd(self, out, inp): inp.g = (inp>0).float() * out.g\n\n\nclass Lin(Module):\n    def __init__(self, w, b): self.w,self.b = w,b\n        \n    def forward(self, inp): return inp@self.w + self.b\n    \n    def bwd(self, out, inp):\n        inp.g = out.g @ self.w.t()\n        self.w.g = torch.einsum(\"bi,bj->ij\", inp, out.g)\n        self.b.g = out.g.sum(0)\n\n\nclass Mse(Module):\n    def forward (self, inp, targ): return (inp.squeeze() - targ).pow(2).mean()\n    def bwd(self, out, inp, targ): inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]\n\n\nclass Model():\n    def __init__(self):\n        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n        self.loss = Mse()\n        \n    def __call__(self, x, targ):\n        for l in self.layers: x = l(x)\n        return self.loss(x, targ)\n    \n    def backward(self):\n        self.loss.backward()\n        for l in reversed(self.layers): l.backward()\n\n\nw1.g,b1.g,w2.g,b2.g = [None]*4\nmodel = Model()\n\n\ntest_near(w2g, w2.g)\ntest_near(b2g, b2.g)\ntest_near(w1g, w1.g)\ntest_near(b1g, b1.g)\ntest_near(ig, x_train.g)"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptfully_connected.html#without-einsum",
    "href": "fastai_notebooks/fastai_ptfully_connected.html#without-einsum",
    "title": "0021_fastai_pt2_2019_fully_connected",
    "section": "Without einsum",
    "text": "Without einsum\n\n2:04:44 - how to replace einsum with pure matrix multiplication with @; and as a result, our own code from scratch is as fast as pytorch 2:05:44 plan for the next lesson\nJump_to lesson 8 video\n\nclass Lin(Module):\n    def __init__(self, w, b): self.w,self.b = w,b\n        \n    def forward(self, inp): return inp@self.w + self.b\n    \n    def bwd(self, out, inp):\n        inp.g = out.g @ self.w.t()\n        self.w.g = inp.t() @ out.g\n        self.b.g = out.g.sum(0)\n\n\nw1.g,b1.g,w2.g,b2.g = [None]*4\nmodel = Model()\n\n\ntest_near(w2g, w2.g)\ntest_near(b2g, b2.g)\ntest_near(w1g, w1.g)\ntest_near(b1g, b1.g)\ntest_near(ig, x_train.g)\n\n\n\nnn.Linear and nn.Module\n\n#export\nfrom torch import nn\n\n\nclass Model(nn.Module):\n    def __init__(self, n_in, nh, n_out):\n        super().__init__()\n        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n        self.loss = mse\n        \n    def __call__(self, x, targ):\n        for l in self.layers: x = l(x)\n        return self.loss(x.squeeze(), targ)\n\n\nmodel = Model(m, nh, 1)"
  },
  {
    "objectID": "fastai_notebooks/fastai_ptfully_connected.html#export",
    "href": "fastai_notebooks/fastai_ptfully_connected.html#export",
    "title": "0021_fastai_pt2_2019_fully_connected",
    "section": "Export",
    "text": "Export\n\n!./notebook2script.py 02_fully_connected.ipynb"
  },
  {
    "objectID": "fastai_notebooks/fastai_first_steps_road_to_top_part_1.html",
    "href": "fastai_notebooks/fastai_first_steps_road_to_top_part_1.html",
    "title": "0008_fastai_first_steps_road_to_top_part_1",
    "section": "",
    "text": "# install fastkaggle if not available\ntry: import fastkaggle\nexcept ModuleNotFoundError:\n    !pip install -Uq fastkaggle\n\nfrom fastkaggle import *"
  },
  {
    "objectID": "fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#getting-set-up",
    "href": "fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#getting-set-up",
    "title": "0008_fastai_first_steps_road_to_top_part_1",
    "section": "Getting set up",
    "text": "Getting set up\n\nhow to setup for fastkaggle; how to use fastkaggle to download dataset from kaggle; how to access the path\nFirst, we’ll get the data. I’ve just created a new library called fastkaggle which has a few handy features, including getting the data for a competition correctly regardless of whether we’re running on Kaggle or elsewhere. Note you’ll need to first accept the competition rules and join the competition, and you’ll need your kaggle API key file kaggle.json downloaded if you’re running this somewhere other than on Kaggle. setup_comp is the function we use in fastkaggle to grab the data, and install or upgrade our needed python modules when we’re running on Kaggle:\n\ncomp = 'paddy-disease-classification'\n\npath = setup_comp(comp, install='fastai \"timm>=0.6.2.dev0\"')\n\n\npath\n\nPath('paddy-disease-classification')\n\n\n\n\nwhich fastai module to use for vision problem; how to check files inside the dataset path; why Jeremy recommend not to use seed in your own analysis;\nNow we can import the stuff we’ll need from fastai, set a seed (for reproducibility – just for the purposes of making this notebook easier to write; I don’t recommend doing that in your own analysis however) and check what’s in the data:\n\nfrom fastai.vision.all import *\nset_seed(42)\n\npath.ls()\n\n(#6) [Path('paddy-disease-classification/sample_submission.csv'),Path('paddy-disease-classification/test_images'),Path('paddy-disease-classification/subm.csv'),Path('paddy-disease-classification/train_images'),Path('paddy-disease-classification/train.csv'),Path('paddy-disease-classification/models')]"
  },
  {
    "objectID": "fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#looking-at-the-data",
    "href": "fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#looking-at-the-data",
    "title": "0008_fastai_first_steps_road_to_top_part_1",
    "section": "Looking at the data",
    "text": "Looking at the data\n\nhow to access a subfolder by name using path from setup_comp; how to extract all image files from a folder\nThe images are in train_images, so let’s grab a list of all of them:\n\ntrn_path = path/'train_images'\nfiles = get_image_files(trn_path)\n\n…and take a look at one:\n\n\nhow to create an image from an image file; how to access the size of an image; how to display it with specified size for viewing\n\nimg = PILImage.create(files[0])\nprint(img.size)\nimg.to_thumb(128)\n\n(480, 640)\n\n\n\n\n\n\n\nhow to use fastcore.parallel to quickly access size of all images; how to count the occurance of each unique value in a pandas\nLooks like the images might be 480x640 – let’s check all their sizes. This is faster if we do it in parallel, so we’ll use fastcore’s parallel for this:\n\nfrom fastcore.parallel import *\n\ndef f(o): return PILImage.create(o).size\nsizes = parallel(f, files, n_workers=8)\npd.Series(sizes).value_counts()\n\n(480, 640)    10403\n(640, 480)        4\ndtype: int64\n\n\n\n\nhow to create an image dataloaders; how to setup item_tfms and batch_tfms on image sizes; why to start with the smallest sizes first; how to display images in batch\nThey’re nearly all the same size, except for a few. Because of those few, however, we’ll need to make sure we always resize each image to common dimensions first, otherwise fastai won’t be able to create batches. For now, we’ll just squish them to 480x480 images, and then once they’re in batches we do a random resized crop down to a smaller size, along with the other default fastai augmentations provided by aug_transforms. We’ll start out with small resized images, since we want to be able to iterate quickly:\n\ndls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, seed=42,\n    item_tfms=Resize(480, method='squish'),\n    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n\ndls.show_batch(max_n=6)"
  },
  {
    "objectID": "fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#our-first-model",
    "href": "fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#our-first-model",
    "title": "0008_fastai_first_steps_road_to_top_part_1",
    "section": "Our first model",
    "text": "Our first model\n\nhow to pick the first pretrained model for our model; how to build our model based on the selected pretrained model\nLet’s create a model. To pick an architecture, we should look at the options in The best vision models for fine-tuning. I like the looks of resnet26d, which is the fastest resolution-independent model which gets into the top-15 lists there.\n\nlearn = vision_learner(dls, 'resnet26d', metrics=error_rate, path='.').to_fp16()\n\n\n\nhow to find the learning rate for our model\nLet’s see what the learning rate finder shows:\n\nlearn.lr_find(suggest_funcs=(valley, slide))\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0008317637839354575, slide=0.0030199517495930195)\n\n\n\n\n\nlr_find generally recommends rather conservative learning rates, to ensure that your model will train successfully. I generally like to push it a bit higher if I can. Let’s train a few epochs and see how it looks:\n\nlearn.fine_tune(3, 0.01)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.805964\n      1.233453\n      0.403652\n      00:14\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.129876\n      0.785891\n      0.266218\n      00:15\n    \n    \n      1\n      0.777808\n      0.456637\n      0.143681\n      00:15\n    \n    \n      2\n      0.557498\n      0.407197\n      0.136473\n      00:15\n    \n  \n\n\n\nWe’re now ready to build our first submission. Let’s take a look at the sample Kaggle provided to see what it needs to look like:"
  },
  {
    "objectID": "fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#submitting-to-kaggle",
    "href": "fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#submitting-to-kaggle",
    "title": "0008_fastai_first_steps_road_to_top_part_1",
    "section": "Submitting to Kaggle",
    "text": "Submitting to Kaggle\n\nhow to check the kaggle submission sample csv file\n\nss = pd.read_csv(path/'sample_submission.csv')\nss\n\n\n\n\n\n  \n    \n      \n      image_id\n      label\n    \n  \n  \n    \n      0\n      200001.jpg\n      NaN\n    \n    \n      1\n      200002.jpg\n      NaN\n    \n    \n      2\n      200003.jpg\n      NaN\n    \n    \n      3\n      200004.jpg\n      NaN\n    \n    \n      4\n      200005.jpg\n      NaN\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      3464\n      203465.jpg\n      NaN\n    \n    \n      3465\n      203466.jpg\n      NaN\n    \n    \n      3466\n      203467.jpg\n      NaN\n    \n    \n      3467\n      203468.jpg\n      NaN\n    \n    \n      3468\n      203469.jpg\n      NaN\n    \n  \n\n3469 rows × 2 columns\n\n\n\n\n\nhow to sort the files in the test set in the alphabetical order; how to create dataloaders for the test set based on the dataloaders of the training set\nOK so we need a CSV containing all the test images, in alphabetical order, and the predicted label for each one. We can create the needed test set using fastai like so:\n\ntst_files = get_image_files(path/'test_images').sorted()\ntst_dl = dls.test_dl(tst_files)\n\n\n\nhow to make predictions for all test set; and what does learn.get_preds return\nWe can now get the probabilities of each class, and the index of the most likely class, from this test set (the 2nd thing returned by get_preds are the targets, which are blank for a test set, so we discard them):\n\nprobs,_,idxs = learn.get_preds(dl=tst_dl, with_decoded=True)\nidxs\n\n\n\n\n\n\n\n\nTensorBase([7, 8, 7,  ..., 8, 7, 5])\n\n\n\n\nhow to access all the classes of labels with dataloaders\nThese need to be mapped to the names of each of these diseases, these names are stored by fastai automatically in the vocab:\n\ndls.vocab\n\n['bacterial_leaf_blight', 'bacterial_leaf_streak', 'bacterial_panicle_blight', 'blast', 'brown_spot', 'dead_heart', 'downy_mildew', 'hispa', 'normal', 'tungro']\n\n\n\n\nhow to map classes to each idx from the predictions\nWe can create an apply this mapping using pandas:\n\nmapping = dict(enumerate(dls.vocab))\nresults = pd.Series(idxs.numpy(), name=\"idxs\").map(mapping)\nresults\n\n0            hispa\n1           normal\n2            hispa\n3            blast\n4            blast\n           ...    \n3464    dead_heart\n3465         hispa\n3466        normal\n3467         hispa\n3468    dead_heart\nName: idxs, Length: 3469, dtype: object\n\n\n\n\nhow to save result into csv file\nKaggle expects the submission as a CSV file, so let’s save it, and check the first few lines:\n\nss['label'] = results\nss.to_csv('subm.csv', index=False)\n!head subm.csv\n\nimage_id,label\n200001.jpg,hispa\n200002.jpg,normal\n200003.jpg,hispa\n200004.jpg,blast\n200005.jpg,blast\n200006.jpg,brown_spot\n200007.jpg,dead_heart\n200008.jpg,brown_spot\n200009.jpg,hispa\n\n\n\n\nhow to submit to kaggle with fastkaggle api\nLet’s submit this to kaggle. We can do it from the notebook if we’re running on Kaggle, otherwise we can use the API:\n\nif not iskaggle:\n    from kaggle import api\n    api.competition_submit_cli('subm.csv', 'initial rn26d 128px', comp)\n\n100%|██████████████████████████████████████████| 70.0k/70.0k [00:05<00:00, 13.8kB/s]\n\n\nSuccessfully submitted to Paddy Doctor: Paddy Disease Classification\n\n\nSuccess! We successfully created a submission."
  },
  {
    "objectID": "fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#conclusion",
    "href": "fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#conclusion",
    "title": "0008_fastai_first_steps_road_to_top_part_1",
    "section": "Conclusion",
    "text": "Conclusion\n\nwhat is the most important thing for your first model\nOur initial submission is not very good (top 80% of teams) but it only took a minute to train. The important thing is that we have a good starting point to iterate from, and we can do rapid iterations. Every step from loading the data to creating the model to submitting to Kaggle is all automated and runs quickly.\nTherefore, we can now try lots of things quickly and easily and use those experiments to improve our results. In the next notebook, we’ll do exactly that!\nIf you found this notebook useful, please remember to click the little up-arrow at the top to upvote it, since I like to know when people have found my work useful, and it helps others find it too. And if you have any questions or comments, please pop them below – I read every comment I receive!"
  },
  {
    "objectID": "fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#addendum",
    "href": "fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#addendum",
    "title": "0008_fastai_first_steps_road_to_top_part_1",
    "section": "Addendum",
    "text": "Addendum\n\nhow to quickly push your local notebook to become kaggle notebook online\nfastkaggle also provides a function that pushes a notebook to Kaggle Notebooks. I wrote this notebook on my own machine, and pushed it to Kaggle from there – here’s the command I used:\n\nif not iskaggle:\n    push_notebook('jhoward', 'first-steps-road-to-the-top-part-1',\n                  title='First Steps: Road to the Top, Part 1',\n                  file='first-steps-road-to-the-top-part-1.ipynb',\n                  competition=comp, private=False, gpu=True)\n\nKernel version 10 successfully pushed.  Please check progress at https://www.kaggle.com/code/jhoward/first-steps-road-to-the-top-part-1\n\n\n\nfrom fastdebug.utils import *\n\n\n\n\n\nnb_name()\n\n'0008_fastai_first_steps_road_to_top_part_1.ipynb'\n\n\n\nipy2md()\n\n[jupytext] Reading /Users/Natsume/Documents/fastdebug/nbs/2022part1/0008_fastai_first_steps_road_to_top_part_1.ipynb in format ipynb\n[jupytext] Writing /Users/Natsume/Documents/fastdebug/nbs/2022part1/0008_fastai_first_steps_road_to_top_part_1.md\ncp to : /Users/Natsume/Documents/divefastai/Debuggable/jupytext\nmove to : /Users/Natsume/Documents/fastdebug/mds/2022part1/\n\n\n[NbConvertApp] Converting notebook /Users/Natsume/Documents/fastdebug/nbs/2022part1/0008_fastai_first_steps_road_to_top_part_1.ipynb to markdown\n\n\ncopy to : /Users/Natsume/Documents/fastdebug/mds_output\nmove to : /Users/Natsume/Documents/divefastai/Debuggable/nbconvert\n\n\n[NbConvertApp] Support files will be in 0008_fastai_first_steps_road_to_top_part_1_files/\n[NbConvertApp] Making directory /Users/Natsume/Documents/fastdebug/nbs/2022part1/0008_fastai_first_steps_road_to_top_part_1_files\n[NbConvertApp] Making directory /Users/Natsume/Documents/fastdebug/nbs/2022part1/0008_fastai_first_steps_road_to_top_part_1_files\n[NbConvertApp] Making directory /Users/Natsume/Documents/fastdebug/nbs/2022part1/0008_fastai_first_steps_road_to_top_part_1_files\n[NbConvertApp] Writing 20191 bytes to /Users/Natsume/Documents/fastdebug/nbs/2022part1/0008_fastai_first_steps_road_to_top_part_1.md\n\n\n\nfastnbs(\"push kaggle\")\n\nhow to quickly push your local notebook to become kaggle notebook online\n\n\nfastkaggle also provides a function that pushes a notebook to Kaggle Notebooks. I wrote this notebook on my own machine, and pushed it to Kaggle from there – here’s the command I used:\nif not iskaggle:\n    push_notebook('jhoward', 'first-steps-road-to-the-top-part-1',\n                  title='First Steps: Road to the Top, Part 1',\n                  file='first-steps-road-to-the-top-part-1.ipynb',\n                  competition=comp, private=False, gpu=True)\n\nfrom fastdebug.utils import *\nnb_name()\nipy2md()\nfastnbs(\"push kaggle\")\n\n\n\nOpen 0008_fastai_first_steps_road_to_top_part_1 in Jupyter Notebook locally\n\n\nOpen 0008_fastai_first_steps_road_to_top_part_1 in Jupyter Notebook on Kaggle"
  },
  {
    "objectID": "questions/question_anno_dict.html",
    "href": "questions/question_anno_dict.html",
    "title": "00_quesolved_anno_dict",
    "section": "",
    "text": "from fastcore.meta import *\nfrom fastcore.test import *\nimport inspect"
  },
  {
    "objectID": "questions/question_anno_dict.html#anno_dict-docs",
    "href": "questions/question_anno_dict.html#anno_dict-docs",
    "title": "00_quesolved_anno_dict",
    "section": "anno_dict docs",
    "text": "anno_dict docs\n\ninspect.getdoc(anno_dict)\n\n\"`__annotation__ dictionary with `empty` cast to `None`, returning empty if doesn't exist\"\n\n\nI have to confess I don’t undersatnd the docs statement very well. So, I look into the source code of anno_dict and empty2none.\n\nprint(inspect.getsource(anno_dict))\n\ndef anno_dict(f):\n    \"`__annotation__ dictionary with `empty` cast to `None`, returning empty if doesn't exist\"\n    return {k:empty2none(v) for k,v in getattr(f, '__annotations__', {}).items()}\n\n\n\n\nprint(inspect.getsource(empty2none))\n\ndef empty2none(p):\n    \"Replace `Parameter.empty` with `None`\"\n    return None if p==inspect.Parameter.empty else p"
  },
  {
    "objectID": "questions/question_anno_dict.html#dive-in",
    "href": "questions/question_anno_dict.html#dive-in",
    "title": "00_quesolved_anno_dict",
    "section": "Dive in",
    "text": "Dive in\nIf a parameter’s default value is Parameter.empty, then empty2none is to replace Parameter.empty with None . So, I think it is reasonable to assume p is primarily used as a parameter’s default value. The cell below supports this assumption.\n\ndef foo(a, b:int=1): pass\nsig = inspect.signature(foo)\nfor k,v in sig.parameters.items():\n    print(f'{k} is a parameter {v}, whose default value is {v.default}, \\\nif apply empty2none to default value, then the default value is {empty2none(v.default)}')\n    print(f'{k} is a parameter {v}, whose default value is {v.default}, \\\nif apply empty2none to parameter, then we get: {empty2none(v)}')\n\na is a parameter a, whose default value is <class 'inspect._empty'>, if apply empty2none to default value, then the default value is None\na is a parameter a, whose default value is <class 'inspect._empty'>, if apply empty2none to parameter, then we get: a\nb is a parameter b: int = 1, whose default value is 1, if apply empty2none to default value, then the default value is 1\nb is a parameter b: int = 1, whose default value is 1, if apply empty2none to parameter, then we get: b: int = 1\n\n\nSo, what is odd is that in anno_dict, empty2none is applied to v which is not parameter’s default value, but mostly classes like int, list ect, as in __annotations__.\nThen I experimented the section below and didn’t find anno_dict doing anything new than __annotations__."
  },
  {
    "objectID": "questions/question_anno_dict.html#anno_dict-seems-not-add-anything-new-to-__annotations__",
    "href": "questions/question_anno_dict.html#anno_dict-seems-not-add-anything-new-to-__annotations__",
    "title": "00_quesolved_anno_dict",
    "section": "anno_dict seems not add anything new to __annotations__",
    "text": "anno_dict seems not add anything new to __annotations__\n\ndef foo(a, b:int=1): pass\ntest_eq(foo.__annotations__, {'b': int})\ntest_eq(anno_dict(foo), {'b': int})\ndef foo(a:bool, b:int=1): pass\ntest_eq(foo.__annotations__, {'a': bool, 'b': int})\ntest_eq(anno_dict(foo), {'a': bool, 'b': int})\ndef foo(a, d:list, b:int=1, c:bool=True): pass\ntest_eq(foo.__annotations__, {'d': list, 'b': int, 'c': bool})\ntest_eq(anno_dict(foo), {'d': list, 'b': int, 'c': bool})\n\n\nfrom fastcore.foundation import L\n\n\ndef foo(a, b): pass\ntest_eq(foo.__annotations__, {})\ntest_eq(anno_dict(foo), {})\n\ndef _f(a:int, b:L)->str: ...\ntest_eq(_f.__annotations__, {'a': int, 'b': L, 'return': str})\ntest_eq(anno_dict(_f), {'a': int, 'b': L, 'return': str})\n\nQuestion! so far above anno_dict has done nothing new or more, so what am I missing here?"
  },
  {
    "objectID": "questions/question_anno_dict.html#use-fastdebug-to-double-check",
    "href": "questions/question_anno_dict.html#use-fastdebug-to-double-check",
    "title": "00_quesolved_anno_dict",
    "section": "use fastdebug to double check",
    "text": "use fastdebug to double check\n\nfrom fastdebug.utils import *\nfrom fastdebug.core import *\nfrom fastcore.meta import *\n\n\n\n\n\nfdb = Fastdb(anno_dict)\nfdb.eg = \"\"\"\ndef foo(a, b): pass\ntest_eq(foo.__annotations__, {})\ntest_eq(anno_dict(foo), {})\n\nfrom fastcore.foundation import L\ndef _f(a:int, b:L)->str: ...\ntest_eq(_f.__annotations__, {'a': int, 'b': L, 'return': str})\ntest_eq(anno_dict(_f), {'a': int, 'b': L, 'return': str})\n\"\"\"\n\n\nfdb.snoop(['empty2none(v)'])\n\n09:48:27.11 >>> Call to anno_dict in File \"/tmp/anno_dict.py\", line 3\n09:48:27.11 ...... f = <function foo>\n09:48:27.11    3 | def anno_dict(f):\n09:48:27.11    5 |     return {k:empty2none(v) for k,v in getattr(f, '__annotations__', {}).items()}\n    09:48:27.11 Dict comprehension:\n    09:48:27.11    5 |     return {k:empty2none(v) for k,v in getattr(f, '__annotations__', {}).items()}\n    09:48:27.11 .......... Iterating over <dict_itemiterator object>\n    09:48:27.11 Result: {}\n09:48:27.11    5 |     return {k:empty2none(v) for k,v in getattr(f, '__annotations__', {}).items()}\n09:48:27.12 <<< Return value from anno_dict: {}\n09:48:27.12 >>> Call to anno_dict in File \"/tmp/anno_dict.py\", line 3\n09:48:27.12 ...... f = <function _f>\n09:48:27.12    3 | def anno_dict(f):\n09:48:27.12    5 |     return {k:empty2none(v) for k,v in getattr(f, '__annotations__', {}).items()}\n    09:48:27.12 Dict comprehension:\n    09:48:27.12    5 |     return {k:empty2none(v) for k,v in getattr(f, '__annotations__', {}).items()}\n    09:48:27.12 .......... Iterating over <dict_itemiterator object>\n    09:48:27.12 .......... Values of k: 'a', 'b', 'return'\n    09:48:27.12 .......... Values of v: <class 'int'>, <class 'fastcore.foundation.L'>, <class 'str'>\n    09:48:27.12 .......... Values of empty2none(v): <class 'int'>, <class 'fastcore.foundation.L'>, <class 'str'>\n    09:48:27.12 Result: {'a': <class 'int'>, 'b': <class 'fastcore.foundation.L'>, 'return': <class 'str'>}\n09:48:27.12    5 |     return {k:empty2none(v) for k,v in getattr(f, '__annotations__', {}).items()}\n09:48:27.12 <<< Return value from anno_dict: {'a': <class 'int'>, 'b': <class 'fastcore.foundation.L'>, 'return': <class 'str'>}\n\n\n========================================================     Investigating anno_dict     =========================================================\n==============================================================     on line None     ==============================================================\n     with example \ndef foo(a, b): pass\ntest_eq(foo.__annotations__, {})\ntest_eq(anno_dict(foo), {})\n\nfrom fastcore.foundation import L\ndef _f(a:int, b:L)->str: ...\ntest_eq(_f.__annotations__, {'a': int, 'b': L, 'return': str})\ntest_eq(anno_dict(_f), {'a': int, 'b': L, 'return': str})\n     \n\n\n\n\nfdb.docsrc(1, \"empty2none works on paramter.default especially when the default is Parameter.empty; anno_dict works on the types \\\nof params, not the value of params; so it is odd to use empty2none in anno_dict;\")\n\n========================================================     Investigating anno_dict     =========================================================\n===============================================================     on line 1     ================================================================\n     with example \ndef foo(a, b): pass\ntest_eq(foo.__annotations__, {})\ntest_eq(anno_dict(foo), {})\n\nfrom fastcore.foundation import L\ndef _f(a:int, b:L)->str: ...\ntest_eq(_f.__annotations__, {'a': int, 'b': L, 'return': str})\ntest_eq(anno_dict(_f), {'a': int, 'b': L, 'return': str})\n     \n\nprint selected srcline with expands below--------\ndef anno_dict(f):                                                                                                                                       (0)\n    \"`__annotation__ dictionary with `empty` cast to `None`, returning empty if doesn't exist\"==========================================================(1)\nempty2none works on paramter.default especially when the default is Parameter.empty; anno_dict works on the types of params, not the value of params; so it is odd to use empty2none in anno_dict;\n    return {k:empty2none(v) for k,v in getattr(f, '__annotations__', {}).items()}                                                                       (2)\n                                                                                                                                                        (3)\n\nReview srcode with all comments added so far======================================================================================================\ndef anno_dict(f):=========================================================================(0)       \n    \"`__annotation__ dictionary with `empty` cast to `None`, returning empty if doesn't exist\" # empty2none works on paramter.default especially when the default is Parameter.empty; anno_dict works on the types of params, not the value of params; so it is odd to use empty2none in anno_dict;;  (1)\n    return {k:empty2none(v) for k,v in getattr(f, '__annotations__', {}).items()}=========(2)       \n                                                                                                                                                        (3)\n                                                                                                                                     part No.1 out of 1 parts\n\n\n\n\nfdb.print()\n\n========================================================     Investigating anno_dict     =========================================================\n===============================================================     on line 1     ================================================================\n     with example \ndef foo(a, b): pass\ntest_eq(foo.__annotations__, {})\ntest_eq(anno_dict(foo), {})\n\nfrom fastcore.foundation import L\ndef _f(a:int, b:L)->str: ...\ntest_eq(_f.__annotations__, {'a': int, 'b': L, 'return': str})\ntest_eq(anno_dict(_f), {'a': int, 'b': L, 'return': str})\n     \n\ndef anno_dict(f):=========================================================================(0)       \n    \"`__annotation__ dictionary with `empty` cast to `None`, returning empty if doesn't exist\" # empty2none works on paramter.default especially when the default is Parameter.empty; anno_dict works on the types of params, not the value of params; so it is odd to use empty2none in anno_dict;;  (1)\n    return {k:empty2none(v) for k,v in getattr(f, '__annotations__', {}).items()}=========(2)       \n                                                                                                                                                        (3)"
  },
  {
    "objectID": "questions/question_anno_dict.html#does-fastcore-want-anno_dict-to-include-params-with-no-annos",
    "href": "questions/question_anno_dict.html#does-fastcore-want-anno_dict-to-include-params-with-no-annos",
    "title": "00_quesolved_anno_dict",
    "section": "Does fastcore want anno_dict to include params with no annos?",
    "text": "Does fastcore want anno_dict to include params with no annos?\nIf so, I have written a lengthy anno_dict_maybe to do it. (can be shorter if needed)\n\ndef anno_dict_maybe(f):\n    \"`__annotation__ dictionary with `empty` cast to `None`, returning empty if doesn't exist\"\n    new_anno = {}\n    for k, v in inspect.signature(f).parameters.items():\n        if k not in f.__annotations__:\n            new_anno[k] = None\n        else: \n            new_anno[k] = f.__annotations__[k]\n    if 'return' in f.__annotations__:\n        new_anno['return'] = f.__annotations__['return']\n#     if hasattr(f, '__annotations__'):\n    if True in [bool(v) for k,v in new_anno.items()]:\n        return new_anno\n    else:\n        return {}\n\n\ndef foo(a:int, b, c:bool=True)->str: pass\n\n\ntest_eq(foo.__annotations__, {'a': int, 'c': bool, 'return': str})\n\n\ntest_eq(anno_dict(foo), {'a': int, 'c': bool, 'return': str})\n\n\ntest_eq(anno_dict_maybe(foo), {'a': int, 'b': None, 'c': bool, 'return': str})\n\n\ndef foo(a, b, c): pass\n\n\ntest_eq(foo.__annotations__, {})\n\n\ntest_eq(anno_dict(foo), {})\n\n\ntest_eq(anno_dict_maybe(foo), {})"
  },
  {
    "objectID": "questions/question_anno_dict.html#jeremys-response",
    "href": "questions/question_anno_dict.html#jeremys-response",
    "title": "00_quesolved_anno_dict",
    "section": "Jeremy’s response",
    "text": "Jeremy’s response\nA supportive and confirmative response from Jeremy on this issue"
  }
]