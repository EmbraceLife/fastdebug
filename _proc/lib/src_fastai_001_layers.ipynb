{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Custom fastai layers and basic functions to grab them.\n",
    "output-file: src_fastai_layers.html\n",
    "title: Layers\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import fastai.layers as fl\n",
    "import fastai.torch_core as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai.torch_core has: \n",
      "85 items in its __all__, and \n",
      "316 user defined functions, \n",
      "137 classes or class objects, \n",
      "4 builtin funcs and methods, and\n",
      "476 callables.\n",
      "\n",
      "None\n",
      "fastai.layers has: \n",
      "61 items in its __all__, and \n",
      "342 user defined functions, \n",
      "172 classes or class objects, \n",
      "4 builtin funcs and methods, and\n",
      "541 callables.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "whatinside(ft)\n",
    "whatinside(fl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic manipulations and resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```module(*flds, **defaults)```\n",
    "- Decorator to create an `nn.Module` using [`f`](https://EmbraceLife.github.io/fastdebug/fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#f) as `forward` method\n",
    "- create parameters from `flds` and `defaults` and make fileds of args from their keys or names\n",
    "- make the decorated function eg. [`Identity`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#identity) a subclass of ```nn.Module``` and \n",
    "- make [`Identity`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#identity) function itself to be the `forward` function of the subclass of ```nn.Module```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L24){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### module\n",
       "\n",
       ">      module (*flds, **defaults)\n",
       "\n",
       "Decorator to create an `nn.Module` using [`f`](https://EmbraceLife.github.io/fastdebug/fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#f) as `forward` method"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L24){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### module\n",
       "\n",
       ">      module (*flds, **defaults)\n",
       "\n",
       "Decorator to create an `nn.Module` using `f` as `forward` method"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L53){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Identity\n",
       "\n",
       ">      Identity ()\n",
       "\n",
       "Do nothing at all"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L53){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Identity\n",
       "\n",
       ">      Identity ()\n",
       "\n",
       "Do nothing at all"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(Identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# doc(module)\n",
    "# doc(Identity)\n",
    "# fastnbs(\"module(*\", \"src\")\n",
    "# module?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:52:40.08 LOG:\n",
      "14:52:40.23 .... module = <function module>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.module(*flds, **defaults)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp(module)\n",
    "# ic(Identity()(1)) # running Identity's own function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(Identity()(1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```Lambda(self, x)```\n",
    "- An easy way to create a pytorch layer for a simple `func`\n",
    "- using ``[`module`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#module)`` decorator, and make ``[`Lambda`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#lambda)`` a subclass of ```nn.Module``` and create a parameter `func` for ``[`Lambda`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#lambda)``\n",
    "- run ```Lambda(func)``` to make the `func` a pytorch layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L60){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Lambda\n",
       "\n",
       ">      Lambda (func)\n",
       "\n",
       "An easy way to create a pytorch layer for a simple `func`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L60){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Lambda\n",
       "\n",
       ">      Lambda (func)\n",
       "\n",
       "An easy way to create a pytorch layer for a simple `func`"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Lambda(func=<function _add2>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _add2(x): return x+2\n",
    "tst = Lambda(_add2)\n",
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(10,20)\n",
    "test_eq(tst(x), x+2) # running foward function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Lambda(func=<function _add2>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst2 = pickle.loads(pickle.dumps(tst)) # question: why dumps and then loads again (check the rubostness of the func?)\n",
    "test_eq(tst2(x), x+2)\n",
    "tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```PartialLambda(Lambda)```\n",
    "- Layer that applies `partial(func, **kwargs)`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# fastnbs(\"module(*flds\", filter_folder=\"src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```PartialLambda(Lambda)```\n",
    "- a subclass of Lambda, which is a subclass of module, which wrap around nn.Module\n",
    "- Layer that applies `partial(func, **kwargs)` which can custom the `func` of ``[`Lambda`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#lambda)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L65){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PartialLambda\n",
       "\n",
       ">      PartialLambda (func)\n",
       "\n",
       "Layer that applies `partial(func, **kwargs)`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L65){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PartialLambda\n",
       "\n",
       ">      PartialLambda (func)\n",
       "\n",
       "Layer that applies `partial(func, **kwargs)`"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(PartialLambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_func(a,b=2): return a+b\n",
    "tst = PartialLambda(test_func, b=5)\n",
    "x.shape\n",
    "test_eq(tst(x), x+5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```view(self:Tensor-1), x.view(x.size(0), -1)```\n",
    "- flatten x into a 1d tensor\n",
    "- flatten x into a 2d tensor, keep the 1dim unchanged, but flatten the rest dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Tensor.view?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "x.size()\n",
    "y = x.view(16)\n",
    "y.size()\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "z.size()\n",
    "z1 = x.view(-1)\n",
    "z1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```Flatten(self, x)```\n",
    "- Flatten `x` to a single dimension, e.g. at end of a model. `full` for rank-1 tensor\"\n",
    "Logic: \n",
    "- use decorator ```module(full=False)``` to make ``[`Flatten`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#flatten)`` a layer and create a parameter ```full=False```\n",
    "- ```Flatten(self, x)``` works as the `forward` function\n",
    "- `self.full` can be access in the `forward` function above\n",
    "- ```Flatten(full=True)```: to flatten all dims of a tensor into a 1d tensor\n",
    "- ```Flatten(full=False)```: to keep 1st dim and flatten the rest dims, so only 2 dims remains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L77){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Flatten\n",
       "\n",
       ">      Flatten (full=False)\n",
       "\n",
       "Flatten `x` to a single dimension, e.g. at end of a model. `full` for rank-1 tensor"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L77){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Flatten\n",
       "\n",
       ">      Flatten (full=False)\n",
       "\n",
       "Flatten `x` to a single dimension, e.g. at end of a model. `full` for rank-1 tensor"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(Flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "tst = Flatten() # this is running __init__\n",
    "x = torch.randn(10,5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(tst(x).shape, [10,20])\n",
    "tst = Flatten(full=True)\n",
    "test_eq(tst(x).shape, [200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```ToTensorBase(self, x)```\n",
    "- make ``[`ToTensorBase`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#totensorbase)`` a subclass of [`module`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#module) which is a subclass of `nn.Module`\n",
    "- ```ToTensorBase(tensor_cls=TensorBase)``` initialize itself with a tensor class (default to TensorBase) as a parameter\n",
    "- after initialization, the output function can take in `x` to turn `x` into an instance of ``[`TensorBase`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_torch_core.html#tensorbase)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L84){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ToTensorBase\n",
       "\n",
       ">      ToTensorBase (tensor_cls=<class 'fastai.torch_core.TensorBase'>)\n",
       "\n",
       "Convert x to TensorBase"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L84){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ToTensorBase\n",
       "\n",
       ">      ToTensorBase (tensor_cls=<class 'fastai.torch_core.TensorBase'>)\n",
       "\n",
       "Convert x to TensorBase"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ToTensorBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# fastnbs(\"def module(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "ttb = ToTensorBase()\n",
    "timg = TensorImage(torch.rand(1,3,32,32))\n",
    "test_eq(type(ttb(timg)), TensorBase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```View(Module)```\n",
    "- ``[`View`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#view)`` is a subclass of ``[`Module`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_torch_core.html#module)``, which inherites from ```nn.Module``` and ```metaclass=PrePostInitMeta```\n",
    "- so, ``[`View`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#view)`` is to create a layer for Viewing data\n",
    "- ```View(*size)``` can initialize itself by setting values for `self.size`\n",
    "- ```View.forward(x)``` can run `x.view(self.size)` to create a new tensor based on `x` but with different shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# fastnbs(\"class Module(\") # to remind me of `Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L89){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### View\n",
       "\n",
       ">      View (*size)\n",
       "\n",
       "Reshape `x` to `size`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L89){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### View\n",
       "\n",
       ">      View (*size)\n",
       "\n",
       "Reshape `x` to `size`"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(View)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(4,5,10)\n",
    "tst = View(10,5,4)\n",
    "test_eq(tst(x).shape, [10,5,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```ResizeBatch(Module)```\n",
    "- ``[`ResizeBatch`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#resizebatch)`` is a subclass of nn.Module and no need to run `super().__init__`\n",
    "- ```ResizeBatch(*size)``` can initialize itself with a specific shape/size for tensors\n",
    "- ```rb(x)``` can reshape `x` so that the batch size dim is unchanged but other dims is changed based on `*size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 2, 3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3,) + (1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L95){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ResizeBatch\n",
       "\n",
       ">      ResizeBatch (*size)\n",
       "\n",
       "Reshape `x` to `size`, keeping batch dim the same size"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L95){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ResizeBatch\n",
       "\n",
       ">      ResizeBatch (*size)\n",
       "\n",
       "Reshape `x` to `size`, keeping batch dim the same size"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ResizeBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "tst = ResizeBatch(5,4)\n",
    "x = torch.randn(10,20)\n",
    "test_eq(tst(x).shape, [10,5,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```Debugger(self,x)```\n",
    "- ``[`Debugger`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#debugger)`` is made into a layer by decorator [`module`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#module) using `nn.Module`\n",
    "- after initialization, `db(x)` will run `set_trace()` and return `x` which is a model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# fastnbs(\"module(*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L102){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Debugger\n",
       "\n",
       ">      Debugger ()\n",
       "\n",
       "A module to debug inside a model."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L102){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Debugger\n",
       "\n",
       ">      Debugger ()\n",
       "\n",
       "A module to debug inside a model."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(Debugger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=5, bias=True)\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=5, bias=True)\n",
       "    (1): Linear(in_features=4, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = nn.Sequential(nn.Linear(4,5), nn.Sequential(nn.Linear(4,5), nn.Linear(4,5)))\n",
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Debugger()(tst) # run this code to activate the ipdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```sigmoid_range(x, low, high)```\n",
    "- calculate sigmoid on tensor `x` and also keep the sigmoid values within `[low, high]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L108){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sigmoid_range\n",
       "\n",
       ">      sigmoid_range (x, low, high)\n",
       "\n",
       "Sigmoid function with range `(low, high)`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L108){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sigmoid_range\n",
       "\n",
       ">      sigmoid_range (x, low, high)\n",
       "\n",
       "Sigmoid function with range `(low, high)`"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(sigmoid_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5398e-05, 5.0000e-01, 9.9995e-01])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.9999,  0.5000,  1.9999])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tensor([-10.,0.,10.])\n",
    "torch.sigmoid(test)\n",
    "sigmoid_range(test, -1,  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "assert torch.allclose(sigmoid_range(test, -1,  2), tensor([-1.,0.5, 2.]), atol=1e-4, rtol=1e-4)\n",
    "assert torch.allclose(sigmoid_range(test, -5, -1), tensor([-5.,-3.,-1.]), atol=1e-4, rtol=1e-4)\n",
    "assert torch.allclose(sigmoid_range(test,  2,  4), tensor([2.,  3., 4.]), atol=1e-4, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```SigmoidRange(self, x)```\n",
    "- ``[`SigmoidRange`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#sigmoidrange)`` is a subclass of `nn.Module`, and the func defined under [`SigmoidRange`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#sigmoidrange) is used as `forward` func, thanks to ``[`module`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#module)`` decorator\n",
    "- ```sr = SigmoidRange(low, high)``` initialize an instance with the value range `[low, high]`, with `low` and `high` as args for `__init__`\n",
    "- `sr(x)` to calc sigmoid on `x` and put it within the range `[low, high]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L114){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SigmoidRange\n",
       "\n",
       ">      SigmoidRange (low, high)\n",
       "\n",
       "Sigmoid module with range `(low, high)`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L114){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SigmoidRange\n",
       "\n",
       ">      SigmoidRange (low, high)\n",
       "\n",
       "Sigmoid module with range `(low, high)`"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(SigmoidRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# fastlistnbs(\"src\")\n",
    "# fastnbs(\"module(*f\", \"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "tst = SigmoidRange(-1, 2)\n",
    "assert torch.allclose(tst(test), tensor([-1.,0.5, 2.]), atol=1e-4, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```AdaptiveConcatPool1d(Module)```\n",
    "- becomes a layer, which is a subclass of [`Module`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_torch_core.html#module), which inherits from `nn.Module` and `PrePostInitMeta` to avoid `super().__init__`\n",
    "- this layer that concats `AdaptiveAvgPool1d` and `AdaptiveMaxPool1d` side by side with each other\n",
    "- ```acp = AdaptiveConcatPool1d(size)``` to initialize the layer with size or num of activations\n",
    "- `acp(x)` is to run tensor `x` through the layer, and if `x.shape` is (5, 10), then the output shape is (5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L119){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AdaptiveConcatPool1d\n",
       "\n",
       ">      AdaptiveConcatPool1d (size=None)\n",
       "\n",
       "Layer that concats `AdaptiveAvgPool1d` and `AdaptiveMaxPool1d`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L119){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AdaptiveConcatPool1d\n",
       "\n",
       ">      AdaptiveConcatPool1d (size=None)\n",
       "\n",
       "Layer that concats `AdaptiveAvgPool1d` and `AdaptiveMaxPool1d`"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(AdaptiveConcatPool1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveConcatPool1d(\n",
       "  (ap): AdaptiveAvgPool1d(output_size=1)\n",
       "  (mp): AdaptiveMaxPool1d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaptiveConcatPool1d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.AdaptiveConcatPool1d"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(AdaptiveConcatPool1d())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(AdaptiveConcatPool1d().children())[0](x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaptiveConcatPool1d()(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```torch.max(a, dim, keepdim)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1961, -0.8795,  0.9460,  2.0959],\n",
       "        [-0.9706, -1.1677,  1.4113, -0.5296],\n",
       "        [ 1.6900, -2.2192,  0.9794, -1.7867],\n",
       "        [-0.4907,  0.6063, -1.1281, -0.2069]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([2.0959, 1.4113, 1.6900, 0.6063]),\n",
       "indices=tensor([3, 2, 0, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[2.0959],\n",
       "        [1.4113],\n",
       "        [1.6900],\n",
       "        [0.6063]]),\n",
       "indices=tensor([[3],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a, 1)\n",
    "torch.max(a, 1)[0].shape\n",
    "torch.max(a, 1)[1].shape\n",
    "torch.max(a, dim=1, keepdim=True)\n",
    "torch.max(a, dim=1, keepdim=True)[0].shape\n",
    "torch.max(a, dim=1, keepdim=True)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1.6900, 0.6063, 1.4113, 2.0959]),\n",
       "indices=tensor([2, 3, 1, 0]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[1.6900, 0.6063, 1.4113, 2.0959]]),\n",
       "indices=tensor([[2, 3, 1, 0]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a, 0)\n",
    "torch.max(a, 0)[0].shape\n",
    "torch.max(a, 0)[1].shape\n",
    "torch.max(a, dim=0, keepdim=True)\n",
    "torch.max(a, dim=0, keepdim=True)[0].shape\n",
    "torch.max(a, dim=0, keepdim=True)[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```AdaptiveConcatPool2d(Module)```\n",
    "- it is like ```AdaptiveConcatPoold(Module)```, but deal with 2d\n",
    "- Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`\"\n",
    "- If the input is `bs x nf x h x h`, the output will be `bs x 2*nf x 1 x 1` if no size is passed or `bs x 2*nf x size x size` (nf: num of filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L128){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AdaptiveConcatPool2d\n",
       "\n",
       ">      AdaptiveConcatPool2d (size=None)\n",
       "\n",
       "Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L128){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AdaptiveConcatPool2d\n",
       "\n",
       ">      AdaptiveConcatPool2d (size=None)\n",
       "\n",
       "Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(AdaptiveConcatPool2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "tst = AdaptiveConcatPool2d()\n",
    "x = torch.randn(10,5,4,4)\n",
    "test_eq(tst(x).shape, [10,10,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 1, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 4, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max1 = torch.max(x,    dim=2, keepdim=True)[0]\n",
    "max2 = torch.max(x,    dim=2, keepdim=False)[0]\n",
    "maxp = torch.max(max1, dim=3, keepdim=True)[0]\n",
    "max1.shape\n",
    "maxp.shape\n",
    "x.shape\n",
    "tst(x).shape\n",
    "test_eq(tst(x)[:,:5], maxp)\n",
    "test_eq(tst(x)[:,5:], x.mean(dim=[2,3], keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 4, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = AdaptiveConcatPool2d(2)\n",
    "x.shape\n",
    "test_eq(tst(x).shape, [10,10,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```PoolType.Avg, PoolType.Max, PoolType.Cat```\n",
    "- they are class properties, which are strings `Avg`, `Max` and [`Cat`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L137){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PoolType\n",
       "\n",
       ">      PoolType ()\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L137){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PoolType\n",
       "\n",
       ">      PoolType ()\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(PoolType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```adaptive_pool(pool_type)```\n",
    "- `pool_type` can be `Avg`, `Max` or [`Cat`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#cat)\n",
    "- return `nn.AdaptiveAvgPool2d`, `nn.AdaptiveMaxPool2d`, `nn.AdaptiveConcatPool2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L140){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### adaptive_pool\n",
       "\n",
       ">      adaptive_pool (pool_type)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L140){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### adaptive_pool\n",
       "\n",
       ">      adaptive_pool (pool_type)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(adaptive_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```nn.AdaptiveAvgPool2d((*output_size))```\n",
    "- to initialize the layer using output_size such as `(5,7)`, `7`, `(None, 7)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveAvgPool2d(output_size=(5, 7))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 5, 7])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn.AdaptiveAvgPool2d??\n",
    "# target output size of 5x7\n",
    "m = nn.AdaptiveAvgPool2d((5,7))\n",
    "m\n",
    "input = torch.randn(1, 64, 8, 9)\n",
    "output = m(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveAvgPool2d(output_size=7)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 7, 7])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target output size of 7x7 (square)\n",
    "m = nn.AdaptiveAvgPool2d(7)\n",
    "m\n",
    "input = torch.randn(1, 64, 10, 9)\n",
    "output = m(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveAvgPool2d(output_size=(None, 7))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 10, 7])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target output size of 10x7\n",
    "m = nn.AdaptiveAvgPool2d((None, 7))\n",
    "m\n",
    "input = torch.randn(1, 64, 10, 9)\n",
    "output = m(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```PoolFlatten(nn.Sequential)```\n",
    "- it inherits from `nn.Sequential`, so it can be a layer\n",
    "- it combines `nn.AdaptiveAvgPool2d` and [`Flatten`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#flatten)\n",
    "- its `nn.AdaptiveAvgPool2d` layer has the last 2 dims to be (1,1)\n",
    "- its [`Flatten`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#flatten) layer only keeps two dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L144){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PoolFlatten\n",
       "\n",
       ">      PoolFlatten (pool_type='Avg')\n",
       "\n",
       "Combine `nn.AdaptiveAvgPool2d` and [`Flatten`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#flatten)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L144){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PoolFlatten\n",
       "\n",
       ">      PoolFlatten (pool_type='Avg')\n",
       "\n",
       "Combine `nn.AdaptiveAvgPool2d` and `Flatten`."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(PoolFlatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# fastnbs(\"Flatten(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolFlatten(\n",
       "  (0): AdaptiveAvgPool2d(output_size=1)\n",
       "  (1): __main__.Flatten(full=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 4, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = PoolFlatten()\n",
    "tst\n",
    "x.shape\n",
    "nn.AdaptiveAvgPool2d(1)(x).shape\n",
    "Flatten()(nn.AdaptiveAvgPool2d(1)(x)).shape\n",
    "test_eq(tst(x).shape, [10,5])\n",
    "test_eq(tst(x), x.mean(dim=[2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x: class=<class 'torch.Tensor'>, shape=torch.Size([10, 5, 4, 4]), dtype=torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-7.1134e-01, -9.9607e-01, -1.2362e+00,  2.2192e+00],\n",
       "          [-9.2149e-01, -4.7613e-01, -1.9622e+00, -7.8476e-01],\n",
       "          [-6.2538e-01,  1.0842e+00,  5.9557e-01, -1.9869e-01],\n",
       "          [-3.3655e-01, -1.4927e+00,  6.3933e-01,  2.5596e-01]],\n",
       "\n",
       "         [[ 1.5941e+00, -2.6400e-01,  3.3970e-02, -1.8899e+00],\n",
       "          [ 9.0067e-01, -5.4662e-02, -4.3492e-01,  2.2304e+00],\n",
       "          [-1.1263e+00, -8.9024e-01,  6.3741e-01,  1.8211e-01],\n",
       "          [ 1.5691e+00, -6.5804e-02,  1.4386e+00,  5.7467e-01]],\n",
       "\n",
       "         [[-1.5395e+00,  3.8009e-01, -1.0150e+00,  4.0274e-02],\n",
       "          [ 5.4112e-01,  1.1350e+00,  6.7048e-01,  1.6456e+00],\n",
       "          [-4.8748e-01, -1.2841e+00,  6.1856e-01, -9.4902e-01],\n",
       "          [-1.4359e+00,  8.3798e-01, -2.2432e+00, -2.6160e-01]],\n",
       "\n",
       "         [[-9.5391e-02,  3.7970e-01, -3.5172e-02,  8.3178e-01],\n",
       "          [-5.8331e-01, -2.6988e-01, -2.7612e-01,  1.3224e+00],\n",
       "          [ 4.1869e-01,  3.3830e-01,  1.6538e-02, -5.4941e-01],\n",
       "          [-4.4819e-01, -1.3498e-01,  4.1665e-01,  1.5720e-01]],\n",
       "\n",
       "         [[ 4.9426e-01, -1.3869e+00,  1.3001e+00,  5.2034e-01],\n",
       "          [-6.0255e-01,  3.8579e-01,  3.5533e-01, -5.8241e-01],\n",
       "          [-1.9062e+00, -9.3887e-01,  1.5800e-01, -1.4945e+00],\n",
       "          [-1.9333e+00,  5.2670e-01, -5.1293e-01, -1.6049e+00]]],\n",
       "\n",
       "\n",
       "        [[[-1.0157e+00, -2.3455e+00, -4.2475e-01, -3.7559e-01],\n",
       "          [ 1.1944e+00,  4.0143e-01, -4.3259e-01, -8.4820e-01],\n",
       "          [-7.4481e-02, -2.1816e-01,  8.3423e-02,  1.0652e+00],\n",
       "          [ 1.6184e+00,  1.3076e+00,  1.6673e-01,  4.0178e-01]],\n",
       "\n",
       "         [[-3.7414e-01, -2.6123e-02, -5.4650e-01, -1.8188e-01],\n",
       "          [-1.2025e+00,  1.3948e+00,  7.2542e-01,  4.6323e-01],\n",
       "          [-2.2198e+00, -7.2702e-01, -2.6050e-01, -2.6035e-01],\n",
       "          [ 5.8270e-01, -1.4014e+00, -1.6328e-02,  5.3239e-01]],\n",
       "\n",
       "         [[ 1.9573e+00, -1.9700e+00, -4.2815e-01, -5.5273e-01],\n",
       "          [ 4.9112e-01,  1.0814e+00, -5.5603e-01, -3.5645e-01],\n",
       "          [-7.9357e-01,  1.1546e+00,  2.0966e+00, -2.9573e-01],\n",
       "          [ 9.7181e-01, -1.0400e+00,  1.2679e+00, -1.2343e+00]],\n",
       "\n",
       "         [[-8.3901e-01, -1.6174e+00, -1.0974e+00, -1.7761e+00],\n",
       "          [ 8.6959e-01, -1.0474e+00,  7.4540e-01,  1.6417e+00],\n",
       "          [ 5.9619e-01, -2.9758e-01,  1.6667e+00, -9.0589e-01],\n",
       "          [ 3.2092e-01, -1.8596e-01,  4.4537e-01, -5.1966e-02]],\n",
       "\n",
       "         [[-2.5424e-01, -1.1967e+00,  5.7911e-01,  1.8584e-01],\n",
       "          [ 1.6691e+00,  3.2990e-01,  6.1244e-01, -7.7749e-01],\n",
       "          [ 8.8799e-01,  5.5377e-01, -1.2193e+00,  2.4213e-02],\n",
       "          [ 1.5533e-01, -1.1091e+00,  4.4351e-01, -2.0776e+00]]],\n",
       "\n",
       "\n",
       "        [[[-1.1319e+00,  2.0076e-01,  1.0232e+00, -1.5897e+00],\n",
       "          [-2.0357e-01, -2.8251e+00,  3.8959e-01,  1.0232e+00],\n",
       "          [-1.0184e+00,  2.5289e-01,  7.3592e-01,  5.7374e-01],\n",
       "          [-1.4978e+00,  6.5334e-02, -6.5226e-01,  1.0083e+00]],\n",
       "\n",
       "         [[ 2.9369e-01, -3.3525e-01, -8.4944e-01,  1.8558e+00],\n",
       "          [-1.5380e+00,  1.0600e+00,  3.3181e-01,  1.2682e+00],\n",
       "          [ 1.4941e+00,  7.8667e-01, -1.3419e+00,  1.2280e+00],\n",
       "          [-7.7970e-02, -5.9542e-01, -2.6168e+00,  1.0010e+00]],\n",
       "\n",
       "         [[-7.3543e-01,  2.6170e+00, -1.0913e+00,  1.6529e+00],\n",
       "          [ 1.9372e-01, -2.6608e+00, -1.4914e-01,  6.7004e-01],\n",
       "          [ 1.4315e-01, -5.4096e-01, -4.0494e-01,  1.5426e+00],\n",
       "          [ 1.1460e+00, -3.3811e-01, -3.2829e-01, -1.1516e+00]],\n",
       "\n",
       "         [[ 2.1251e-01, -2.5890e-01, -7.5580e-01, -9.8821e-01],\n",
       "          [ 3.1658e-01, -2.5991e-01,  1.0066e+00,  1.2465e+00],\n",
       "          [ 1.5539e+00, -4.9563e-01, -1.8770e+00, -7.2246e-01],\n",
       "          [-9.9305e-01,  8.0784e-01,  1.0672e-02,  4.7153e-01]],\n",
       "\n",
       "         [[ 2.5651e-01, -2.1439e-01, -2.6471e-01,  2.0702e+00],\n",
       "          [-1.2004e+00,  1.3182e+00, -8.6991e-01, -1.0670e+00],\n",
       "          [ 6.9865e-01,  1.9459e+00,  1.9976e+00, -2.0958e-01],\n",
       "          [-7.7282e-01, -1.6011e+00,  3.9619e-01, -7.7430e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2093e+00, -8.1950e-01, -2.5434e-02, -6.8060e-01],\n",
       "          [-4.9330e-01, -2.8020e-01,  9.8972e-01,  9.7297e-01],\n",
       "          [ 6.4830e-01,  2.5073e-01,  2.6888e-01, -9.3854e-01],\n",
       "          [-3.2507e-01,  4.9615e-01,  7.9890e-01,  1.5446e+00]],\n",
       "\n",
       "         [[-8.1331e-01, -3.6518e-01,  7.7109e-01,  6.9970e-01],\n",
       "          [-2.3026e+00, -9.1488e-01, -7.1835e-01,  1.0142e+00],\n",
       "          [ 2.6651e-02, -2.7526e-01,  5.2323e-01, -3.3234e-02],\n",
       "          [ 1.0167e+00,  1.1015e+00,  2.1942e+00,  8.0602e-01]],\n",
       "\n",
       "         [[ 1.4669e+00, -3.4106e-01, -6.5527e-01, -4.7170e-01],\n",
       "          [-1.0834e+00, -2.1852e+00, -1.8642e+00, -1.4551e+00],\n",
       "          [ 6.1257e-01, -1.7239e+00,  1.6451e+00,  5.2325e-04],\n",
       "          [ 1.3523e+00, -2.2505e-01,  1.6659e-01,  1.1650e+00]],\n",
       "\n",
       "         [[ 4.4918e-01, -1.0368e+00,  1.1763e+00,  1.1114e-02],\n",
       "          [-1.6019e+00,  9.3257e-02,  1.0813e+00, -1.3974e+00],\n",
       "          [-1.3091e+00,  1.3476e+00,  1.2510e+00, -4.7561e-02],\n",
       "          [ 8.6856e-01, -2.5905e-01,  1.7444e-01, -8.4461e-01]],\n",
       "\n",
       "         [[ 3.3506e-01, -1.3883e+00, -5.9094e-01,  1.8419e-01],\n",
       "          [ 1.1352e+00,  1.3375e+00,  1.0208e+00, -6.4435e-01],\n",
       "          [-9.0285e-01,  3.0084e-01, -6.0607e-01,  4.8166e-01],\n",
       "          [ 5.3981e-01,  8.8007e-01,  3.7355e-01,  4.6180e-01]]],\n",
       "\n",
       "\n",
       "        [[[-9.0571e-01,  7.9029e-01, -1.1794e+00, -8.0096e-02],\n",
       "          [ 8.7670e-01, -2.4142e-02, -4.0806e-01, -8.3221e-02],\n",
       "          [-4.8874e-01, -2.1448e-01,  5.8343e-01,  1.9045e+00],\n",
       "          [-1.1570e-01,  1.2363e+00, -9.0250e-01,  3.3993e-01]],\n",
       "\n",
       "         [[-4.7792e-01,  6.7091e-01,  8.2414e-01, -5.1808e-01],\n",
       "          [ 1.7345e+00,  3.2963e-01, -8.4986e-01, -2.1885e-01],\n",
       "          [ 6.0303e-01,  7.6727e-01, -1.1845e+00,  9.7677e-02],\n",
       "          [-3.2229e-01,  5.6926e-01,  3.9369e-01, -3.2665e-01]],\n",
       "\n",
       "         [[-2.0682e+00,  3.9969e-01, -7.2576e-01,  1.2333e+00],\n",
       "          [-1.7421e-01, -3.2267e-01, -1.2077e+00,  1.4455e+00],\n",
       "          [ 7.7890e-01,  7.7048e-01,  1.2610e-01, -6.0329e-01],\n",
       "          [ 9.0818e-01, -8.4406e-01, -2.9910e-01, -3.0544e-01]],\n",
       "\n",
       "         [[-4.7576e-01,  7.9694e-01,  8.1631e-02,  2.5017e-02],\n",
       "          [ 3.7546e-01,  9.1021e-01,  1.5452e-01,  9.6281e-01],\n",
       "          [ 1.5576e+00,  3.3024e-01, -1.5683e+00,  3.0350e-01],\n",
       "          [-1.8896e+00, -1.3941e+00, -2.8641e-01, -3.5747e-01]],\n",
       "\n",
       "         [[ 7.2289e-01,  2.0987e+00, -3.3702e-01,  2.1694e+00],\n",
       "          [-9.8494e-01, -2.2353e+00, -1.7367e+00,  1.4042e+00],\n",
       "          [-2.1083e+00, -6.4073e-01, -2.0975e+00, -3.6848e-01],\n",
       "          [-1.8404e-01, -1.5693e+00, -6.0938e-01,  1.6194e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.5645e+00,  1.3684e+00,  1.6816e-01, -7.6315e-01],\n",
       "          [ 1.1518e+00,  4.8765e-01, -6.4365e-01, -1.6646e-01],\n",
       "          [-6.5168e-01,  1.4889e+00, -3.5659e-01, -6.6924e-01],\n",
       "          [-9.4892e-01, -5.2736e-01, -3.8948e-01, -8.7832e-02]],\n",
       "\n",
       "         [[ 1.3596e+00, -2.1955e-01,  2.2069e-01, -1.7030e+00],\n",
       "          [-5.0489e-01,  1.7579e-01,  3.9333e-01, -3.5957e-01],\n",
       "          [-1.4848e+00, -1.1054e-01, -3.0408e-01, -2.0735e+00],\n",
       "          [-1.7488e+00,  1.5904e-02, -6.6630e-01, -1.5875e-01]],\n",
       "\n",
       "         [[-4.1066e-01,  1.1661e+00,  9.2669e-01, -3.7516e-01],\n",
       "          [ 1.0622e+00, -7.9659e-01, -1.1568e-01,  1.9987e+00],\n",
       "          [ 7.3940e-01, -1.6579e-01, -1.3167e+00,  2.2857e-01],\n",
       "          [-1.4001e+00,  6.3376e-01,  9.4178e-01,  4.6071e-01]],\n",
       "\n",
       "         [[-6.7605e-01,  9.8846e-01,  9.7990e-01,  1.0766e+00],\n",
       "          [-1.8742e+00, -6.0104e-01, -1.0522e+00,  2.1566e+00],\n",
       "          [ 3.7905e-01,  1.5747e-01, -4.2352e-01, -1.1492e+00],\n",
       "          [ 1.4159e+00, -7.3884e-01, -3.6326e-01, -4.5874e-01]],\n",
       "\n",
       "         [[-7.0899e-03,  7.5393e-01, -6.6801e-01, -2.3622e-01],\n",
       "          [ 1.6022e-01,  4.4819e-01,  1.1378e+00, -1.0354e+00],\n",
       "          [-1.2523e+00,  8.1739e-01,  2.1197e+00,  3.8932e-01],\n",
       "          [-1.8869e+00, -1.6848e+00, -1.5382e+00,  8.5648e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.4108e-01, -5.5777e-01, -9.5274e-02, -1.8150e+00],\n",
       "          [-1.3210e-01, -1.2753e-01,  1.5278e-01,  9.4364e-02],\n",
       "          [-6.3930e-02,  2.9066e+00, -1.4014e+00,  6.1019e-01],\n",
       "          [-1.3037e+00, -7.9879e-01,  1.2175e-01, -9.5121e-01]],\n",
       "\n",
       "         [[-3.2208e-01, -2.0547e+00,  9.8241e-01,  1.1295e+00],\n",
       "          [ 5.0798e-01,  6.6591e-02, -1.8618e-01,  6.1505e-01],\n",
       "          [ 1.2628e+00,  5.0201e-01, -2.5604e-01, -1.6296e+00],\n",
       "          [-8.9917e-01,  7.2231e-01, -3.8776e-01, -1.0471e-02]],\n",
       "\n",
       "         [[-9.4769e-01,  9.4623e-01, -1.0016e+00, -2.3024e-02],\n",
       "          [ 1.1242e+00, -7.8809e-02, -1.6865e+00,  1.1589e+00],\n",
       "          [-1.6647e+00,  1.6115e+00, -9.2662e-02,  3.5332e-01],\n",
       "          [-5.0983e-02,  1.1632e+00, -1.2704e+00, -1.7280e-01]],\n",
       "\n",
       "         [[-7.3661e-01,  1.0124e+00,  6.6844e-01,  1.6411e-02],\n",
       "          [ 1.5428e-01,  9.9501e-01, -3.4633e-01, -8.6644e-01],\n",
       "          [-6.0005e-01,  2.5242e-01, -1.0435e+00, -3.4366e-01],\n",
       "          [ 3.5180e-01,  2.1368e-01, -7.7975e-01, -9.7630e-01]],\n",
       "\n",
       "         [[-5.1927e-01,  2.9015e+00,  2.1524e-01,  7.1904e-01],\n",
       "          [ 1.0004e+00, -1.3255e+00,  3.0691e-01, -1.0313e+00],\n",
       "          [ 1.3765e+00,  4.3625e-01,  7.7203e-01,  8.8723e-01],\n",
       "          [ 1.2455e-01, -2.7815e-01,  4.4031e-01,  1.2033e+00]]],\n",
       "\n",
       "\n",
       "        [[[-5.2607e-01, -1.9414e-01, -1.5587e+00, -5.8147e-01],\n",
       "          [ 1.1435e+00, -1.4865e+00, -4.0082e-01, -2.7370e-01],\n",
       "          [ 4.5247e-01,  9.3737e-01, -2.0299e+00, -3.9682e-04],\n",
       "          [-8.3269e-01, -1.5331e-01, -1.1885e+00,  4.5343e-01]],\n",
       "\n",
       "         [[ 4.9789e-01, -1.1788e+00,  1.1917e+00, -1.2961e+00],\n",
       "          [ 6.9166e-01,  1.4038e+00,  1.4819e+00,  5.3665e-01],\n",
       "          [-1.2591e+00, -4.5341e-01, -7.5515e-01, -7.2794e-01],\n",
       "          [ 3.0047e-01, -6.8652e-02,  1.5926e-02, -2.3904e-01]],\n",
       "\n",
       "         [[ 1.5157e+00,  4.7548e-01,  6.2731e-02, -7.1596e-02],\n",
       "          [ 5.6397e-01, -1.3262e+00, -1.1214e+00,  1.7090e+00],\n",
       "          [-1.1481e+00, -5.5349e-01,  1.2108e-01, -1.2124e+00],\n",
       "          [-8.0474e-01, -4.0069e-01,  8.5053e-02,  1.6795e+00]],\n",
       "\n",
       "         [[-3.4908e-01, -1.3580e+00,  1.9778e+00, -5.6038e-01],\n",
       "          [ 5.9964e-02,  1.3697e+00,  2.2952e-01,  1.2338e+00],\n",
       "          [ 2.6539e-01,  9.5732e-02,  2.6049e-01, -3.0509e-01],\n",
       "          [ 1.7603e+00, -1.0335e+00,  1.4180e-01, -1.9307e+00]],\n",
       "\n",
       "         [[-1.7344e+00, -3.6356e-01,  1.7767e+00,  1.2724e+00],\n",
       "          [ 2.6266e+00,  1.6071e-01, -5.7090e-01,  2.0255e+00],\n",
       "          [ 1.3758e+00, -5.8043e-01,  3.3445e-01, -4.9063e-01],\n",
       "          [-8.4320e-01,  4.1818e-01,  3.1326e-01, -7.5748e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.1371e+00,  1.0132e+00,  8.8670e-01,  3.9788e-01],\n",
       "          [ 7.3021e-01,  7.9143e-01,  2.9210e-01,  4.0294e-02],\n",
       "          [-4.0587e-01, -1.0899e+00, -6.9569e-01,  1.2365e+00],\n",
       "          [ 1.0535e+00,  7.7362e-01,  3.4564e-01,  6.5072e-01]],\n",
       "\n",
       "         [[-2.1455e+00,  1.4068e+00,  8.1426e-02, -8.9781e-01],\n",
       "          [ 6.3621e-01, -4.0519e-01,  7.8058e-01, -7.6835e-03],\n",
       "          [-1.6004e+00,  1.4019e+00, -1.0040e+00, -7.5760e-01],\n",
       "          [ 7.9327e-01,  4.4595e-02,  4.5663e-01,  4.2593e-02]],\n",
       "\n",
       "         [[-8.3540e-04, -1.5268e+00,  3.2712e-01, -1.8549e-01],\n",
       "          [-1.1860e+00, -4.4049e-01, -8.9372e-01, -3.7910e-01],\n",
       "          [-2.6682e-01, -5.9872e-01, -1.5979e+00, -1.4854e+00],\n",
       "          [ 8.4257e-01,  1.1993e+00,  1.9692e+00,  5.2776e-01]],\n",
       "\n",
       "         [[-7.2501e-01, -4.9189e-01, -1.6312e+00, -7.4351e-01],\n",
       "          [ 6.3122e-01, -4.8949e-02,  3.3338e-01, -7.0890e-01],\n",
       "          [ 7.8867e-01, -6.7354e-01, -4.0503e-02,  2.0207e+00],\n",
       "          [ 9.0374e-01,  2.8125e-01, -9.0018e-02,  4.5729e-01]],\n",
       "\n",
       "         [[-9.1603e-02,  5.6410e-01, -8.5473e-01, -8.4376e-01],\n",
       "          [ 9.3179e-01,  1.1740e+00, -1.8299e-01, -1.9015e-01],\n",
       "          [-9.5030e-01,  2.9436e-01, -2.0207e-01, -4.7721e-01],\n",
       "          [-8.5018e-02,  1.1248e+00,  1.6164e-01,  2.4080e-01]]],\n",
       "\n",
       "\n",
       "        [[[-8.6686e-01, -2.9960e-01,  8.0157e-01, -8.6211e-01],\n",
       "          [ 2.4365e+00, -4.1328e-01, -3.5045e-01, -1.3216e+00],\n",
       "          [-6.2284e-02,  1.3707e+00, -1.6568e-01,  9.1302e-01],\n",
       "          [-1.8815e+00, -1.1336e+00, -5.3247e-01, -3.9840e-01]],\n",
       "\n",
       "         [[-2.4079e+00,  1.2210e-01, -6.6324e-01, -7.1417e-01],\n",
       "          [-4.5398e-01,  1.5027e+00,  1.1016e+00, -6.0969e-01],\n",
       "          [ 9.1224e-01,  3.9161e-01, -7.3733e-01, -1.2696e+00],\n",
       "          [-2.1931e-01,  1.8106e+00,  7.9962e-01, -7.0053e-01]],\n",
       "\n",
       "         [[-9.3824e-01, -6.3403e-01,  7.5732e-01,  1.4464e+00],\n",
       "          [-1.6821e+00,  1.2188e+00,  1.6393e+00,  8.9150e-02],\n",
       "          [-1.3109e+00, -5.7144e-01, -1.3480e+00, -6.9490e-01],\n",
       "          [-2.4465e-01, -3.8417e-01,  2.6887e-01,  6.6231e-01]],\n",
       "\n",
       "         [[ 1.3556e+00,  2.1708e-01, -1.3076e+00,  1.9358e+00],\n",
       "          [ 9.3762e-01,  8.5401e-01,  6.5951e-01, -4.5369e-01],\n",
       "          [-1.5324e+00,  3.4974e-02, -1.3442e+00,  2.3610e+00],\n",
       "          [-8.7915e-01, -1.2860e+00,  4.5144e-01, -9.8597e-01]],\n",
       "\n",
       "         [[-1.2221e-02, -9.5632e-01, -2.1982e-01,  1.2271e+00],\n",
       "          [ 1.2993e+00, -5.9235e-01, -4.2703e-01,  1.0354e+00],\n",
       "          [ 2.8287e-02,  1.1631e+00,  3.9992e-01,  3.1695e-01],\n",
       "          [ 5.2600e-01, -1.1039e+00, -8.1282e-01,  6.4756e-02]]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchNorm layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```NormType``` with `Enum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<NormType.Batch: 1>,\n",
       " <NormType.BatchZero: 2>,\n",
       " <NormType.Weight: 3>,\n",
       " <NormType.Spectral: 4>,\n",
       " <NormType.Instance: 5>,\n",
       " <NormType.InstanceZero: 6>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# help(Enum)\n",
    "list(NormType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Batch'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(NormType)[0].name\n",
    "list(NormType)[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature: (value, names=None, *, module=None, qualname=None, type=None, start=1)\n",
      "__class__: <class 'enum.EnumMeta'>\n",
      "__repr__: <enum 'NormType'>\n",
      "\n",
      "__module__: __main__\n",
      "__doc__:\n",
      "An enumeration.\n",
      "__dict__: \n",
      "mappingproxy({'Batch': <NormType.Batch: 1>,\n",
      "              'BatchZero': <NormType.BatchZero: 2>,\n",
      "              'Instance': <NormType.Instance: 5>,\n",
      "              'InstanceZero': <NormType.InstanceZero: 6>,\n",
      "              'Spectral': <NormType.Spectral: 4>,\n",
      "              'Weight': <NormType.Weight: 3>,\n",
      "              '__doc__': 'An enumeration.',\n",
      "              '__module__': '__main__',\n",
      "              '__new__': <function Enum.__new__>,\n",
      "              '_generate_next_value_': <function Enum._generate_next_value_>,\n",
      "              '_member_map_': {'Batch': <NormType.Batch: 1>,\n",
      "                               'BatchZero': <NormType.BatchZero: 2>,\n",
      "                               'Instance': <NormType.Instance: 5>,\n",
      "                               'InstanceZero': <NormType.InstanceZero: 6>,\n",
      "                               'Spectral': <NormType.Spectral: 4>,\n",
      "                               'Weight': <NormType.Weight: 3>},\n",
      "              '_member_names_': ['Batch',\n",
      "                                 'BatchZero',\n",
      "                                 'Weight',\n",
      "                                 'Spectral',\n",
      "                                 'Instance',\n",
      "                                 'InstanceZero'],\n",
      "              '_member_type_': <class 'object'>,\n",
      "              '_value2member_map_': {1: <NormType.Batch: 1>,\n",
      "                                     2: <NormType.BatchZero: 2>,\n",
      "                                     3: <NormType.Weight: 3>,\n",
      "                                     4: <NormType.Spectral: 4>,\n",
      "                                     5: <NormType.Instance: 5>,\n",
      "                                     6: <NormType.InstanceZero: 6>}})\n",
      "metaclass: False\n",
      "class: True\n",
      "decorator: False\n",
      "function: False\n",
      "method: False\n"
     ]
    }
   ],
   "source": [
    "check(NormType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature: None\n",
      "__class__: <enum 'NormType'>\n",
      "__repr__: NormType.Batch\n",
      "\n",
      "__module__: __main__\n",
      "__doc__:\n",
      "An enumeration.\n",
      "__dict__: \n",
      "{'__objclass__': <enum 'NormType'>, '_name_': 'Batch', '_value_': 1}\n",
      "metaclass: False\n",
      "class: False\n",
      "decorator: False\n",
      "function: False\n",
      "method: False\n"
     ]
    }
   ],
   "source": [
    "check(list(NormType)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```_get_norm(prefix, nf, ndim=2, zero=False, **kwargs)```\n",
    "official doc: Norm layer with `nf` features and `ndim` initialized depending on `norm_type`.\n",
    "\n",
    "My doc: to create a `nn.BatchNorm` between 1d to 3d, and output `nf` activation, and can set `weight.data` to either 0 or 1\n",
    "- to get normalization layer\n",
    "- `prefix`: tell which type of normalization layer, like 'BatchNorm'\n",
    "- `ndim=2`: default to 2d, so we get `BatchNorm2d`\n",
    "- `nf`: like 15, to return 15 output or activation at the end of the BatchNorm2d layer\n",
    "- `zero`: True or False, to set BatchNorm layer's weight to be either 0 or 1\n",
    "- `bn.affine`: when it is False, then weight and bias will be None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```BatchNorm(nf, ndim=2, norm_type=NormType.Batch, **kwargs)```\n",
    "Official doc:  BatchNorm layer with `nf` features and `ndim` initialized depending on `norm_type`.\n",
    "\n",
    "My doc: create a BatchNorm layer (2d, by default) by wrapping around [`_get_norm`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#_get_norm)\n",
    "- use kwargs from `nn.BatchNorm2d`\n",
    "- `ndim=2`: by default to create a `nn.BatchNorm2d`\n",
    "- `nf`: like 15, to output 15 activations\n",
    "- `norm_type`: if not `NormType.BatchZero`, then make `wegith.data` all equals 1; otherwise, equals 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NormType.Batch: 1>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<NormType.BatchZero: 2>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NormType.Batch\n",
    "NormType.BatchZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L166){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BatchNorm\n",
       "\n",
       ">      BatchNorm (nf, ndim=2, norm_type=<NormType.Batch: 1>, eps:float=1e-05,\n",
       ">                 momentum:float=0.1, affine:bool=True,\n",
       ">                 track_running_stats:bool=True, device=None, dtype=None)\n",
       "\n",
       "BatchNorm layer with `nf` features and `ndim` initialized depending on `norm_type`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| nf |  |  |  |\n",
       "| ndim | int | 2 |  |\n",
       "| norm_type | NormType | NormType.Batch | pass its args to BatchNorm |\n",
       "| eps | float | 1e-05 |  |\n",
       "| momentum | float | 0.1 |  |\n",
       "| affine | bool | True |  |\n",
       "| track_running_stats | bool | True |  |\n",
       "| device | NoneType | None |  |\n",
       "| dtype | NoneType | None |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L166){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BatchNorm\n",
       "\n",
       ">      BatchNorm (nf, ndim=2, norm_type=<NormType.Batch: 1>, eps:float=1e-05,\n",
       ">                 momentum:float=0.1, affine:bool=True,\n",
       ">                 track_running_stats:bool=True, device=None, dtype=None)\n",
       "\n",
       "BatchNorm layer with `nf` features and `ndim` initialized depending on `norm_type`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| nf |  |  |  |\n",
       "| ndim | int | 2 |  |\n",
       "| norm_type | NormType | NormType.Batch | pass its args to BatchNorm |\n",
       "| eps | float | 1e-05 |  |\n",
       "| momentum | float | 0.1 |  |\n",
       "| affine | bool | True |  |\n",
       "| track_running_stats | bool | True |  |\n",
       "| device | NoneType | None |  |\n",
       "| dtype | NoneType | None |  |"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(BatchNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# help(torch.nn.modules.batchnorm.BatchNorm2d) # to check the meaning of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.BatchNorm(nf, ndim=2, norm_type=<NormType.Batch: 1>, *, eps: float = 1e-05, momentum: float = 0.1, affine: bool = True, track_running_stats: bool = True, device=None, dtype=None)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BatchNorm # receive kwargs from nn.BatchNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "tst = BatchNorm(15)\n",
    "assert isinstance(tst, nn.BatchNorm2d)\n",
    "test_eq(tst.weight, torch.ones(15))\n",
    "tst = BatchNorm(15, norm_type=NormType.BatchZero)\n",
    "test_eq(tst.weight, torch.zeros(15))\n",
    "tst = BatchNorm(15, ndim=1)\n",
    "assert isinstance(tst, nn.BatchNorm1d)\n",
    "tst = BatchNorm(15, ndim=3)\n",
    "assert isinstance(tst, nn.BatchNorm3d)\n",
    "test_eq(BatchNorm(15, affine=False).weight, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```InstanceNorm(nf, ndim=2, norm_type=NormType.Instance, affine=True, **kwargs)```\n",
    "official doc: InstanceNorm layer with `nf` features and `ndim` initialized depending on `norm_type`.\n",
    "\n",
    "mydoc: to create a InstanceNorm layer (1d-3d), any num of activations, set weight.data to 0 or 1, set `affine` True by default\n",
    "- wrapping around [`_get_norm`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#_get_norm)\n",
    "- using kwargs from `nn.InstanceNorm2d`; \n",
    "- default to `NormType.Instance` and `weight.data` will be set to 1; if `NormType.InstanceZero` then `weight.data` is set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L172){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### InstanceNorm\n",
       "\n",
       ">      InstanceNorm (nf, ndim=2, norm_type=<NormType.Instance: 5>, affine=True,\n",
       ">                    eps:float=1e-05, momentum:float=0.1,\n",
       ">                    track_running_stats:bool=False, device=None, dtype=None)\n",
       "\n",
       "InstanceNorm layer with `nf` features and `ndim` initialized depending on `norm_type`."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L172){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### InstanceNorm\n",
       "\n",
       ">      InstanceNorm (nf, ndim=2, norm_type=<NormType.Instance: 5>, affine=True,\n",
       ">                    eps:float=1e-05, momentum:float=0.1,\n",
       ">                    track_running_stats:bool=False, device=None, dtype=None)\n",
       "\n",
       "InstanceNorm layer with `nf` features and `ndim` initialized depending on `norm_type`."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(InstanceNorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kwargs` are passed to `nn.BatchNorm` and can be `eps`, `momentum`, `affine` and `track_running_stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "tst = InstanceNorm(15)\n",
    "assert isinstance(tst, nn.InstanceNorm2d)\n",
    "test_eq(tst.weight, torch.ones(15))\n",
    "tst = InstanceNorm(15, norm_type=NormType.InstanceZero)\n",
    "test_eq(tst.weight, torch.zeros(15))\n",
    "tst = InstanceNorm(15, ndim=1)\n",
    "assert isinstance(tst, nn.InstanceNorm1d)\n",
    "tst = InstanceNorm(15, ndim=3)\n",
    "assert isinstance(tst, nn.InstanceNorm3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `affine` is false the weight should be `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(BatchNorm(15, affine=False).weight, None)\n",
    "test_eq(InstanceNorm(15, affine=False).weight, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```BatchNorm1dFlat(nn.BatchNorm1d)```, `running_mean`, `running_var`, `contiguous`\n",
    "official doc: `nn.BatchNorm1d`, but first flattens leading dimensions\n",
    "\n",
    "mydoc: allow high dim `x` to run through `nn.BatchNorm1d` by flattening leading dims first, and return `x` in its original shape\n",
    "- how to use `torch.Tensor.contiguous`: stackoverflow [answer](https://stackoverflow.com/questions/48915810/what-does-contiguous-do-in-pytorch)\n",
    "- how to access `bn.running_mean` and `bn.running_var`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L177){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BatchNorm1dFlat\n",
       "\n",
       ">      BatchNorm1dFlat (num_features:int, eps:float=1e-05, momentum:float=0.1,\n",
       ">                       affine:bool=True, track_running_stats:bool=True,\n",
       ">                       device=None, dtype=None)\n",
       "\n",
       "`nn.BatchNorm1d`, but first flattens leading dimensions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L177){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BatchNorm1dFlat\n",
       "\n",
       ">      BatchNorm1dFlat (num_features:int, eps:float=1e-05, momentum:float=0.1,\n",
       ">                       affine:bool=True, track_running_stats:bool=True,\n",
       ">                       device=None, dtype=None)\n",
       "\n",
       "`nn.BatchNorm1d`, but first flattens leading dimensions"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(BatchNorm1dFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# check(BatchNorm1dFlat)\n",
    "# help(BatchNorm1dFlat)\n",
    "# help(torch.nn.modules.batchnorm._NormBase)\n",
    "# help(torch.nn.modules.module.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm1dFlat(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = BatchNorm1dFlat(15)\n",
    "tst\n",
    "tst.running_mean\n",
    "tst.running_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0008, -0.0007, -0.0008, -0.0011, -0.0030,  0.0044, -0.0006,  0.0005,\n",
       "        -0.0027, -0.0016, -0.0008, -0.0001, -0.0014, -0.0006, -0.0017])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.9983, 0.9983, 1.0020, 1.0052, 1.0031, 0.9971, 0.9996, 1.0019, 1.0006,\n",
       "        0.9978, 0.9978, 0.9990, 0.9989, 1.0028, 1.0056])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(32, 64, 15)\n",
    "y = tst(x)\n",
    "y.shape\n",
    "tst.running_mean\n",
    "tst.running_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "mean = x.mean(dim=[0,1])\n",
    "test_close(tst.running_mean, 0*0.9 + mean*0.1)\n",
    "var = (x-mean).pow(2).mean(dim=[0,1])\n",
    "test_close(tst.running_var, 1*0.9 + var*0.1, eps=1e-4)\n",
    "test_close(y, (x-mean)/torch.sqrt(var+1e-5) * tst.weight + tst.bias, eps=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```LinBnDrop(nn.Sequential)```\n",
    "official doc: Module grouping `BatchNorm1d`, `Dropout` and `Linear` layers\"\n",
    "\n",
    "mydoc: create a block of layers (BatchNorm1d, Dropout, Linear) together \n",
    "- `lin_first=False`: default to put linear layer to the end of the block\n",
    "- `act=None`: default to None, adding a something (None, or a layer like nn.ReLu, maybe) behind linear layer\n",
    "- `p=0.`: default to 0., as num of dropouts\n",
    "- `bn=True`: default to True, to have a BatchNorm layer or not; if True, the linear layer removes bias\n",
    "- `n_in, n_out`: num of input and output activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L190){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LinBnDrop\n",
       "\n",
       ">      LinBnDrop (n_in, n_out, bn=True, p=0.0, act=None, lin_first=False)\n",
       "\n",
       "Module grouping `BatchNorm1d`, `Dropout` and `Linear` layers"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L190){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LinBnDrop\n",
       "\n",
       ">      LinBnDrop (n_in, n_out, bn=True, p=0.0, act=None, lin_first=False)\n",
       "\n",
       "Module grouping `BatchNorm1d`, `Dropout` and `Linear` layers"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(LinBnDrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`BatchNorm`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#batchnorm) layer is skipped if `bn=False`, as is the dropout if `p=0.`. Optionally, you can add an activation for after the linear layer with `act`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinBnDrop(\n",
       "  (0): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Linear(in_features=10, out_features=20, bias=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Linear(in_features=10, out_features=20, bias=False)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = LinBnDrop(10, 20)\n",
    "tst\n",
    "mods = list(tst.children())\n",
    "mods\n",
    "test_eq(len(mods), 2)\n",
    "assert isinstance(mods[0], nn.BatchNorm1d)\n",
    "assert isinstance(mods[1], nn.Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinBnDrop(\n",
       "  (0): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Dropout(p=0.1, inplace=False)\n",
       "  (2): Linear(in_features=10, out_features=20, bias=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " Linear(in_features=10, out_features=20, bias=False)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = LinBnDrop(10, 20, p=0.1)\n",
    "tst\n",
    "mods = list(tst.children())\n",
    "mods\n",
    "test_eq(len(mods), 3)\n",
    "assert isinstance(mods[0], nn.BatchNorm1d)\n",
    "assert isinstance(mods[1], nn.Dropout)\n",
    "assert isinstance(mods[2], nn.Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinBnDrop(\n",
       "  (0): Linear(in_features=10, out_features=20, bias=False)\n",
       "  (1): ReLU()\n",
       "  (2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=10, out_features=20, bias=False),\n",
       " ReLU(),\n",
       " BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = LinBnDrop(10, 20, act=nn.ReLU(), lin_first=True)\n",
    "tst\n",
    "mods = list(tst.children())\n",
    "mods\n",
    "test_eq(len(mods), 3)\n",
    "assert isinstance(mods[0], nn.Linear)\n",
    "assert isinstance(mods[1], nn.ReLU)\n",
    "assert isinstance(mods[2], nn.BatchNorm1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinBnDrop(\n",
       "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=10, out_features=20, bias=True)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = LinBnDrop(10, 20, bn=False)\n",
    "tst\n",
    "mods = list(tst.children())\n",
    "mods\n",
    "test_eq(len(mods), 1)\n",
    "assert isinstance(mods[0], nn.Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```clamp(min, max)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function clamp:\n",
      "\n",
      "clamp(...) method of torch.Tensor instance\n",
      "    clamp(min=None, max=None) -> Tensor\n",
      "    \n",
      "    See :func:`torch.clamp`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(x.clamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3040, -0.8230,  1.9708],\n",
       "        [-0.7702,  0.2772, -1.4552]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.7865, 0.3051, 0.8777],\n",
       "        [0.3164, 0.5689, 0.1892]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.3051, 0.5000],\n",
       "        [0.3164, 0.5000, 0.1892]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3)\n",
    "x\n",
    "x.sigmoid()\n",
    "x.sigmoid().clamp(0,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```sigmoid(input, eps=1e-7)```\n",
    "official docs: Same as `torch.sigmoid`, plus clamping to `(eps,1-eps)`\n",
    "\n",
    "mydoc: wrap around `torch.sigmoid` and clamping values to be within `[eps, 1-eps]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L201){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sigmoid\n",
       "\n",
       ">      sigmoid (input, eps=1e-07)\n",
       "\n",
       "Same as `torch.sigmoid`, plus clamping to `(eps,1-eps)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L201){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sigmoid\n",
       "\n",
       ">      sigmoid (input, eps=1e-07)\n",
       "\n",
       "Same as `torch.sigmoid`, plus clamping to `(eps,1-eps)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0752, -0.0275, -0.4274],\n",
       "        [ 0.1253,  0.2610,  0.0779]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2544, 0.4931, 0.3947],\n",
       "        [0.5313, 0.5649, 0.5195]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2544, 0.4931, 0.3947],\n",
       "        [0.5000, 0.5000, 0.5000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3)\n",
    "x\n",
    "x.sigmoid()\n",
    "x.sigmoid().clamp(0,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2544, 0.4931, 0.3947],\n",
       "        [0.5313, 0.5649, 0.5195]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0752, -0.0275, -0.4274],\n",
       "        [ 0.1253,  0.2610,  0.0779]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```sigmoid_(input, eps=1e-7)```\n",
    "official docs: Same as `torch.sigmoid_`, plus clamping to `(eps,1-eps)`\n",
    "\n",
    "mydoc: inplace version of [`sigmoid`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L206){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sigmoid_\n",
       "\n",
       ">      sigmoid_ (input, eps=1e-07)\n",
       "\n",
       "Same as `torch.sigmoid_`, plus clamping to `(eps,1-eps)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L206){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sigmoid_\n",
       "\n",
       ">      sigmoid_ (input, eps=1e-07)\n",
       "\n",
       "Same as `torch.sigmoid_`, plus clamping to `(eps,1-eps)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(sigmoid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8335, -0.1666,  0.6176],\n",
       "        [ 1.5064,  0.5305, -1.0481]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6971, 0.4584, 0.6497],\n",
       "        [0.8185, 0.6296, 0.2596]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6971, 0.4584, 0.6497],\n",
       "        [0.8185, 0.6296, 0.2596]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3)\n",
    "x\n",
    "sigmoid_(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```kaiming_uniform_,uniform_,xavier_uniform_,normal_``` from `torch.nn.init`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```vleaky_relu(input, inplace=True)```\n",
    "original docs: `F.leaky_relu` with 0.3 slope\n",
    "\n",
    "mydoc: wrap `F.leaky_rely` and set `negative_slop` to 0.3 and set `inplace` True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L214){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### vleaky_relu\n",
       "\n",
       ">      vleaky_relu (input, inplace=True)\n",
       "\n",
       "`F.leaky_relu` with 0.3 slope"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L214){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### vleaky_relu\n",
       "\n",
       ">      vleaky_relu (input, inplace=True)\n",
       "\n",
       "`F.leaky_relu` with 0.3 slope"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(vleaky_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9864,  2.3052,  0.5506],\n",
       "        [ 2.5464, -0.7592, -0.4969]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0099,  2.3052,  0.5506],\n",
       "        [ 2.5464, -0.0076, -0.0050]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2959,  2.3052,  0.5506],\n",
       "        [ 2.5464, -0.2277, -0.1491]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3)\n",
    "x\n",
    "F.leaky_relu(x)\n",
    "vleaky_relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```__default_init__``` of all ReLus are set to ```kaiming_uniform_```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```__default_init__``` of all sigmoid are set to ```xavier_uniform_```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```nested_callable(m, 'bias.fill_')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4230, -0.0635])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Linear(3,2)\n",
    "m.bias.data\n",
    "with torch.no_grad(): nested_callable(m, 'bias.fill_')(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```init_default(m, func=nn.init.kaiming_normal_)```\n",
    "official docs:Initialize `m` weights with `func` and set `bias` to 0.\n",
    "\n",
    "mydoc: \n",
    "- initialize a model `m.weight` with `func` which default to `kaiming_normal_`\n",
    "- initialize `m.bias` with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L227){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### init_default\n",
       "\n",
       ">      init_default (m, func=<function kaiming_normal_>)\n",
       "\n",
       "Initialize `m` weights with `func` and set `bias` to 0."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L227){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### init_default\n",
       "\n",
       ">      init_default (m, func=<function kaiming_normal_>)\n",
       "\n",
       "Initialize `m` weights with `func` and set `bias` to 0."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(init_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2378,  0.3854, -0.2254],\n",
       "        [-0.2904,  0.4997, -0.1770]], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1925, -0.3759], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=2, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.5843,  1.3520, -0.3061],\n",
       "        [-0.8992, -0.6008, -1.3654]], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Linear(3,2)\n",
    "m.weight\n",
    "m.bias\n",
    "init_default(m)\n",
    "m.weight\n",
    "m.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```init_linear(m, act_func=None, init='auto', bias_std=0.01)```\n",
    "mydoc: initialize a linear layer or any layer's weight and bias\n",
    "- normalize bias with 0 mean and bias_std=0.01 by default; if bias is not available or bias_std is None, then set biase to be 0\n",
    "- normalize weight with `kaiming_uniform_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L234){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### init_linear\n",
       "\n",
       ">      init_linear (m, act_func=None, init='auto', bias_std=0.01)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L234){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### init_linear\n",
       "\n",
       ">      init_linear (m, act_func=None, init='auto', bias_std=0.01)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(init_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.init.normal_(tensor: torch.Tensor, mean: float = 0.0, std: float = 1.0) -> torch.Tensor>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```_conv_func(ndim=2, transpose=False)```\n",
    "official: Return the proper conv `ndim` function, potentially a `transposed`\n",
    "\n",
    "mydoc: return a conv layer with 1d to 3d, can be transposed if set True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```defaults.activation``` is set to `nn.ReLU`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```weight_norm```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=20, out_features=40, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=20, out_features=40, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 20])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# help(weight_norm)\n",
    "nn.Linear(20, 40)\n",
    "m = weight_norm(nn.Linear(20, 40), name='weight')\n",
    "m\n",
    "m.weight_g.size()\n",
    "m.weight_v.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```ConvLayer(nn.Sequential)```\n",
    "official:    Create a sequence of convolutional (`ni` to `nf`), ReLU (if `use_activ`) and `norm_type` layers.\n",
    "\n",
    "mydoc: create a block/sequence of layers including convolutional, ReLU and norm_type layers\n",
    "- use `padding` and `transpose` to set padding to be `(ks-1)/2` or 0\n",
    "- set `bn` True if either `NormType.Batch` or `NormType.BatchZero`\n",
    "- set `inn` True if either `NormType.Instance` or `NormType.InstanceZero`\n",
    "- set `bias` True, if `bn` or `inn` is False and `bias` is given as None\n",
    "- `conv_func` is assigned to a conv layer class created by [`_conv_func`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#_conv_func) with `ndim` dimension and `transpose` or not\n",
    "- `conv` is assigned to an actual conv layer object by running `conv_func(ni, nf, kernel_size=ks, bias=bias, stride=stride, padding=padding, **kwargs)`\n",
    "- `act` is assigned to None or a layer class by calling `act_cls()` which gives us ReLU\n",
    "- use `init_linear(conv, act, init=init, bias_std=bias_std)` to initialize weight and bias of `conv` \n",
    "- use `weight_norm` or `spectral_norm` to normalize the weight of `conv` if `norm_type == NormType.Weight` or `==NormType.Spectral`\n",
    "- create a list `act_bn` to store `act` layer, `BatchNorm(nf, norm_type=norm_type, ndim=ndim)`, `InstanceNorm(nf, norm_type=norm_type, ndim=ndim)` if `act is not None`, `bn, inn` are True respectively; and reverse the list order if `bn_1st` True\n",
    "- put `conv` layer in the front of the `act_bn` list and assign the new list to `layers`\n",
    "- if there is `xtra` layer, then add it to the end of the list `layers`\n",
    "- finally asking the `super()` i.e., `nn.Sequential` initialze all the layers inside `layers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L254){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ConvLayer\n",
       "\n",
       ">      ConvLayer (ni, nf, ks=3, stride=1, padding=None, bias=None, ndim=2,\n",
       ">                 norm_type=<NormType.Batch: 1>, bn_1st=True, act_cls=<class\n",
       ">                 'torch.nn.modules.activation.ReLU'>, transpose=False,\n",
       ">                 init='auto', xtra=None, bias_std=0.01,\n",
       ">                 dilation:Union[int,Tuple[int,int]]=1, groups:int=1,\n",
       ">                 padding_mode:str='zeros', device=None, dtype=None)\n",
       "\n",
       "Create a sequence of convolutional (`ni` to `nf`), ReLU (if `use_activ`) and `norm_type` layers."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L254){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ConvLayer\n",
       "\n",
       ">      ConvLayer (ni, nf, ks=3, stride=1, padding=None, bias=None, ndim=2,\n",
       ">                 norm_type=<NormType.Batch: 1>, bn_1st=True, act_cls=<class\n",
       ">                 'torch.nn.modules.activation.ReLU'>, transpose=False,\n",
       ">                 init='auto', xtra=None, bias_std=0.01,\n",
       ">                 dilation:Union[int,Tuple[int,int]]=1, groups:int=1,\n",
       ">                 padding_mode:str='zeros', device=None, dtype=None)\n",
       "\n",
       "Create a sequence of convolutional (`ni` to `nf`), ReLU (if `use_activ`) and `norm_type` layers."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ConvLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolution uses `ks` (kernel size) `stride`, `padding` and `bias`. `padding` will default to the appropriate value (`(ks-1)//2` if it's not a transposed conv) and `bias` will default to `True` the `norm_type` is `Spectral` or `Weight`, `False` if it's `Batch` or `BatchZero`. Note that if you don't want any normalization, you should pass `norm_type=None`.\n",
    "\n",
    "This defines a conv layer with `ndim` (1,2 or 3) that will be a ConvTranspose if `transpose=True`. `act_cls` is the class of the activation function to use (instantiated inside). Pass `act=None` if you don't want an activation function. If you quickly want to change your default activation, you can change the value of `defaults.activation`.\n",
    "\n",
    "`init` is used to initialize the weights (the bias are initialized to 0) and `xtra` is an optional layer to add at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLayer(\n",
       "  (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = ConvLayer(16, 32)\n",
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU()]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods = list(tst.children())\n",
    "mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(len(mods), 3)\n",
    "test_eq(mods[1].weight, torch.ones(32))\n",
    "test_eq(mods[0].padding, (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(64, 16, 8, 8)#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#Padding is selected to make the shape the same if stride=1\n",
    "test_eq(tst(x).shape, [64,32,8,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#Padding is selected to make the shape half if stride=2\n",
    "tst = ConvLayer(16, 32, stride=2)\n",
    "test_eq(tst(x).shape, [64,32,4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#But you can always pass your own padding if you want\n",
    "tst = ConvLayer(16, 32, padding=0)\n",
    "test_eq(tst(x).shape, [64,32,6,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#No bias by default for Batch NormType\n",
    "assert mods[0].bias is None\n",
    "#But can be overridden with `bias=True`\n",
    "tst = ConvLayer(16, 32, bias=True)\n",
    "assert first(tst.children()).bias is not None\n",
    "#For no norm, or spectral/weight, bias is True by default\n",
    "for t in [None, NormType.Spectral, NormType.Weight]:\n",
    "    tst = ConvLayer(16, 32, norm_type=t)\n",
    "    assert first(tst.children()).bias is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#Various n_dim/tranpose\n",
    "tst = ConvLayer(16, 32, ndim=3)\n",
    "assert isinstance(list(tst.children())[0], nn.Conv3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "tst = ConvLayer(16, 32, ndim=1, transpose=True)\n",
    "assert isinstance(list(tst.children())[0], nn.ConvTranspose1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLayer(\n",
       "  (0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No activation/leaky\n",
    "tst = ConvLayer(16, 32, ndim=3, act_cls=None)\n",
    "tst\n",
    "mods = list(tst.children())\n",
    "mods\n",
    "test_eq(len(mods), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLayer(\n",
       "  (0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): LeakyReLU(negative_slope=0.1)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " LeakyReLU(negative_slope=0.1)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = ConvLayer(16, 32, ndim=3, act_cls=partial(nn.LeakyReLU, negative_slope=0.1))\n",
    "tst\n",
    "mods = list(tst.children())\n",
    "mods\n",
    "test_eq(len(mods), 3)\n",
    "assert isinstance(mods[2], nn.LeakyReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #export\n",
    "# def linear(in_features, out_features, bias=True, act_cls=None, init='auto'):\n",
    "#     \"Linear layer followed by optional activation, with optional auto-init\"\n",
    "#     res = nn.Linear(in_features, out_features, bias=bias)\n",
    "#     if act_cls: act_cls = act_cls()\n",
    "#     init_linear(res, act_cls, init=init)\n",
    "#     if act_cls: res = nn.Sequential(res, act_cls)\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #export\n",
    "# @delegates(ConvLayer)\n",
    "# def conv1d(ni, nf, ks, stride=1, ndim=1, norm_type=None, **kwargs):\n",
    "#     \"Convolutional layer followed by optional activation, with optional auto-init\"\n",
    "#     return ConvLayer(ni, nf, ks, stride=stride, ndim=ndim, norm_type=norm_type, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #export\n",
    "# @delegates(ConvLayer)\n",
    "# def conv2d(ni, nf, ks, stride=1, ndim=2, norm_type=None, **kwargs):\n",
    "#     \"Convolutional layer followed by optional activation, with optional auto-init\"\n",
    "#     return ConvLayer(ni, nf, ks, stride=stride, ndim=ndim, norm_type=norm_type, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #export\n",
    "# @delegates(ConvLayer)\n",
    "# def conv3d(ni, nf, ks, stride=1, ndim=3, norm_type=None, **kwargs):\n",
    "#     \"Convolutional layer followed by optional activation, with optional auto-init\"\n",
    "#     return ConvLayer(ni, nf, ks, stride=stride, ndim=ndim, norm_type=norm_type, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```AdaptiveAvgPool(sz=1, ndim=2)```\n",
    "official: nn.AdaptiveAvgPool layer for `ndim`\n",
    "\n",
    "instantiate an AdaptiveAvgPool2d layer object with 1 activation output by default\n",
    "- it can be 1d to 3d\n",
    "- it can output any number of activations with `sz` arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L280){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AdaptiveAvgPool\n",
       "\n",
       ">      AdaptiveAvgPool (sz=1, ndim=2)\n",
       "\n",
       "nn.AdaptiveAvgPool layer for `ndim`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L280){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AdaptiveAvgPool\n",
       "\n",
       ">      AdaptiveAvgPool (sz=1, ndim=2)\n",
       "\n",
       "nn.AdaptiveAvgPool layer for `ndim`"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(AdaptiveAvgPool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveAvgPool3d(output_size=3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaptiveAvgPool(3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```MaxPool(ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)```\n",
    "official: nn.MaxPool layer for `ndim`\n",
    "\n",
    "instantiate an nn.MaxPool2d layer object with kernel size 2, stride 2, padding 0, no ceil_mode by default\n",
    "- it can be 1d to 3d\n",
    "- according to `nn.MaxPool2d`, by default `stride` is equal to `ks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L286){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MaxPool\n",
       "\n",
       ">      MaxPool (ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)\n",
       "\n",
       "nn.MaxPool layer for `ndim`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L286){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MaxPool\n",
       "\n",
       ">      MaxPool (ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)\n",
       "\n",
       "nn.MaxPool layer for `ndim`"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(MaxPool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# help(nn.MaxPool2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MaxPool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MaxPool(3, ndim=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```AvgPool(ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)```\n",
    "official: nn.AvgPool layer for `ndim`\n",
    "\n",
    "instantiate an nn.AvgPool2d layer object with kernel size 2, stride 2, padding 0, no ceil_mode by default\n",
    "- it can be 1d to 3d\n",
    "- according to `nn.AvgPool2d`, by default `stride` is equal to `ks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L292){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AvgPool\n",
       "\n",
       ">      AvgPool (ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)\n",
       "\n",
       "nn.AvgPool layer for `ndim`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L292){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AvgPool\n",
       "\n",
       ">      AvgPool (ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)\n",
       "\n",
       "nn.AvgPool layer for `ndim`"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(AvgPool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AvgPool2d(kernel_size=2, stride=2, padding=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "AvgPool3d(kernel_size=3, stride=5, padding=2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AvgPool()\n",
    "AvgPool(3, 5, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```trunc_normal_(x, mean=0., std=1.)```\n",
    "official: Truncated normal initialization (approximation)\n",
    "\n",
    "This is to implement a finding from a paper. There is discussion on how to implement it. https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L298){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### trunc_normal_\n",
       "\n",
       ">      trunc_normal_ (x, mean=0.0, std=1.0)\n",
       "\n",
       "Truncated normal initialization (approximation)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L298){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### trunc_normal_\n",
       "\n",
       ">      trunc_normal_ (x, mean=0.0, std=1.0)\n",
       "\n",
       "Truncated normal initialization (approximation)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(trunc_normal_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```Embedding(nn.Embedding)```\n",
    "official: Embedding layer with truncated normal initialization\n",
    "\n",
    "- is a subclass of `nn.Embedding`\n",
    "- instantiate an embedding layer with `nn.Embedding(num_input, n_features, std=0.01)`\n",
    "- then apply truncated normalization on the weight using std=0.01 by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L304){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Embedding\n",
       "\n",
       ">      Embedding (ni, nf, std=0.01)\n",
       "\n",
       "Embedding layer with truncated normal initialization"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L304){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Embedding\n",
       "\n",
       ">      Embedding (ni, nf, std=0.01)\n",
       "\n",
       "Embedding layer with truncated normal initialization"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(10, 5)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding(10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncated normal initialization bounds the distribution to avoid large value. For a given standard deviation `std`, the bounds are roughly `-2*std`, `2*std`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "std = 0.02\n",
    "tst = Embedding(10, 30, std)\n",
    "assert tst.weight.min() > -2*std\n",
    "assert tst.weight.max() < 2*std\n",
    "test_close(tst.weight.mean(), 0, 1e-2)\n",
    "test_close(tst.weight.std(), std, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```SelfAttention(Module)```\n",
    "official: Self attention layer for `n_channels`.\n",
    "\n",
    "To build SelfAttention from scratch, key implementation details is discussed below\n",
    "- `sa = SelfAttention(n_channels)` to instantiate a SelfAttention layer\n",
    "- during instantiation, 3 conv1d layers are created with `n_in`, `n_out` calculated based on `n_channels`\n",
    "- the forward function is to implement the paper in the link below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L311){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SelfAttention\n",
       "\n",
       ">      SelfAttention (n_channels)\n",
       "\n",
       "Self attention layer for `n_channels`."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L311){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SelfAttention\n",
       "\n",
       ">      SelfAttention (n_channels)\n",
       "\n",
       "Self attention layer for `n_channels`."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(SelfAttention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-attention layer as introduced in [Self-Attention Generative Adversarial Networks](https://arxiv.org/abs/1805.08318).\n",
    "\n",
    "Initially, no change is done to the input. This is controlled by a trainable parameter named `gamma` as we return `x + gamma * out`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelfAttention(\n",
       "  (query): ConvLayer(\n",
       "    (0): Conv1d(16, 2, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (key): ConvLayer(\n",
       "    (0): Conv1d(16, 2, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (value): ConvLayer(\n",
       "    (0): Conv1d(16, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = SelfAttention(16)\n",
    "tst\n",
    "tst.gamma.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(32, 16, 8, 8)\n",
    "test_eq(tst(x),x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then during training `gamma` will probably change since it's a trainable parameter. Let's see what's happening when it gets a nonzero value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst.gamma.data.fill_(1.)\n",
    "y = tst(x)\n",
    "test_eq(y.shape, [32,16,8,8])\n",
    "test_ne(y, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attention mechanism requires three matrix multiplications (here represented by 1x1 convs). The multiplications are done on the channel level (the second dimension in our tensor) and we flatten the feature map (which is 8x8 here). As in the paper, we note [`f`](https://EmbraceLife.github.io/fastdebug/fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#f), `g` and `h` the results of those multiplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLayer(\n",
       "  (0): Conv1d(16, 2, kernel_size=(1,), stride=(1,), bias=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Conv1d(16, 2, kernel_size=(1,), stride=(1,), bias=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst.query\n",
    "tst.query[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "q,k,v = tst.query[0].weight.data,tst.key[0].weight.data,tst.value[0].weight.data\n",
    "test_eq([q.shape, k.shape, v.shape], [[2, 16, 1], [2, 16, 1], [16, 16, 1]])\n",
    "f,g,h = map(lambda m: x.view(32, 16, 64).transpose(1,2) @ m.squeeze().t(), [q,k,v])\n",
    "test_eq([f.shape, g.shape, h.shape], [[32,64,2], [32,64,2], [32,64,16]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key part of the attention layer is to compute attention weights for each of our location in the feature map (here 8x8 = 64). Those are positive numbers that sum to 1 and tell the model to pay attention to this or that part of the picture. We make the product of [`f`](https://EmbraceLife.github.io/fastdebug/fastai_notebooks/fastai_first_steps_road_to_top_part_1.html#f) and the transpose of `g` (to get something of size bs by 64 by 64) then apply a softmax on the first dimension (to get the positive numbers that sum up to 1). The result can then be multiplied with `h` transposed to get an output of size bs by channels by 64, which we can then be viewed as an output the same size as the original input. \n",
    "\n",
    "The final result is then `x + gamma * out` as we saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "beta = F.softmax(torch.bmm(f, g.transpose(1,2)), dim=1)\n",
    "test_eq(beta.shape, [32, 64, 64])\n",
    "out = torch.bmm(h.transpose(1,2), beta)\n",
    "test_eq(out.shape, [32, 16, 64])\n",
    "test_close(y, x + out.view(32, 16, 8, 8), eps=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```PooledSelfAttention2d(Module)```\n",
    "official: Pooled self attention layer for 2d.\n",
    "\n",
    "Implemented from scratch and build with the template of [`SelfAttention`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#selfattention), and the difference between [`SelfAttention`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#selfattention) is discussed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L330){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PooledSelfAttention2d\n",
       "\n",
       ">      PooledSelfAttention2d (n_channels)\n",
       "\n",
       "Pooled self attention layer for 2d."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L330){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PooledSelfAttention2d\n",
       "\n",
       ">      PooledSelfAttention2d (n_channels)\n",
       "\n",
       "Pooled self attention layer for 2d."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(PooledSelfAttention2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-attention layer used in the [Big GAN paper](https://arxiv.org/abs/1809.11096).\n",
    "\n",
    "It uses the same attention as in [`SelfAttention`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#selfattention) but adds a max pooling of stride 2 before computing the matrices `g` and `h`: the attention is ported on one of the 2x2 max-pooled window, not the whole feature map. There is also a final matrix product added at the end to the output, before retuning `gamma * out + x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PooledSelfAttention2d(\n",
       "  (query): ConvLayer(\n",
       "    (0): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (key): ConvLayer(\n",
       "    (0): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (value): ConvLayer(\n",
       "    (0): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (out): ConvLayer(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PooledSelfAttention2d(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```_conv1d_spect(ni:int, no:int, ks:int=1, stride:int=1, padding:int=0, bias:bool=False)```\n",
    "official : Create and initialize a `nn.Conv1d` layer with spectral normalization.\n",
    "\n",
    "- create a conv1d layer with `nn.Conv1d(ni, no, ks, stride=stride, padding=padding, bias=bias)`\n",
    "- initialize it with `nn.init.kaiming_normal_(conv.weight)`\n",
    "- if `bias=True`, make them zero\n",
    "- run spectral normalization on this conv layer and return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(3, 2, kernel_size=(1,), stride=(1,), bias=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_conv1d_spect(3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```SimpleSelfAttention(self, n_in:int, ks=1, sym=False)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L359){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SimpleSelfAttention\n",
       "\n",
       ">      SimpleSelfAttention (n_in:int, ks=1, sym=False)\n",
       "\n",
       "Same as `nn.Module`, but no need for subclasses to call `super().__init__`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L359){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SimpleSelfAttention\n",
       "\n",
       ">      SimpleSelfAttention (n_in:int, ks=1, sym=False)\n",
       "\n",
       "Same as `nn.Module`, but no need for subclasses to call `super().__init__`"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(SimpleSelfAttention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PixelShuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PixelShuffle introduced in [this article](https://arxiv.org/pdf/1609.05158.pdf) to avoid checkerboard artifacts when upsampling images. If we want an output with `ch_out` filters, we use a convolution with `ch_out * (r**2)` filters, where `r` is the upsampling factor. Then we reorganize those filters like in the picture below:\n",
    "\n",
    "<img src=\"images/pixelshuffle.png\" alt=\"Pixelshuffle\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```icnr_init(x, scale=2, init=nn.init.kaiming_normal_)```\n",
    "official: ICNR init of `x`, with `scale` and `init` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L382){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### icnr_init\n",
       "\n",
       ">      icnr_init (x, scale=2, init=<function kaiming_normal_>)\n",
       "\n",
       "ICNR init of `x`, with `scale` and `init` function"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L382){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### icnr_init\n",
       "\n",
       ">      icnr_init (x, scale=2, init=<function kaiming_normal_>)\n",
       "\n",
       "ICNR init of `x`, with `scale` and `init` function"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(icnr_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICNR init was introduced in [this article](https://arxiv.org/abs/1707.02937). It suggests to initialize the convolution that will be used in PixelShuffle so that each of the `r**2` channels get the same weight (so that in the picture above, the 9 colors in a 3 by 3 window are initially the same).\n",
    "\n",
    "> Note: This is done on the first dimension because PyTorch stores the weights of a convolutional layer in this format: `ch_out x ch_in x ks x ks`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "tst = torch.randn(16*4, 32, 1, 1)\n",
    "tst = icnr_init(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "for i in range(0,16*4,4):\n",
    "    test_eq(tst[i],tst[i+1])\n",
    "    test_eq(tst[i],tst[i+2])\n",
    "    test_eq(tst[i],tst[i+3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```PixelShuffle_ICNR(nn.Sequential)```\n",
    "official: Upsample by `scale` from `ni` filters to `nf` (default `ni`), using `nn.PixelShuffle`.\n",
    "\n",
    "- subclass of `nn.Sequential`\n",
    "- if `nf` is None, set it to be `ni`\n",
    "- create a list of layers, by default they are Conv2d, ReLU, PixelShuffle\n",
    "- if NormType.Weight, apply ICNR init to Conv2d's weight_v, and weight_g\n",
    "- if blur, add nn.ReplicationPad2d, nn.AvgPool2d to the layers list\n",
    "- finally, put all the layers into the Sequential block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L393){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PixelShuffle_ICNR\n",
       "\n",
       ">      PixelShuffle_ICNR (ni, nf=None, scale=2, blur=False,\n",
       ">                         norm_type=<NormType.Weight: 3>, act_cls=<class\n",
       ">                         'torch.nn.modules.activation.ReLU'>)\n",
       "\n",
       "Upsample by `scale` from `ni` filters to `nf` (default `ni`), using `nn.PixelShuffle`."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L393){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PixelShuffle_ICNR\n",
       "\n",
       ">      PixelShuffle_ICNR (ni, nf=None, scale=2, blur=False,\n",
       ">                         norm_type=<NormType.Weight: 3>, act_cls=<class\n",
       ">                         'torch.nn.modules.activation.ReLU'>)\n",
       "\n",
       "Upsample by `scale` from `ni` filters to `nf` (default `ni`), using `nn.PixelShuffle`."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(PixelShuffle_ICNR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolutional layer is initialized with [`icnr_init`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#icnr_init) and passed `act_cls` and `norm_type` (the default of weight normalization seemed to be what's best for super-resolution problems, in our experiments). \n",
    "\n",
    "The `blur` option comes from [Super-Resolution using Convolutional Neural Networks without Any Checkerboard Artifacts](https://arxiv.org/abs/1806.02658) where the authors add a little bit of blur to completely get rid of checkerboard artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PixelShuffle_ICNR(\n",
       "  (0): ConvLayer(\n",
       "    (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (1): PixelShuffle(upscale_factor=2)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "PixelShuffle(upscale_factor=2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psfl = PixelShuffle_ICNR(16)\n",
    "psfl\n",
    "psfl[0][0]\n",
    "psfl[0][1]\n",
    "psfl[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| psfl(x).shape: torch.Size([64, 16, 16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 16, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| psfl[0][0](x).shape: torch.Size([64, 64, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 8, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| psfl[0][1](layer1).shape: torch.Size([64, 64, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 8, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| psfl[1](layer2).shape: torch.Size([64, 16, 16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 16, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(64, 16, 8, 8)\n",
    "y = psfl(x)\n",
    "ic(psfl(x).shape)\n",
    "ic(psfl[0][0](x).shape)\n",
    "layer1 = psfl[0][0](x)\n",
    "ic(psfl[0][1](layer1).shape)\n",
    "layer2 = psfl[0][1](layer1)\n",
    "ic(psfl[1](layer2).shape)\n",
    "\n",
    "test_eq(y.shape, [64, 16, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#ICNR init makes every 2x2 window (stride 2) have the same elements\n",
    "for i in range(0,16,2):\n",
    "    for j in range(0,16,2):\n",
    "        test_eq(y[:,:,i,j],y[:,:,i+1,j])\n",
    "        test_eq(y[:,:,i,j],y[:,:,i  ,j+1])\n",
    "        test_eq(y[:,:,i,j],y[:,:,i+1,j+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "psfl = PixelShuffle_ICNR(16, norm_type=None)\n",
    "x = torch.randn(64, 16, 8, 8)\n",
    "y = psfl(x)\n",
    "test_eq(y.shape, [64, 16, 16, 16])\n",
    "#ICNR init makes every 2x2 window (stride 2) have the same elements\n",
    "for i in range(0,16,2):\n",
    "    for j in range(0,16,2):\n",
    "        test_eq(y[:,:,i,j],y[:,:,i+1,j])\n",
    "        test_eq(y[:,:,i,j],y[:,:,i  ,j+1])\n",
    "        test_eq(y[:,:,i,j],y[:,:,i+1,j+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "psfl = PixelShuffle_ICNR(16, norm_type=NormType.Spectral)\n",
    "x = torch.randn(64, 16, 8, 8)\n",
    "y = psfl(x)\n",
    "test_eq(y.shape, [64, 16, 16, 16])\n",
    "#ICNR init makes every 2x2 window (stride 2) have the same elements\n",
    "for i in range(0,16,2):\n",
    "    for j in range(0,16,2):\n",
    "        test_eq(y[:,:,i,j],y[:,:,i+1,j])\n",
    "        test_eq(y[:,:,i,j],y[:,:,i  ,j+1])\n",
    "        test_eq(y[:,:,i,j],y[:,:,i+1,j+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```sequential(*args)```\n",
    "official: Create an `nn.Sequential`, wrapping items with [`Lambda`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#lambda) if needed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# help(Lambda)\n",
    "# help(nn.ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L410){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sequential\n",
       "\n",
       ">      sequential (*args)\n",
       "\n",
       "Create an `nn.Sequential`, wrapping items with [`Lambda`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#lambda) if needed"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L410){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sequential\n",
       "\n",
       ">      sequential (*args)\n",
       "\n",
       "Create an `nn.Sequential`, wrapping items with `Lambda` if needed"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Lambda(func=<class 'torch.nn.modules.activation.ReLU'>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lambda(nn.ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): __main__.Lambda(func=[<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.linear.Linear'>])\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential()\n",
    "sequential([nn.ReLU, nn.Linear])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```SequentialEx(Module)```\n",
    "official: Like `nn.Sequential`, but with ModuleList semantics, and can access module input\"\n",
    "\n",
    "To build a block of layers and let x pass through them one after another and each layer's input remembers the original input\n",
    "- This is useful to write layers that require to remember the input (like a resnet block) in a sequential way.\n",
    "- the input is remembered as `x.orig` or `res.orig` before running `l(res)` so that `MergeLayer.forward(res)` defined below can utilize `res.orig` before setting to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L419){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SequentialEx\n",
       "\n",
       ">      SequentialEx (*layers)\n",
       "\n",
       "Like `nn.Sequential`, but with ModuleList semantics, and can access module input"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L419){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SequentialEx\n",
       "\n",
       ">      SequentialEx (*layers)\n",
       "\n",
       "Like `nn.Sequential`, but with ModuleList semantics, and can access module input"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(SequentialEx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful to write layers that require to remember the input (like a resnet block) in a sequential way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```MergeLayer(Module)```\n",
    "official: Merge a shortcut with the result of the module by adding them or concatenating them if `dense=True`.\n",
    "\n",
    "- MergeLayer() turns to be the last layer of the layer block, so `x` for MergeLayer.forward is usually the output of last layer\n",
    "- since MergeLayer is used inside SequentialEx, `x` will bring the original input `x.orig` into [`MergeLayer.forward`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#mergelayer.forward) to process\n",
    "- if `dense=False`, the output shape won't change as `x + x.orig`\n",
    "- if `dense=True`, the output shape (2nd dim) will double due to `torch.concat([x, x.orig], dim=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L440){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MergeLayer\n",
       "\n",
       ">      MergeLayer (dense:bool=False)\n",
       "\n",
       "Merge a shortcut with the result of the module by adding them or concatenating them if `dense=True`."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L440){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MergeLayer\n",
       "\n",
       ">      MergeLayer (dense:bool=False)\n",
       "\n",
       "Merge a shortcut with the result of the module by adding them or concatenating them if `dense=True`."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(MergeLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(32, 16, 8, 8)\n",
    "res_block = SequentialEx(ConvLayer(16, 16), ConvLayer(16,16))\n",
    "y = res_block(x)\n",
    "test_eq(y.shape, (32, 16, 8, 8))\n",
    "test_eq(y.orig, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): ConvLayer(\n",
       "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): ConvLayer(\n",
       "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (2): MergeLayer()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_block.append(MergeLayer()) # just to test append - normally it would be in init params\n",
    "y1 = res_block(x)\n",
    "test_eq(y1.shape, [32, 16, 8, 8])\n",
    "test_eq(y1.orig, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): ConvLayer(\n",
       "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): ConvLayer(\n",
       "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (2): MergeLayer()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(32, 16, 8, 8)\n",
    "res_block = SequentialEx(ConvLayer(16, 16), ConvLayer(16,16))\n",
    "res_block.append(MergeLayer()) # just to test append - normally it would be in init params\n",
    "y = res_block(x)\n",
    "test_eq(y, x + res_block[1](res_block[0](x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): ConvLayer(\n",
       "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): ConvLayer(\n",
       "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (2): MergeLayer()\n",
       "  (3): MergeLayer()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_block.append(MergeLayer(True)) # just to test append - normally it would be in init params\n",
    "y = res_block(x)\n",
    "test_eq(y.shape, [32, 32, 8, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```Cat(nn.ModuleList)```\n",
    "official: Concatenate layers outputs over a given dim\n",
    "\n",
    "by default, the outputs of all layers inside the ModuleList will be concatenated on 2nd dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalent to keras.layers.Concatenate, it will concat the outputs of a ModuleList over a given dimension (default the filter dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L452){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Cat\n",
       "\n",
       ">      Cat (layers, dim=1)\n",
       "\n",
       "Concatenate layers outputs over a given dim"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L452){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Cat\n",
       "\n",
       ">      Cat (layers, dim=1)\n",
       "\n",
       "Concatenate layers outputs over a given dim"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(Cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cat(\n",
       "  (0): ConvLayer(\n",
       "    (0): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): ConvLayer(\n",
       "    (0): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (2): ConvLayer(\n",
       "    (0): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [ConvLayer(2,4), ConvLayer(2,4), ConvLayer(2,4)] \n",
    "x = torch.rand(1,2,8,8) \n",
    "cat = Cat(layers) \n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| l(x): class=<class 'torch.Tensor'>, shape=torch.Size([1, 4, 8, 8]), dtype=torch.float32\n",
      "ic| l(x): class=<class 'torch.Tensor'>, shape=torch.Size([1, 4, 8, 8]), dtype=torch.float32\n",
      "ic| l(x): class=<class 'torch.Tensor'>, shape=torch.Size([1, 4, 8, 8]), dtype=torch.float32\n"
     ]
    }
   ],
   "source": [
    "test_eq(cat(x).shape, [1,12,8,8]) \n",
    "test_eq(cat(x), torch.cat([ic(l(x)) for l in layers], dim=1)) # a good use case for ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready-to-go models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```SimpleCNN(nn.Sequential)```\n",
    "Create a simple CNN with `filters`.\n",
    "\n",
    "- use `filters` like `[8, 16, 32]` to define `kernel_szs` and `strides`, and the number of Conv layers to create\n",
    "- then add a PoolFlatten layer\n",
    "- finally put them all into a Sequential block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L460){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SimpleCNN\n",
       "\n",
       ">      SimpleCNN (filters, kernel_szs=None, strides=None, bn=True)\n",
       "\n",
       "Create a simple CNN with `filters`."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L460){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SimpleCNN\n",
       "\n",
       ">      SimpleCNN (filters, kernel_szs=None, strides=None, bn=True)\n",
       "\n",
       "Create a simple CNN with `filters`."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(SimpleCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a succession of convolutional layers from `(filters[0],filters[1])` to `(filters[n-2],filters[n-1])` (if `n` is the length of the `filters` list) followed by a [`PoolFlatten`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#poolflatten). `kernel_szs` and `strides` defaults to a list of 3s and a list of 2s. If `bn=True` the convolutional layers are successions of conv-relu-batchnorm, otherwise conv-relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (0): ConvLayer(\n",
       "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): ConvLayer(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (2): PoolFlatten(\n",
       "    (0): AdaptiveAvgPool2d(output_size=1)\n",
       "    (1): __main__.Flatten(full=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = SimpleCNN([8,16,32])\n",
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "mods = list(tst.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(len(mods), 3)\n",
    "test_eq([[m[0].in_channels, m[0].out_channels] for m in mods[:2]], [[8,16], [16,32]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test kernel sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "tst = SimpleCNN([8,16,32], kernel_szs=[1,3])\n",
    "mods = list(tst.children())\n",
    "test_eq([m[0].kernel_size for m in mods[:2]], [(1,1), (3,3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "tst = SimpleCNN([8,16,32], strides=[1,2])\n",
    "mods = list(tst.children())\n",
    "test_eq([m[0].stride for m in mods[:2]], [(1,1),(2,2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```ProdLayer(Module)```\n",
    "official: Merge a shortcut with the result of the module by multiplying them.\n",
    "\n",
    "check ``[`MergeLayer`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#mergelayer)`` doc for better understanding of ProdLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L473){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ProdLayer\n",
       "\n",
       ">      ProdLayer ()\n",
       "\n",
       "Merge a shortcut with the result of the module by multiplying them."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L473){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ProdLayer\n",
       "\n",
       ">      ProdLayer ()\n",
       "\n",
       "Merge a shortcut with the result of the module by multiplying them."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ProdLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```inplace_relu```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```SEModule(ch, reduction, act_cls=defaults.activation)```\n",
    "Use SequentialEx to put AdaptiveAvgPool2d, 2 ConvLayer, ProdLayer together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L481){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SEModule\n",
       "\n",
       ">      SEModule (ch, reduction, act_cls=<class\n",
       ">                'torch.nn.modules.activation.ReLU'>)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L481){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SEModule\n",
       "\n",
       ">      SEModule (ch, reduction, act_cls=<class\n",
       ">                'torch.nn.modules.activation.ReLU'>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(SEModule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```ResBlock(Module)```\n",
    "official: Resnet block from `ni` to `nh` with `stride`\n",
    "\n",
    "How ResBlock is initialized\n",
    "- user inputs without default: `expansion`, `ni`, `nf`\n",
    "- `norm2` is to choose between `BatchZero`, `InstanceZero`, or other `norm_type`\n",
    "- `nh1` and `nh2` are defined by `nf`\n",
    "- `nf` and `ni` is multiplied with `expansion`\n",
    "- `k0`, `k1` are two dicts of norm_type, act_cls, ndim, and `**kwargs`\n",
    "- `convpath`: a list of ConvLayers; if expansion == 1, 2 ConvLayers; otherwise, 3 ConvLayers\n",
    "- if reduction, then add SEModule layer block\n",
    "- if sa: add SimpleSelfAttention \n",
    "- self.convpath: take all the layers above into a single Sequential\n",
    "- self.idpath: create a Sequential block in which there may or may be be a AvgPool and ConvLayer (position can switch too)\n",
    "- self.act: default.activation or act_cls()\n",
    "\n",
    "How ResBlock transforms input in `forward`\n",
    "- self.act(self.convpath(x) + self.idpath(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L489){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ResBlock\n",
       "\n",
       ">      ResBlock (expansion, ni, nf, stride=1, groups=1, reduction=None,\n",
       ">                nh1=None, nh2=None, dw=False, g2=1, sa=False, sym=False,\n",
       ">                norm_type=<NormType.Batch: 1>, act_cls=<class\n",
       ">                'torch.nn.modules.activation.ReLU'>, ndim=2, ks=3,\n",
       ">                pool=<function AvgPool>, pool_first=True, padding=None,\n",
       ">                bias=None, bn_1st=True, transpose=False, init='auto',\n",
       ">                xtra=None, bias_std=0.01, dilation:Union[int,Tuple[int,int]]=1,\n",
       ">                padding_mode:str='zeros', device=None, dtype=None)\n",
       "\n",
       "Resnet block from `ni` to `nh` with `stride`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L489){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ResBlock\n",
       "\n",
       ">      ResBlock (expansion, ni, nf, stride=1, groups=1, reduction=None,\n",
       ">                nh1=None, nh2=None, dw=False, g2=1, sa=False, sym=False,\n",
       ">                norm_type=<NormType.Batch: 1>, act_cls=<class\n",
       ">                'torch.nn.modules.activation.ReLU'>, ndim=2, ks=3,\n",
       ">                pool=<function AvgPool>, pool_first=True, padding=None,\n",
       ">                bias=None, bn_1st=True, transpose=False, init='auto',\n",
       ">                xtra=None, bias_std=0.01, dilation:Union[int,Tuple[int,int]]=1,\n",
       ">                padding_mode:str='zeros', device=None, dtype=None)\n",
       "\n",
       "Resnet block from `ni` to `nh` with `stride`"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ResBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a resnet block (normal or bottleneck depending on `expansion`, 1 for the normal block and 4 for the traditional bottleneck) that implements the tweaks from [Bag of Tricks for Image Classification with Convolutional Neural Networks](https://arxiv.org/abs/1812.01187). In particular, the last batchnorm layer (if that is the selected `norm_type`) is initialized with a weight (or gamma) of zero to facilitate the flow from the beginning to the end of the network. It also implements optional [Squeeze and Excitation](https://arxiv.org/abs/1709.01507) and grouped convs for [ResNeXT](https://arxiv.org/abs/1611.05431) and similar models (use `dw=True` for depthwise convs).\n",
    "\n",
    "The `kwargs` are passed to [`ConvLayer`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#convlayer) along with `norm_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResBlock(\n",
       "  (convpath): Sequential(\n",
       "    (0): ConvLayer(\n",
       "      (0): Conv2d(4, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1): ConvLayer(\n",
       "      (0): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (idpath): Sequential(\n",
       "    (0): ConvLayer(\n",
       "      (0): Conv2d(4, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (act): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResBlock(1, 4, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```SEBlock(expansion, ni, nf, groups=1, reduction=16, stride=1, **kwargs)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L521){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SEBlock\n",
       "\n",
       ">      SEBlock (expansion, ni, nf, groups=1, reduction=16, stride=1, **kwargs)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L521){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SEBlock\n",
       "\n",
       ">      SEBlock (expansion, ni, nf, groups=1, reduction=16, stride=1, **kwargs)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(SEBlock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```SEResNeXtBlock(expansion, ni, nf, groups=32, reduction=16, stride=1, base_width=4, **kwargs)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L525){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SEResNeXtBlock\n",
       "\n",
       ">      SEResNeXtBlock (expansion, ni, nf, groups=32, reduction=16, stride=1,\n",
       ">                      base_width=4, **kwargs)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L525){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SEResNeXtBlock\n",
       "\n",
       ">      SEResNeXtBlock (expansion, ni, nf, groups=32, reduction=16, stride=1,\n",
       ">                      base_width=4, **kwargs)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(SEResNeXtBlock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```SeparableBlock(expansion, ni, nf, reduction=16, stride=1, base_width=4, **kwargs)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L530){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SeparableBlock\n",
       "\n",
       ">      SeparableBlock (expansion, ni, nf, reduction=16, stride=1, base_width=4,\n",
       ">                      **kwargs)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L530){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SeparableBlock\n",
       "\n",
       ">      SeparableBlock (expansion, ni, nf, reduction=16, stride=1, base_width=4,\n",
       ">                      **kwargs)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(SeparableBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# fastnbs(\"AvgPool(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Distributed Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalent to Keras [`TimeDistributed`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#timedistributed) Layer, enables computing pytorch [`Module`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_torch_core.html#module) over an axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```_stack_tups(tuples, stack_dim=1)```\n",
    "official: Stack tuple of tensors along `stack_dim`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```TimeDistributed(Module)```\n",
    "official: Applies [`module`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#module) over `tdim` identically for each step, use `low_mem` to compute one at a time.\n",
    "\n",
    "- apply on individual layer: `tconv = TimeDistributed(nn.Conv2d(3,4,1))`\n",
    "- on a user defined layer: `TimeDistributed(Mod())`\n",
    "- how to use low_memory: out = tmod(x,y)tmod.low_mem=True out_low_mem = tmod(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L549){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TimeDistributed\n",
       "\n",
       ">      TimeDistributed (module, low_mem=False, tdim=1)\n",
       "\n",
       "Applies [`module`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#module) over `tdim` identically for each step, use `low_mem` to compute one at a time."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L549){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TimeDistributed\n",
       "\n",
       ">      TimeDistributed (module, low_mem=False, tdim=1)\n",
       "\n",
       "Applies `module` over `tdim` identically for each step, use `low_mem` to compute one at a time."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(TimeDistributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 3, 2, 2]), torch.Size([2, 5, 3, 2, 2]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs, seq_len = 2, 5\n",
    "x, y = torch.rand(bs,seq_len,3,2,2), torch.rand(bs,seq_len,3,2,2)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "tconv = TimeDistributed(nn.Conv2d(3,4,1))\n",
    "test_eq(tconv(x).shape, (2,5,4,2,2))\n",
    "tconv.low_mem=True\n",
    "test_eq(tconv(x).shape, (2,5,4,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class Mod(Module):\n",
    "    def __init__(self):\n",
    "        self.conv = nn.Conv2d(3,4,1)\n",
    "    def forward(self, x, y):\n",
    "        return self.conv(x) + self.conv(y)\n",
    "tmod = TimeDistributed(Mod())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "out = tmod(x,y)\n",
    "test_eq(out.shape, (2,5,4,2,2))\n",
    "tmod.low_mem=True\n",
    "out_low_mem = tmod(x,y)\n",
    "test_eq(out_low_mem.shape, (2,5,4,2,2))\n",
    "test_eq(out, out_low_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class Mod2(Module):\n",
    "    def __init__(self):\n",
    "        self.conv = nn.Conv2d(3,4,1)\n",
    "    def forward(self, x, y):\n",
    "        return self.conv(x), self.conv(y)\n",
    "tmod2 = TimeDistributed(Mod2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "out = tmod2(x,y)\n",
    "test_eq(len(out), 2)\n",
    "test_eq(out[0].shape, (2,5,4,2,2))\n",
    "tmod2.low_mem=True\n",
    "out_low_mem = tmod2(x,y)\n",
    "test_eq(out_low_mem[0].shape, (2,5,4,2,2))\n",
    "test_eq(out, out_low_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# show_doc(TimeDistributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module is equivalent to [Keras TimeDistributed Layer](https://keras.io/api/layers/recurrent_layers/time_distributed/). This wrapper allows to apply a layer to every temporal slice of an input. By default it is assumed the time axis (`tdim`) is the 1st one (the one after the batch size). A typical usage would be to encode a sequence of images using an image encoder.\n",
    "\n",
    "The `forward` function of [`TimeDistributed`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_layers.html#timedistributed) supports `*args` and `**kkwargs` but only `args` will be split and passed to the underlying module independently for each timestep, `kwargs` will be passed as they are. This is useful when you have module that take multiple arguments as inputs, this way, you can put all tensors you need spliting as `args` and other arguments that don't need split as `kwargs`.\n",
    "\n",
    "> This module is heavy on memory, as it will try to pass mutiple timesteps at the same time on the batch dimension, if you get out of memorey errors, try first reducing your batch size by the number of timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `create_body` not found.\n"
     ]
    }
   ],
   "source": [
    "create_body??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = create_body(resnet18())\n",
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A resnet18 will encode a feature map of 512 channels. Height and Width will be divided by 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "time_resnet = TimeDistributed(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a synthetic batch of 2 image-sequences of lenght 5. `(bs, seq_len, ch, w, h)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "image_sequence = torch.rand(2, 5, 3, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 512, 2, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_resnet(image_sequence).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, one can encode a sequence of images on feature space.\n",
    "There is also a `low_mem_forward` that will pass images one at a time to reduce GPU memory consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 512, 2, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_resnet.low_mem_forward(image_sequence).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swish and Mish\n",
    "autograd in fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```script, _swish_ji_fwd, _SwishJitAutoFn, swish, Swish, _mish_jit_fwd```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L609){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### swish\n",
       "\n",
       ">      swish (x, inplace=False)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L609){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### swish\n",
       "\n",
       ">      swish (x, inplace=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(swish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L612){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Swish\n",
       "\n",
       ">      Swish ()\n",
       "\n",
       "Same as `nn.Module`, but no need for subclasses to call `super().__init__`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L612){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Swish\n",
       "\n",
       ">      Swish ()\n",
       "\n",
       "Same as `nn.Module`, but no need for subclasses to call `super().__init__`"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(Swish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L625){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MishJitAutoFn\n",
       "\n",
       ">      MishJitAutoFn (*args, **kwargs)\n",
       "\n",
       "Base class to create custom `autograd.Function`\n",
       "\n",
       "To create a custom `autograd.Function`, subclass this class and implement\n",
       "the :meth:`forward` and :meth:`backward` static methods. Then, to use your custom\n",
       "op in the forward pass, call the class method `[`apply`](https://EmbraceLife.github.io/fastdebug/lib/src_fastai_torch_core.html#apply)`. Do not call\n",
       ":meth:`forward` directly.\n",
       "\n",
       "To ensure correctness and best performance, make sure you are calling the\n",
       "correct methods on ``ctx`` and validating your backward function using\n",
       ":func:`torch.autograd.gradcheck`.\n",
       "\n",
       "See :ref:`extending-autograd` for more details on how to use this class.\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> class Exp(Function):\n",
       "    >>>     @staticmethod\n",
       "    >>>     def forward(ctx, i):\n",
       "    >>>         result = i.exp()\n",
       "    >>>         ctx.save_for_backward(result)\n",
       "    >>>         return result\n",
       "    >>>\n",
       "    >>>     @staticmethod\n",
       "    >>>     def backward(ctx, grad_output):\n",
       "    >>>         result, = ctx.saved_tensors\n",
       "    >>>         return grad_output * result\n",
       "    >>>\n",
       "    >>> # Use it by calling the apply method:\n",
       "    >>> output = Exp.apply(input)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L625){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MishJitAutoFn\n",
       "\n",
       ">      MishJitAutoFn (*args, **kwargs)\n",
       "\n",
       "Base class to create custom `autograd.Function`\n",
       "\n",
       "To create a custom `autograd.Function`, subclass this class and implement\n",
       "the :meth:`forward` and :meth:`backward` static methods. Then, to use your custom\n",
       "op in the forward pass, call the class method ``apply``. Do not call\n",
       ":meth:`forward` directly.\n",
       "\n",
       "To ensure correctness and best performance, make sure you are calling the\n",
       "correct methods on ``ctx`` and validating your backward function using\n",
       ":func:`torch.autograd.gradcheck`.\n",
       "\n",
       "See :ref:`extending-autograd` for more details on how to use this class.\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> class Exp(Function):\n",
       "    >>>     @staticmethod\n",
       "    >>>     def forward(ctx, i):\n",
       "    >>>         result = i.exp()\n",
       "    >>>         ctx.save_for_backward(result)\n",
       "    >>>         return result\n",
       "    >>>\n",
       "    >>>     @staticmethod\n",
       "    >>>     def backward(ctx, grad_output):\n",
       "    >>>         result, = ctx.saved_tensors\n",
       "    >>>         return grad_output * result\n",
       "    >>>\n",
       "    >>> # Use it by calling the apply method:\n",
       "    >>> output = Exp.apply(input)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(MishJitAutoFn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L637){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### mish\n",
       "\n",
       ">      mish (x)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L637){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### mish\n",
       "\n",
       ">      mish (x)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(mish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L640){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Mish\n",
       "\n",
       ">      Mish ()\n",
       "\n",
       "Same as `nn.Module`, but no need for subclasses to call `super().__init__`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L640){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Mish\n",
       "\n",
       ">      Mish ()\n",
       "\n",
       "Same as `nn.Module`, but no need for subclasses to call `super().__init__`"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(Mish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for submodules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to get the list of all parameters of a given model. For when you want all submodules (like linear/conv layers) without forgetting lone parameters, the following class wraps those in fake modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```ParameterModule(Module)```\n",
    "Register a lone parameter `p` in a module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L650){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ParameterModule\n",
       "\n",
       ">      ParameterModule (p)\n",
       "\n",
       "Register a lone parameter `p` in a module."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L650){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ParameterModule\n",
       "\n",
       ">      ParameterModule (p)\n",
       "\n",
       "Register a lone parameter `p` in a module."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ParameterModule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```children_and_parameters(m)```\n",
    "Return the children of `m` and its direct parameters not registered in modules.\n",
    "\n",
    "The direct parameters are those not inside those parameters of `m.children()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([[1],[2]],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L657){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### children_and_parameters\n",
       "\n",
       ">      children_and_parameters (m)\n",
       "\n",
       "Return the children of `m` and its direct parameters not registered in modules."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L657){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### children_and_parameters\n",
       "\n",
       ">      children_and_parameters (m)\n",
       "\n",
       "Return the children of `m` and its direct parameters not registered in modules."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(children_and_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class TstModule(Module):\n",
    "    def __init__(self): self.a,self.lin = nn.Parameter(torch.randn(1)),nn.Linear(5,10)\n",
    "\n",
    "tst = TstModule()\n",
    "children = children_and_parameters(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(len(children), 2)\n",
    "test_eq(children[0], tst.lin)\n",
    "assert isinstance(children[1], ParameterModule)\n",
    "test_eq(children[1].val, tst.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```has_children(m)```\n",
    "Whether a model has children layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L667){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### has_children\n",
       "\n",
       ">      has_children (m)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L667){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### has_children\n",
       "\n",
       ">      has_children (m)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(has_children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class A(Module): pass\n",
    "assert not has_children(A())\n",
    "assert has_children(TstModule())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L673){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### flatten_model\n",
       "\n",
       ">      flatten_model (m)\n",
       "\n",
       "Return the list of all submodules and parameters of `m`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L673){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### flatten_model\n",
       "\n",
       ">      flatten_model (m)\n",
       "\n",
       "Return the list of all submodules and parameters of `m`"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(flatten_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): TstModule(\n",
       "    (lin): Linear(in_features=5, out_features=10, bias=True)\n",
       "  )\n",
       "  (1): TstModule(\n",
       "    (lin): Linear(in_features=5, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=5, out_features=10, bias=True),\n",
       " ParameterModule(),\n",
       " Linear(in_features=5, out_features=10, bias=True),\n",
       " ParameterModule()]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = nn.Sequential(TstModule(), TstModule())\n",
    "tst\n",
    "children = flatten_model(tst)\n",
    "children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(len(children), 4)\n",
    "assert isinstance(children[1], ParameterModule)\n",
    "assert isinstance(children[3], ParameterModule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```NoneReduce()```\n",
    "A context manager to evaluate `loss_func` with none reduce.\n",
    "\n",
    "within this context, the `loss_func.reduction` is set to None or its `reduction` arg is set to None, before applying data to the `loss_func`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L678){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NoneReduce\n",
       "\n",
       ">      NoneReduce (loss_func)\n",
       "\n",
       "A context manager to evaluate `loss_func` with none reduce."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L678){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NoneReduce\n",
       "\n",
       ">      NoneReduce (loss_func)\n",
       "\n",
       "A context manager to evaluate `loss_func` with none reduce."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(NoneReduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x,y = torch.randn(5),torch.randn(5)\n",
    "loss_fn = nn.MSELoss()\n",
    "test_eq(\"reduction\" in str(inspect.signature(loss_fn)), False)\n",
    "test_eq(loss_fn.reduction, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "with NoneReduce(loss_fn) as loss_func:\n",
    "    loss = loss_func(x,y)\n",
    "test_eq(loss.shape, [5])\n",
    "test_eq(loss_fn.reduction, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "loss_fn = F.mse_loss\n",
    "test_eq(\"reduction\" in str(inspect.signature(loss_fn)), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "with NoneReduce(loss_fn) as loss_func:\n",
    "    loss = loss_func(x,y)\n",
    "test_eq(loss.shape, [5])\n",
    "test_eq(loss_fn, F.mse_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```in_channels(m)```\n",
    "Return the shape of the first weight layer in `m`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L694){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### in_channels\n",
       "\n",
       ">      in_channels (m)\n",
       "\n",
       "Return the shape of the first weight layer in `m`."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/todeletelayers.py#L694){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### in_channels\n",
       "\n",
       ">      in_channels (m)\n",
       "\n",
       "Return the shape of the first weight layer in `m`."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Conv2d(5,4,3).weight.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# help(nested_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels(nn.Sequential(nn.Conv2d(5,4,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(in_channels(nn.Sequential(nn.Conv2d(5,4,3), nn.Conv2d(4,3,3))), 5)\n",
    "test_eq(in_channels(nn.Sequential(nn.AvgPool2d(4), nn.Conv2d(4,3,3))), 4)\n",
    "test_eq(in_channels(nn.Sequential(BatchNorm(4), nn.Conv2d(4,3,3))), 4)\n",
    "test_eq(in_channels(nn.Sequential(InstanceNorm(4), nn.Conv2d(4,3,3))), 4)\n",
    "test_eq(in_channels(nn.Sequential(InstanceNorm(4, affine=False), nn.Conv2d(4,3,3))), 4)\n",
    "test_fail(lambda : in_channels(nn.Sequential(nn.AvgPool2d(4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
