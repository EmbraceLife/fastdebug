{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: groundup_get_data_ready.html\n",
    "skip_exec: true\n",
    "title: 0001_groundup_get_data_ready\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5bd93c",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastdebug.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a007cb56",
   "metadata": {},
   "source": [
    "# Matrix multiplication from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d963854",
   "metadata": {},
   "source": [
    "The *foundations* we'll assume throughout this course are:\n",
    "\n",
    "- Python\n",
    "- Python modules (non-DL)\n",
    "- pytorch indexable tensor, and tensor creation (including RNGs - random number generators)\n",
    "- fastai.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb7328",
   "metadata": {},
   "source": [
    "## autoreload and matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da07a5a",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from fastdebug.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9dc59e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# autoreload??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d12cff",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## <mark style=\"background-color: #ffff00\">autoreload</mark>  <mark style=\"background-color: #ffff00\">plus</mark>  <mark style=\"background-color: #FFFF00\">matplotlib</mark>  inline for every notebook\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "This section contains only the current heading 2 and its subheadings\n",
       "<!-- #region -->\n",
       "As mentioned above, you need the autoreload extension. If you want it to automatically start every time you launch ipython, you need to add it to the ipython_config.py startup file:\n",
       "\n",
       "It may be necessary to generate one first:\n",
       "```python\n",
       "ipython profile create\n",
       "```\n",
       "Then include these lines in ~/.ipython/profile_default/ipython_config.py:\n",
       "\n",
       "```python\n",
       "c.InteractiveShellApp.exec_lines = []\n",
       "c.InteractiveShellApp.exec_lines.append('%load_ext autoreload')\n",
       "c.InteractiveShellApp.exec_lines.append('%autoreload 2')\n",
       "c.InteractiveShellApp.exec_lines.append('%matplotlib inline')\n",
       "```\n",
       "\n",
       "As well as an optional warning in case you need to take advantage of compiled Python code in .pyc files:\n",
       "```python\n",
       "c.InteractiveShellApp.exec_lines.append('print(\"Warning: disable autoreload in ipython_config.py to improve performance.\")')\n",
       "```\n",
       "<!-- #endregion -->\n",
       "\n",
       "### If individual notebook, I can just run the function below to setup autoreload\n",
       "\n",
       "```python\n",
       "#| exporti\n",
       "def autoreload():\n",
       "    from IPython.core.interactiveshell import InteractiveShell\n",
       "    get_ipython().run_line_magic(magic_name=\"load_ext\", line = \"autoreload\")\n",
       "    get_ipython().run_line_magic(magic_name=\"autoreload\", line = \"2\")\n",
       "    get_ipython().run_line_magic(magic_name=\"matplotlib\", line = \"inline\")\n",
       "```\n",
       "\n",
       "```python\n",
       "\n",
       "```\n",
       "\n",
       "start of another heading 2\n",
       "## Expand cells"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Open `utils` in Jupyter Notebook locally](http://localhost:8888/tree/nbs/lib/utils.ipynb)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fastnbs(\"autoreload plus matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147dfeae",
   "metadata": {},
   "source": [
    "## operator module and test_eq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f925e9b2",
   "metadata": {},
   "source": [
    "### import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6433355f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from fastdebug.delete0000 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5589027",
   "metadata": {},
   "source": [
    "### operatore: About"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59685fc",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operator interface.\n",
      "\n",
      "This module exports a set of functions implemented in C corresponding\n",
      "to the intrinsic operators of Python.  For example, operator.add(x, y)\n",
      "is equivalent to the expression x+y.  The function names are those\n",
      "used for special methods; variants without leading and trailing\n",
      "'__' are also provided for convenience.\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getdoc(operator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e0bb9",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operator has: \n",
      "54 items in its __all__, and \n",
      "0 user defined functions, \n",
      "3 classes or class objects, \n",
      "97 builtin funcs and methods, and\n",
      "100 callables.\n",
      "\n",
      "Operator interface.\n",
      "\n",
      "This module exports a set of functions implemented in C corresponding\n",
      "to the intrinsic operators of Python.  For example, operator.add(x, y)\n",
      "is equivalent to the expression x+y.  The function names are those\n",
      "used for special methods; variants without leading and trailing\n",
      "'__' are also provided for convenience.\n"
     ]
    }
   ],
   "source": [
    "whatinside(operator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046a260",
   "metadata": {},
   "source": [
    "## test and test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea50017",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L8){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### test\n",
       "\n",
       ">      test (a, b, cmp, cname=None)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L8){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### test\n",
       "\n",
       ">      test (a, b, cmp, cname=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L13){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### test_eq\n",
       "\n",
       ">      test_eq (a, b)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L13){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### test_eq\n",
       "\n",
       ">      test_eq (a, b)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(test_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5eaf7",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(TEST,'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381c9e73",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add982b",
   "metadata": {},
   "source": [
    "### fastai.data.external/transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59732460",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import fastai.data.external as fde\n",
    "import fastai.data.transforms as fdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab7aea4",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai.data.external has: \n",
      "4 items in its __all__, and \n",
      "337 user defined functions, \n",
      "180 classes or class objects, \n",
      "4 builtin funcs and methods, and\n",
      "541 callables.\n",
      "\n",
      "None\n",
      "fastai_cfg:_lru_cache_wrapper\n",
      "fastai_path:     function    Local path to `folder` in `Config`\n",
      "URLs:            class, type    Global constants for dataset and model URLs.\n",
      "untar_data:      function    Download `url` using `FastDownload.get`\n"
     ]
    }
   ],
   "source": [
    "whatinside(fde, dun=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f0eed",
   "metadata": {},
   "source": [
    "### URLs, match_pct, search_data_url\n",
    "Download and extract dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04faae0b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from fastai.data.external import untar_data,URLs\n",
    "from fastai.data.transforms import get_image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a27e2a",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature: ()\n",
      "__class__: <class 'type'>\n",
      "__repr__: <class 'fastai.data.external.URLs'>\n",
      "\n",
      "__doc__:\n",
      "Global constants for dataset and model URLs.\n",
      "__dict__: \n",
      "mappingproxy({'ADULT_SAMPLE': 'https://s3.amazonaws.com/fast-ai-sample/adult_sample.tgz',\n",
      "              'AG_NEWS': 'https://s3.amazonaws.com/fast-ai-nlp/ag_news_csv.tgz',\n",
      "              'AMAZON_REVIEWS': 'https://s3.amazonaws.com/fast-ai-nlp/amazon_review_full_csv.tgz',\n",
      "              'AMAZON_REVIEWS_POLARITY': 'https://s3.amazonaws.com/fast-ai-nlp/amazon_review_polarity_csv.tgz',\n",
      "              'BIWI_HEAD_POSE': 'https://s3.amazonaws.com/fast-ai-imagelocal/biwi_head_pose.tgz',\n",
      "              'BIWI_SAMPLE': 'https://s3.amazonaws.com/fast-ai-sample/biwi_sample.tgz',\n",
      "              'CALTECH_101': 'https://s3.amazonaws.com/fast-ai-imageclas/caltech_101.tgz',\n",
      "              'CAMVID': 'https://s3.amazonaws.com/fast-ai-imagelocal/camvid.tgz',\n",
      "              'CAMVID_TINY': 'https://s3.amazonaws.com/fast-ai-sample/camvid_tiny.tgz',\n",
      "              'CARS': 'https://s3.amazonaws.com/fast-ai-imageclas/stanford-cars.tgz',\n",
      "              'CIFAR': 'https://s3.amazonaws.com/fast-ai-sample/cifar10.tgz',\n",
      "              'CIFAR_100': 'https://s3.amazonaws.com/fast-ai-imageclas/cifar100.tgz',\n",
      "              'COCO_SAMPLE': 'https://s3.amazonaws.com/fast-ai-coco/coco_sample.tgz',\n",
      "              'COCO_TINY': 'https://s3.amazonaws.com/fast-ai-coco/coco_tiny.tgz',\n",
      "              'CUB_200_2011': 'https://s3.amazonaws.com/fast-ai-imageclas/CUB_200_2011.tgz',\n",
      "              'DBPEDIA': 'https://s3.amazonaws.com/fast-ai-nlp/dbpedia_csv.tgz',\n",
      "              'DOGS': 'https://s3.amazonaws.com/fast-ai-sample/dogscats.tgz',\n",
      "              'FLOWERS': 'https://s3.amazonaws.com/fast-ai-imageclas/oxford-102-flowers.tgz',\n",
      "              'FOOD': 'https://s3.amazonaws.com/fast-ai-imageclas/food-101.tgz',\n",
      "              'GOOGLE': 'https://storage.googleapis.com/',\n",
      "              'HUMAN_NUMBERS': 'https://s3.amazonaws.com/fast-ai-sample/human_numbers.tgz',\n",
      "              'IMAGENETTE': 'https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz',\n",
      "              'IMAGENETTE_160': 'https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz',\n",
      "              'IMAGENETTE_320': 'https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz',\n",
      "              'IMAGEWANG': 'https://s3.amazonaws.com/fast-ai-imageclas/imagewang.tgz',\n",
      "              'IMAGEWANG_160': 'https://s3.amazonaws.com/fast-ai-imageclas/imagewang-160.tgz',\n",
      "              'IMAGEWANG_320': 'https://s3.amazonaws.com/fast-ai-imageclas/imagewang-320.tgz',\n",
      "              'IMAGEWOOF': 'https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2.tgz',\n",
      "              'IMAGEWOOF_160': 'https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2-160.tgz',\n",
      "              'IMAGEWOOF_320': 'https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2-320.tgz',\n",
      "              'IMDB': 'https://s3.amazonaws.com/fast-ai-nlp/imdb.tgz',\n",
      "              'IMDB_SAMPLE': 'https://s3.amazonaws.com/fast-ai-sample/imdb_sample.tgz',\n",
      "              'LOCAL_PATH': Path('/Users/Natsume/Documents/fastdebug/nbs/lib'),\n",
      "              'LSUN_BEDROOMS': 'https://s3.amazonaws.com/fast-ai-imageclas/bedroom.tgz',\n",
      "              'MACAQUES': 'https://storage.googleapis.com/ml-animal-sounds-datasets/macaques.zip',\n",
      "              'MDL': 'http://files.fast.ai/models/',\n",
      "              'ML_100k': 'https://files.grouplens.org/datasets/movielens/ml-100k.zip',\n",
      "              'ML_SAMPLE': 'https://s3.amazonaws.com/fast-ai-sample/movie_lens_sample.tgz',\n",
      "              'MNIST': 'https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz',\n",
      "              'MNIST_SAMPLE': 'https://s3.amazonaws.com/fast-ai-sample/mnist_sample.tgz',\n",
      "              'MNIST_TINY': 'https://s3.amazonaws.com/fast-ai-sample/mnist_tiny.tgz',\n",
      "              'MNIST_VAR_SIZE_TINY': 'https://s3.amazonaws.com/fast-ai-imageclas/mnist_var_size_tiny.tgz',\n",
      "              'MT_ENG_FRA': 'https://s3.amazonaws.com/fast-ai-nlp/giga-fren.tgz',\n",
      "              'OPENAI_TRANSFORMER': 'https://s3.amazonaws.com/fast-ai-modelzoo/transformer.tgz',\n",
      "              'PASCAL_2007': 'https://s3.amazonaws.com/fast-ai-imagelocal/pascal_2007.tgz',\n",
      "              'PASCAL_2012': 'https://s3.amazonaws.com/fast-ai-imagelocal/pascal_2012.tgz',\n",
      "              'PETS': 'https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz',\n",
      "              'PLANET_SAMPLE': 'https://s3.amazonaws.com/fast-ai-sample/planet_sample.tgz',\n",
      "              'PLANET_TINY': 'https://s3.amazonaws.com/fast-ai-sample/planet_tiny.tgz',\n",
      "              'S3': 'https://s3.amazonaws.com/fast-ai-',\n",
      "              'S3_AUDI': 'https://s3.amazonaws.com/fast-ai-audio/',\n",
      "              'S3_COCO': 'https://s3.amazonaws.com/fast-ai-coco/',\n",
      "              'S3_IMAGE': 'https://s3.amazonaws.com/fast-ai-imageclas/',\n",
      "              'S3_IMAGELOC': 'https://s3.amazonaws.com/fast-ai-imagelocal/',\n",
      "              'S3_MODEL': 'https://s3.amazonaws.com/fast-ai-modelzoo/',\n",
      "              'S3_NLP': 'https://s3.amazonaws.com/fast-ai-nlp/',\n",
      "              'SIIM_SMALL': 'https://s3.amazonaws.com/fast-ai-imagelocal/siim_small.tgz',\n",
      "              'SOGOU_NEWS': 'https://s3.amazonaws.com/fast-ai-nlp/sogou_news_csv.tgz',\n",
      "              'TCGA_SMALL': 'https://s3.amazonaws.com/fast-ai-imagelocal/tcga_small.tgz',\n",
      "              'URL': 'https://s3.amazonaws.com/fast-ai-sample/',\n",
      "              'WIKITEXT': 'https://s3.amazonaws.com/fast-ai-nlp/wikitext-103.tgz',\n",
      "              'WIKITEXT_TINY': 'https://s3.amazonaws.com/fast-ai-nlp/wikitext-2.tgz',\n",
      "              'WT103_BWD': 'https://s3.amazonaws.com/fast-ai-modelzoo/wt103-bwd.tgz',\n",
      "              'WT103_FWD': 'https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz',\n",
      "              'YAHOO_ANSWERS': 'https://s3.amazonaws.com/fast-ai-nlp/yahoo_answers_csv.tgz',\n",
      "              'YELP_REVIEWS': 'https://s3.amazonaws.com/fast-ai-nlp/yelp_review_full_csv.tgz',\n",
      "              'YELP_REVIEWS_POLARITY': 'https://s3.amazonaws.com/fast-ai-nlp/yelp_review_polarity_csv.tgz',\n",
      "              'ZEBRA_FINCH': 'https://storage.googleapis.com/ml-animal-sounds-datasets/zebra_finch.zip',\n",
      "              '__dict__': <attribute '__dict__' of 'URLs' objects>,\n",
      "              '__doc__': 'Global constants for dataset and model URLs.',\n",
      "              '__module__': 'fastai.data.external',\n",
      "              '__weakref__': <attribute '__weakref__' of 'URLs' objects>,\n",
      "              'path': <function URLs.path>})\n",
      "metaclass: False\n",
      "class: True\n",
      "decorator: False\n",
      "function: False\n",
      "method: False\n"
     ]
    }
   ],
   "source": [
    "check(URLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dddb42c",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('__module__', 'fastai.data.external'), ('__doc__', 'Global constants for dataset and model URLs.'), ('LOCAL_PATH', Path('/Users/Natsume/Documents/fastdebug/nbs/lib')), ('MDL', 'http://files.fast.ai/models/'), ('GOOGLE', 'https://storage.googleapis.com/'), ('S3', 'https://s3.amazonaws.com/fast-ai-'), ('URL', 'https://s3.amazonaws.com/fast-ai-sample/'), ('S3_IMAGE', 'https://s3.amazonaws.com/fast-ai-imageclas/'), ('S3_IMAGELOC', 'https://s3.amazonaws.com/fast-ai-imagelocal/'), ('S3_AUDI', 'https://s3.amazonaws.com/fast-ai-audio/'), ('S3_NLP', 'https://s3.amazonaws.com/fast-ai-nlp/'), ('S3_COCO', 'https://s3.amazonaws.com/fast-ai-coco/'), ('S3_MODEL', 'https://s3.amazonaws.com/fast-ai-modelzoo/'), ('ADULT_SAMPLE', 'https://s3.amazonaws.com/fast-ai-sample/adult_sample.tgz'), ('BIWI_SAMPLE', 'https://s3.amazonaws.com/fast-ai-sample/biwi_sample.tgz'), ('CIFAR', 'https://s3.amazonaws.com/fast-ai-sample/cifar10.tgz'), ('COCO_SAMPLE', 'https://s3.amazonaws.com/fast-ai-coco/coco_sample.tgz'), ('COCO_TINY', 'https://s3.amazonaws.com/fast-ai-coco/coco_tiny.tgz'), ('HUMAN_NUMBERS', 'https://s3.amazonaws.com/fast-ai-sample/human_numbers.tgz'), ('IMDB', 'https://s3.amazonaws.com/fast-ai-nlp/imdb.tgz'), ('IMDB_SAMPLE', 'https://s3.amazonaws.com/fast-ai-sample/imdb_sample.tgz'), ('ML_SAMPLE', 'https://s3.amazonaws.com/fast-ai-sample/movie_lens_sample.tgz'), ('ML_100k', 'https://files.grouplens.org/datasets/movielens/ml-100k.zip'), ('MNIST_SAMPLE', 'https://s3.amazonaws.com/fast-ai-sample/mnist_sample.tgz'), ('MNIST_TINY', 'https://s3.amazonaws.com/fast-ai-sample/mnist_tiny.tgz'), ('MNIST_VAR_SIZE_TINY', 'https://s3.amazonaws.com/fast-ai-imageclas/mnist_var_size_tiny.tgz'), ('PLANET_SAMPLE', 'https://s3.amazonaws.com/fast-ai-sample/planet_sample.tgz'), ('PLANET_TINY', 'https://s3.amazonaws.com/fast-ai-sample/planet_tiny.tgz'), ('IMAGENETTE', 'https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz'), ('IMAGENETTE_160', 'https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz'), ('IMAGENETTE_320', 'https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz'), ('IMAGEWOOF', 'https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2.tgz'), ('IMAGEWOOF_160', 'https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2-160.tgz'), ('IMAGEWOOF_320', 'https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2-320.tgz'), ('IMAGEWANG', 'https://s3.amazonaws.com/fast-ai-imageclas/imagewang.tgz'), ('IMAGEWANG_160', 'https://s3.amazonaws.com/fast-ai-imageclas/imagewang-160.tgz'), ('IMAGEWANG_320', 'https://s3.amazonaws.com/fast-ai-imageclas/imagewang-320.tgz'), ('DOGS', 'https://s3.amazonaws.com/fast-ai-sample/dogscats.tgz'), ('CALTECH_101', 'https://s3.amazonaws.com/fast-ai-imageclas/caltech_101.tgz'), ('CARS', 'https://s3.amazonaws.com/fast-ai-imageclas/stanford-cars.tgz'), ('CIFAR_100', 'https://s3.amazonaws.com/fast-ai-imageclas/cifar100.tgz'), ('CUB_200_2011', 'https://s3.amazonaws.com/fast-ai-imageclas/CUB_200_2011.tgz'), ('FLOWERS', 'https://s3.amazonaws.com/fast-ai-imageclas/oxford-102-flowers.tgz'), ('FOOD', 'https://s3.amazonaws.com/fast-ai-imageclas/food-101.tgz'), ('MNIST', 'https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz'), ('PETS', 'https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz'), ('AG_NEWS', 'https://s3.amazonaws.com/fast-ai-nlp/ag_news_csv.tgz'), ('AMAZON_REVIEWS', 'https://s3.amazonaws.com/fast-ai-nlp/amazon_review_full_csv.tgz'), ('AMAZON_REVIEWS_POLARITY', 'https://s3.amazonaws.com/fast-ai-nlp/amazon_review_polarity_csv.tgz'), ('DBPEDIA', 'https://s3.amazonaws.com/fast-ai-nlp/dbpedia_csv.tgz'), ('MT_ENG_FRA', 'https://s3.amazonaws.com/fast-ai-nlp/giga-fren.tgz'), ('SOGOU_NEWS', 'https://s3.amazonaws.com/fast-ai-nlp/sogou_news_csv.tgz'), ('WIKITEXT', 'https://s3.amazonaws.com/fast-ai-nlp/wikitext-103.tgz'), ('WIKITEXT_TINY', 'https://s3.amazonaws.com/fast-ai-nlp/wikitext-2.tgz'), ('YAHOO_ANSWERS', 'https://s3.amazonaws.com/fast-ai-nlp/yahoo_answers_csv.tgz'), ('YELP_REVIEWS', 'https://s3.amazonaws.com/fast-ai-nlp/yelp_review_full_csv.tgz'), ('YELP_REVIEWS_POLARITY', 'https://s3.amazonaws.com/fast-ai-nlp/yelp_review_polarity_csv.tgz'), ('BIWI_HEAD_POSE', 'https://s3.amazonaws.com/fast-ai-imagelocal/biwi_head_pose.tgz'), ('CAMVID', 'https://s3.amazonaws.com/fast-ai-imagelocal/camvid.tgz'), ('CAMVID_TINY', 'https://s3.amazonaws.com/fast-ai-sample/camvid_tiny.tgz'), ('LSUN_BEDROOMS', 'https://s3.amazonaws.com/fast-ai-imageclas/bedroom.tgz'), ('PASCAL_2007', 'https://s3.amazonaws.com/fast-ai-imagelocal/pascal_2007.tgz'), ('PASCAL_2012', 'https://s3.amazonaws.com/fast-ai-imagelocal/pascal_2012.tgz'), ('MACAQUES', 'https://storage.googleapis.com/ml-animal-sounds-datasets/macaques.zip'), ('ZEBRA_FINCH', 'https://storage.googleapis.com/ml-animal-sounds-datasets/zebra_finch.zip'), ('SIIM_SMALL', 'https://s3.amazonaws.com/fast-ai-imagelocal/siim_small.tgz'), ('TCGA_SMALL', 'https://s3.amazonaws.com/fast-ai-imagelocal/tcga_small.tgz'), ('OPENAI_TRANSFORMER', 'https://s3.amazonaws.com/fast-ai-modelzoo/transformer.tgz'), ('WT103_FWD', 'https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz'), ('WT103_BWD', 'https://s3.amazonaws.com/fast-ai-modelzoo/wt103-bwd.tgz'), ('path', <function URLs.path>), ('__dict__', <attribute '__dict__' of 'URLs' objects>), ('__weakref__', <attribute '__weakref__' of 'URLs' objects>)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(URLs.__dict__).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ae6a6",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/fast-ai-sample/mnist_sample.tgz\n",
      "https://s3.amazonaws.com/fast-ai-sample/mnist_tiny.tgz\n",
      "https://s3.amazonaws.com/fast-ai-imageclas/mnist_var_size_tiny.tgz\n",
      "https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz\n"
     ]
    }
   ],
   "source": [
    "for k, v in dict(URLs.__dict__).items():\n",
    "    if \"mnist\" in k.lower():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f346b1fd",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[True, False].count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L16){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### match_pct\n",
       "\n",
       ">      match_pct (query, text)\n",
       "\n",
       "calc the percent of the match between the query string and the text"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L16){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### match_pct\n",
       "\n",
       ">      match_pct (query, text)\n",
       "\n",
       "calc the percent of the match between the query string and the text"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(match_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368c218",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def search_data_url(dataname):\n",
    "    from fastai.data.external import URLs\n",
    "    name_keys = dataname.split(\" \")\n",
    "    total = len(name_keys)\n",
    "    for k, v in dict(URLs.__dict__).items():\n",
    "        pct = [key in k.lower() for key in name_keys].count(True)/total\n",
    "        if pct == 1.0:\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L24){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### search_data_url\n",
       "\n",
       ">      search_data_url (dataname)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L24){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### search_data_url\n",
       "\n",
       ">      search_data_url (dataname)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(search_data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df3b61",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/fast-ai-sample/mnist_sample.tgz\n",
      "https://s3.amazonaws.com/fast-ai-sample/mnist_tiny.tgz\n",
      "https://s3.amazonaws.com/fast-ai-imageclas/mnist_var_size_tiny.tgz\n",
      "https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_data_url(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f573ce",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/fast-ai-imageclas/mnist_var_size_tiny.tgz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://s3.amazonaws.com/fast-ai-imageclas/mnist_var_size_tiny.tgz'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_data_url(\"mnist var\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c65823",
   "metadata": {},
   "source": [
    "### check_data_directories\n",
    "check data folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4638a5c9",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3.amazonaws.com/fast-ai-imageclas/mnist_var_size_tiny.tgz'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URLs.MNIST_VAR_SIZE_TINY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8084c0",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Get image files in `path` recursively, only in `folders`, if specified.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getdoc(get_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b2004",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_VAR_SIZE_TINY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517320b9",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf6dea",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Natsume/.fastai/data/mnist_tiny\n",
      "labels.csv  mnist_tiny/ models/     test/       train/      valid/\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad88f595",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Natsume/.fastai/data/mnist_tiny/train\n",
      "3/     7/     train/\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993149a0",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8aa09",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/fast-ai-imageclas/mnist_var_size_tiny.tgz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(search_data_url(\"mnist var\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L35){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### check_data_directories\n",
       "\n",
       ">      check_data_directories (query)\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| query | query of data url |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L35){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### check_data_directories\n",
       "\n",
       ">      check_data_directories (query)\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| query | query of data url |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(check_data_directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b90948",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/fast-ai-sample/mnist_sample.tgz\n",
      "https://s3.amazonaws.com/fast-ai-sample/mnist_tiny.tgz\n",
      "https://s3.amazonaws.com/fast-ai-imageclas/mnist_var_size_tiny.tgz\n",
      "https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_data_url(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67c2ed",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# check_data_directories(\"mnist_png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a478f8",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/fast-ai-sample/mnist_sample.tgz\n",
      "cd /Users/Natsume/.fastai/data/mnist_sample\n",
      "labels.csv\n",
      "mnist_sample\n",
      "train\n",
      "valid\n",
      "\n",
      "cd /Users/Natsume/.fastai/data/mnist_sample/valid\n",
      "3\n",
      "7\n",
      "\n",
      "cd /Users/Natsume/.fastai/data/mnist_sample/train\n",
      "3\n",
      "7\n",
      "\n",
      "cd /Users/Natsume/.fastai/data/mnist_sample/mnist_sample\n",
      "labels.csv\n",
      "train\n",
      "valid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_data_directories(\"mnist_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22a4fb",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/fast-ai-sample/mnist_tiny.tgz\n",
      "cd /Users/Natsume/.fastai/data/mnist_tiny\n",
      "labels.csv\n",
      "mnist_tiny\n",
      "models\n",
      "test\n",
      "train\n",
      "valid\n",
      "\n",
      "cd /Users/Natsume/.fastai/data/mnist_tiny/valid\n",
      "3\n",
      "7\n",
      "\n",
      "cd /Users/Natsume/.fastai/data/mnist_tiny/test\n",
      "1503.png\n",
      "1605.png\n",
      "1883.png\n",
      "2032.png\n",
      "205.png\n",
      "2642.png\n",
      "3515.png\n",
      "3848.png\n",
      "3878.png\n",
      "4605.png\n",
      "4654.png\n",
      "500.png\n",
      "5071.png\n",
      "585.png\n",
      "5988.png\n",
      "617.png\n",
      "6335.png\n",
      "6501.png\n",
      "6517.png\n",
      "6736.png\n",
      "\n",
      "cd /Users/Natsume/.fastai/data/mnist_tiny/mnist_tiny\n",
      "__init__.py\n",
      "labels.csv\n",
      "models\n",
      "test\n",
      "train\n",
      "valid\n",
      "\n",
      "cd /Users/Natsume/.fastai/data/mnist_tiny/models\n",
      "tmp.pth\n",
      "\n",
      "cd /Users/Natsume/.fastai/data/mnist_tiny/train\n",
      "3\n",
      "7\n",
      "train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_data_directories(\"mnist_tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258cb3da",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/fast-ai-imageclas/mnist_var_size_tiny.tgz\n",
      "cd /Users/Natsume/.fastai/data/mnist_var_size_tiny\n",
      "labels.csv\n",
      "models\n",
      "process.txt\n",
      "test\n",
      "train\n",
      "valid\n",
      "\n",
      "cd /Users/Natsume/.fastai/data/mnist_var_size_tiny/valid\n",
      "3\n",
      "7\n",
      "\n",
      "cd /Users/Natsume/.fastai/data/mnist_var_size_tiny/test\n",
      "1503.png\n",
      "1605.png\n",
      "1883.png\n",
      "2032.png\n",
      "205.png\n",
      "2642.png\n",
      "3515.png\n",
      "3848.png\n",
      "3878.png\n",
      "4605.png\n",
      "4654.png\n",
      "500.png\n",
      "5071.png\n",
      "585.png\n",
      "5988.png\n",
      "617.png\n",
      "6335.png\n",
      "6501.png\n",
      "6517.png\n",
      "6736.png\n",
      "\n",
      "cd /Users/Natsume/.fastai/data/mnist_var_size_tiny/models\n",
      "tmp.pth\n",
      "\n",
      "cd /Users/Natsume/.fastai/data/mnist_var_size_tiny/train\n",
      "3\n",
      "7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_data_directories(\"mnist var\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff0d628",
   "metadata": {},
   "source": [
    "### get_image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a393f617",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73375dc",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature: (path, recurse=True, folders=None)\n",
      "__class__: <class 'function'>\n",
      "__repr__: <function get_image_files>\n",
      "\n",
      "__doc__:\n",
      "Get image files in `path` recursively, only in `folders`, if specified.\n",
      "__dict__: \n",
      "{}\n",
      "metaclass: False\n",
      "class: False\n",
      "decorator: False\n",
      "function: True\n",
      "method: False\n"
     ]
    }
   ],
   "source": [
    "check(get_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce5bcf",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709, 699, 20)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_train = get_image_files(path/\"train\")\n",
    "files_valid = get_image_files(path/\"valid\")\n",
    "files_test = get_image_files(path/\"test\")\n",
    "len(files_train), len(files_valid), len(files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e63ce",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9243.png'),Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9519.png'),Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/7534.png'),Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9082.png'),Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/8377.png')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L49){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_img_paths\n",
       "\n",
       ">      get_img_paths (query, train, valid, test)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L49){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_img_paths\n",
       "\n",
       ">      get_img_paths (query, train, valid, test)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(get_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0033e86e",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/fast-ai-imageclas/mnist_var_size_tiny.tgz\n",
      "train: 709, valid: 699, test: 20\n"
     ]
    }
   ],
   "source": [
    "files_train, files_valid, files_test = get_img_paths(\"mnist var\", \"train\", \"valid\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9772a6dc",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24699319",
   "metadata": {},
   "source": [
    "### get_labels\n",
    "extract label y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a83faf",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a33676",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/\"labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe499ce",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/3/7463.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/3/9829.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/3/7881.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/3/8065.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/3/7046.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  label\n",
       "0  train/3/7463.png      3\n",
       "1  train/3/9829.png      3\n",
       "2  train/3/7881.png      3\n",
       "3  train/3/8065.png      3\n",
       "4  train/3/7046.png      3"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#5) [Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9243.png'),Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9519.png'),Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/7534.png'),Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9082.png'),Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/8377.png')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]\n",
    "files_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c86334",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9243.png'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(files_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a2ca0",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1408, step=1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f9c9bc",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "label_train = []\n",
    "for f in files_train:\n",
    "    for i in df.index:\n",
    "        if df[\"name\"][i] in str(f):\n",
    "            label_train.append(df[\"label\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50b6591",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[7, 7, 7, 7, 7]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_train)\n",
    "label_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a77569",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53633e95",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[608, 544, 272, 609, 309]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#5) [Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/3/7771.png'),Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/3/9146.png'),Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/8655.png'),Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/3/7765.png'),Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9498.png')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "fastcore.foundation.L"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = [random.randint(0,len(files_train)) for i in range(5)]\n",
    "rand\n",
    "files_train[rand]\n",
    "type(files_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70b6c3",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9519.png'),Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9082.png'),Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/8377.png')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_train[1,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L60){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_labels\n",
       "\n",
       ">      get_labels (img_files)\n",
       "\n",
       "get labels for each x from a list of file paths"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L60){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_labels\n",
       "\n",
       ">      get_labels (img_files)\n",
       "\n",
       "get labels for each x from a list of file paths"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(get_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f871be",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 709, random view: [7, 7, 3, 3, 7]\n",
      "[Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9644.png'), Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/819.png'), Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/3/7692.png'), Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/3/7132.png'), Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/7386.png')]\n",
      "len: 699, random view: [3, 7, 3, 7, 7]\n",
      "[Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/valid/3/7956.png'), Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/valid/7/8302.png'), Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/valid/3/9670.png'), Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/valid/7/8402.png'), Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/valid/7/7355.png')]\n"
     ]
    }
   ],
   "source": [
    "y_train = get_labels(files_train)\n",
    "y_valid = get_labels(files_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0e350d",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900fa27c",
   "metadata": {},
   "source": [
    "### idx_line and check\n",
    "I have used these funcs more than once, so turned into funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/utils.py#L701){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### idx_line\n",
       "\n",
       ">      idx_line (lst)\n",
       "\n",
       "return zip(range(len(lst)), lst)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/utils.py#L701){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### idx_line\n",
       "\n",
       ">      idx_line (lst)\n",
       "\n",
       "return zip(range(len(lst)), lst)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(idx_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/utils.py#L706){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### check\n",
       "\n",
       ">      check (f, n=10)\n",
       "\n",
       "check any object on its signature, class, __repr__, docs, __dict__, and other checks borrowed from utils\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| f |  |  | function name, like PIL.Image.open |\n",
       "| n | int | 10 | num of lines to print, if n = -1 then print the entire __doc__ |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/utils.py#L706){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### check\n",
       "\n",
       ">      check (f, n=10)\n",
       "\n",
       "check any object on its signature, class, __repr__, docs, __dict__, and other checks borrowed from utils\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| f |  |  | function name, like PIL.Image.open |\n",
       "| n | int | 10 | num of lines to print, if n = -1 then print the entire __doc__ |"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba21dc88",
   "metadata": {},
   "source": [
    "### PIL and PIL.Image.open\n",
    "to view an image from the image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d139f1b9",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c3964",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL has: \n",
      "0 items in its __all__, and \n",
      "0 user defined functions, \n",
      "1 classes or class objects, \n",
      "0 builtin funcs and methods, and\n",
      "1 callables.\n",
      "\n",
      "Pillow (Fork of the Python Imaging Library)\n",
      "\n",
      "Pillow is the friendly PIL fork by Alex Clark and Contributors.\n",
      "    https://github.com/python-pillow/Pillow/\n",
      "\n",
      "Pillow is forked from PIL 1.1.7.\n",
      "\n",
      "PIL is the Python Imaging Library by Fredrik Lundh and Contributors.\n",
      "Copyright (c) 1999 by Secret Labs AB.\n",
      "\n",
      "Use PIL.__version__ for this Pillow version.\n",
      "\n",
      ";-)\n"
     ]
    }
   ],
   "source": [
    "whatinside(PIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b43bc",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature: (fp, mode='r', formats=None)\n",
      "__class__: <class 'function'>\n",
      "__repr__: <function open>\n",
      "\n",
      "__doc__:\n",
      "Opens and identifies the given image file.\n",
      "\n",
      "This is a lazy operation; this function identifies the file, but\n",
      "the file remains open and the actual image data is not read from\n",
      "the file until you try to process the data (or call the\n",
      ":py:meth:`~PIL.Image.Image.load` method).  See\n",
      ":py:func:`~PIL.Image.new`. See :ref:`file-handling`.\n",
      "\n",
      ":param fp: A filename (string), pathlib.Path object or a file object.\n",
      "   The file object must implement ``file.read``,\n",
      "   ``file.seek``, and ``file.tell`` methods,\n",
      "   and be opened in binary mode.\n",
      ":param mode: The mode.  If given, this argument must be \"r\".\n",
      ":param formats: A list or tuple of formats to attempt to load the file in.\n",
      "   This can be used to restrict the set of formats checked.\n",
      "   Pass ``None`` to try all supported formats. You can print the set of\n",
      "   available formats by running ``python3 -m PIL`` or using\n",
      "   the :py:func:`PIL.features.pilinfo` function.\n",
      ":returns: An :py:class:`~PIL.Image.Image` object.\n",
      ":exception FileNotFoundError: If the file cannot be found.\n",
      ":exception PIL.UnidentifiedImageError: If the image cannot be opened and\n",
      "   identified.\n",
      ":exception ValueError: If the ``mode`` is not \"r\", or if a ``StringIO``\n",
      "   instance is used for ``fp``.\n",
      ":exception TypeError: If ``formats`` is not ``None``, a list or a tuple.\n",
      "__dict__: \n",
      "{}\n",
      "metaclass: False\n",
      "class: False\n",
      "decorator: False\n",
      "function: True\n",
      "method: False\n"
     ]
    }
   ],
   "source": [
    "check(PIL.Image.open, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161b2b19",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACEAAAApCAAAAACe3B/eAAABOUlEQVR4nGNgGAXUBowoPCZO5t8//+FRziQxY2+lEpogCzKHL8NbStXkwNGX3Gpfz3/AooJVLUT47gduKT1OKYs383ZjUSEeLLtz9+tfHxkkOP8x/cLmDMvbz10gOiSTg5nhjkMo4FHlPPHwDwMDAwOz3q87f7GoMIhmWPeKgYGBgYlf+/llbH5h/Xrg7DcGBgYm2Urtx1gDRdRcn4uRgYFBuPD6QlNsCuBAY/+FSD4ElwlDAZMw+6YTnxB8FgwVkpo35zxC1oGugMsinPUHAz4Vsub/u9/jVaGs/uL2b3wqZN1kTqMowFBhoX17918UEVS/MEo6Mu++gaoH1QxmO+tfdxnwqrD6s/s0PhWM/MYPT31FU4HkDiYWmfRHay4y4FZhGC6tOuvQJ3QVSLaw8vzccOAduoJhBQAtH1UjlpwyMgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=33x41>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB8AAAAoCAAAAAAjun7wAAABeklEQVR4nGNgGAX4ACMy29uC7///V9d+nvr4BybGgizvFCfMwPDh9s8Tay/8wCL//7SEKju7qCmDmXjPtT+Y5jOwSGsK8eqbK/P8Sdj8FZeLuH2P/frhCjOXCdPFfz///ynGgUM3C4fP7R9f1yrgkGb1n3fk99fdbpxYZRlZK+58+PJ0pgE3IxZZFueqFY///3/crIrpKAYGBiaZqQ9+//////2uMgmEAqTw+a/wbs8TFkM7J12xOfd+YRrAlhYtycBsNv3Bv8/d0jjcz8DAoDLz9e9nDrjD59Hic/+EFThxyv+6d/3f/z//keWZufk4EAo/n//LZCSILK/cuy9LAaqAkUHUi+3/sTfI/mMVMBbSXXzhwz8GBgYxKxd7xtdf/yHL3ztqqyBg+PTDkXdyqvKyokJfpl6C+R8S0BrRvgr8DH/ufxMQ4WJ4f3zHxmd/UeRZZfWU5dVFNLgYfr94cGXJxW8w58PTFyOLgKaoIS/Dt0cPn1yGy44CABf9hUzj8SUZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=31x40>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PIL.Image.open(files_train[0])\n",
    "PIL.Image.open(files_valid[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57481808",
   "metadata": {},
   "source": [
    "### img, img.convert, img.resize\n",
    "convert img color mode to L or RGB, and resize img to shape (28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3fdef4",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13011e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "img = PIL.Image.open(files_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b308eb8e",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mode=None, matrix=None, dither=None, palette=<Palette.WEB: 0>, colors=256)\n"
     ]
    }
   ],
   "source": [
    "print(inspect.signature(img.convert)) # add this line to the doc func defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9207fd3f",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.PngImagePlugin.PngImageFile"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "PIL.PngImagePlugin.PngImageFile"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.__class__\n",
    "type(img) # add this to doc func above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ad30f9",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.PngImagePlugin.PngImageFile"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to quickly know about an object, make doc to solve this problem\n",
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ba5baf",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.__doc__ == None # add this to func doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0266b0",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'im': None,\n",
       " 'mode': 'L',\n",
       " '_size': (33, 41),\n",
       " 'palette': None,\n",
       " 'info': {'gamma': 0.45455,\n",
       "  'chromaticity': (0.3127, 0.329, 0.64, 0.33, 0.3, 0.6, 0.15, 0.06)},\n",
       " '_category': 0,\n",
       " 'readonly': 1,\n",
       " 'pyaccess': None,\n",
       " '_exif': None,\n",
       " '_min_frame': 0,\n",
       " 'custom_mimetype': None,\n",
       " 'tile': [('zip', (0, 0, 33, 41), 134, 'L')],\n",
       " 'decoderconfig': (),\n",
       " 'decodermaxblock': 65536,\n",
       " 'fp': <_io.BufferedReader name='/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9243.png'>,\n",
       " 'filename': '/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9243.png',\n",
       " '_exclusive_fp': True,\n",
       " '_fp': <_io.BufferedReader name='/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9243.png'>,\n",
       " '_PngImageFile__frame': 0,\n",
       " 'private_chunks': [],\n",
       " 'png': <PIL.PngImagePlugin.PngStream>,\n",
       " '_text': None,\n",
       " 'n_frames': 1,\n",
       " 'default_image': False,\n",
       " '_PngImageFile__prepare_idat': 312,\n",
       " 'is_animated': False}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.__dict__ # add this into doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccccf7cc",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature: None\n",
      "__class__: <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "__repr__: <PIL.PngImagePlugin.PngImageFile image mode=L size=33x41>\n",
      "\n",
      "__doc__: not exist\n",
      "\n",
      "__dict__: \n",
      "{'_PngImageFile__frame': 0,\n",
      " '_PngImageFile__prepare_idat': 312,\n",
      " '_category': 0,\n",
      " '_exclusive_fp': True,\n",
      " '_exif': None,\n",
      " '_fp': <_io.BufferedReader name='/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9243.png'>,\n",
      " '_min_frame': 0,\n",
      " '_size': (33, 41),\n",
      " '_text': None,\n",
      " 'custom_mimetype': None,\n",
      " 'decoderconfig': (),\n",
      " 'decodermaxblock': 65536,\n",
      " 'default_image': False,\n",
      " 'filename': '/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9243.png',\n",
      " 'fp': <_io.BufferedReader name='/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9243.png'>,\n",
      " 'im': None,\n",
      " 'info': {'chromaticity': (0.3127, 0.329, 0.64, 0.33, 0.3, 0.6, 0.15, 0.06),\n",
      "          'gamma': 0.45455},\n",
      " 'is_animated': False,\n",
      " 'mode': 'L',\n",
      " 'n_frames': 1,\n",
      " 'palette': None,\n",
      " 'png': <PIL.PngImagePlugin.PngStream object>,\n",
      " 'private_chunks': [],\n",
      " 'pyaccess': None,\n",
      " 'readonly': 1,\n",
      " 'tile': [('zip', (0, 0, 33, 41), 134, 'L')]}\n",
      "metaclass: False\n",
      "class: False\n",
      "decorator: False\n",
      "function: False\n",
      "method: False\n"
     ]
    }
   ],
   "source": [
    "check(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc5ce19",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=L size=33x41>\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09bb0a0",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Image.convert of <PIL.PngImagePlugin.PngImageFile image mode=L size=33x41>>\n"
     ]
    }
   ],
   "source": [
    "print(img.convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3328eb",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature: (mode=None, matrix=None, dither=None, palette=<Palette.WEB: 0>, colors=256)\n",
      "__class__: <class 'method'>\n",
      "__repr__: <bound method Image.convert of <PIL.PngImagePlugin.PngImageFile image mode=L size=33x41>>\n",
      "\n",
      "__doc__:\n",
      "Returns a converted copy of this image. For the \"P\" mode, this\n",
      "method translates pixels through the palette.  If mode is\n",
      "omitted, a mode is chosen so that all information in the image\n",
      "and the palette can be represented without a palette.\n",
      "\n",
      "The current version supports all possible conversions between\n",
      "\"L\", \"RGB\" and \"CMYK.\" The ``matrix`` argument only supports \"L\"\n",
      "and \"RGB\".\n",
      "\n",
      "When translating a color image to greyscale (mode \"L\"),\n",
      "the library uses the ITU-R 601-2 luma transform::\n",
      "__dict__: \n",
      "{}\n",
      "metaclass: False\n",
      "class: False\n",
      "decorator: False\n",
      "function: False\n",
      "method: True\n"
     ]
    }
   ],
   "source": [
    "check(img.convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e201f",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACEAAAApCAIAAAA01ddVAAACqklEQVR4nO2UTUsyURSAZ+51iFHRxRDNTM4mGS0GTNFwKggCcePSQMSli9y29Df0ByIiaB8R7uQSDYIgSVS0qJhcaAs/ilJhIkezd/n2Rs2Hb23CZ3vPOc+5nHsuho0ZM+a3gxuMAwCQJAkh7Pf7vV5vOBx+cyMAAJqmt7a2jo6OstnszMyMqXSLkSCHw5HJZGKxGMuyPM+HQiFJkorFYrPZtNlsHo9HUZSzs7N2uz2igyAIj8eztrZGUVSlUmm32zabjWVZn89HkiTLsqIoPjw87O7uIoRGdExNTcXjcY7j8vk8Quj+/l5V1U6ng2EYTdMkSQ6HQwCAqqq6pb5kcXFRluV6vR6JRCyWjz0xDJNOp+PxOITwqwpAW2C323meJ0myVCpVq9XBYPD+FELo8/lUVb29vX19fR3R4ff7U6kUhmEHBwetVuufTACcTqcgCPV6/fLyUqOIzjwIglAURZKk09PT5+fn9wKO47LZrCAId3d3/7Uuk5OT4XB4fn7earXi+N+FpShqY2Pj6upqb29vYWFhdIEGs7Ozx8fH5+fnyWTS4XBoB+vM4/McACiKmpiYyOVypVKp2+1qxxva8w8wDDM3N3dzc7Ozs1Or1fR7MiuwWq2iKCYSCYIgXl5ejKSYdnAcFw6H397eNjc3n56efsThdru9Xm+j0ZBlud/vf7+D47hoNOpyucrlskGBaYcoioIgyLKMENL4PD5g9F3hOM4wzOrqKoQQIXR9fW28M6P3gBCurKwsLy+rqlqpVIwLzDmWlpYGgwFCqFwuf78Dx3Gn0xkMBqvV6snJiaIophw68wAAWCwWl8u1vr5eq9X29/cvLi5MCfQdgUAgkUhMT0/zPL+9vV0oFHR/p08a1T4mCMJut/d6vcPDQ0mSHh8fzQrGjPkh/gB7PP71+jZNhgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=33x41>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(33, 41)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACEAAAApCAAAAACe3B/eAAABOUlEQVR4nGNgGAXUBowoPCZO5t8//+FRziQxY2+lEpogCzKHL8NbStXkwNGX3Gpfz3/AooJVLUT47gduKT1OKYs383ZjUSEeLLtz9+tfHxkkOP8x/cLmDMvbz10gOiSTg5nhjkMo4FHlPPHwDwMDAwOz3q87f7GoMIhmWPeKgYGBgYlf+/llbH5h/Xrg7DcGBgYm2Urtx1gDRdRcn4uRgYFBuPD6QlNsCuBAY/+FSD4ElwlDAZMw+6YTnxB8FgwVkpo35zxC1oGugMsinPUHAz4Vsub/u9/jVaGs/uL2b3wqZN1kTqMowFBhoX17918UEVS/MEo6Mu++gaoH1QxmO+tfdxnwqrD6s/s0PhWM/MYPT31FU4HkDiYWmfRHay4y4FZhGC6tOuvQJ3QVSLaw8vzccOAduoJhBQAtH1UjlpwyMgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=33x41>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(33, 41)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.convert(\"RGB\")\n",
    "img.size\n",
    "img.convert(\"L\")\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be78ae73",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature: (size, resample=None, box=None, reducing_gap=None)\n",
      "__class__: <class 'method'>\n",
      "__repr__: <bound method Image.resize of <PIL.PngImagePlugin.PngImageFile image mode=L size=33x41>>\n",
      "\n",
      "__doc__:\n",
      "Returns a resized copy of this image.\n",
      "\n",
      ":param size: The requested size in pixels, as a 2-tuple:\n",
      "   (width, height).\n",
      ":param resample: An optional resampling filter.  This can be\n",
      "   one of :py:data:`PIL.Image.Resampling.NEAREST`,\n",
      "   :py:data:`PIL.Image.Resampling.BOX`,\n",
      "   :py:data:`PIL.Image.Resampling.BILINEAR`,\n",
      "   :py:data:`PIL.Image.Resampling.HAMMING`,\n",
      "   :py:data:`PIL.Image.Resampling.BICUBIC` or\n",
      "   :py:data:`PIL.Image.Resampling.LANCZOS`.\n",
      "__dict__: \n",
      "{}\n",
      "metaclass: False\n",
      "class: False\n",
      "decorator: False\n",
      "function: False\n",
      "method: True\n"
     ]
    }
   ],
   "source": [
    "check(img.resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246e79e",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = img.resize((28, 28))\n",
    "img.size\n",
    "# img = img.resize((1, 28, 28)) # this is not allowed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f783735",
   "metadata": {},
   "source": [
    "### torch.Tensor, torch.stack, imgs2tensor\n",
    "convert from img type to np.array to pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd98b795",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA0UlEQVR4nGNgGDaAEYnN78544iGyJAuCyZ2Xz3Jk+/H3YqI37v1Dk2R3Tn1+6RO3moC+zso5P9AkRbP+FJ/++4+J/cGjQ7/QjOVyU1976gMDAwMP//4bEFMZmGCSgvrXV3xmYGCQKHd89Qvd2eyKSmwMDAwCzVcLBHB5TWVHrxwuOeGMhTIIHhOKHKu139E3uCSlPb+u/4FDkt1He+dHBuySjGY+Fzf9wiHJHS6w7y0DDkk1ve0H/yJLwqOMW1fD++zSxyjuQ4StpdqF5ahyAwIAnSk8in4P9UEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6f272f",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=L size=28x28>\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04df1f",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9447cf7",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[184, 222,  70,  17,  14],\n",
       "       [223, 140,  16,   0,   0],\n",
       "       [182,  52,   3,   0,   0],\n",
       "       [ 34,   6,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(img)[10:15, 10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218951b2",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c23de49",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(np.array(img)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5ac5b7",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "t = torch.Tensor(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b68e78",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/Users/Natsume/.fastai/data/mnist_var_size_tiny/train/7/9519.png')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 28, 28])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 2, 28])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_train[1]\n",
    "img1 = PIL.Image.open(files_train[1])\n",
    "img1 = img1.resize((28,28))\n",
    "t1 = torch.Tensor(np.array(img1))\n",
    "# t1\n",
    "torch.stack([t, t1], dim=0).shape\n",
    "torch.stack([t, t1], dim=1).shape\n",
    "torch.stack([t, t1], dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd5a256",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 28, 28])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_t = []\n",
    "for f in files_train[:5]:\n",
    "    img = PIL.Image.open(f).resize((28,28))\n",
    "    t = torch.Tensor(np.array(img))\n",
    "    lst_t.append(t)\n",
    "torch.stack(lst_t, dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2b2870",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def imgs2tensor(img_folder, n=-1, size=28):\n",
    "    \"convert image folders into a tensor in which images stack on each other\"\n",
    "    lst_t = []\n",
    "    if n > 0: selected = img_folder[:n]\n",
    "    else: selected = img_folder\n",
    "    for f in selected:\n",
    "        img = PIL.Image.open(f).resize((size,size))\n",
    "        t = torch.Tensor(np.array(img))\n",
    "        lst_t.append(t)\n",
    "    res = torch.stack(lst_t, dim=0)\n",
    "    print(res.shape)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd2aee1",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([709, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "x_train = imgs2tensor(files_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b7b160",
   "metadata": {},
   "source": [
    "### torch.permute, torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54d7bed",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.isbuiltin(x_train.permute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd570ea4",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npermute(*dims) -> Tensor\\n\\nSee :func:`torch.permute`\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.permute.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0937069f",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature: None\n",
      "__class__: <class 'builtin_function_or_method'>\n",
      "__repr__: <built-in method permute of Tensor object>\n",
      "\n",
      "__doc__:\n",
      "permute(*dims) -> Tensor\n",
      "\n",
      "See :func:`torch.permute`\n",
      "__dict__: not exist \n",
      "\n",
      "metaclass: False\n",
      "class: False\n",
      "decorator: False\n",
      "function: False\n",
      "method: False\n"
     ]
    }
   ],
   "source": [
    "check(x_train.permute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bda1f6",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature: None\n",
      "__class__: <class 'builtin_function_or_method'>\n",
      "__repr__: <built-in method permute of type object>\n",
      "\n",
      "__doc__:\n",
      "permute(input, dims) -> Tensor\n",
      "\n",
      "Returns a view of the original tensor :attr:`input` with its dimensions permuted.\n",
      "\n",
      "Args:\n",
      "    input (Tensor): the input tensor.\n",
      "    dims (tuple of ints): The desired ordering of dimensions\n",
      "\n",
      "Example:\n",
      "    >>> x = torch.randn(2, 3, 5)\n",
      "    >>> x.size()\n",
      "    torch.Size([2, 3, 5])\n",
      "    >>> torch.permute(x, (2, 0, 1)).size()\n",
      "    torch.Size([5, 2, 3])\n",
      "__dict__: not exist \n",
      "\n",
      "metaclass: False\n",
      "class: False\n",
      "decorator: False\n",
      "function: False\n",
      "method: False\n"
     ]
    }
   ],
   "source": [
    "check(torch.permute,n=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d8e2ca",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature: None\n",
      "__class__: <class 'builtin_function_or_method'>\n",
      "__repr__: <built-in method float of Tensor object>\n",
      "\n",
      "__doc__:\n",
      "float(memory_format=torch.preserve_format) -> Tensor\n",
      "\n",
      "``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "\n",
      "Args:\n",
      "    memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "        returned Tensor. Default: ``torch.preserve_format``.\n",
      "__dict__: not exist \n",
      "\n",
      "metaclass: False\n",
      "class: False\n",
      "decorator: False\n",
      "function: False\n",
      "method: False\n"
     ]
    }
   ],
   "source": [
    "check(x_train.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e329eab",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature: None\n",
      "__class__: <class 'method_descriptor'>\n",
      "__repr__: <method 'float' of 'torch._C._TensorBase' objects>\n",
      "\n",
      "__doc__:\n",
      "float(memory_format=torch.preserve_format) -> Tensor\n",
      "\n",
      "``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "\n",
      "Args:\n",
      "    memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "        returned Tensor. Default: ``torch.preserve_format``.\n",
      "__dict__: not exist \n",
      "\n",
      "metaclass: False\n",
      "class: False\n",
      "decorator: False\n",
      "function: False\n",
      "method: False\n"
     ]
    }
   ],
   "source": [
    "check(torch.Tensor.float, n=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2688f2ba",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature: (object)\n",
      "__class__: <class 'function'>\n",
      "__repr__: <function ismethoddescriptor>\n",
      "\n",
      "__doc__:\n",
      "Return true if the object is a method descriptor.\n",
      "\n",
      "But not if ismethod() or isclass() or isfunction() are true.\n",
      "\n",
      "This is new in Python 2.2, and, for example, is true of int.__add__.\n",
      "An object passing this test has a __get__ attribute but not a __set__\n",
      "attribute, but beyond that the set of attributes varies.  __name__ is\n",
      "usually sensible, and __doc__ often is.\n",
      "\n",
      "Methods implemented via descriptors that also pass one of the other\n",
      "tests return false from the ismethoddescriptor() test, simply because\n",
      "__dict__: \n",
      "{}\n",
      "metaclass: False\n",
      "class: False\n",
      "decorator: False\n",
      "function: True\n",
      "method: False\n"
     ]
    }
   ],
   "source": [
    "check(inspect.ismethoddescriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546ed7d",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.ismethoddescriptor(torch.Tensor.float) # to improve on func check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75e5a26",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature: None\n",
      "__class__: <class 'builtin_function_or_method'>\n",
      "__repr__: <built-in method is_floating_point of Tensor object>\n",
      "\n",
      "__doc__:\n",
      "is_floating_point() -> bool\n",
      "\n",
      "Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "__dict__: not exist \n",
      "\n",
      "metaclass: False\n",
      "class: False\n",
      "decorator: False\n",
      "function: False\n",
      "method: False\n"
     ]
    }
   ],
   "source": [
    "check(x_train.is_floating_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bfa908",
   "metadata": {},
   "source": [
    "### mean_std, normalize, imgs2tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e975da8",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(255.), tensor(0.), tensor(0.), tensor(28.4574))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(tensor(28.4574), tensor(68.6432))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max(), x_train.min(), x_train.median(), x_train.mean()\n",
    "\n",
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L76){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### mean_std\n",
       "\n",
       ">      mean_std (t)\n",
       "\n",
       "check mean and std of a tensor"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L76){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### mean_std\n",
       "\n",
       ">      mean_std (t)\n",
       "\n",
       "check mean and std of a tensor"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(mean_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62aaba",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x_train = x_train/x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L81){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### normalize\n",
       "\n",
       ">      normalize (t)\n",
       "\n",
       "to normalize a tensor by dividing its maximum value"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L81){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### normalize\n",
       "\n",
       ">      normalize (t)\n",
       "\n",
       "to normalize a tensor by dividing its maximum value"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230efc9",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x_train = normalize(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97705f8",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.11159760504961014, std: 0.2691890597343445\n"
     ]
    }
   ],
   "source": [
    "mean_std(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L86){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### imgs2tensor\n",
       "\n",
       ">      imgs2tensor (img_folder:list, n=-1, size=28)\n",
       "\n",
       "convert image folders into a tensor in which images stack on each other, and normalize it\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| img_folder | list |  | a list of image files path in string |\n",
       "| n | int | -1 | n == -1 to process all files in the list, otherwise just [:n] files |\n",
       "| size | int | 28 | images to be resized to (size, size) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/EmbraceLife/fastdebug/blob/master/fastdebug/groundup.py#L86){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### imgs2tensor\n",
       "\n",
       ">      imgs2tensor (img_folder:list, n=-1, size=28)\n",
       "\n",
       "convert image folders into a tensor in which images stack on each other, and normalize it\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| img_folder | list |  | a list of image files path in string |\n",
       "| n | int | -1 | n == -1 to process all files in the list, otherwise just [:n] files |\n",
       "| size | int | 28 | images to be resized to (size, size) |"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(imgs2tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2fd734",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([709, 28, 28])\n",
      "mean: 0.11159760504961014, std: 0.2691890597343445\n",
      "torch.Size([699, 28, 28])\n",
      "mean: 0.12307247519493103, std: 0.28430673480033875\n",
      "torch.Size([20, 28, 28])\n",
      "mean: 0.11439651250839233, std: 0.27472028136253357\n"
     ]
    }
   ],
   "source": [
    "x_train = imgs2tensor(files_train)\n",
    "x_valid = imgs2tensor(files_valid)\n",
    "x_test = imgs2tensor(files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570904b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a19b84a",
   "metadata": {},
   "source": [
    "### %whos \n",
    "https://www.wrighters.io/how-to-view-all-your-variables-in-a-jupyter-notebook/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d251b",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FunctionType',\n",
       " 'In',\n",
       " 'MethodType',\n",
       " 'Out',\n",
       " 'PIL',\n",
       " 'TEST',\n",
       " 'URLs',\n",
       " 'check',\n",
       " 'df',\n",
       " 'exit',\n",
       " 'f',\n",
       " 'fastcodes',\n",
       " 'fastlistnbs',\n",
       " 'fastlistsrcs',\n",
       " 'fastnbs',\n",
       " 'fastnotes',\n",
       " 'fastsrcs',\n",
       " 'fastview',\n",
       " 'fde',\n",
       " 'fdt',\n",
       " 'i',\n",
       " 'img',\n",
       " 'img1',\n",
       " 'imgs2tensor',\n",
       " 'inspect',\n",
       " 'ipy2md',\n",
       " 'isdecorator',\n",
       " 'ismetaclass',\n",
       " 'k',\n",
       " 'kagglenbs',\n",
       " 'normalize',\n",
       " 'np',\n",
       " 'openNB',\n",
       " 'openNBKaggle',\n",
       " 'operator',\n",
       " 'path',\n",
       " 'pd',\n",
       " 'quit',\n",
       " 'rand',\n",
       " 'random',\n",
       " 't',\n",
       " 't1',\n",
       " 'tensor',\n",
       " 'test',\n",
       " 'torch',\n",
       " 'v',\n",
       " 'whatinside',\n",
       " 'whichversion']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d for d in dir() if not \"__\" in d and not \"_\" in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd2a1f",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                 Type        Data/Info\n",
      "----------------------------------------------\n",
      "check                    function    <function check>\n",
      "check_data_directories   function    <function check_data_directories>\n",
      "fastcodes                function    <function fastcodes>\n",
      "fastlistnbs              function    <function fastlistnbs>\n",
      "fastlistsrcs             function    <function fastlistsrcs>\n",
      "fastnbs                  function    <function fastnbs>\n",
      "fastnotes                function    <function fastnotes>\n",
      "fastsrcs                 function    <function fastsrcs>\n",
      "fastview                 function    <function fastview>\n",
      "files_test               L           [Path('/Users/Natsume/.fa<...>ize_tiny/test/5071.png')]\n",
      "files_train              L           [Path('/Users/Natsume/.fa<...>_tiny/train/3/7288.png')]\n",
      "files_valid              L           [Path('/Users/Natsume/.fa<...>_tiny/valid/3/8811.png')]\n",
      "get_all_nbs              function    <function get_all_nbs>\n",
      "get_image_files          function    <function get_image_files>\n",
      "get_img_paths            function    <function get_img_paths>\n",
      "get_labels               function    <function get_labels>\n",
      "idx_line                 function    <function idx_line>\n",
      "imgs2tensor              function    <function imgs2tensor>\n",
      "inspect_class            function    <function inspect_class>\n",
      "ipy2md                   function    <function ipy2md>\n",
      "isdecorator              function    <function isdecorator>\n",
      "ismetaclass              function    <function ismetaclass>\n",
      "kagglenbs                list        n=27\n",
      "label_train              list        n=709\n",
      "lst_t                    list        n=5\n",
      "match_pct                function    <function match_pct>\n",
      "mean_std                 function    <function mean_std>\n",
      "nb_name                  function    <function nb_name>\n",
      "nb_path                  function    <function nb_path>\n",
      "nb_url                   function    <function nb_url>\n",
      "normalize                function    <function normalize>\n",
      "openNB                   function    <function openNB>\n",
      "openNBKaggle             function    <function openNBKaggle>\n",
      "rand                     list        n=5\n",
      "search_data_url          function    <function search_data_url>\n",
      "test                     function    <function test>\n",
      "test_eq                  function    <function test_eq>\n",
      "test_is                  function    <function test_is>\n",
      "untar_data               function    <function untar_data>\n",
      "whatinside               function    <function whatinside>\n",
      "whichversion             function    <function whichversion>\n",
      "y_train                  list        n=709\n",
      "y_valid                  list        n=699\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "045a3f03",
   "metadata": {},
   "source": [
    "## export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b995ac3",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569bbd59",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
