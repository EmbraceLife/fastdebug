{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: index.html\n",
    "title: Learning fastai with joy\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c39e2f",
   "metadata": {},
   "source": [
    "## Search notes and notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fff4d1",
   "metadata": {},
   "source": [
    "### search notebooks\n",
    "The first step to learn fastai with joy is to make revision easier. I would like to be able to search learning points in fastai notebooks with ease.\n",
    "\n",
    "If I want to read or run the notebook, I could click the second link to run the notebook on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12083308",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### <mark style=\"background-color: #ffff00\">how</mark>  does <mark style=\"background-color: #ffff00\">gradient</mark>  <mark style=\"background-color: #ffff00\">accumulation</mark>  <mark style=\"background-color: #FFFF00\">work</mark>  under the hood\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "<!-- #region -->\n",
       "For instance, here's a basic example of a single epoch of a training loop without gradient accumulation:\n",
       "\n",
       "```python\n",
       "for x,y in dl:\n",
       "    calc_loss(coeffs, x, y).backward()\n",
       "    coeffs.data.sub_(coeffs.grad * lr)\n",
       "    coeffs.grad.zero_()\n",
       "```\n",
       "\n",
       "Here's the same thing, but with gradient accumulation added (assuming a target effective batch size of 64):\n",
       "\n",
       "```python\n",
       "count = 0            # track count of items seen since last weight update\n",
       "for x,y in dl:\n",
       "    count += len(x)  # update count based on this minibatch size\n",
       "    calc_loss(coeffs, x, y).backward()\n",
       "    if count>64:     # count is greater than accumulation target, so do weight update\n",
       "        coeffs.data.sub_(coeffs.grad * lr)\n",
       "        coeffs.grad.zero_()\n",
       "        count=0      # reset count\n",
       "```\n",
       "\n",
       "The full implementation in fastai is only a few lines of code -- here's the [source code](https://github.com/fastai/fastai/blob/master/fastai/callback/training.py#L26).\n",
       "\n",
       "To see the impact of gradient accumulation, consider this small model:\n",
       "<!-- #endregion -->\n",
       "\n",
       "```python\n",
       "train('convnext_small_in22k', 128, epochs=1, accum=1, finetune=False)\n",
       "```\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Open `0010_fastai_scaling_up_road_to_top_part_3` in Jupyter Notebook locally](http://localhost:8888/tree/nbs/2022part1/0010_fastai_scaling_up_road_to_top_part_3.ipynb)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Open `0010_fastai_scaling_up_road_to_top_part_3` in Jupyter Notebook on Kaggle](https://www.kaggle.com/code/jhoward/scaling-up-road-to-the-top-part-3)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| column: page\n",
    "fastnbs(\"how gradient accumulation work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d09be4",
   "metadata": {},
   "source": [
    "If [`fastnbs`](https://EmbraceLife.github.io/fastdebug/lib/utils.html#fastnbs) doesn't return anything to your query, it is because the search ability of [`fastnbs`](https://EmbraceLife.github.io/fastdebug/lib/utils.html#fastnbs) is minimum, I need to learn to improve it.  But don't worry the next function below [`fastlistnbs`](https://EmbraceLife.github.io/fastdebug/lib/utils.html#fastlistnbs) will assist you to continue searching. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad3b9f7",
   "metadata": {},
   "source": [
    "### list all notebook learning points\n",
    "I would also like to view all the learning points (in the form of questions) of all the fastai notebooks I have studied. This is a long list, so press `cmd + f` and search keywords e.g., \"ensemble\" to find the relevant questions, and then use [`fastnbs`](https://EmbraceLife.github.io/fastdebug/lib/utils.html#fastnbs) to search and display the details like above.\n",
    "\n",
    "press `cmd + o` to view them all without scrolling inside a small window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e49eff",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/Natsume/Documents/fastdebug/mds/2022part1/0007_fastai_how_random_forests_really_work.md\n",
      "## Introduction\n",
      "### why ensemble of decision trees, such as Random Forests and Gradient Boosting Machines\n",
      "### how to set print options for numpy and import `fastai.imports`\n",
      "## Data preprocessing\n",
      "### how to get Titanic dataset ready for creating a decision tree model\n",
      "## Binary splits\n",
      "### what is binary splits and who does it work\n",
      "### how to plot barplot and countplot with Seaborn\n",
      "### Create a simplest model based on binary split\n",
      "### how to do train and test split using `sklearn.model_selection.train_test_split`\n",
      "### how to access dependent and independent values for both training set and test set \n",
      "### calc the prediction (the simplest so far)\n",
      "### calc loss with mean absolute error using `sklearn.metrics.mean_absolute_error`\n",
      "### how to do binary split on a continuous column rather than category column\n",
      "### how to plot a boxenplot on survival and non-survival using `sns.logFare` column; how to a density plot with logFare using `sns.kdeplot` \n",
      "### how to find the binary split to calc predictions based on logFare using the boxenplot above\n",
      "### see how good is this model and prediction using loss (mean absolute error)\n",
      "### how does impurity measure the goodness of a split; how to create impurity as a measure for how good of a split\n",
      "### how to create a score function for a single side of the split\n",
      "### how to create the score function to measure the goodness of a binary split\n",
      "### calc the impurity score for sex split and then logFare split\n",
      "### how to make interactive on choose different split and calc score on continuous columns\n",
      "### how to make interactive on choose different split and calc score on categorical columns\n",
      "### how to make a list of all possible split points\n",
      "### how to get the score for all possible splits of a particular column like Age; how to get the index for the lowest core\n",
      "### how to write a function to return the best split value and its score on a particular column given the dataframe and the name of the column\n",
      "### how to run this function on all columns of the dataset\n",
      "### what is OneR classifier; why should it be a baseline to more sophisiticated models\n",
      "## Creating a decision tree\n",
      "### how is to do better than a OneR classifier which predict survival using sex? how about doing another OneR upon the first OneR classifier result (male group and female group)\n",
      "### how to get the dataset splitted by sex in pandas dataframe\n",
      "### how to find the best binary splits and score out of all columns in male dataset and then femal dataset\n",
      "### what does a decision tree mean when the second binary split is done here\n",
      "### how to do a decision tree automatically using sklearn\n",
      "### how to visualize the decision tree above\n",
      "## how is gini different from impurity \n",
      "### how to cacl gini\n",
      "### how to wrap the process of preparing submission csv file for kaggle\n",
      "### why no need to worry about dummy variables in decision trees\n",
      "## The random forest\n",
      "### what is random forest; what is bagging; what is the great insight behind it\n",
      "### how to create uncorrelated trees using random subset of data\n",
      "### how to make prediciton on each tree and take average on them, and then calc the loss\n",
      "### how is sklearn's RandomForestClassifier differ from the forest from scratch above; how to do random forest with sklearn\n",
      "## Conclusion\n",
      "### how should we think of simple models like OneR and decision tree and randomforest\n",
      "\n",
      "/Users/Natsume/Documents/fastdebug/mds/2022part1/0004_fastai_how_neuralnet_work.md\n",
      "## Fitting a function with *gradient descent*\n",
      "### Is neuralnet just a math function? what does the function look like?\n",
      "### why neuralnet is random at first and how to make neuralnet useful\n",
      "### `plot_function`: how to plot a function with plt; how to create x input with torch.linspace; how to plot x, y, color and title with plt;\n",
      "### how to create a particular quadratic function\n",
      "### how to write a function `quad` to create any quadratic function\n",
      "### how does `partial` and `quad` work to modify `quad` to a slightly different func?\n",
      "### how to add noise to both mult and add of the neuralnet/function; how to create noise using `np.random.normal`\n",
      "### how to create a random seed to ensure x and y are the same each run\n",
      "## A numpy book recommended by Jeremy; what is a tensor\n",
      "### how to scatterplot with plt\n",
      "### how to plot a scatterplot and a line and slides for 3 params of the line func\n",
      "### why need a loss function? how to write a mean absolute error function with torch.abs and mean\n",
      "### how display and change loss by changing values of params with sliders of interactive plot\n",
      "### A 15-min calculus video series recommended by Jeremy to watch first\n",
      "## Automating gradient descent\n",
      "### how derivatives automatically guide params to change for a lower loss\n",
      "### how to create a mean absolute error function on any quadratic model\n",
      "### how to create an random tensor with 3 values as initialized params\n",
      "### how to calc gradients of params? 1. tell PyTorch to get ready for calculating gradients for these params; 2. calc loss; 3. calc the gradients with `loss.backward()`; 4. how to access params' gradients; \n",
      "### how to change params with gradients properly to lower loss¶\n",
      "### why `with torch.no_grad():` when updating params with gradients\n",
      "### how to do 10 iterations of updating params with gradients\n",
      "## How a neural network approximates any given function\n",
      "## how to combine a linear func with max(x, 0) into a rectified linear function; how to use torch.clip(y, 0.) to perform max(y, 0.)\n",
      "## how to use partial to wrap rectified_linear to create a specific rectified_linear func\n",
      "## how to use `F.relu` to replace `torch.clip` to create a rectified linear func; \n",
      "### create double and quaduple relu func/neuralnet\n",
      "## How to recognise an owl\n",
      "### deep learning basically is drawing squiggly lines infinitely given computation and time\n",
      "\n",
      "/Users/Natsume/Documents/fastdebug/mds/2022part1/0001_fastai_is_it_a_bird.md\n",
      "## Useful Course sites\n",
      "## How to use autoreload\n",
      "## How to install and update libraries\n",
      "## Know a little about the libraries\n",
      "### what is fastai\n",
      "### what is duckduckgo\n",
      "## How to use fastdebug with fastai notebooks\n",
      "### how to use fastdebug\n",
      "### Did I document it in a notebook before?\n",
      "### Did I document it in a src before?\n",
      "## how to search and get a url of an image; how to download with an url; how to view an image;\n",
      "### how to create folders using path; how to search and download images in folders; how to resize images \n",
      "## Train my model\n",
      "### How to find and unlink images not properly downloaded\n",
      "### How to create a DataLoaders with DataBlock; how to view data with it\n",
      "### How to build my model with dataloaders and pretrained model; how to train my model\n",
      "### How to predict with my model; how to avoid running cells in nbdev_prepare\n",
      "\n",
      "/Users/Natsume/Documents/fastdebug/mds/2022part1/0006_fastai_why_should_use_framework.md\n",
      "## Introduction and set up\n",
      "### what are the benefits of using fastai and PyTorch frameworks\n",
      "### which fastai module is for tabular data; how to set float format display for pandas; how to set random seed;\n",
      "## Prep the data\n",
      "### no worry of dummy variables, normalization, missing values and so on if using fastai; interesting feature ideas from a nice Titanic feature notebook;\n",
      "### how to create a tabular dataloaders with `TabularPandas` which handles all messing processing; how to set the parameters of `TabularPandas`\n",
      "## Train the model\n",
      "### how to create a tabular learner using tabular dataloader, metrics and layers\n",
      "### how to find the learning rate automatically in fastai\n",
      "### how to pick the best learning rate from the learning rate curve; how to train model 16 epochs using `learn.fit`\n",
      "## Submit to Kaggle\n",
      "### how to prepare test data including added new features\n",
      "### how to apply all the processing steps of training data to test data with `learn.dls.test_dl`\n",
      "### how to calc all predictions for test set using `learn.get_preds`\n",
      "### how to prepare the results of test set into a csv file for kaggle submission; how to save into csv file without idx number\n",
      "## Ensembling\n",
      "### what is ensembling and why it is more robust than any single model\n",
      "### how to create an ensemble function to create multiple models and generate predictions from each of them\n",
      "### how to get the average predictions from all ensembed models\n",
      "### how to create the csv file to Titanic competition\n",
      "## Final thoughts\n",
      "### Why you should use a framework like fastai\n",
      "\n",
      "/Users/Natsume/Documents/fastdebug/mds/2022part1/0010_fastai_scaling_up_road_to_top_part_3.md\n",
      "## Memory and gradient accumulation\n",
      "### how to get the train_val dataset folder/path ready; how to get the test set images files ready\n",
      "### how to quickly train an ensemble of larger models with larger inputs on Kaggle\n",
      "### how to find out the num of files in each disease class using `pandas.value_counts`\n",
      "### how to choose a data folder which has the least num of image files for training\n",
      "### how `fine_tune` differ from `fit_one_cycle`\n",
      "### how to create a `train` function to do either fine_tune + tta or fit_one_cycle for all layers without freezing; how to add `gradient accumulation` to `train`\n",
      "### what does gradient accumulation do?\n",
      "### What benefits does gradient accumulation bring\n",
      "### how does gradient accumulation work under the hood\n",
      "### how to find out how much gpu memory is used; and how to free up the gpu memory\n",
      "## Checking memory use\n",
      "### how to check the gpu memory usage of large models with large image inputs\n",
      "## Running the models\n",
      "### how to use a dictionary to organize all models and their item and batch transformation setups\n",
      "### how to train all the selected models with transformation setups and save the tta results into a list\n",
      "## Ensembling\n",
      "### how to save all the tta results (a list) into a pickle file\n",
      "### how to get all the predictions from a list of results in which each result contains a prediction and a target for each row of test set\n",
      "### why and how to double the weights for vit models in the ensembles\n",
      "### what is the simplest way of doing ensembling\n",
      "### how to all the classes or vocab of the dataset using dataloaders; how to prepare the csv for kaggle submission\n",
      "### how to submit to kaggle using fastkaggle api\n",
      "## Conclusion\n",
      "### how fastai can superbly simply the codes and standardize processes\n",
      "\n",
      "/Users/Natsume/Documents/fastdebug/mds/2022part1/0008_fastai_first_steps_road_to_top_part_1.md\n",
      "### how to install fastkaggle if not available\n",
      "### how to iterate like a grandmaster\n",
      "### what are the related walkthrus on paddy doctor competition\n",
      "## Getting set up\n",
      "### how to setup for fastkaggle; how to use fastkaggle to download dataset from kaggle; how to access the path\n",
      "### which fastai module to use for vision problem; how to check files inside the dataset path; why Jeremy recommend not to use seed in your own analysis;\n",
      "## Looking at the data\n",
      "### how to access a subfolder by name using path from `setup_comp`; how to extract all image files from a folder\n",
      "### how to create an image from an image file; how to access the size of an image; how to display it with specified size for viewing\n",
      "### how to use `fastcore.parallel` to quickly access size of all images; how to count the occurance of each unique value in a pandas \n",
      "### how to create an image dataloaders; how to setup `item_tfms` and `batch_tfms` on image sizes; why to start with the smallest sizes first; how to display images in batch\n",
      "## Our first model\n",
      "### how to pick the first pretrained model for our model; how to build our model based on the selected pretrained model\n",
      "### how to find the learning rate for our model\n",
      "## Submitting to Kaggle\n",
      "### how to check the kaggle submission sample csv file\n",
      "### how to sort the files in the test set in the alphabetical order; how to create dataloaders for the test set based on the dataloaders of the training set\n",
      "### how to make predictions for all test set; and what does `learn.get_preds` return\n",
      "### how to access all the classes of labels with dataloaders\n",
      "### how to map classes to each idx from the predictions\n",
      "### how to save result into csv file\n",
      "### how to submit to kaggle with fastkaggle api\n",
      "## Conclusion\n",
      "### what is the most important thing for your first model\n",
      "## Addendum\n",
      "### how to quickly push your local notebook to become kaggle notebook online\n",
      "\n",
      "/Users/Natsume/Documents/fastdebug/mds/2022part1/0009_fastai_small_models_road_to_the_top_part_2.md\n",
      "## Going faster\n",
      "### why kaggle gpu is much slower for training and how does fastai to fix it with `resize_images`\n",
      "### how to create a new folder with `Path`\n",
      "### how to resize all images (including those in subfolders) of `train_images` folder and save them into a new destination folder; max_size = 256 does shrink the total size by 4+, but question: how Jeremy pick 256 not 250; \n",
      "### how to create an image dataloaders using the resized image folder and specify the resize for each image item; how to display just 3 images in a batch\n",
      "### how to wrap dataloaders creation, model creation, fine tuning together in a func `train` and return the trained model; how use model architecture, item transforms, and batch transforms, and num of epochs as the params of the `train` function;\n",
      "## A ConvNeXt model\n",
      "### How to tell whether a larger pretrained model would affect our training speed by reading GPU and CPU usage bar? why to pick convnext_small for our second model;\n",
      "### how to load and use a new pretrained model in fastai\n",
      "## Preprocessing experiments\n",
      "### question: why trying different ways of cutting images could possibly improve model performance; what are the proper options for cutting images or preparing images\n",
      "### how to try cutting image with `crop` instead of `squish` \n",
      "### what is transform image with padding and how does it differ from squish and crop\n",
      "### question: how `resize(256, 192)` and `size(171, 128)` are determined\n",
      "## Test time augmentation\n",
      "### how does test time augmentation TTA work; question: what is the rationale behind TTA\n",
      "### how to check the performance of our model on validation set\n",
      "### how to display the transformations which have been done to a single image in the training set\n",
      "### how to do TTA on validation set\n",
      "### how to calc the error rate of the tta_preds\n",
      "## Scaling up\n",
      "### how to scale up on the model using padding and the tta approach in terms of image size and epoch number\n",
      "### how to check the performance of the scaled up model using validation set\n",
      "## Submission\n",
      "### how to use TTA to predict instead of the usual `get_preds` to get predictions on the test set\n",
      "### how to get the index of the predictions\n",
      "### how to replace index with vocab or classes\n",
      "### how to submit prediction csv to kaggle with comment using fastkaggle api\n",
      "### how to push local notebook to Kaggle online\n",
      "## Conclusion\n",
      "\n",
      "/Users/Natsume/Documents/fastdebug/mds/2022part1/0002_fastai_saving_a_basic_fastai_model.md\n",
      "## what to import to handle vision problems in fastai\n",
      "## how to download and decompress datasets prepared by fastai\n",
      "## how to tell it is a cat by reading filename\n",
      "## how to create dataloaders with `from_name_func`\n",
      "## how to create a pretrained model with resnet18 and error_rate; how to fine tune it 3 epochs\n",
      "## how to export model to a pickle file and download it from Kaggle\n",
      "## how to convert ipynb to md\n",
      "\n",
      "/Users/Natsume/Documents/fastdebug/mds/2022part1/0005_fastai_linear_neuralnet_scratch.md\n",
      "## how to not execute the entire notebook\n",
      "## Introduction\n",
      "## How to download kaggle dataset to your local machine or colab? how to ues kaggle api and zipfile to download data into specified folder; how to use `pathlib.Path` to create a path;\n",
      "## how to set the print display option for numpy, torch and pandas\n",
      "## Cleaning the data\n",
      "### how to read csv file with pandas and `path/'subfolder_name'`\n",
      "### why missing value is a problem? how to find out the num of missing values of each column with pandas?\n",
      "### which value is most used to replace missing value? how to get mode for each column with pandas using `iloc[0]`\n",
      "### how to use pandas `iloc` function\n",
      "### how to fill missing values with mode without making a new copy with `pandas.fillna`\n",
      "### how to get a quick summary of all the numeric columns with pandas and numpy\n",
      "### what is long-tailed data in histogram and why it is a problem for neuralnet\n",
      "### how to plot histogram with pandas on a single column\n",
      "### how to fix long-tailed data with logarithm; why should logarithm work; how to handle zero values when applying logarithm\n",
      "### how to get a quick summary of all the non-numeric columns with pandas\n",
      "### when do we need dummy variables and how to create dummy variables with pandas\n",
      "### how to check the first few rows of selected columns with pandas\n",
      "### how to create dependent/target variable and independent/predictor variables in PyTorch tensors; how to create variables in tensor from pandas dataframe\n",
      "### how to check the size (rows and columns) of independent variables in tensor\n",
      "## Setting up a linear model\n",
      "### how to create coefficients for each (column) of our independent variables; how to get random seed in torch; how to get the num of columns; how to create random number between -0.5 and 0.5;\n",
      "### why no bias or a constant is needed for this Titanic dataset?\n",
      "### why a column `Age` having higher values than other columns can cause problem for our model; how to solve this problem by making them the same scale; how to get the max value of each column with pandas dataframe max func\n",
      "### what is maxtrix by vector operation (multiply or divide)\n",
      "### How to calculate the prediction of a linear model\n",
      "### how to look at the first 10 values of predictions\n",
      "### how to calc mean absolute error\n",
      "### how to calc predictions with a func `calc_preds`; how to calc loss with a func `calc_loss`\n",
      "## Doing a gradient descent step\n",
      "### How to cacl gradients for coefficients\n",
      "### why set gradients to zero after each gradient descent step; how to set gradient to zero; how to do one iteration of training\n",
      "### what does _ mean for `coeffs.sub_()` and `grad.zero_()`\n",
      "## Training the linear model\n",
      "### how to split the dataset by using train and valid idx produced by `fastai.data.transforms.RandomSplitter`\n",
      "### how to udpate coefficients in a function `update_coeffs`\n",
      "### how to do one epoch training in a function `one_epoch`\n",
      "### how to initializing coefficients in a function `init_coeffs`\n",
      "### how to integrate funcs above to form a function `train_model` on multiple epochs\n",
      "### how to display coefficients of the model with func `show_coeffs`\n",
      "## Measuring accuracy\n",
      "### There are many possible loss options such as accuracy other than mean absolute error\n",
      "### how to calc accuracy for the binary dependent variable\n",
      "### how to wrap the process of calc accuracy using coeffs into a func `acc(coeffs)`\n",
      "## Using sigmoid\n",
      "### when will we be needing something like sigmoid\n",
      "### how to write and plot a func like `sigmoid` using sympy\n",
      "### how to update `calc_preds` by wrapping `torch.sigmoid` around prediction\n",
      "## Submitting to Kaggle\n",
      "### read test data using `pandas.read_csv`\n",
      "### why and how to fill the missing value in Fare column with 0 instead of mode\n",
      "### how to handle missing values, long-tailed distribution and dummies together for test data\n",
      "### how to turn independent variable values into tensor\n",
      "### how to make sure independent variable in test data share the same value scare with those in training data\n",
      "### how to turn true or false into 1 or 0 and save them into a column\n",
      "### how to select two columns of a dataframe and save them into a csv file using `to_csv`\n",
      "### how to check the first few lines of the csv file using `!head`\n",
      "## Using matrix product\n",
      "### how to do matrix product `@` between a matrix and a vector with PyTorch; how to use `@` instead of doing multiplication and then addition together\n",
      "### update `calc_preds` func using matrix multiplication `@`\n",
      "### how to initialize coeffs and turn it into a matrix with a single column; question: but why make coeffs between 0 and 0.1 instead of -0.5 and 0.5\n",
      "### how to turn a single column of dependent variable into a single column matrix or a column vector\n",
      "### question: why set learning rate to be 100 for this Titanic model\n",
      "## A neural network\n",
      "### how to initialize coeffs for a neuralnet with two layers (including a hidden layer of n neurons) and the final output layer is a single neuron with a single coeff; question: how do `-0.5` and `-0.3` come from?\n",
      "### how to update `calc_preds` for this 2 layer neuralnet using `F.relu`, matrix product `@`, and `torch.sigmoid`\n",
      "### how to update coeffs layer by layer with `layer.sub_` and `layer.grad.zero_`\n",
      "### question: how the learning rate is chosen (1.4 or 20) when training\n",
      "## Deep learning\n",
      "### how to move from neuralnet with one hidden layer to a deep learning\n",
      "### why so many messy constants and how they block the progress of deep learning in the early days\n",
      "### how to use `enumerate` to loop both idx and item\n",
      "## Final thoughts\n",
      "### How much similar or different between practical models and the models from scratch above\n",
      "\n",
      "/Users/Natsume/Documents/fastdebug/mds/2022part1/0003_fastai_which_image_model_best.md\n",
      "## timm\n",
      "## how to git clone TIMM analysis data; how to enter a directory with %cd\n",
      "## how to read a csv file with pandas\n",
      "## how to merge data with pandas; how to create new column with pandas; how to string extract with regex expression; how to select columns up to a particular column with pandas; how to do loc in pandas; how to select a group of columns using str.contains and regex\n",
      "## Inference results\n",
      "### how to scatterplot with plotly.express; how to set the plot's width, height, size, title, x, y, log_x, color, hover_name, hover_data; \n",
      "### how to scatterplot on a subgroup of data using regex and plotly\n",
      "## Training results\n",
      "### convert ipynb to md\n"
     ]
    }
   ],
   "source": [
    "#| column: page\n",
    "fastlistnbs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ab473",
   "metadata": {},
   "source": [
    "### Search notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdebf391",
   "metadata": {},
   "source": [
    "I would also like to search my own fastai notes with ease. The [`fastnotes`](https://EmbraceLife.github.io/fastdebug/lib/utils.html#fastnotes) can search but very rough at the moment, and the notes need a lot of rewrite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bea8d9",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# fastnotes(\"how random forest work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcd0a95",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
