# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/lib/0001_groundup_get_data_ready.ipynb.

# %% auto 0
__all__ = ['test', 'test_eq', 'match_pct', 'search_data_url', 'check_data_directories', 'get_img_paths', 'get_labels', 'idx_line',
           'check', 'mean_std', 'normalize', 'imgs2tensor']

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 18
def test(a,b,cmp,cname=None):
    if cname is None: cname=cmp.__name__
    assert cmp(a,b),f"{cname}:\n{a}\n{b}"

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 19
def test_eq(a,b): test(a,b,operator.eq,'==')

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 31
def match_pct(query, text):
    "calc the percent of the match between the query string and the text"
    query_keys = query.split(" ")
    total = len(query_keys)
    pct = [key in text.lower() for key in query_keys].count(True)/total
    return pct

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 33
def search_data_url(dataname):
    from fastai.data.external import URLs
    url = ""
    for k, v in dict(URLs.__dict__).items():
        pct = match_pct(dataname, k)
        if pct == 1.0:
            print(v)    
            url = v            
    return url            

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 45
def check_data_directories(query): # query of data url
    from fastai.data.external import untar_data
    path = untar_data(search_data_url(query))
    import os
    print(f"cd {str(path)}")
    os.system(f"ls {str(path)}")
    print()
    for p in os.listdir(path):
        if not "." in p:
            print(f"cd {str(path/p)}")
            os.system(f"ls {str(path/p)}")
            print()

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 54
def get_img_paths(query):
    from fastai.data.external import untar_data
    from fastai.data.transforms import get_image_files
    path = untar_data(search_data_url(query))
    files_train = get_image_files(path/"train")
    files_valid = get_image_files(path/"valid")
    files_test = get_image_files(path/"test")
    len(files_train), len(files_valid), len(files_test)
    

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 66
def get_labels(img_files):
    "get labels for each x from a list of file paths"
    df = pd.read_csv(path/"labels.csv")
    labels = []
    for f in img_files:
        for i in df.index:
            if df["name"][i] in str(f):
                labels.append(df["label"][i])
    import random
    from fastcore.foundation import L
    rand = [random.randint(0,len(labels)) for i in range(5)]
    print(f"len: {len(labels)}, random view: {L(labels)[rand]}")
    print(img_files[rand])
    return labels

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 70
def idx_line(lst):
    "return zip(range(len(lst)), lst)"
    return zip(range(len(lst)), lst)

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 71
def check(f, # function name, like PIL.Image.open
        n=10 # num of lines to print, if n = -1 then print the entire __doc__
       ): 
    "check any object on its signature, class, __repr__, docs, __dict__, and other checks borrowed from utils"
    if callable(f) and not inspect.isbuiltin(f) and not inspect.ismethoddescriptor(f) or hasattr(f, '__signature__'):
        print(f"signature: {inspect.signature(f)}")
    else: print("signature: None")
        
    print(f"__class__: {getattr(f, '__class__', None)}")
    print(f'__repr__: {f}\n')
    
    if bool(getattr(f, '__doc__', None)): # make sure not None
        doclst = inspect.getdoc(f).split("\n")
        print(f'__doc__:')
        for idx, l in idx_line(doclst):
            print(l)
            if n > 0 and idx >= n: break
    else: print("__doc__: not exist\n")

    from pprint import pprint
    if hasattr(f, '__dict__') and f.__dict__ != None:
        print(f"__dict__: ")
        pprint(f.__dict__)
    elif hasattr(f, '__dict__') and f.__dict__ == None: print(f"__dict__: None")
    else: print(f'__dict__: not exist \n')
        
    from fastdebug.utils import ismetaclass, isdecorator
    print(f"metaclass: {ismetaclass(f)}")
    print(f"class: {inspect.isclass(f)}")
    print(f"decorator: {isdecorator(f)}")
    print(f"function: {inspect.isfunction(f)}")
    print(f"method: {inspect.ismethod(f)}")

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 116
def mean_std(t):
    "check mean and std of a tensor"
    print(f'mean: {t.mean()}, std: {t.std()}')

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 118
def normalize(t):
    "to normalize a tensor by dividing its maximum value"
    return t/t.max()

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 121
def imgs2tensor(img_folder:list, # a list of image files path in string
                n=-1, # n == -1 to process all files in the list, otherwise just [:n] files
                size=28 # images to be resized to (size, size)
               ): 
    "convert image folders into a tensor in which images stack on each other, and normalize it"
    lst_t = []
    if n > 0: selected = img_folder[:n]
    else: selected = img_folder
    for f in selected:
        img = PIL.Image.open(f).resize((size,size))
        t = torch.Tensor(np.array(img))
        lst_t.append(t)
    res = torch.stack(lst_t, dim=0)
    res = normalize(res)
    print(res.shape)
    mean_std(res)
    return res
