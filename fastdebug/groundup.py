# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/lib/groundup_002_get_data_ready.ipynb.

# %% auto 0
__all__ = ['test', 'test_eq', 'match_pct', 'search_data_url', 'check_data_directories', 'get_img_paths', 'get_labels', 'mean_std', 'normalize', 'imgs2tensor', 'get_exp_data', 'chunks', 'chunks_faster', 'Matrix', 'rand', 'matmul_3loops', 'dot', 'matmul_2loops_njit', 'matmul_2loops_elementwise', 'matmul_2loops_dotproduct', 'matmul_1loop_broadcast', 'matmul_einsum_noloop', 'lin', 'relu']

# %% ../nbs/lib/groundup_002_get_data_ready.ipynb 12
import operator

# %% ../nbs/lib/groundup_002_get_data_ready.ipynb 19
def test(a,b,cmp,cname=None):
    if cname is None: cname=cmp.__name__
    assert cmp(a,b),f"{cname}:\n{a}\n{b}"

# %% ../nbs/lib/groundup_002_get_data_ready.ipynb 20
def test_eq(a,b): test(a,b,operator.eq,'==')

# %% ../nbs/lib/groundup_002_get_data_ready.ipynb 32
def match_pct(query, text):
    "calc the percent of the match between the query string and the text"
    query_keys = query.split(" ")
    total = len(query_keys)
    pct = [key in text.lower() for key in query_keys].count(True)/total
    return pct

# %% ../nbs/lib/groundup_002_get_data_ready.ipynb 34
def search_data_url(dataname):
    from fastai.data.external import URLs
    url = ""
    for k, v in dict(URLs.__dict__).items():
        pct = match_pct(dataname, k)
        if pct == 1.0:
            print(v)    
            url = v            
    return url            

# %% ../nbs/lib/groundup_002_get_data_ready.ipynb 46
def check_data_directories(query): # query of data url
    from fastai.data.external import untar_data
    path = untar_data(search_data_url(query))
    import os
    print(f"cd {str(path)}")
    os.system(f"ls {str(path)}")
    print()
    for p in os.listdir(path):
        if not "." in p:
            print(f"cd {str(path/p)}")
            os.system(f"ls {str(path/p)}")
            print()

# %% ../nbs/lib/groundup_002_get_data_ready.ipynb 57
def get_img_paths(query, train, valid, test):
    from fastai.data.external import untar_data
    from fastai.data.transforms import get_image_files
    path = untar_data(search_data_url(query))
    files_train = get_image_files(path/train)
    files_valid = get_image_files(path/valid)
    files_test = get_image_files(path/test)
    print(f'train: {len(files_train)}, valid: {len(files_valid)}, test: {len(files_test)}')
    return files_train, files_valid, files_test

# %% ../nbs/lib/groundup_002_get_data_ready.ipynb 71
def get_labels(img_files):
    "get labels for each x from a list of file paths"
    df = pd.read_csv(path/"labels.csv")
    labels = []
    for f in img_files:
        for i in df.index:
            if df["name"][i] in str(f):
                labels.append(df["label"][i])
    import random
    from fastcore.foundation import L
    rand = [random.randint(0,len(labels)) for i in range(5)]
    print(f"len: {len(labels)}, random view: {L(labels)[rand]}")
    print(img_files[rand])
    return labels

# %% ../nbs/lib/groundup_002_get_data_ready.ipynb 121
def mean_std(t):
    "check mean and std of a tensor"
    print(f'mean: {t.mean()}, std: {t.std()}')

# %% ../nbs/lib/groundup_002_get_data_ready.ipynb 123
def normalize(t):
    "to normalize a tensor by dividing its maximum value"
    return t/t.max()

# %% ../nbs/lib/groundup_002_get_data_ready.ipynb 126
def imgs2tensor(img_folder:list, # a list of image files path in string
                n=-1, # n == -1 to process all files in the list, otherwise just [:n] files
                size=28 # images to be resized to (size, size)
               ): 
    "convert image folders into a tensor in which images stack on each other, and normalize it"
    lst_t = []
    if n > 0: selected = img_folder[:n]
    else: selected = img_folder
    for f in selected:
        img = PIL.Image.open(f).resize((size,size))
        t = torch.Tensor(np.array(img))
        lst_t.append(t)
    res = torch.stack(lst_t, dim=0)
    res = normalize(res)
    print(res.shape)
    mean_std(res)
    return res

# %% ../nbs/lib/groundup_003_matmul.ipynb 9
from pathlib import Path
import pickle, gzip, math, os, time, shutil, matplotlib as mpl, matplotlib.pyplot as plt

# %% ../nbs/lib/groundup_003_matmul.ipynb 21
def get_exp_data():
    from pathlib import Path
    MNIST_URL='https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'
    path_data = Path('data')
    path_data.mkdir(exist_ok=True) # created a data folder in the current directory
    path_gz = path_data/'mnist.pkl.gz'
    from urllib.request import urlretrieve
    if not path_gz.exists(): urlretrieve(MNIST_URL, path_gz)
    with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')
    return x_train, y_train, x_valid, y_valid

# %% ../nbs/lib/groundup_003_matmul.ipynb 26
def chunks(x, sz):
    for i in range(0, len(x), sz): 
        print(i)
        yield x[i:i+sz]

# %% ../nbs/lib/groundup_003_matmul.ipynb 51
def chunks_faster(x, sz):
    "if the data is numpy.ndarray and shape is 1 dimension, then we use chunks to make it a pseudo 2d"
    lst = list(x)
    it = iter(lst)
    img = list(iter(lambda: list(islice(it, sz)), []))
    print(f'len: {len(img)}')
    return img

# %% ../nbs/lib/groundup_003_matmul.ipynb 58
class Matrix:
    "turning a list of list into a maxtrix like object"
    def __init__(self, xs): self.xs = xs
    def __getitem__(self, idxs): return self.xs[idxs[0]][idxs[1]]

# %% ../nbs/lib/groundup_003_matmul.ipynb 91
def rand():
    "create a random number between 0 and 1"
    global rnd_state
    x, y, z = rnd_state
    x = (171 * x) % 30269
    y = (172 * y) % 30307
    z = (170 * z) % 30323
    rnd_state = x,y,z
    return (x/30269 + y/30307 + z/30323) % 1.0

# %% ../nbs/lib/groundup_003_matmul.ipynb 116
def matmul_3loops(a, b):
    (ar,ac),(br,bc) = a.shape,b.shape
    c = torch.zeros(ar, bc)
    for i in range(ar): # ar == 5
        for j in range(bc): # bc == 10
            for k in range(ac): c[i,j] += a[i,k] * b[k,j] # ac == 784

    print(f'shapes => a: {a.shape}, b: {b.shape}, res: {c.shape}')
    return c

# %% ../nbs/lib/groundup_003_matmul.ipynb 125
import numba

# %% ../nbs/lib/groundup_003_matmul.ipynb 128
from numba import njit, jit

# %% ../nbs/lib/groundup_003_matmul.ipynb 131
@njit
def dot(a,b):
    res = 0.
    for i in range(len(a)): res+=a[i]*b[i]
    return res

# %% ../nbs/lib/groundup_003_matmul.ipynb 138
def matmul_2loops_njit(a,b):
    "doing matrix multiplication with 2 python loops and 1 loop in machine code"
    a,b = a.numpy(),b.numpy() # njit or numba don't work with torch.tensor but numpy array
    (ar,ac),(br,bc) = a.shape,b.shape
    c = torch.zeros(ar, bc)
    for i in range(ar):
        for j in range(bc): c[i,j] = dot(a[i,:], b[:,j])
    return c

# %% ../nbs/lib/groundup_003_matmul.ipynb 161
def matmul_2loops_elementwise(a,b):
    (ar,ac),(br,bc) = a.shape,b.shape
    c = torch.zeros(ar, bc)
    for i in range(ar):
        for j in range(bc): c[i,j] = (a[i,:] * b[:,j]).sum()
    return c

# %% ../nbs/lib/groundup_003_matmul.ipynb 167
def matmul_2loops_dotproduct(a,b):
    (ar,ac),(br,bc) = a.shape,b.shape
    c = torch.zeros(ar, bc)
    for i in range(ar):
        for j in range(bc): c[i,j] = torch.dot(a[i,:], b[:,j])
    return c

# %% ../nbs/lib/groundup_003_matmul.ipynb 232
def matmul_1loop_broadcast(a,b):
    (ar,ac),(br,bc) = a.shape,b.shape
    c = torch.zeros(ar, bc)
    for i in range(ar):
        c[i]   = (a[i,:,None] * b).sum(dim=0) # broadcast version
    return c

# %% ../nbs/lib/groundup_003_matmul.ipynb 244
def matmul_einsum_noloop(a,b): return torch.einsum('ik,kj->ij', a, b)
# c[i,j] += a[i,k] * b[k,j]
# c[i,j] = (a[i,:] * b[:,j]).sum()

# %% ../nbs/lib/groundup_004_forward_backward_passes.ipynb 28
def lin(x, w, b): 
    "build a single layer linear model. use torch.matmul (faster version of einsum) to create a linear model"
    return x@w + b

# %% ../nbs/lib/groundup_004_forward_backward_passes.ipynb 32
def relu(x): 
    "basic relu with max in torch"
    return x.clamp_min(0.)