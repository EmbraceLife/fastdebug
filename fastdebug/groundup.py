# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/lib/0001_groundup_get_data_ready.ipynb.

# %% auto 0
__all__ = ['test', 'test_eq', 'match_pct', 'search_data_url', 'check_data_directories', 'get_img_paths', 'get_labels', 'mean_std',
           'normalize', 'imgs2tensor']

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 18
def test(a,b,cmp,cname=None):
    if cname is None: cname=cmp.__name__
    assert cmp(a,b),f"{cname}:\n{a}\n{b}"

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 19
def test_eq(a,b): test(a,b,operator.eq,'==')

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 31
def match_pct(query, text):
    "calc the percent of the match between the query string and the text"
    query_keys = query.split(" ")
    total = len(query_keys)
    pct = [key in text.lower() for key in query_keys].count(True)/total
    return pct

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 33
def search_data_url(dataname):
    from fastai.data.external import URLs
    url = ""
    for k, v in dict(URLs.__dict__).items():
        pct = match_pct(dataname, k)
        if pct == 1.0:
            print(v)    
            url = v            
    return url            

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 45
def check_data_directories(query): # query of data url
    from fastai.data.external import untar_data
    path = untar_data(search_data_url(query))
    import os
    print(f"cd {str(path)}")
    os.system(f"ls {str(path)}")
    print()
    for p in os.listdir(path):
        if not "." in p:
            print(f"cd {str(path/p)}")
            os.system(f"ls {str(path/p)}")
            print()

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 56
def get_img_paths(query, train, valid, test):
    from fastai.data.external import untar_data
    from fastai.data.transforms import get_image_files
    path = untar_data(search_data_url(query))
    files_train = get_image_files(path/train)
    files_valid = get_image_files(path/valid)
    files_test = get_image_files(path/test)
    print(f'train: {len(files_train)}, valid: {len(files_valid)}, test: {len(files_test)}')
    return files_train, files_valid, files_test

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 70
def get_labels(img_files):
    "get labels for each x from a list of file paths"
    df = pd.read_csv(path/"labels.csv")
    labels = []
    for f in img_files:
        for i in df.index:
            if df["name"][i] in str(f):
                labels.append(df["label"][i])
    import random
    from fastcore.foundation import L
    rand = [random.randint(0,len(labels)) for i in range(5)]
    print(f"len: {len(labels)}, random view: {L(labels)[rand]}")
    print(img_files[rand])
    return labels

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 120
def mean_std(t):
    "check mean and std of a tensor"
    print(f'mean: {t.mean()}, std: {t.std()}')

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 122
def normalize(t):
    "to normalize a tensor by dividing its maximum value"
    return t/t.max()

# %% ../nbs/lib/0001_groundup_get_data_ready.ipynb 125
def imgs2tensor(img_folder:list, # a list of image files path in string
                n=-1, # n == -1 to process all files in the list, otherwise just [:n] files
                size=28 # images to be resized to (size, size)
               ): 
    "convert image folders into a tensor in which images stack on each other, and normalize it"
    lst_t = []
    if n > 0: selected = img_folder[:n]
    else: selected = img_folder
    for f in selected:
        img = PIL.Image.open(f).resize((size,size))
        t = torch.Tensor(np.array(img))
        lst_t.append(t)
    res = torch.stack(lst_t, dim=0)
    res = normalize(res)
    print(res.shape)
    mean_std(res)
    return res
