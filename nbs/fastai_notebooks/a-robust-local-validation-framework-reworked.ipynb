{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds on my previous work -- [co-visitation matrix - simplified, imprvd logic 🔥](https://www.kaggle.com/code/radek1/co-visitation-matrix-simplified-imprvd-logic?scriptVersionId=110068977) that achieves 0.558 on the LB.\n",
    "\n",
    "Here we take the functionality from that notebook, run on 1/1000 of the data (it achieves ~0.487 on public LB).\n",
    "\n",
    "The next step in improving our results is to create a robust local validation framework to facilitate experimentation. This can be a stepping stone towards a much stronger result.\n",
    "\n",
    "Let's take a stab at implementing a local validation framework in this notebook!\n",
    "\n",
    "<strong>Please smash that thumbs up button if you like this notebook! Thank you! 🙂</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pickle5\n",
      "  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.4/256.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pickle5\n",
      "Successfully installed pickle5-0.0.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install pickle5\n",
    "import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.54 s, sys: 9 s, total: 17.5 s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_parquet('../input/otto-full-optimized-memory-footprint/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# did we actually used the test from here in original Radek's code? (It seems not)\n",
    "# test = pd.read_parquet('../input/otto-full-optimized-memory-footprint/test.parquet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_LOCAL_VALIDATION = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For local CV, we will use the last weeks data of train for validation.\n",
    "\n",
    "Essentially, without modifying the calculations in the notebook, we can run evaluation locally if we replace the contents of the `train` and `test` variables.\n",
    "\n",
    "When doing local validation, we will print out local results. And without it, we will train on full data and submit to Kaggle LB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the start and end datetime of training sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1659304800, 1661723999)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_min, ts_max = train.ts.min(), train.ts.max()\n",
    "ts_min, ts_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function fromtimestamp:\n",
      "\n",
      "fromtimestamp(...) method of builtins.type instance\n",
      "    timestamp[, tz] -> tz's local time from POSIX timestamp.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(datetime.datetime.fromtimestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datetime.datetime.fromtimestamp(ts_min/1000) make no sense to me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2022, 7, 31, 22, 0),\n",
       " datetime.datetime(2022, 8, 28, 21, 59, 59),\n",
       " datetime.datetime(1970, 1, 20, 4, 55, 4, 800000),\n",
       " datetime.datetime(1970, 1, 20, 5, 35, 23, 999000))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.fromtimestamp(ts_min), datetime.datetime.fromtimestamp(ts_max), \\\n",
    "datetime.datetime.fromtimestamp(ts_min/1000), datetime.datetime.fromtimestamp(ts_max/1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `7*24*60*60*1000` won't make the actual 7 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If 7 days is `7*24*60*60*1000` (604_800_000), then there is no cutoff which stays between ts_max and ts_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seven_days = 7*24*60*60*1000 # 604_800_000\n",
    "train_cutoff = ts_max - seven_days # 1_056_923_999 = 1_661_723_999 - 604_800_000\n",
    "ts_max > ts_min > train_cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cut is not 7 days from the last day, but 7000 days from the last day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(1970, 1, 1, 0, 0),\n",
       " datetime.datetime(2003, 6, 29, 21, 59, 59),\n",
       " datetime.datetime(2022, 7, 31, 22, 0),\n",
       " datetime.datetime(2022, 8, 28, 21, 59, 59))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.fromtimestamp(0), datetime.datetime.fromtimestamp(train_cutoff), datetime.datetime.fromtimestamp(ts_min), datetime.datetime.fromtimestamp(ts_max), \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If 7 days is `7*24*60*60` (604_800), then the cutoff which can stay between ts_max and ts_min, and cutoff is at the 7 days from the last day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seven_days = 7*24*60*60 # 604_800\n",
    "train_cutoff = ts_max - seven_days # 1_056_923_999 = 1_661_723_999 - 604_800\n",
    "ts_max > train_cutoff > ts_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(1970, 1, 1, 0, 0),\n",
       " datetime.datetime(2022, 8, 21, 21, 59, 59),\n",
       " datetime.datetime(2022, 7, 31, 22, 0),\n",
       " datetime.datetime(2022, 8, 28, 21, 59, 59))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.fromtimestamp(0), datetime.datetime.fromtimestamp(train_cutoff), \\\n",
    "datetime.datetime.fromtimestamp(ts_min), datetime.datetime.fromtimestamp(ts_max), \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How big is train, local_train, local_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((216716096, 4),\n",
       " Index            128\n",
       " session    866864384\n",
       " aid        866864384\n",
       " ts         866864384\n",
       " type       216716096\n",
       " dtype: int64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, train.memory_usage() # 216_716_096 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_train = train[train.ts <= train_cutoff] # 163_955_181 rows, and RAM on session metrics doubled from 4.6G to 9.1G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((163955181, 4),\n",
       " Index      1311641448\n",
       " session     655820724\n",
       " aid         655820724\n",
       " ts          655820724\n",
       " type        163955181\n",
       " dtype: int64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run\n",
    "local_train.shape, local_train.memory_usage() # the Index is a huge number on RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "local_test = train[train.ts > train_cutoff] # 52_760_915 rows, and RAM raise from 9.1G to 10.1G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52760915, 4),\n",
       " Index      422087320\n",
       " session    211043660\n",
       " aid        211043660\n",
       " ts         211043660\n",
       " type        52760915\n",
       " dtype: int64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run \n",
    "local_test.shape, local_test.memory_usage() # the Index is a huge number on RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we save the RAM by making the index smaller? \n",
    "https://stackoverflow.com/questions/54603378/pandas-convert-from-int64index-to-rangeindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(train.reset_index) \n",
    "#     >>> df = pd.DataFrame([('bird', 389.0),\n",
    "#     ...                    ('bird', 24.0),\n",
    "#     ...                    ('mammal', 80.5),\n",
    "#     ...                    ('mammal', np.nan)],\n",
    "#     ...                   index=['falcon', 'parrot', 'lion', 'monkey'],\n",
    "#     ...                   columns=('class', 'max_speed'))\n",
    "#     >>> df\n",
    "#              class  max_speed\n",
    "#     falcon    bird      389.0\n",
    "#     parrot    bird       24.0\n",
    "#     lion    mammal       80.5\n",
    "#     monkey  mammal        NaN\n",
    "    \n",
    "#     When we reset the index, the old index is added as a column, and a\n",
    "#     new sequential index is used:\n",
    "    \n",
    "#     >>> df.reset_index()\n",
    "#         index   class  max_speed\n",
    "#     0  falcon    bird      389.0\n",
    "#     1  parrot    bird       24.0\n",
    "#     2    lion  mammal       80.5\n",
    "#     3  monkey  mammal        NaN\n",
    "    \n",
    "#     We can use the `drop` parameter to avoid the old index being added as\n",
    "#     a column:\n",
    "    \n",
    "#     >>> df.reset_index(drop=True)\n",
    "#         class  max_speed\n",
    "#     0    bird      389.0\n",
    "#     1    bird       24.0\n",
    "#     2  mammal       80.5\n",
    "#     3  mammal        NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RangeIndex(start=0, stop=216716096, step=1),\n",
       " Int64Index([        0,         1,         2,         3,         4,         5,\n",
       "                     6,         7,         8,         9,\n",
       "             ...\n",
       "             201331366, 201331419, 201331437, 201331440, 201331459, 201331461,\n",
       "             201331464, 201331469, 201331485, 201331512],\n",
       "            dtype='int64', length=163955181),\n",
       " Int64Index([      147,       148,       149,       150,       151,       152,\n",
       "                   153,       154,       155,       156,\n",
       "             ...\n",
       "             216716086, 216716087, 216716088, 216716089, 216716090, 216716091,\n",
       "             216716092, 216716093, 216716094, 216716095],\n",
       "            dtype='int64', length=52760915))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.index, local_train.index, local_test.index # RangeIndex vs Int64Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert index from Int64Range to RangeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RangeIndex(start=0, stop=163955181, step=1),\n",
       " Index            128\n",
       " session    655820724\n",
       " aid        655820724\n",
       " ts         655820724\n",
       " type       163955181\n",
       " dtype: int64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_train.reset_index(inplace=True, drop=True) # no effect on RAM from the session metrics board\n",
    "local_train.index, local_train.memory_usage() # but the number for Index dropped drastically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RangeIndex(start=0, stop=52760915, step=1),\n",
       " Index            128\n",
       " session    211043660\n",
       " aid        211043660\n",
       " ts         211043660\n",
       " type        52760915\n",
       " dtype: int64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_test.reset_index(inplace=True, drop=True) # no effect on RAM from the session metrics board\n",
    "local_test.index, local_test.memory_usage() # but the number for Index dropped drastically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train # RAM dropped from 10.1G to 7.5G according to session metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove intersecting sessions between local_train and local_test from local_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.9 s, sys: 2.16 s, total: 28.1 s\n",
      "Wall time: 27.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "overlapping_sessions = set(local_train.session).intersection(set(local_test.session)) # not use use RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3521833, 11098528, 5323084)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(overlapping_sessions), local_train.session.unique().shape[0], local_test.session.unique().shape[0] \n",
    "# 3_521_833, 11_098_528, 5_323_084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.07 s, sys: 387 ms, total: 2.45 s\n",
      "Wall time: 2.45 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Int64Index([37376338, 37376339, 37376340, 37376341, 37376342, 37376343,\n",
       "             37376344, 37376345, 37376346, 37376347,\n",
       "             ...\n",
       "             52760905, 52760906, 52760907, 52760908, 52760909, 52760910,\n",
       "             52760911, 52760912, 52760913, 52760914],\n",
       "            dtype='int64', length=15384577),\n",
       " Index      123076616\n",
       " session     61538308\n",
       " aid         61538308\n",
       " ts          61538308\n",
       " type        15384577\n",
       " dtype: int64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "local_test = local_test[~local_test.session.isin(overlapping_sessions)] # RAM raise from 7.5 to 7.9\n",
    "local_test.index, local_test.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RangeIndex(start=0, stop=15384577, step=1),\n",
       " Index           128\n",
       " session    61538308\n",
       " aid        61538308\n",
       " ts         61538308\n",
       " type       15384577\n",
       " dtype: int64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_test.reset_index(inplace=True, drop=True) # but not reduce RAM according to session metrics, stays at 7.9G\n",
    "local_test.index, local_test.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is no empty rows in any sessions of local_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_zero = local_test.groupby('session')['aid'].count().apply(lambda x: x == 0)\n",
    "count_one = local_test.groupby('session')['aid'].count().apply(lambda x: x > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1801251, 1801251)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(count_zero), sum(count_one), local_test.session.unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data samples for local test and local validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 44s, sys: 10.5 s, total: 2min 55s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_test = []\n",
    "data_to_calculate_validation_score = []\n",
    "\n",
    "for grp in local_test.groupby('session'): # loop each session of local_test\n",
    "    # select a random row from the session as cutoff row, we want at least a single item in our validation data for each session\n",
    "    cutoff = np.random.randint(1, grp[1].shape[0]) \n",
    "    new_test.append(grp[1].iloc[:cutoff]) # take the left part from cutoff as data samples for local test\n",
    "    data_to_calculate_validation_score.append(grp[1].iloc[cutoff:]) # take the right part from the cutoff as data samples for local validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 3s, sys: 18.2 s, total: 6min 21s\n",
      "Wall time: 6min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = pd.concat(new_test).reset_index(drop=True) # stack a list of smaller dfs onto each otehr\n",
    "valid = pd.concat(data_to_calculate_validation_score).reset_index(drop=True) # maximum to 24G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7695335, 4),\n",
       " Index           128\n",
       " session    30781340\n",
       " aid        30781340\n",
       " ts         30781340\n",
       " type        7695335\n",
       " dtype: int64,\n",
       " (7689242, 4),\n",
       " Index           128\n",
       " session    30756968\n",
       " aid        30756968\n",
       " ts         30756968\n",
       " type        7689242\n",
       " dtype: int64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape, test.memory_usage(), valid.shape, valid.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 2.03 s, total: 18.8 s\n",
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test.to_parquet('_test.parquet') # save to a parquet file\n",
    "valid.to_parquet('_valid.parquet')\n",
    "\n",
    "del new_test, data_to_calculate_validation_score # now dropped to 9.8G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del local_test # from 9.8G down to 9.3G according to session metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = local_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_LOCAL_VALIDATION = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now swapped the train and test sets for the ones we conjured and can now proceed to train as we would normally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create subsets for experiments from local_train (now, known as train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_of_sessions_to_use = 1/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.1 s, sys: 1.06 s, total: 10.2 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lucky_sessions_train = train.drop_duplicates(['session']).sample(frac=fraction_of_sessions_to_use)['session']\n",
    "subset_of_train = train[train.session.isin(lucky_sessions_train)]\n",
    "\n",
    "lucky_sessions_test = test.drop_duplicates(['session']).sample(frac=fraction_of_sessions_to_use)['session']\n",
    "subset_of_test = test[test.session.isin(lucky_sessions_test)]\n",
    "\n",
    "# now session metrics reports RAM to be 10.5GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add session as index for the subsets (train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_of_train.index = pd.MultiIndex.from_frame(subset_of_train[['session']])\n",
    "subset_of_test.index = pd.MultiIndex.from_frame(subset_of_test[['session']]) # now effect on RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((164323, 4), 11099, (7507, 4), 1801)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_of_train.shape, subset_of_train.session.unique().shape[0], subset_of_test.shape, subset_of_test.session.unique().shape[0],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.78 s, sys: 86.2 ms, total: 3.87 s\n",
      "Wall time: 3.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_consecutive_AIDs = [] \n",
    "chunk_size = 60_000\n",
    "\n",
    "sessions = subset_of_train.session.unique() # all unique sessions of subset_of_train\n",
    "for i in range(0, sessions.shape[0], chunk_size): # loop every 60_000 sessions, not rows (each session has multiple rows)\n",
    "    # take every 60_000 sessions (with all rows in each session) put into a new df named current_chunk (also remove session as index)\n",
    "    current_chunk = subset_of_train.loc[sessions[i]:sessions[min(sessions.shape[0]-1, i+chunk_size-1)]].reset_index(drop=True)\n",
    "    # update current_chunk by selecting the last 30 rows of each session (make sure no additional index)\n",
    "    current_chunk = current_chunk.groupby('session').apply(lambda g: g.tail(30)).reset_index(drop=True)\n",
    "    # @radek1 has a nice explanation on this line of code, see the cell below\n",
    "    # consecutive_AIDs contains 60_000 sessions, each aid has paired with every aids    \n",
    "    consecutive_AIDs = current_chunk.merge(current_chunk, on='session')\n",
    "    # remove all rows where the pair of aids are the same\n",
    "    consecutive_AIDs = consecutive_AIDs[consecutive_AIDs.aid_x != consecutive_AIDs.aid_y]\n",
    "    # add a column named 'days_elapsed' to record how many days passed between two aids\n",
    "    # whether divided by 1000 or not should make no difference in RAM, as they are all float64 type\n",
    "    consecutive_AIDs['days_elapsed'] = (consecutive_AIDs.ts_y - consecutive_AIDs.ts_x) / (24 * 60 * 60 * 1000)\n",
    "    # select only rows where first aid comes before second aid and both occurred in the same day\n",
    "    consecutive_AIDs = consecutive_AIDs[(consecutive_AIDs.days_elapsed > 0) & (consecutive_AIDs.days_elapsed <= 1)]\n",
    "    # put every 60_000 session df processed above into a list\n",
    "    all_consecutive_AIDs.append(\n",
    "        consecutive_AIDs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How @radek1 explains `current_chunk.merge(current_chunk, on='session')` above from [discussion](https://www.kaggle.com/code/radek1/co-visitation-matrix-simplified-imprvd-logic/comments#2031136)\n",
    "so that we can create a cartesian product of aids\n",
    "\n",
    "essentially, it is a trick to create aid pairs by session\n",
    "\n",
    "if a user had three aids in a session 1, 2, 3 this will create all possible pairs [1, 1], [1,2], [1,3], [2,1]… etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply the same logic above to the subset_of_test, and append them to consecutive_AIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 513 ms, sys: 2 ms, total: 515 ms\n",
      "Wall time: 513 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sessions = subset_of_test.session.unique()\n",
    "for i in range(0, sessions.shape[0], chunk_size):\n",
    "    current_chunk = subset_of_test.loc[sessions[i]:sessions[min(sessions.shape[0]-1, i+chunk_size-1)]].reset_index(drop=True)\n",
    "    current_chunk = current_chunk.groupby('session').apply(lambda g: g.tail(30)).reset_index(drop=True)\n",
    "    consecutive_AIDs = current_chunk.merge(current_chunk, on='session')\n",
    "    consecutive_AIDs = consecutive_AIDs[consecutive_AIDs.aid_x != consecutive_AIDs.aid_y]\n",
    "    consecutive_AIDs['days_elapsed'] = (consecutive_AIDs.ts_y - consecutive_AIDs.ts_x) / (24 * 60 * 60 * 1000)\n",
    "    consecutive_AIDs = consecutive_AIDs[(consecutive_AIDs.days_elapsed > 0) & (consecutive_AIDs.days_elapsed <= 1)]\n",
    "    all_consecutive_AIDs.append(\n",
    "        consecutive_AIDs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stack all dfs inside all_consecutive_AIDs into a single df and remove the rows when their session, aid_x, aid_y are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 137 ms, sys: 962 µs, total: 138 ms\n",
      "Wall time: 135 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_consecutive_AIDs = pd.concat(all_consecutive_AIDs).drop_duplicates(['session', 'aid_x', 'aid_y'])[['aid_x', 'aid_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid_x</th>\n",
       "      <th>aid_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236819</td>\n",
       "      <td>4268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>236819</td>\n",
       "      <td>994930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>236819</td>\n",
       "      <td>305933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>236819</td>\n",
       "      <td>569669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4268</td>\n",
       "      <td>994930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     aid_x   aid_y\n",
       "1   236819    4268\n",
       "2   236819  994930\n",
       "8   236819  305933\n",
       "11  236819  569669\n",
       "18    4268  994930"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_consecutive_AIDs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Counter with defaultdict to count the num of occurrences of other aids given each aid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 861 ms, sys: 21 ms, total: 882 ms\n",
      "Wall time: 881 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "next_AIDs = defaultdict(Counter)\n",
    "\n",
    "for row in all_consecutive_AIDs.itertuples():\n",
    "    next_AIDs[row.aid_x][row.aid_y] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236819\n",
      "Counter({4268: 1, 994930: 1, 305933: 1, 569669: 1})\n"
     ]
    }
   ],
   "source": [
    "for k,v in next_AIDs.items(): \n",
    "    print(k)\n",
    "    print(v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49916"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next_AIDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's generate the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session\n",
       "11098528    [11830, 1679529, 92401, 1055218, 1561739, 1679...\n",
       "11098529                                            [1105029]\n",
       "11098530     [264500, 264500, 409236, 409236, 409236, 409236]\n",
       "11098531    [452188, 1239060, 1557766, 452188, 396199, 130...\n",
       "11098532                     [7651, 876469, 1596491, 1550739]\n",
       "                                  ...                        \n",
       "12899774                                              [33035]\n",
       "12899775                                            [1743151]\n",
       "12899776                                             [548599]\n",
       "12899777                                             [384045]\n",
       "12899778                                             [561560]\n",
       "Name: aid, Length: 1801251, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby('session')['aid'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.3 s, sys: 434 ms, total: 34.8 s\n",
      "Wall time: 34.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "session\n",
       "11098528    [11830, 1679529, 92401, 1055218, 1561739, 1679...\n",
       "11098529                                            [1105029]\n",
       "11098530     [264500, 264500, 409236, 409236, 409236, 409236]\n",
       "11098531    [452188, 1239060, 1557766, 452188, 396199, 130...\n",
       "11098532                     [7651, 876469, 1596491, 1550739]\n",
       "Name: aid, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# get aid into a list for every session in the processed local_test\n",
    "test_session_AIDs = test.groupby('session')['aid'].apply(list)\n",
    "test_session_AIDs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_types = ['clicks', 'carts', 'orders']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rd: recsys - otto - robust local validation - debug a block of code by making it a func and use print and return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The original code** here and see debuggable version in the next cell\n",
    "```python\n",
    "labels = []\n",
    "\n",
    "for AIDs in test_session_AIDs: # loop each session to get its list of aids\n",
    "    AIDs = list(dict.fromkeys(AIDs[::-1])) # reverse the order of the list of aids and remove duplicated aids and return a list\n",
    "    if len(AIDs) >= 20: # if there are more than 20 aids in the session, then takes the first 20 aids into labels (a list)\n",
    "        labels.append(AIDs[:20])\n",
    "    else:\n",
    "        counter = Counter()\n",
    "        for AID in AIDs: # loop every aid of the list of aid from the session\n",
    "            subsequent_AID_counter = next_AIDs.get(AID) # use next_AIDs to access all the pair partners of AID, which is a counter\n",
    "            # if the counter exist, merge subsequent_AID_counter to counter (counter is still a single counter with a lot more items each time)\n",
    "            if subsequent_AID_counter:\n",
    "                counter += subsequent_AID_counter\n",
    "        # now, counter is a Counter contains a Counter of other aids for every aid in a session (which means a lot of other aids counts)\n",
    "        # take the 40 most common other aids, if they are not already in AIDs, then add them to AIDs\n",
    "        AIDs += [AID for AID, cnt in counter.most_common(40) if AID not in AIDs]\n",
    "        # in the end only take the first 20 aids into labels for each session\n",
    "        labels.append(AIDs[:20])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 466 ms, total: 1min 2s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def f():\n",
    "    labels = []\n",
    "\n",
    "    for AIDs in test_session_AIDs: # loop each session to get its list of aids\n",
    "        AIDs = list(dict.fromkeys(AIDs[::-1])) # reverse the order of the list of aids and remove duplicated aids and return a list\n",
    "        if len(AIDs) >= 20: # if there are more than 20 aids in the session, then takes the first 20 aids into labels (a list)\n",
    "            labels.append(AIDs[:20])\n",
    "        else:\n",
    "            counter = Counter()\n",
    "#             idx = 0\n",
    "            for AID in AIDs: # loop every aid of the list of aid from the session\n",
    "                subsequent_AID_counter = next_AIDs.get(AID) # use next_AIDs to access all the pair partners of AID, which is a counter\n",
    "                # if the counter exist, merge subsequent_AID_counter to counter (counter is still a single counter with a lot more items each time)\n",
    "                if subsequent_AID_counter:\n",
    "#                     idx+=1\n",
    "                    counter += subsequent_AID_counter\n",
    "#                     print(f\"subsequent_AID_counter: {subsequent_AID_counter}\")\n",
    "#                     print(f\"counter: {counter}\")\n",
    "#                     print()\n",
    "#                     if idx>1:\n",
    "#                         return\n",
    "\n",
    "            # now, counter is a Counter contains a Counter of other aids for every aid in a session (which means a lot of other aids counts)\n",
    "            # take the 40 most common other aids, if they are not already in AIDs, then add them to AIDs\n",
    "#             print(counter.most_common(40))\n",
    "#             help(counter.most_common)\n",
    "#             return\n",
    "            AIDs += [AID for AID, cnt in counter.most_common(40) if AID not in AIDs]\n",
    "            # in the end only take the first 20 aids into labels for each session\n",
    "            labels.append(AIDs[:20])\n",
    "    \n",
    "    return labels\n",
    "\n",
    "labels = f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist([len(l) for l in labels]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the submission format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make the list of aids into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "      <td>369774 440367 11830 1033148 990658 1199737 167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529</td>\n",
       "      <td>1105029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530</td>\n",
       "      <td>409236 264500 860 492245 1151358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098531</td>\n",
       "      <td>1553691 1271998 396199 1728212 1365569 1557766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098532</td>\n",
       "      <td>1550739 1596491 876469 7651 1402537 123224 400...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_type                                             labels\n",
       "0      11098528  369774 440367 11830 1033148 990658 1199737 167...\n",
       "1      11098529                                            1105029\n",
       "2      11098530                   409236 264500 860 492245 1151358\n",
       "3      11098531  1553691 1271998 396199 1728212 1365569 1557766...\n",
       "4      11098532  1550739 1596491 876469 7651 1402537 123224 400..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_as_strings = [' '.join([str(l) for l in lls]) for lls in labels]\n",
    "predictions = pd.DataFrame(data={'session_type': test_session_AIDs.index, 'labels': labels_as_strings})\n",
    "labels_as_strings[:2]\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dfs = []\n",
    "\n",
    "for st in session_types:\n",
    "    modified_predictions = predictions.copy()\n",
    "    modified_predictions.session_type = modified_predictions.session_type.astype('str') + f'_{st}'\n",
    "    prediction_dfs.append(modified_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528_clicks</td>\n",
       "      <td>369774 440367 11830 1033148 990658 1199737 167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529_clicks</td>\n",
       "      <td>1105029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530_clicks</td>\n",
       "      <td>409236 264500 860 492245 1151358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098531_clicks</td>\n",
       "      <td>1553691 1271998 396199 1728212 1365569 1557766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098532_clicks</td>\n",
       "      <td>1550739 1596491 876469 7651 1402537 123224 400...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_type                                             labels\n",
       "0  11098528_clicks  369774 440367 11830 1033148 990658 1199737 167...\n",
       "1  11098529_clicks                                            1105029\n",
       "2  11098530_clicks                   409236 264500 860 492245 1151358\n",
       "3  11098531_clicks  1553691 1271998 396199 1728212 1365569 1557766...\n",
       "4  11098532_clicks  1550739 1596491 876469 7651 1402537 123224 400..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528_carts</td>\n",
       "      <td>369774 440367 11830 1033148 990658 1199737 167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529_carts</td>\n",
       "      <td>1105029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530_carts</td>\n",
       "      <td>409236 264500 860 492245 1151358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098531_carts</td>\n",
       "      <td>1553691 1271998 396199 1728212 1365569 1557766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098532_carts</td>\n",
       "      <td>1550739 1596491 876469 7651 1402537 123224 400...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     session_type                                             labels\n",
       "0  11098528_carts  369774 440367 11830 1033148 990658 1199737 167...\n",
       "1  11098529_carts                                            1105029\n",
       "2  11098530_carts                   409236 264500 860 492245 1151358\n",
       "3  11098531_carts  1553691 1271998 396199 1728212 1365569 1557766...\n",
       "4  11098532_carts  1550739 1596491 876469 7651 1402537 123224 400..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_dfs[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528_orders</td>\n",
       "      <td>369774 440367 11830 1033148 990658 1199737 167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529_orders</td>\n",
       "      <td>1105029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530_orders</td>\n",
       "      <td>409236 264500 860 492245 1151358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098531_orders</td>\n",
       "      <td>1553691 1271998 396199 1728212 1365569 1557766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098532_orders</td>\n",
       "      <td>1550739 1596491 876469 7651 1402537 123224 400...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_type                                             labels\n",
       "0  11098528_orders  369774 440367 11830 1033148 990658 1199737 167...\n",
       "1  11098529_orders                                            1105029\n",
       "2  11098530_orders                   409236 264500 860 492245 1151358\n",
       "3  11098531_orders  1553691 1271998 396199 1728212 1365569 1557766...\n",
       "4  11098532_orders  1550739 1596491 876469 7651 1402537 123224 400..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_dfs[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528_clicks</td>\n",
       "      <td>369774 440367 11830 1033148 990658 1199737 167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529_clicks</td>\n",
       "      <td>1105029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530_clicks</td>\n",
       "      <td>409236 264500 860 492245 1151358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098531_clicks</td>\n",
       "      <td>1553691 1271998 396199 1728212 1365569 1557766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098532_clicks</td>\n",
       "      <td>1550739 1596491 876469 7651 1402537 123224 400...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_type                                             labels\n",
       "0  11098528_clicks  369774 440367 11830 1033148 990658 1199737 167...\n",
       "1  11098529_clicks                                            1105029\n",
       "2  11098530_clicks                   409236 264500 860 492245 1151358\n",
       "3  11098531_clicks  1553691 1271998 396199 1728212 1365569 1557766...\n",
       "4  11098532_clicks  1550739 1596491 876469 7651 1402537 123224 400..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.concat(prediction_dfs).reset_index(drop=True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We either submit to Kaggle or run validation locally\n",
    "\n",
    "We need to now reverse the processing we applied to our predictions to shape them into a submission.\n",
    "\n",
    "I am undoing this work here on purpose. I will replace the code I use for predictions down the road, so I want my evaluation framework to work with data formatted like for making a submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/otto-full-optimized-memory-footprint/id2type.pkl', \"rb\") as fh:\n",
    "    id2type = pickle.load(fh)\n",
    "with open('../input/otto-full-optimized-memory-footprint/type2id.pkl', \"rb\") as fh:\n",
    "    type2id = pickle.load(fh)\n",
    "    \n",
    "sample_sub = pd.read_csv('../input/otto-recommender-system/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899779_clicks</td>\n",
       "      <td>129004 126836 118524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899779_carts</td>\n",
       "      <td>129004 126836 118524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899779_orders</td>\n",
       "      <td>129004 126836 118524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899780_clicks</td>\n",
       "      <td>129004 126836 118524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899780_carts</td>\n",
       "      <td>129004 126836 118524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_type                labels\n",
       "0  12899779_clicks  129004 126836 118524\n",
       "1   12899779_carts  129004 126836 118524\n",
       "2  12899779_orders  129004 126836 118524\n",
       "3  12899780_clicks  129004 126836 118524\n",
       "4   12899780_carts  129004 126836 118524"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local validation score: 0.4439805579019317\n",
      "CPU times: user 2min 32s, sys: 4.54 s, total: 2min 37s\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if DO_LOCAL_VALIDATION:\n",
    "    # convert back for experiment\n",
    "    submission['session'] = submission.session_type.apply(lambda x: int(x.split('_')[0]))\n",
    "    submission['type'] = submission.session_type.apply(lambda x: x.split('_')[1])\n",
    "    submission.labels = submission.labels.apply(lambda x: [int(i) for i in x.split(' ')])\n",
    "\n",
    "    # convert type from idx to string-type for validation set\n",
    "    valid.type = valid.type.map(lambda idx: id2type[idx])\n",
    "    # group by session, then group by type, to access all aids, and make all aids into a list\n",
    "    ground_truth = valid.groupby(['session', 'type'])['aid'].apply(list)\n",
    "    # remove index and rename column aid to labels\n",
    "    ground_truth = ground_truth.reset_index().rename(columns={'aid': 'labels'})\n",
    "    # \n",
    "    ground_truth.loc[ground_truth.type == 'clicks', 'labels'] = ground_truth.loc[ground_truth.type == 'clicks', 'labels'].str[-1:]\n",
    "\n",
    "    submission_with_gt = submission.merge(ground_truth[['session', 'type', 'labels']], how='left', on=['session', 'type'])\n",
    "    submission_with_gt = submission_with_gt[~submission_with_gt.labels_y.isna()]\n",
    "    submission_with_gt['hits'] = submission_with_gt.apply(lambda df: len(set(df.labels_x).intersection(set(df.labels_y))), axis=1)\n",
    "    submission_with_gt['gt_count'] = submission_with_gt.labels_y.str.len()\n",
    "\n",
    "    recall_per_type = submission_with_gt.groupby(['type'])['hits'].sum() / submission_with_gt.groupby(['type'])['gt_count'].sum() \n",
    "    local_validation_score = (recall_per_type * pd.Series({'clicks': 0.10, 'carts': 0.30, 'orders': 0.60})).sum()\n",
    "    print(f'Local validation score: {local_validation_score}')\n",
    "\n",
    "else:\n",
    "    submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment to figure what some lines do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528_clicks</td>\n",
       "      <td>369774 440367 11830 1033148 990658 1199737 167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529_clicks</td>\n",
       "      <td>1105029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530_clicks</td>\n",
       "      <td>409236 264500 860 492245 1151358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098531_clicks</td>\n",
       "      <td>1553691 1271998 396199 1728212 1365569 1557766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098532_clicks</td>\n",
       "      <td>1550739 1596491 876469 7651 1402537 123224 400...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_type                                             labels\n",
       "0  11098528_clicks  369774 440367 11830 1033148 990658 1199737 167...\n",
       "1  11098529_clicks                                            1105029\n",
       "2  11098530_clicks                   409236 264500 860 492245 1151358\n",
       "3  11098531_clicks  1553691 1271998 396199 1728212 1365569 1557766...\n",
       "4  11098532_clicks  1550739 1596491 876469 7651 1402537 123224 400..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.concat(prediction_dfs).reset_index(drop=True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            session_type                                           labels_x  \\\n",
      "0        11098528_clicks  [369774, 440367, 11830, 1033148, 990658, 11997...   \n",
      "1        11098529_clicks                                          [1105029]   \n",
      "3        11098531_clicks  [1553691, 1271998, 396199, 1728212, 1365569, 1...   \n",
      "4        11098532_clicks  [1550739, 1596491, 876469, 7651, 1402537, 1232...   \n",
      "5        11098533_clicks  [144447, 1493503, 1233050, 23678, 941187, 7613...   \n",
      "...                  ...                                                ...   \n",
      "5403303  12899329_orders                                          [1333457]   \n",
      "5403311  12899337_orders  [558573, 1584505, 1046124, 899637, 698100, 877...   \n",
      "5403329  12899355_orders  [1115942, 465366, 1439071, 933686, 1446430, 20...   \n",
      "5403347  12899373_orders  [1766353, 995962, 487949, 1265534, 320314, 873...   \n",
      "5403499  12899525_orders  [1488793, 1599360, 127479, 996393, 531353, 101...   \n",
      "\n",
      "          session    type                   labels_y  hits  gt_count  \n",
      "0        11098528  clicks                   [588923]     0         1  \n",
      "1        11098529  clicks                  [1298277]     0         1  \n",
      "3        11098531  clicks                  [1365569]     1         1  \n",
      "4        11098532  clicks                   [444527]     0         1  \n",
      "5        11098533  clicks                  [1188296]     0         1  \n",
      "...           ...     ...                        ...   ...       ...  \n",
      "5403303  12899329  orders                   [931182]     0         1  \n",
      "5403311  12899337  orders                   [851751]     0         1  \n",
      "5403329  12899355  orders                   [465366]     1         1  \n",
      "5403347  12899373  orders                  [1766353]     1         1  \n",
      "5403499  12899525  orders  [1599360, 996393, 956231]     2         3  \n",
      "\n",
      "[2213594 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def f():\n",
    "    if DO_LOCAL_VALIDATION:\n",
    "        # convert back for experiment\n",
    "        submission['session'] = submission.session_type.apply(lambda x: int(x.split('_')[0]))\n",
    "        submission['type'] = submission.session_type.apply(lambda x: x.split('_')[1])\n",
    "        submission.labels = submission.labels.apply(lambda x: [int(i) for i in x.split(' ')])\n",
    "\n",
    "        # convert type from idx to string-type for validation set\n",
    "        valid.type = valid.type.map(lambda idx: id2type[idx])\n",
    "        # group by session, then group by type, to access all aids, and make all aids into a list\n",
    "        ground_truth = valid.groupby(['session', 'type'])['aid'].apply(list)\n",
    "#         print(ground_truth)\n",
    "#         return\n",
    "        # remove index and rename column aid to labels (no more aid as column)\n",
    "        ground_truth = ground_truth.reset_index().rename(columns={'aid': 'labels'})\n",
    "#         print(ground_truth)\n",
    "#         return\n",
    "        # debug to figure out what does .str[-1:] do: to get the last aid of the labels as the only label for each row if the type is clicks\n",
    "        ground_truth.loc[ground_truth.type == 'clicks', 'labels'] = ground_truth.loc[ground_truth.type == 'clicks', 'labels'].str[-1:]\n",
    "#         print(ground_truth)\n",
    "#         return        \n",
    "        # how to merge submission with ground_truth on session and type\n",
    "        submission_with_gt = submission.merge(ground_truth[['session', 'type', 'labels']], how='left', on=['session', 'type'])\n",
    "#         print(submission_with_gt)\n",
    "#         return         \n",
    "        # make sure rows with ground_truth.label as na is not selected\n",
    "        submission_with_gt = submission_with_gt[~submission_with_gt.labels_y.isna()]\n",
    "        # create a column for submission_with_gt to check which rows has labels_x and labels_y have aid intersections (true or false)\n",
    "        submission_with_gt['hits'] = submission_with_gt.apply(lambda df: len(set(df.labels_x).intersection(set(df.labels_y))), axis=1)\n",
    "        # add a column to count the ground truth or the number of aids of labels_y (turn labels_y into a string, \n",
    "        # len() of it can tell us how many aids are there)\n",
    "        submission_with_gt['gt_count'] = submission_with_gt.labels_y.str.len()\n",
    "        print(submission_with_gt)\n",
    "        return         \n",
    "\n",
    "        # calc recall for each type\n",
    "        recall_per_type = submission_with_gt.groupby(['type'])['hits'].sum() / submission_with_gt.groupby(['type'])['gt_count'].sum() \n",
    "        # calc validation score with recall and then print it\n",
    "        local_validation_score = (recall_per_type * pd.Series({'clicks': 0.10, 'carts': 0.30, 'orders': 0.60})).sum()\n",
    "        print(f'Local validation score: {local_validation_score}')\n",
    "\n",
    "    else:\n",
    "        submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "submission = pd.concat(prediction_dfs).reset_index(drop=True)\n",
    "valid = pd.read_parquet('_valid.parquet')\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
