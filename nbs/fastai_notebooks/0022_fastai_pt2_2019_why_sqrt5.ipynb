{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df3eb8e",
   "metadata": {},
   "source": [
    "# 0022_fastai_pt2_2019_why_sqrt5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "324d7db9",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb52e93",
   "metadata": {},
   "source": [
    "## Does nn.Conv2d init work well?\n",
    "### [00:00](https://youtu.be/AcA8HAYh7IE?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=0) one of the purpose of part 2 is to demonstrate how Jeremy does research; Jeremy is going to show us how he does research to find out how well does a mysterious line of code in the pytorch work\n",
    "\n",
    "[01:28](https://youtu.be/AcA8HAYh7IE?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=88) - \n",
    "\n",
    "[02:28](https://youtu.be/AcA8HAYh7IE?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=148) - how to resize a 3 color channel image into a single changel image 28x28\n",
    "\n",
    "[03:06](https://youtu.be/AcA8HAYh7IE?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=186) - when would Jeremy create a function during research; experiment to show that the line is not performing well\n",
    "\n",
    "[08:55](https://youtu.be/AcA8HAYh7IE?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=535) - Jeremy writing his own version of kaiming init\n",
    "\n",
    "[15:59](https://youtu.be/AcA8HAYh7IE?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=959) - Jeremy reimplemented what pytorch had on kaiming init; Jeremy used an example to test on how useless or useful of the line in pytorch;\n",
    "\n",
    "[17:30](https://youtu.be/AcA8HAYh7IE?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=1050) -  using kaiming_uniform_ to test the line, and the result is better but still problematic\n",
    "\n",
    "[18:58](https://youtu.be/AcA8HAYh7IE?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=1138) - look at 2b why need a good init; why in the past neuralnet is so hard to train; why weights initialization is so crucial to training or learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0a2164",
   "metadata": {},
   "source": [
    "[21:04](https://youtu.be/AcA8HAYh7IE?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=1264) - Sylvian further explained something interesting \n",
    "\n",
    "[21:30](https://youtu.be/AcA8HAYh7IE?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=1290) - how pytorch team responded\n",
    "\n",
    "[23:52](https://youtu.be/AcA8HAYh7IE?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=1433) - many init papers and approaches\n",
    "\n",
    "[27:11](https://youtu.be/AcA8HAYh7IE?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=1631) - ground up so that we can ask questions on pytorch strange and historical edges\n",
    "\n",
    "[28:56](https://youtu.be/AcA8HAYh7IE?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=1736) - let's train a model with our fully connected architecture with cross-entropy\n",
    "\n",
    "[30:21](https://youtu.be/AcA8HAYh7IE?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=1821) - how to understand  log cross-entropy from scratch\n",
    "\n",
    "[34:26](https://youtu.be/AcA8HAYh7IE?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=2066) - how to write negative log likelihood in pytorch with a trick\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c5018",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course19.fast.ai/videos/?lesson=9&t=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4fea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_02 import *\n",
    "\n",
    "def get_data():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "def normalize(x, m, s): return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8364a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.modules.conv._ConvNd.reset_parameters??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "train_mean,train_std = x_train.mean(),x_train.std()\n",
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "x_valid = normalize(x_valid, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.view(-1,1,28,28)\n",
    "x_valid = x_valid.view(-1,1,28,28)\n",
    "x_train.shape,x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73595206",
   "metadata": {},
   "outputs": [],
   "source": [
    "n,*_ = x_train.shape\n",
    "c = y_train.max()+1\n",
    "nh = 32\n",
    "n,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3087a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = nn.Conv2d(1, nh, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f6ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_valid[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19ad18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9cae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(x): return x.mean(),x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7deee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ffdd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(l1.weight),stats(l1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e4400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = l1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a10d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "init.kaiming_normal_(l1.weight, a=1.)\n",
    "stats(l1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a10bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x,a=0): return F.leaky_relu(l1(x),a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "init.kaiming_normal_(l1.weight, a=0)\n",
    "stats(f1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = nn.Conv2d(1, nh, 5)\n",
    "stats(f1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23408cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# receptive field size\n",
    "rec_fs = l1.weight[0,0].numel()\n",
    "rec_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9bb175",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf,ni,*_ = l1.weight.shape\n",
    "nf,ni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91608f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fan_in  = ni*rec_fs\n",
    "fan_out = nf*rec_fs\n",
    "fan_in,fan_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565cb49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(a): return math.sqrt(2.0 / (1 + a**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71610573",
   "metadata": {},
   "outputs": [],
   "source": [
    "gain(1),gain(0),gain(0.01),gain(0.1),gain(math.sqrt(5.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ebe1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros(10000).uniform_(-1,1).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f0620",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/math.sqrt(3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a130f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming2(x,a, use_fan_out=False):\n",
    "    nf,ni,*_ = x.shape\n",
    "    rec_fs = x[0,0].shape.numel()\n",
    "    fan = nf*rec_fs if use_fan_out else ni*rec_fs\n",
    "    std = gain(a) / math.sqrt(fan)\n",
    "    bound = math.sqrt(3.) * std\n",
    "    x.data.uniform_(-bound,bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0013cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaiming2(l1.weight, a=0);\n",
    "stats(f1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95614b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaiming2(l1.weight, a=math.sqrt(5.))\n",
    "stats(f1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ee454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self,x): return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5980eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sequential(\n",
    "    nn.Conv2d(1,8, 5,stride=2,padding=2), nn.ReLU(),\n",
    "    nn.Conv2d(8,16,3,stride=2,padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16,32,3,stride=2,padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(32,1,3,stride=2,padding=1),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Flatten(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_valid[:100].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fa984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = m(x)\n",
    "stats(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6defa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = mse(t,y)\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd0172",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(m[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad8ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "init.kaiming_uniform_??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in m:\n",
    "    if isinstance(l,nn.Conv2d):\n",
    "        init.kaiming_uniform_(l.weight)\n",
    "        l.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db489ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = m(x)\n",
    "stats(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac53086",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = mse(t,y)\n",
    "l.backward()\n",
    "stats(m[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf16eb53",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461a286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./notebook2script.py 02a_why_sqrt5.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0119f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastdebug.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8db44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## <mark style=\"background-color: #ffff00\">the</mark>  <mark style=\"background-color: #ffff00\">forward</mark>  <mark style=\"background-color: #ffff00\">and</mark>  <mark style=\"background-color: #ffff00\">backward</mark>  <mark style=\"background-color: #FFFF00\">passes</mark> \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "This section contains only the current heading 2 and its subheadings\n",
       "### get_data\n",
       "\n",
       "#### [1:23:03](https://youtu.be/4u8FxNEDUeg?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=4983) - how to download and prepare the mnist dataset and wrap the process into a function called `get_data`; \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "[Jump_to lesson 8 video](https://course19.fast.ai/videos/?lesson=8&t=4960)\n",
       "\n",
       "```python\n",
       "#export\n",
       "from exp.nb_01 import *\n",
       "\n",
       "def get_data():\n",
       "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
       "    with gzip.open(path, 'rb') as f:\n",
       "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
       "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
       "```\n",
       "\n",
       "```python\n",
       "x_train,y_train,x_valid,y_valid = get_data()\n",
       "```\n",
       "\n",
       "\n",
       "### normalize(x, m, s)\n",
       "\n",
       "#### [1:23:48](https://youtu.be/4u8FxNEDUeg?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=5028) - how to create `normalize` function to use broadcast to normalize the Xs and Ys; what does normalization to Xs and Ys mean (make Xs and Ys to have a distribution whose mean is 0 and std is 1)? how to make the mean and std of Xs and Ys to be 0 and 1 (using the formula of normalization below) Why we don't use validation set's mean and std to normalization Xs and Ys of validation set but use those of training set? (make sure validation set and training set share the same scale as training set) What example did Jeremy give to explain the importance of using training set's mean and std for normalization of validation set\n",
       "\n",
       "\n",
       "\n",
       "```python\n",
       "def normalize(x, m, s): return (x-m)/s\n",
       "```\n",
       "\n",
       "```python\n",
       "train_mean,train_std = x_train.mean(),x_train.std()\n",
       "train_mean,train_std\n",
       "```\n",
       "\n",
       "```python\n",
       "x_train = normalize(x_train, train_mean, train_std)\n",
       "# NB: Use training, not validation mean for validation set\n",
       "x_valid = normalize(x_valid, train_mean, train_std)\n",
       "```\n",
       "\n",
       "### test_near_zero  and  assert\n",
       "\n",
       "#### [1:24:52](https://youtu.be/4u8FxNEDUeg?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=5092) - how to check the mean and std values are close to 0 and 1 using `test_near_zero` using `assert`\n",
       "\n",
       "```python\n",
       "train_mean,train_std = x_train.mean(),x_train.std()\n",
       "train_mean,train_std\n",
       "```\n",
       "\n",
       "```python\n",
       "#export\n",
       "def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\"\n",
       "```\n",
       "\n",
       "```python\n",
       "test_near_zero(x_train.mean())\n",
       "test_near_zero(1-x_train.std())\n",
       "```\n",
       "\n",
       "### getting dimensions of weights of different layers\n",
       "\n",
       "#### [1:25:16](https://youtu.be/4u8FxNEDUeg?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=5116) - how to get the number of activations of each layer `n` (rows of input), `m` (columns of input), `c` (number of targets/classes) from the shape of `x_train` and `y_train`\n",
       "\n",
       "\n",
       "```python\n",
       "n,m = x_train.shape\n",
       "c = y_train.max()+1\n",
       "n,m,c\n",
       "```\n",
       "\n",
       "start of another heading 2\n",
       "## Foundations version"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Open `0021_fastai_pt2_2019_fully_connected` in Jupyter Notebook locally](http://localhost:8888/tree/nbs/fastai_notebooks/0021_fastai_pt2_2019_fully_connected.ipynb)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### [1:55:22](https://youtu.be/4u8fxnedueg?list=plfyubjixbdttidte1u8qgyxo4jy2y91uj&t=6922) - how to put <mark style=\"background-color: #ffff00\">forward</mark>  pass <mark style=\"background-color: #ffff00\">and</mark>  <mark style=\"background-color: #FFFF00\">backward</mark>  pass into one function `foward_and_backward`; <mark style=\"background-color: #ffff00\">and</mark>  <mark style=\"background-color: #FFFF00\">backward</mark>  pass is <mark style=\"background-color: #ffff00\">the</mark>  chain rule (people who say no are liars) <mark style=\"background-color: #ffff00\">and</mark>  saving <mark style=\"background-color: #ffff00\">the</mark>  gradients as well; \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "This section contains only the current heading 3 and its subheadings\n",
       "\n",
       "```python\n",
       "def forward_and_backward(inp, targ):\n",
       "    # forward pass:\n",
       "    l1 = inp @ w1 + b1\n",
       "    l2 = relu(l1)\n",
       "    out = l2 @ w2 + b2\n",
       "    # we don't actually need the loss in backward!\n",
       "    loss = mse(out, targ)\n",
       "    \n",
       "    # backward pass:\n",
       "    mse_grad(out, targ)\n",
       "    lin_grad(l2, out, w2, b2)\n",
       "    relu_grad(l1, l2)\n",
       "    lin_grad(inp, l1, w1, b1)\n",
       "```\n",
       "\n",
       "```python\n",
       "forward_and_backward(x_train, y_train)\n",
       "```\n",
       "\n",
       "start of another heading 3\n",
       "### [1:56:41](https://youtu.be/4u8FxNEDUeg?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=7001) - how to use pytorch's gradient calculation functions to test whether our own gradients are calculated correctly; "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Open `0021_fastai_pt2_2019_fully_connected` in Jupyter Notebook locally](http://localhost:8888/tree/nbs/fastai_notebooks/0021_fastai_pt2_2019_fully_connected.ipynb)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fastnbs(\"The forward and backward passes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7c564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
