{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256bd5fa",
   "metadata": {},
   "source": [
    "# üìà What do we know so far? ‚ö°Summary with links to relevant resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae45563",
   "metadata": {},
   "source": [
    "## Discussion summary\n",
    "\n",
    "-   Training on test data is okay! ü•≥\n",
    "    -   as observed by¬†[@cdeotte](https://www.kaggle.com/cdeotte)¬†[here](https://www.kaggle.com/competitions/otto-recommender-system/discussion/363939)\n",
    "    -   and confirmed by the organizer¬†[here](https://www.kaggle.com/competitions/otto-recommender-system/discussion/363939)\n",
    "-   How are sessions defined?\n",
    "    -   A session is all activity by a single user either in train or in test\n",
    "    -   confirmed by the organizer¬†[here](https://www.kaggle.com/competitions/otto-recommender-system/discussion/363554#2015486)\n",
    "-   In the beginning, there were issues with the competition metric (someone managed to score ~4.8 on recall on public LBüòÖ)\n",
    "    -   This has now been¬†[corrected](https://www.kaggle.com/competitions/otto-recommender-system/discussion/363772). Thank you,¬†[@inversion](https://www.kaggle.com/inversion)! üôå\n",
    "-   Some good thoughts on the competition¬†[here](https://www.kaggle.com/competitions/otto-recommender-system/discussion/363874)¬†by¬†[@narsil](https://www.kaggle.com/narsil).\n",
    "\n",
    "## Notebooks recap\n",
    "\n",
    "-   The outstanding¬†[co-visitation matrix](https://www.kaggle.com/code/vslaykovsky/co-visitation-matrix)¬†by¬†[@vslaykovsky](https://www.kaggle.com/vslaykovsky)!\n",
    "-   A notebook by¬†[@cdeotte](https://www.kaggle.com/cdeotte)¬†building on the co-visitation matrix üëÜ and demonstrating the power of training on the test data! (maybe training is too strong of a word, rather using the leak in your calculations)\n",
    "-   the last 20 AIDs are very powerful! ([original code](https://www.kaggle.com/code/ttahara/last-aid-20),¬†[simplified without need for chunking](https://www.kaggle.com/code/radek1/last-20-aids)\n",
    "\n",
    "# Resources for getting started\n",
    "\n",
    "-   A¬†[great post](https://www.kaggle.com/competitions/otto-recommender-system/discussion/363624)¬†from¬†[@andradaolteanu](https://www.kaggle.com/andradaolteanu)¬†with a link to Andrew Ng's videos on Recommender Systems\n",
    "\n",
    "### rd: recsys - otto - get started - Andrew Ng videos\n",
    "\n",
    "**Lecture 16.2 ‚Äî Recommender Systems Intro**\n",
    "[00:00](https://youtu.be/giIXNoiqO_U?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=0) - How important recommendation system to the real world?\n",
    "[01:30](https://youtu.be/giIXNoiqO_U?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=90) - Why should we study recommendation system? (Did or do academics pay much attention to it? Can it teach us the power of learning features of ML?)\n",
    "[03:00](https://youtu.be/giIXNoiqO_U?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=180) - Andrew presented the recommendation system problem with a simplest example\n",
    "\n",
    "**Lecture 16.2 ‚Äî Recommender Systems | Content Based Recommendations**\n",
    "[00:00](https://youtu.be/9siFuMMHNIA?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=0) - recap of the problem of recommendation system \n",
    "[00:23](https://youtu.be/9siFuMMHNIA?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=23) - What is content-based recommendation system? How to describe the recommendation system problem in details with symbols (mathematically)? \n",
    "How To predict the rate of any user to any movie, we just need to find out the features of the user and the features of the movie; we need to use the existing ratings of movies by current users to find out the features of current users and current movies\n",
    "[06:12](https://youtu.be/9siFuMMHNIA?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=372) - How to learn the features of a single user by designing a simple loss function?\n",
    "[10:06](https://youtu.be/9siFuMMHNIA?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=606) - How to learn the features of all users by combining all of the losses based on the loss function above?\n",
    "[11:25](https://youtu.be/9siFuMMHNIA?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=685) - How to calculate the derivaties or doing gradient descent on user features?\n",
    "[13:37](https://youtu.be/9siFuMMHNIA?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=817) - Why called content based? using features of movies (contents) to find out features of users and then to make predictions on ratings\n",
    "\n",
    "**Lecture 16.3 ‚Äî Recommender Systems | Collaborative filtering Recommendations Intro**\n",
    "[00:00](https://youtu.be/9AP-DgFBNP4?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=0) - What's special about collaborative filtering compared with content-based recommendation system? It can learn all the features itself without giving features of movies first like content-based approach\n",
    "[00:21](https://youtu.be/9AP-DgFBNP4?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=21) - How to present collaborative filtering in terms of knowing user features and using rating data to find out features of movies and then make predictions on ratings (well, it is a just another content based approach using user features instead of movie features)\n",
    "[04:39](https://youtu.be/9AP-DgFBNP4?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=279) - What is the simplest loss function to help do gradient descent to find out features of all movies\n",
    "[06:56](https://youtu.be/9AP-DgFBNP4?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=416) - Why called collaborative filtering? what are collaborating? (between two content based approaches) why called filtering? What ensures such collaboration can learning possible? (data is good: a movie is rated by multiple users, a user has rated multiple movies)\n",
    "[09:15](https://youtu.be/9AP-DgFBNP4?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=555) - Andrew Ng explained why called collaboration filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f446a74",
   "metadata": {},
   "source": [
    "**Lecture 16.4 ‚Äî Recommender Systems | Collaborative Filtering Algorithm**\n",
    "[00:00](https://youtu.be/YW2b8La2ICo?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=0) - How to combine the loss function of both content-based approaches to do gradient descent on both features of users and movies, instead of finding features of users and then movies sequentially?\n",
    "[04:40](https://youtu.be/YW2b8La2ICo?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=355) - Andrew present the collaborative algorithm in steps\n",
    "\n",
    "**Lecture 16.5 ‚Äî Recommender Systems | Vectorization Low Rank Matrix Factorization**\n",
    "[00:00](https://youtu.be/5R1xOJOFRzs?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=0) - What is low-rank matrix factorization? put all features of all movies into a matrix, all features of all users into a matrix and put all rating prediction as a dot product of two matricies\n",
    "[05:07](https://youtu.be/5R1xOJOFRzs?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&t=307) - How can collaborative filtering enable recommendations of similar movies to a user? As it finds out all the features of all movies, we can compare the similarity of movie feature vectors to find out similar movies\n",
    "\n",
    "-   [Getting started resources](https://www.kaggle.com/competitions/otto-recommender-system/discussion/363814)¬†from yours truly, among other things a link to a legendary lecture by Xavier Amatriain of Netflix fame\n",
    "-   [Transformers4Rec](https://www.kaggle.com/competitions/otto-recommender-system/discussion/363980)¬†by NVIDIA, deep learning session-based recommendation models, as recommended by¬†[@snnclsr](https://www.kaggle.com/snnclsr)! üöÄ\n",
    "-   [A post on RecBole](https://www.kaggle.com/competitions/otto-recommender-system/discussion/363603), a very interesting looking Recommendation Model library implemented in PyTorch üî•(thanks¬†[@hidehisaarai1213](https://www.kaggle.com/hidehisaarai1213))\n",
    "\n",
    "üí° Also, do note that there is¬†[a repo on GitHub](https://github.com/otto-de/recsys-dataset)¬†under which the data for this competition has been shared. It contains preprocessing code and information beyond what is available on Kaggle in the competition tabs (you can find most if not all of it in the discussions though that I link to above)!\n",
    "\n",
    "The competition is shaping up really nicely and I am super excited about it! ü•≥\n",
    "\n",
    "- [ ] Thanks so much for all the hard work and the amazing resources that so many people have shared! üôè\n",
    "\n",
    "### jn: Why start to try Kaggle Recommendation competition OTTO now /2022-11-7\n",
    "Radek is doing it now, it's a great opportunity to try out his method and makes him my mentor without asking\n",
    "\n",
    "Also it is a great test to see whether I can follow this method and learn something my inner self believe not possible\n",
    "\n",
    "I can always come back to paddy and other finished competitions as they are done and notebooks are there always.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
